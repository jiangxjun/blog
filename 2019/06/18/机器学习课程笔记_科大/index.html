<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/blog/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/blog/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/blog/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/blog/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/blog/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon32.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon16.png?v=5.1.4">


  <link rel="mask-icon" href="/blog/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,">





  <link rel="alternate" href="/blog/atom.xml" title="Ataraxia" type="application/atom+xml">






<meta name="description" content="机器学习基础课程笔记">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记_科大">
<meta property="og:url" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/index.html">
<meta property="og:site_name" content="Ataraxia">
<meta property="og:description" content="机器学习基础课程笔记">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/machine-learning-process.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/9.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/14200239_f81W.jpg">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/14200246_clMw.jpg">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/12.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/13.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/14.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/15.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/16.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/17.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/18.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/公式1.PNG">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/公式2.PNG">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/矩阵1.PNG">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/解1.PNG">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/解2.PNG">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/解3.PNG">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/19.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/自相关矩阵.PNG">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/1.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/2.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/3.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/4.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/5.jpg">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/6.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/7.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/8.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/10.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/20.jpg">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/21.jpg">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/1554814626931.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/1554815556746.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/1554816215904.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/1554816600696.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/11.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/22.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/23.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/24.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/25.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/26.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/27.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/28.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/29.gif">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/30.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/31.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/32.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/34.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/35.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/33.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/36.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/37.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/38.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/42.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/43.jpg">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/40.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/39.png">
<meta property="og:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/41.png">
<meta property="og:updated_time" content="2020-07-08T08:19:52.176Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习笔记_科大">
<meta name="twitter:description" content="机器学习基础课程笔记">
<meta name="twitter:image" content="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/machine-learning-process.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/blog/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://jiangxj.top/blog/2019/06/18/机器学习课程笔记_科大/">





  <title>机器学习笔记_科大 | Ataraxia</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/blog/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ataraxia</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Hi, I'm Jiang.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/blog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/blog/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/blog/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/blog/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/blog/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.css">
<script src="https://cdn.jsdelivr.net/npm/aplayer@1.7.0/dist/APlayer.min.js"></script> </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jiangxj.top/blog/blog/2019/06/18/机器学习课程笔记_科大/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jiangxj">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/blog/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ataraxia">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习笔记_科大</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-18T00:00:00+08:00">
                2019-06-18
              </time>
            
			
			

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/笔记/" itemprop="url" rel="index">
                    <span itemprop="name">笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  61.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  257
                </span>
              
            </div>
          

          
              <div class="post-description">
                  机器学习基础课程笔记
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>What is machine learning and does it matter?</p>
<p>Learning can be explained as a process which <strong>improves performances from experience</strong>（经验）, an extension(延伸，拓展) to this definition would be, the process of  ML which can be explained or defined, as a  method through which computer programs, that habitually （习惯地，惯常地）or spontaneously（自然地，自发地，不由自主地） improve their performance through experience.</p>
<p>This would basically translate into machine’s learning to improve their performance based on limited programming interventions(干涉，介入). ML can be considered as an extension to AI ,which believes that machines should be able to adapt and learn through experience.</p>
<p>ML is not  a new innovation and has been around for years ,however with new computing technologies, ML has evolved, most of the algorithms have been around, however ,the ability to <strong>apply complex algorithms to big data ,in a loop and more rapidly</strong>, is a recent development.</p>
<p>ML is quite integrated in our everyday lives, so much that we might not be consciously aware how frequently we are using the application.  For example ,there is  great  excitement over google’s self drive car, a product of ML. Spam emails being diligently dumped away, or frequent recommendations while shopping online, or offers from particular brands(扔掉) of your  interest being brought to your notice, are all direct outcomes of Machine Learning.</p>
<p>Besides the basic applications, more recent complex uses of ML would be early <em>fraud (欺诈)detection in banking</em>, a lot of businesses are able to have a consolidated（巩固，加强） look at what their customers feel about them, emotional and sentimental analysis is possible through data mining（数据挖掘） techniques, again a direct product of ML.</p>
<p>In current times ML matters, for the possiblities and advantages it offers. There are growing volumes(卷，册，容量，体积) of data available to us easily, computational processing is cost effective, and we have better data storage opportunities, all this indicates that we are right in the center of exciting times, where, we will be able to analyse bigger and complex data faster and more accurately. Which directly means that organisations will have a better vantage（优势，有利地位） point to make informed decisions, leading to better profits and avoiding risks.</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/machine-learning-process.png" title="machine learning process">
<p>with a good investment of time in creating training data for machines, learning can then be expedited through experienced  and learning through algorithms. Implementation and automation then become easy for machines, upon learning, a machine can process several images without any fatigue as oppased to human brain, which might deliver data with errors.</p>
<p>With good training data input and intelligent processing, with an accurate algorithm, the output can be phenomenal(非凡的). Hence（因此） it is believed that big data and ML is a great combination, opening doors to various opportunities.</p>
<p>Application of algorithms in building models may expose links which can help an entity(实体，独立存在体) make better decisions with minimal human interventions（人为干预）, keeping biases（偏见，偏置） away.</p>
<p>Most organizations in recent times have understood the importance, benefits and value of Machine Learning technology, as most insights from the avaliable data can be received in real time, hence giving companies an edge over their competitors, and assisting them in better aligning（满足，匹配，使结盟，使成一行） their needs with those of their customers.</p>
<p>Due to these paybacks, application of ML can be seen in Financial services, Healthcare , Marketing and Sales, Transportation and logistics（后勤，符号逻辑）, Goverment agencies like Utilities（公共事业，公用工程） and Publics Safety.</p>
<p>So while machine learning has many advantages ,it has  a few challenges, however, the benefits of the application outweigh the limitations（超过限制）, The ability to decipher（破译，辨认） big data, with  minimal programming, faster and accurate results in real time ,will see ML be applied in various aspects of our daily lives.</p>
<p>汤姆米切尔（Mitchell）:</p>
<p>对于某一类任务T和性能度量P，如果一个计算机程序在某些任务T 上以P度量的性能随着经验E的增加而提高，那么称这个计算机程序是重经验E中学习[1]。</p>
<blockquote>
<p>[1] Machine Learning, Tom Mitchell, McGraw Hill, 1997.</p>
<p><a href="http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html</a></p>
</blockquote>
<p>伊恩·古德费罗（Ian Goodfellow）、约舒亚·本吉奥（Yoshua Bengio）和亚伦·库尔维尔（Aaron Courville）:</p>
<p>机器学习本质上属于应用统计学，更多的关注如何利用计算机对复杂函数进行统计估计，而不太关注如何估算这些函数的置信区间 [2]</p>
<blockquote>
<p>[2] Deep Learning, Ian Goodfellow, Yoshua Bengio &amp; Aaron Courville, MIT Press, 2016.</p>
<p><a href="https://www.deeplearningbook.org/" target="_blank" rel="noopener">https://www.deeplearningbook.org/</a></p>
</blockquote>
<p>伊恩·威腾（Ian Witten）、埃贝·弗兰克（Eibe Frank）和马克·霍尔（Mark Hall）：</p>
<p>我们感兴趣的是在新情境下性能的替身或者是性能提升的潜力。</p>
<p>当以一种可以使自身在未来表现更好的方式改变自己的行为时，就是在学习。</p>
<p>学习意味着思考和目标，必须有目标地去学习。</p>
<p>经验表明，在机器学习和数据挖掘的许多应用中，获得清晰的知识结构，即结构化描述，以及在新实例预测中表现良好的能力，通常使用数据挖掘来获取知识，而不是仅仅用来预测[3]。</p>
<blockquote>
<p>[3] Data Mining: Practical Machine Learning Tools and Techniques (3rd ed.), Ian Witten, Eibe Frank &amp; Mark Hall, Morgan Kaufmann, 2011.（很少涉及数学，多实用性解释，去除数据挖掘部分，适用机器学习）</p>
<p><a href="https://www.cs.waikato.ac.nz/ml/weka/book.html" target="_blank" rel="noopener">https://www.cs.waikato.ac.nz/ml/weka/book.html</a></p>
</blockquote>
<p>克里斯托弗·毕肖普（Christopher Bishop）：</p>
<p>以算法为中心，间接定义机器学习。</p>
<p>机器学习算法的结果可以表示为一个函数y(x)，输入新的数字图像x，产生向量y，用同样的方法编码来作为目标向量。</p>
<p>在训练阶段（即学习阶段），根据训练数据确定y(x)精确的形式。</p>
<p>一旦训练完成模型，就可以用它来确认测试集中新数字图像的类别，正确分类新数字图像的能力被称为<strong>泛化</strong>，这些新数字图像不同于训练时的数字图像。</p>
<p>在实际应用中，输入向量的多样性使得训练数据只能包含所有可能输入向量的一小部分，因此<strong>泛化是模式识别的核心目标</strong>[4]。</p>
<blockquote>
<p>[4] Pattern Recognition and Machine Learning, Christopher M. Bishop, Springer, 2006.</p>
<p><a href="https://www.springer.com/gp/book/9780387310732" target="_blank" rel="noopener">https://www.springer.com/gp/book/9780387310732</a></p>
</blockquote>
<p><a href="/download/吴恩达机器学习笔记.pdf">吴恩达机器学习笔记</a></p>
<h1 id="机器学习的几种定义"><a href="#机器学习的几种定义" class="headerlink" title="机器学习的几种定义"></a>机器学习的几种定义</h1><p>这里有四种机器学习定义的方法：</p>
<ul>
<li>根据优化过程，抽象定义机器学习</li>
<li>更具规范性的定义，指出计算力在机器学习中的重要性</li>
<li>关注“学习”哪些方面在机器学习过程中是相似的和重要的</li>
<li>从算法角度概述机器学习</li>
</ul>
<p>都不是完整的，但便于我们自己对机器学习的定义的扩展。</p>
<h1 id="机器学习中的数学基础"><a href="#机器学习中的数学基础" class="headerlink" title="机器学习中的数学基础"></a>机器学习中的数学基础</h1><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>假设一个函数$J(w)$，如下图：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/9.png" title="梯度下降法示意图">
<p>要求得当$w$为何值时，$J(w)$能够取得最小值。初始位置的切线的斜率为$a&gt;0$（即该点导数大于0），$w=w-a$能使得让$w$的值减小，循环求导更新$w$直到$J(w)$取得最小值。如果函数$J(w)$包含多个变量，需要分别对不同的变量求偏导来更新不同变量的值。</p>
<h2 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h2><p>即复合函数求导</p>
<p>$f’[g(x)] = f’[g(x)]g’(x)$</p>
<h2 id="常用距离度量方法"><a href="#常用距离度量方法" class="headerlink" title="常用距离度量方法"></a>常用距离度量方法</h2><h3 id="欧式距离（Euclidean-distance）"><a href="#欧式距离（Euclidean-distance）" class="headerlink" title="欧式距离（Euclidean distance）"></a>欧式距离（Euclidean distance）</h3><img src="/blog/2019/06/18/机器学习课程笔记_科大/14200239_f81W.jpg" title="欧式距离">
<ul>
<li>二维平面上点$a(x_1,y_1),b(x_2,y_2)$间的欧式距离为：</li>
</ul>
<p>​     $d_{12} = \sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$。</p>
<ul>
<li><p>n维度空间点$a(x_{11},x_{12},…,x_{1n}),b(x_{21},x_{22},…,x_{2n})$间的欧式距离为：</p>
<p>$d_{12}= \sqrt{\sum_{k=1}^n(x_{1k}-x_{2k})^2}$。</p>
</li>
</ul>
<p>二维空间欧式距离python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclidean2</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    distance = sqrt( (a[<span class="number">0</span>]-b[<span class="number">0</span>])**<span class="number">2</span>+ (a[<span class="number">1</span>]-b[<span class="number">1</span>])**<span class="number">2</span> )</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line">print(<span class="string">'a,b两点之间的欧式距离为：'</span>，euclidean2((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>)))</span><br></pre></td></tr></table></figure>
<p>三维空间欧式距离实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclidean3</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    distance = sqrt( (a[<span class="number">0</span>]-b[<span class="number">0</span>])**<span class="number">2</span>+ (a[<span class="number">1</span>]-b[<span class="number">1</span>])**<span class="number">2</span> +(a[<span class="number">2</span>]-b[<span class="number">2</span>])**<span class="number">2</span> )</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line">print(<span class="string">'a,b两点之间的欧式距离为：'</span>，euclidean3((<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)))</span><br></pre></td></tr></table></figure>
<p>多维空间的欧式距离实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclideann</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    sum =<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)):</span><br><span class="line">        sun+=(a[i]-b[i])**<span class="number">2</span></span><br><span class="line">    distance = np.sqrt(sum)</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line">print(<span class="string">'a,b两点之间的欧式距离为：'</span>，euclideann((<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclieann2</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    A = np.array(a)</span><br><span class="line">    B = np.array(b)</span><br><span class="line">    C = (A-B)**<span class="number">2</span></span><br><span class="line">    distance = np.sqrt(sum(c))</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line">print(<span class="string">'a,b两点之间的欧式距离为：'</span>，euclidean2((<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="标准化欧式距离（standardized-Euclidean-distance）"><a href="#标准化欧式距离（standardized-Euclidean-distance）" class="headerlink" title="标准化欧式距离（standardized Euclidean distance）"></a>标准化欧式距离（standardized Euclidean distance）</h3><p>​    针对欧式距离的缺点做的一种改进。</p>
<p>​    标准欧式距离思路：既然数据各维分量的分布不一样，那先将各个分量都“标准化”到均值、方差等。假设样本集X的均值（mean）为m ,标准差（standard deviation）为s。</p>
<ul>
<li><p>X的“标准化变量”表示为：</p>
<p>$X^* = \frac {X-m}s$。</p>
</li>
<li><p>标准化欧式距离公式为：</p>
<p>$d_{12} = \sqrt{\sum_{k=1}^n (\frac {x_{1k}-x_{2k}}{s_k})^2}$。</p>
<p>如果将方差的倒数看成一个权重，也称为<strong>加权欧式距离</strong>(weighted Euclidean distance)。</p>
</li>
</ul>
<p>标准化欧式距离实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclideans</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    sumnum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)):</span><br><span class="line">        avg = (a[i] - b[i]) / <span class="number">2</span></span><br><span class="line">        si = np.sqrt( (a[i]-avg)**<span class="number">2</span> + (b[i] - avg)**<span class="number">2</span> )</span><br><span class="line">        sumnum += ((a[i]-b[i]) /si)**<span class="number">2</span></span><br><span class="line">    distance = np.sqrt(sumnum)</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line">print(<span class="string">'a,b两点之间的标准化欧式距离为：'</span>，euclideans((<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="曼哈顿距离（Manhattan-distance）"><a href="#曼哈顿距离（Manhattan-distance）" class="headerlink" title="曼哈顿距离（Manhattan distance）"></a>曼哈顿距离（Manhattan distance）</h3><p>​     “驾驶距离”不是两点间的直线距离， 也称为“城市街区距离（city block distance）”</p>
<ul>
<li><p>二维平面上点$a(x_1,y_1),b(x_2,y_2)$间的曼哈顿距离为：</p>
<p>$d_{12}=|x_1-x_2| + |y_1-y_2|$。</p>
</li>
<li><p>n维度空间点$a(x_{11},x_{12},…,x_{1n}),b(x_{21},x_{22},…,x_{2n})$间的曼哈顿距离为：</p>
<p>$d_{12} = \sum_{k=1}^n |x_{1k}-x_{2k}|$。</p>
</li>
</ul>
<p>二维空间曼哈顿距离实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">manhattan2</span><span class="params">(a,b)</span>:</span></span><br><span class="line">    distance = np.abs(a[<span class="number">0</span>]-b[<span class="number">0</span>])+np.abs(a[<span class="number">1</span>]-b[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line">print(<span class="string">'二维空间a,b两点之间的曼哈顿距离为：'</span>，manhattan((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>)))</span><br></pre></td></tr></table></figure>
<p>多维空间曼哈顿距离的实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">manhattann</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    n维空间曼哈顿距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    distance = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)):</span><br><span class="line">        distance += np.abs(a[i]-b[i])</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'n维空间a, b两点之间的曼哈顿距离为： '</span>, manhattann((<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>)))</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">manhattann2</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    n维空间曼哈顿距离, 不使用循环</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    A = np.array(a)</span><br><span class="line">    B = np.array(b)</span><br><span class="line">    distance = sum(np.abs(A-B))</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'n维空间a, b两点之间的曼哈顿距离为： '</span>, manhattann2((<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="切比雪夫距离（chebyshev-distance）"><a href="#切比雪夫距离（chebyshev-distance）" class="headerlink" title="切比雪夫距离（chebyshev distance）"></a>切比雪夫距离（chebyshev distance）</h3><p>​    国际象棋中，国王可以直行、横行、斜行，所以这个国王走一步可以移动到相邻的8个方格任意一个，国王从格子$(x_1,y_1)$走到格子$(x_2,y_2)$最少需要走多少步，这个距离称为切比雪夫距离。</p>
<ul>
<li><p>二维平面上点$a(x_1,y_1),b(x_2,y_2)$间的切比雪夫距离为：</p>
<p>$d_{12}=max(|x_1-x_2| + |y_1-y_2|)$。</p>
</li>
<li><p>n维度空间点$a(x_{11},x_{12},…,x_{1n}),b(x_{21},x_{22},…,x_{2n})$间的切比雪夫距离为：</p>
<p>$d_{12}=\underset{i}max(|x_{1i}-x_{2i}| )$。</p>
<p>该公式等价于：</p>
<p>$d_{12}=\lim\limits_{k\rightarrow\infty}(\sum_{i=1}^{n}\left|x_{1i}-x_{2i}\right|^k)^{\frac{1}{k}}$</p>
</li>
</ul>
<p>二维切比雪夫距离实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chebyshev2</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    二维空间切比雪夫距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    distance = max(abs(a[<span class="number">0</span>]-b[<span class="number">0</span>]), abs(a[<span class="number">1</span>]-b[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'二维空间a, b两点之间的欧式距离为： '</span>, chebyshev2((<span class="number">1</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<p>多维切比雪夫距离实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chebyshevn</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    n维空间切比雪夫距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    distance = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)):</span><br><span class="line">        <span class="keyword">if</span> (abs(a[i]-b[i]) &gt; distance):</span><br><span class="line">            distance = abs(a[i]-b[i])</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'n维空间a, b两点之间的切比雪夫距离为：'</span> , chebyshevn((<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>),(<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>)))</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chebyshevn2</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    n维空间切比雪夫距离, 不使用循环</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    distance = <span class="number">0</span></span><br><span class="line">    A = np.array(a)</span><br><span class="line">    B = np.array(b)</span><br><span class="line">    distance = max(abs(A-B))</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> (<span class="string">'n维空间a, b两点之间的切比雪夫距离为：'</span> , chebyshevn2((<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>),(<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="闵科夫斯基距离（minkowski-distance）"><a href="#闵科夫斯基距离（minkowski-distance）" class="headerlink" title="闵科夫斯基距离（minkowski distance）"></a>闵科夫斯基距离（minkowski distance）</h3><p>​    闵氏距离不是一种距离，而是一组距离的定义，是对多个距离公式的概括性的表述。</p>
<ul>
<li><p>闵氏距离定义：</p>
</li>
<li><p>两个n维度空间点$a(x_{11},x_{12},…,x_{1n}),b(x_{21},x_{22},…,x_{2n})$间的闵氏距离定义为：</p>
<p>$d_{12} = \sqrt[\uproot{10}\leftroot{-2}p]{\sum_{k=1}^n |x_{1k}-x_{2k}|^p}$。</p>
<p>其中p是一个参数：</p>
<ul>
<li>当$p=1$时，曼哈顿距离</li>
<li>当$p=2$时，欧式距离</li>
<li>当$p \to \infty$时，切比雪夫距离</li>
</ul>
<p>因此，根据参数不同，闵氏距离可以表示为某一类/种距离。但是存在缺点：</p>
<ul>
<li>将各个分量的量纲（scale），即“单位”相同看待</li>
<li>未考虑各个分量的分布（期望、方差等）可能是不同的</li>
</ul>
</li>
</ul>
<p>python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minkowski</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    闵可夫斯基距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    A = np.array(a)</span><br><span class="line">    B = np.array(b)</span><br><span class="line">    <span class="comment">#方法一：根据公式求解</span></span><br><span class="line">    distance1 = np.sqrt(np.sum(np.square(A-B)))</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#方法二：根据scipy库求解</span></span><br><span class="line">    <span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> pdist</span><br><span class="line">    X = np.vstack([A,B])</span><br><span class="line">    distance2 = pdist(X)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> distance1, distance2</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'二维空间a, b两点之间的闵可夫斯基距离为：'</span> , minkowski((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>))[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h3 id="马氏距离（mahalanobis-distance）"><a href="#马氏距离（mahalanobis-distance）" class="headerlink" title="马氏距离（mahalanobis distance）"></a>马氏距离（mahalanobis distance）</h3><p>​    概念：马氏距离是基于样本分布的一种距离。</p>
<p>​    物理意义：在规范化的主成分空间种的欧式距离。</p>
<p>​     规范化的主成分空间就是利用主成分分析对一些数据进行主成分分解。在对所有的主成分分解轴做归一化，形成新的坐标轴。由这些坐标轴张成的空间就是规范化的主成分空间。【马氏距离椭圆图】</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/14200246_clMw.jpg" title="马氏距离">
<p>​       定义：有M个样本向量$X_1-X_m$，协方差矩阵记为S，均值记为向量$\mu$,则：</p>
<ul>
<li>其中的样本向量$X$到$\mu$的马氏距离表示为：</li>
</ul>
<p>​         $D(X) = \sqrt{(X-\mu)^TS^{-1}(X-\mu)}$。</p>
<ul>
<li>向量$X_i$与$X_j$之间的马氏距离定义为：</li>
</ul>
<p>​         $D(X_i,X_j) = \sqrt{(X_i-X_j)^TS^{-1}(X_i-X_j)}$。</p>
<ul>
<li>若协方差矩阵是单位阵（各个样本向量之间独立同分布），则$X_i$与$X_j$之间的马氏距离等于他们之间的欧式距离：</li>
</ul>
<p>​          $D(X_i,X_j) = \sqrt{(X_i-X_j)^T(X_i-X_j)}$。</p>
<ul>
<li>若协方差矩阵式对角矩阵，则是标准化欧式距离。</li>
</ul>
<p>马氏距离特点：</p>
<ul>
<li><p>量纲无关，排除变量之间的相关性干扰</p>
</li>
<li><p>马氏距离的计算是建立在总体样本的基础上的，如果拿同样的两个样本，放入两个不同的总体中，最后计算得出的两个样本间的马氏距离通常是不相同的，排除这两个总体的协方差矩阵也相同。</p>
</li>
<li><p>计算马氏距离过程中，要求总体的样本数大于样本的维数，否则得到的总体样本协方差矩阵逆矩阵不存在，这种情况，用欧式距离计算即可。</p>
<p>python实现：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mahalanobis</span> <span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    马氏距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    A = np.array(a)</span><br><span class="line">    B = np.array(b)</span><br><span class="line">    <span class="comment">#马氏距离要求样本数要大于维数，否则无法求协方差矩阵</span></span><br><span class="line">    <span class="comment">#此处进行转置，表示10个样本，每个样本2维</span></span><br><span class="line">    X = np.vstack([A,B])</span><br><span class="line">    XT = X.T</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#方法一：根据公式求解</span></span><br><span class="line">    S = np.cov(X)   <span class="comment">#两个维度之间协方差矩阵</span></span><br><span class="line">    SI = np.linalg.inv(S) <span class="comment">#协方差矩阵的逆矩阵</span></span><br><span class="line">    <span class="comment">#马氏距离计算两个样本之间的距离，此处共有10个样本，两两组合，共有45个距离。</span></span><br><span class="line">    n = XT.shape[<span class="number">0</span>]</span><br><span class="line">    distance1 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, n):</span><br><span class="line">            delta = XT[i] - XT[j]</span><br><span class="line">            d = np.sqrt(np.dot(np.dot(delta,SI),delta.T))</span><br><span class="line">            distance1.append(d)</span><br><span class="line"> </span><br><span class="line">    <span class="comment">#方法二：根据scipy库求解</span></span><br><span class="line">    <span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> pdist</span><br><span class="line">    distance2 = pdist(XT,<span class="string">'mahalanobis'</span>)</span><br><span class="line">    <span class="keyword">return</span>  distance1, distance2</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'(1, 2)，(1, 3)，(2, 2)，(3, 1)两两之间的闵可夫斯基距离为：'</span> , mahalanobis((<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>),(<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>))[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>​      </p>
<h3 id="余弦距离（cosine-distance"><a href="#余弦距离（cosine-distance" class="headerlink" title="余弦距离（cosine distance)"></a>余弦距离（cosine distance)</h3><p>夹角余弦用于衡量两个向量方向的差异，机器学习中，借用此来衡量样本向量之间的差异。</p>
<p>二维空间上向量$A(x_1,y_1),B(x_2,y_2)$间的夹角余弦公式为：</p>
<p>$\cos \theta = \frac{x_1x_2+y_1y_2}{\sqrt{x_1^2+y_1^2}\sqrt{x_2^2+y_2^2}}$</p>
<p>两个n维度样本点$a(x_{11},x_{12},\dots,x_{1n}),b(x_{21},x_{22},\dots,x_{2n})$间的夹角余弦为：</p>
<p>$\cos \theta=\frac{a \cdot b}{|a||b|}$</p>
<p> 即：</p>
<p>$\cos \theta = \frac{\sum_{k=1}^n x_{1k} x_{2k}}  {\sqrt{\sum_{k=1}^n {x_{1k}}^2}     \sqrt{\sum_{k=1}^n {x_{2k}}^2}}$。</p>
<p>夹角余弦取值范围为$[-1,1]$。余弦越大表示两个向量的夹角越小，余弦越小，夹角越大。当两个向量的方向重合时余弦取最大值1，当两个向量的方向完全相反取余弦最小值-1。</p>
<p>二维空间夹角余弦python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cos2</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    cos = (a[<span class="number">0</span>]*b[<span class="number">0</span>] + a[<span class="number">1</span>]*b[<span class="number">1</span>]) / (np.sqrt(a[<span class="number">0</span>]**<span class="number">2</span> + a[<span class="number">1</span>]**<span class="number">2</span>) * np.sqrt(b[<span class="number">0</span>]**<span class="number">2</span>+b[<span class="number">1</span>]**<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> cos</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a,b 二维夹角余弦距离：'</span>,cos2((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>)))</span><br></pre></td></tr></table></figure>
<p>多维空间向量的夹角余弦python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosn</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    n维夹角余弦</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    sum1 = sum2 = sum3 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)):</span><br><span class="line">        sum1 += a[i] * b[i]</span><br><span class="line">        sum2 += a[i] ** <span class="number">2</span></span><br><span class="line">        sum3 += b[i] ** <span class="number">2</span></span><br><span class="line">    cos = sum1 / (np.sqrt(sum2) * np.sqrt(sum3))</span><br><span class="line">    <span class="keyword">return</span> cos</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a,b 多维夹角余弦距离：'</span>,cosn((<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cosn2</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    n维夹角余弦, 不使用循环</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    A, B = np.array(a), np.array(b)</span><br><span class="line">    sum1 = sum(A * B)</span><br><span class="line">    sum2 = np.sqrt(np.sum(A**<span class="number">2</span>))</span><br><span class="line">    sum3 = np.sqrt(np.sum(B**<span class="number">2</span>))</span><br><span class="line">    cos = sum1 / (sum2 * sum3)</span><br><span class="line">    <span class="keyword">return</span> cos</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a,b 多维夹角余弦距离：'</span>,cosn2((<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="汉明距离（hamming-distance）"><a href="#汉明距离（hamming-distance）" class="headerlink" title="汉明距离（hamming distance）"></a>汉明距离（hamming distance）</h3><p>​    定义：两个等长的字符串s1与s2的汉明距离为：将其中一个变为另外一个所需要作的最小字符替换次数。</p>
<blockquote>
<p>the hamming distance between “1011101” and “1001001” is 2</p>
<p>the hamming distance between “2143896” and “2233796” is 3</p>
</blockquote>
<p>​    汉明重量：是字符串相对于同样长度的零字符串的汉明距离，即，它是字符串中非零的元素个数。对于二进制数字符串来说，就是1的个数。即11101的汉明重量为4。因此，向量空间中的元素a和b之间的汉明距离等于它们的汉明重量的差a-b。</p>
<p>​    应用：信息论、编码理论、密码学等领域都有应用。如在信息编码过程中，<strong>为了增强容错性，应使得编码间的最小汉明距离尽可能大</strong>。但是，如果比较两个不同长度的字符串，不仅要进行替换，而且要进行插入与删除的运算，这种情况下，通常使用更加复杂的编辑距离等算法。</p>
<p>python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hamming</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    汉明距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    sumnum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(a)):</span><br><span class="line">        <span class="keyword">if</span> a[i]!=b[i]:</span><br><span class="line">            sumnum += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> sumnum</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a,b 汉明距离：'</span>,hamming((<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)))</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hamming2</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    汉明距离, 不使用循环</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    matV = np.array(a) - np.array(b)</span><br><span class="line">    numsum = len(np.nonzero(matV)[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> numsum</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a,b 汉明距离：'</span>,hamming2((<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="杰卡德距离（Jaccard-distance）"><a href="#杰卡德距离（Jaccard-distance）" class="headerlink" title="杰卡德距离（Jaccard distance）"></a>杰卡德距离（Jaccard distance）</h3><p>​    杰卡德相似系数（jaccard similarity coeffcient）:两个集合A和B的交集元素在A、B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示。</p>
<p>​    $J(A,B) = \frac{|A∩B|}{|A∪B|}$。</p>
<p>杰卡德相似系数python实现;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">jaccard_coefficient</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    杰卡德相似系数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    set_a = set(a)</span><br><span class="line">    set_b = set(b)</span><br><span class="line">    distance = float(len(set_a &amp; set_b)) / len(set_a | set_b)</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a,b 杰卡德相似系数：'</span>, jaccard_coefficient((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<p>   杰卡德距离：与杰卡德相似系数相反，用两个集合中<strong>不同元素</strong>所占元素的比例来衡量两个集合的区分度：</p>
<p>$J_\delta(A,B) = 1- J(A,B) = \frac{|A∪B|-|A∩B|}{|A∪B|} $。</p>
<p>杰卡德距离python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">jaccard_distance</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    杰卡德距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    set_a = set(a)</span><br><span class="line">    set_b = set(b)</span><br><span class="line">    distance = float(len(set_a | set_b) - len(set_a &amp; set_b)) / len(set_a | set_b)</span><br><span class="line">    <span class="keyword">return</span> distance</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'a,b 杰卡德距离：'</span>, jaccard_coefficient((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure>
<p>杰卡德相似系数与杰卡德距离的应用：</p>
<p>杰卡德相似系数可以用在衡量样本的相似度上。</p>
<p>样本A和样本B是两个n维向量，而且所有维度的取值都是0或1。将样本看成一个集合，1表示集合包含该元素，0表示集合不包含该元素。</p>
<p>p: 样本A与B都是1的维度的个数</p>
<p>q: 样本A是1，样本B是0的维度的个数</p>
<p>r: 样本A是0，样本B是1的维度的个数</p>
<p>s: 样本A与B都是0的维度的个数</p>
<p>$p+q+r$可以理解为A与B的并集的元素的个数，$p$是A与B的交集的元素的个数。</p>
<p>则样本A与B的杰卡德相似系数可以表示为：$J(A,B) = \frac{p} {p+q+r}$</p>
<p>样本A与B的杰卡德距离表示为：$1-J(A,B) = \frac{q+r} {p+q+r}$</p>
<h3 id="相关距离（correlation-distance）"><a href="#相关距离（correlation-distance）" class="headerlink" title="相关距离（correlation distance）"></a>相关距离（correlation distance）</h3><p>​      <strong>相关系数(correlation coefficient)</strong>：衡量随机变量X与Y相关程度的一种方法，相关系数的取值范围是[-1,1]。相关系数的绝对值越大，则表明X与Y的相关度越高。当X与Y线性相关时，相关系数为1（正线性相关）或-1（负线性相关）。</p>
<p>​      $\large \rho_{XY} = \frac{Cov(X,Y)}{\sqrt{D(X)}{\sqrt{D(Y)}}}  =   \frac{E(X-EX)(Y-EY)}{\sqrt{D(X)}{\sqrt{D(Y)}}} $。</p>
<p>​      相关距离：</p>
<p>​       $D_{xy} = 1- \large \rho_{XY} $。</p>
<p>相关系数的python实现：</p>
<p>可以利用numpy库中的corrcoef函数来计算，例如：对于矩阵$\rm a,numpy.corrcoef(a)$可计算行与行之间的相关系数，$\rm numpy.corrcoef(a,rowvar =0)$用于计算各列之间的相关系数，输出为相关系数矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">correlation_coefficient</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    相关系数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    a = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'a的行之间相关系数为： '</span>, np.corrcoef(a))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'a的列之间相关系数为： '</span>, np.corrcoef(a,rowvar=<span class="number">0</span>))</span><br><span class="line">correlation_coefficient()</span><br></pre></td></tr></table></figure>
<p>相关距离的python实现（基于相关系数）：</p>
<p>同样对于矩阵a</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">correlation_distance</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    相关距离</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    a = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'a的行之间相关距离为： '</span>, np.ones(np.shape(np.corrcoef(a)),int) - np.corrcoef(a))</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'a的列之间相关距离为： '</span>, np.ones(np.shape(np.corrcoef(a,rowvar = <span class="number">0</span>)),int) - np.corrcoef(a,rowvar = <span class="number">0</span>))</span><br><span class="line">correlation_distance()</span><br></pre></td></tr></table></figure>
<h3 id="信息熵（Information-Entropy）"><a href="#信息熵（Information-Entropy）" class="headerlink" title="信息熵（Information Entropy）"></a>信息熵（Information Entropy）</h3><p>​      以上的距离度量方法度量的都是两个样本（向量）之间的距离，<strong>信息熵描述的时整个系统内部样本之间的一个距离</strong>，或者称之为系统内样本分布的集中程度（一致程度）、分散程度、混乱程度（不一致程度）。系统内样本分布越分散（或者说分布越平均），信息熵越大。分布越有序（或者说分布越集中），信息熵越小。</p>
<p>​      计算给定样本集X的信息熵公式：</p>
<p>​       $Entropy(X) = \sum_{i=1}^n  \large-p_i  log_{\small2}    \large p_i$。</p>
<p>​      参数的含义：</p>
<p>​       $n$:样本集X的分类数</p>
<p>​       $p_i$:X中的第i类元素出现的概率</p>
<ul>
<li>​    信息熵越大表明样本集S的分布越分散（分布均衡），信息熵越小则表明样本集X的分布越集中（分布不均衡）。</li>
<li>​    当S中的n个分类出现的概率一样大时（都是$\frac1n$）,信息熵取最大值$log_2 \large n$。</li>
<li>​    当X只有一个分类时，信息熵取得最小值0。</li>
</ul>
<p>python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_entropy</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    计算信息熵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    x_value_list = set([x[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">0</span>])])</span><br><span class="line">    ent = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> x_value <span class="keyword">in</span> x_value_list:</span><br><span class="line">        p = float(x[x == x_value].shape[<span class="number">0</span>]) / x.shape[<span class="number">0</span>]</span><br><span class="line">        logp = np.log2(p)</span><br><span class="line">        ent -= p * logp</span><br><span class="line">    <span class="keyword">return</span> ent</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_condition_entropy</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    计算条件信息熵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># calc ent(y|x)</span></span><br><span class="line">    x_value_list = set([x[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">0</span>])])</span><br><span class="line">    ent = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> x_value <span class="keyword">in</span> x_value_list:</span><br><span class="line">        sub_y = y[x == x_value]</span><br><span class="line">        temp_ent = calc_entropy(sub_y)</span><br><span class="line">        ent += (float(sub_y.shape[<span class="number">0</span>]) / y.shape[<span class="number">0</span>]) * temp_ent</span><br><span class="line">    <span class="keyword">return</span> ent</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_entropy_grap</span><span class="params">(x,y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    计算信息增益</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"> </span><br><span class="line">    base_ent = calc_entropy(y)</span><br><span class="line">    condition_ent = calc_condition_entropy(x, y)</span><br><span class="line">    ent_grap = base_ent - condition_ent</span><br><span class="line">    <span class="keyword">return</span> ent_grap</span><br></pre></td></tr></table></figure>
<p><a href="https://jiangxj.top/2019/05/07/机器学习的数学基础/">具体涉及到数学知识参考此条笔记</a></p>
<h1 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h1><blockquote>
<p>参考周志华《机器学习》</p>
</blockquote>
<hr>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>聚类是一种无监督学习方法。</p>
<p>无监督学习的目标是通过对无标记训练样本的学习，发掘和揭示数据集本身潜在的结构和规律。</p>
<p>聚类直观上是将相似的样本聚在一起，从而形成一个<strong>类簇</strong>(cluster)，通过<strong>距离度量</strong>来评判相似性。对应到多维样本，每个样本可以对应于高维空间中的一个数据点，如果距离相近，则称相似。聚类结果的好坏，需要<strong>性能度量</strong>。</p>
<h2 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h2><p>度量距离需要满足以下性质：</p>
<ul>
<li>非负性：$\rm dist(x_i,x_j) \geq 0$</li>
<li>同一性：$\rm dist(x_i,x_j) =0$当且仅当$x_i = x_j$</li>
<li>对称性：$\rm dist(x_i,x_j) = dist(x_j,x_i)$</li>
<li>直递性：$\rm dist(x_i,x_j) \leq dist(x_i,x_k) +dist(x_k,x_j)$，三角形不等式，两边之和大于第三边。</li>
</ul>
<p>最常用的距离度量方法是<strong>闵科夫斯基距离</strong>：</p>
<p>$\rm {dist_{mk}} (x_i,x_j) = \left( \sum\limits_{u=1}^n \left| x_{iu} -x_{ju}\right|^p\right)^{\frac{1}{p}}$</p>
<p>当$p=1$时，闵科夫斯基距离即<strong>曼哈顿距离</strong>：</p>
<p>$\rm {dist_{mk}} (x_i,x_j) =||x_i - x_j||_1 = \sum\limits_{u=1}^n |x_{iu} -x_{ju}|$</p>
<p>当$p=2$时，闵科夫斯基距离即<strong>欧式距离</strong>：</p>
<p>$\rm dist_{ed}$$(x_i,x_j) = ||x_i-x_j||_2 = \sqrt{\sum\limits_{u=1}^n |x_{iu} - x_{ju}|^2}$</p>
<p>属性分为两种：<strong>连续属性</strong>和<strong>离散属性</strong>(取值有限个)。</p>
<p>对于连续属性：一般可以被学习器所用，有时会更具具体的情形作相应的预处理，例如：归一化等。</p>
<p>对于离散属性，需要做如下处理：</p>
<blockquote>
<p>若属性值之间存在序关系，则可以将其转化为连续值。如：身高属性“高”“中”“矮”,可转化为{1，0.5，0}。</p>
<p>若属性之间不存在序关系，则可以将其转化为向量形式。如：性别属性“男”“女”，可以转化为{（1，0），（0，1）}。</p>
</blockquote>
<p>在进行距离度量时，连续属性和存在序关系的离散属性都可以直接参与计算，都可以反应一种程度，称之为“有序属性”。</p>
<p>对于”无序属性”，一般采用<strong>VDM</strong>进行距离计算。如：对于离散属性的两个取值a和b，定义：</p>
<p>$VDM_p(a,b) = \sum\limits_{i=1}^k \left| \frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}}\right|^p$，其中$i$表示类簇。</p>
<p>所以，在计算两个样本之间的距离时，可以将闵科夫斯基距离和VDM混合在一起计算 ，即：</p>
<p>$MinkovDM_p(\pmb x_i,\pmb x_j) = \left(   \sum\limits_{u=1}^{n_c}\left|x_{iu}-x_{ju}\right|^p - \sum\limits_{u=n_c+1}^n VDM_p(x_{iu},x_{ju})    \right)^{\frac{1}{p}}$</p>
<p>其中式子括号内左边部分表示有序属性，右边部分表示无序属性。</p>
<p>通过距离度量相似性，距离越小，相似性越大，反之距离越大，相似性越小。</p>
<p>如果距离的度量方法不满足前面所说的四个基本属性，这样的方法称为：<strong>非距离度量</strong>（non-metric distance）。</p>
<h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><h3 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h3><p>将聚类结果与某个参考模型的结果进行比较，<strong>以参考模型的输出作为标准，来评价聚类好坏</strong>。假设聚类给出的结果为$\lambda$，参考模型输出的结果为$\lambda’$，将样本两两配对，定义：</p>
<p>$a=|SS|,SS=\{(\pmb x_i,\pmb x_j) | \lambda_i = \lambda_j,\lambda’_i = \lambda’_j,i&lt;j\}$,参考结果同类簇，聚类结果同类簇。</p>
<p>$a=|SD|,SD=\{(\pmb x_i,\pmb x_j) | \lambda_i = \lambda_j,\lambda’_i \neq \lambda’_j,i&lt;j\}$,参考结果不同类簇，聚类结果同类簇。</p>
<p>$a=|DS|,DS=\{(\pmb x_i,\pmb x_j) | \lambda_i \neq \lambda_j,\lambda’_i = \lambda’_j,i&lt;j\}$,参考结果同类簇，聚类结果不同类簇。</p>
<p>$a=|DD|,DD=\{(\pmb x_i,\pmb x_j) | \lambda_i \neq \lambda_j,\lambda’_i \neq \lambda’_j,i&lt;j\}$,参考结果不同类簇，聚类结果不同类簇。</p>
<p>$a,b$代表着聚类结果好坏的正能量，$b,c$表示参考结果和聚类结果相矛盾，基于这四个值可以导出以下常用的外部评价指标：</p>
<ul>
<li>Jaccard系数(Jaccard Coefficient，JC)：$JC= \frac{a}{a+b+c}$</li>
<li>FM指数(Fowlkes and Malloes Index，FMI)：$FMI = \sqrt{\frac{a}{a+b}·\frac{a}{a+c}}$</li>
<li>Rand指数(Rand Index，RI)：$RI = \frac{2(a+d)}{m(m-1)}$</li>
</ul>
<p>这三个评价指标取值范围（0，1）,取值越大越好。</p>
<h3 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h3><p>不依赖任何外部模型，直接对聚类结果进行评估，聚类的目的是将那些相似的样本尽可能地聚在一起，不相似地样本尽可能分开。定义为：</p>
<ul>
<li><p>$\rm avg(C)$$= \frac{2}{|C|(|C|-1)} \sum\limits_{1\le i&lt;j\le|C|}$$\rm dist$$(\pmb x_i,\pmb x_j)$，簇内平均聚类，越小越好。</p>
</li>
<li><p>$\rm diam$$(C)=\rm max$$_{1\le i&lt;j\le|C|}$$\rm dist$$(\pmb x_i,\pmb x_j)$，簇内最大距离，越小越好。</p>
</li>
<li><p>$d_{min}(C_i,C_j) = min_{\pmb x_i \in C_i,\pmb x_j \in C_j} \rm dist$$(\pmb x_i,\pmb x_j)$，簇间最小距离，越大越好。</p>
</li>
<li><p>$d_{cen}(C_i,C_j) = \rm dist$$(\pmb \mu_i ,\pmb \mu_j)$，簇中心距离，越大越好。</p>
</li>
</ul>
<p>基于上面四个距离，可以导出下面常用的内部评价指标：</p>
<ul>
<li>DB指数(Davies-Bouldin Index，DBI)：$DBI=\frac{1}{k} \sum\limits_{i=1}^k \rm max_{\substack{j \ne i}} \left( \frac{avg(C_i)+avg(C_j)}{d_{cen}(\pmb \mu_i,\pmb \mu_j)}\right)$，越小越好。</li>
<li>Dunn指数(Dunn Index，DI)：$DI = \min\limits_{1\le i \le k} \left( \min\limits_{j \ne i}\left( \frac{d_{min}(C_i,C_j)}{\max\limits_{1 \le l \le k}diam (C_l)}\right) \right)$，越大越好。</li>
</ul>
<h2 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h2><p>基于原型的聚类，即通过参考一个模板向量或者模板分布的方式完成聚类过程，常见的<strong>K-Means</strong>即是基于簇中心来实现聚类，混合高斯聚类是基于簇分布来实现聚类。</p>
<h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h3><p>首先随机指定类中心，根据样本与类中心的远近划分分类簇，接着重新计算类中心，迭代直至收敛。</p>
<p>将样本的类别看作隐变量(latent variable)，类中心看作为样本的分布参数，这一过程通过<strong>EM算法</strong>的两步走策略而计算出，目的是最小化平方误差函数E：</p>
<p>$E=\sum\limits_{i=1}^k \sum\limits_{x\in C_i}||x-\mu_i||_2^2$</p>
<p>算法流程如下：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/12.png" title="K-means算法流程">
<h3 id="学习向量量化-LVQ"><a href="#学习向量量化-LVQ" class="headerlink" title="学习向量量化(LVQ)"></a>学习向量量化(LVQ)</h3><p>LVQ也是基于原型的聚类算法，与K-Means不同，<strong>LVQ使用样本真实类标记辅助聚类</strong>。</p>
<p>LVQ根据样本的类标记，从各类中分别随机选出一个样本作为该类簇的原型，从而组成了一个原型特征向量组，然后从样本集中随机挑选一个样本，计算其与原型向量组中每个向量的距离，并选择距离最小的原型向量所在的类簇作为其划分结果，再与真实类标比较。</p>
<p>若划分结果正确，则对应的原型向量向这个样本靠近一些；若划分结果不正确，在对应原型向量向这个样本远离一些。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/13.png" title="LVQ算法流程">
<h3 id="高斯混合聚类"><a href="#高斯混合聚类" class="headerlink" title="高斯混合聚类"></a>高斯混合聚类</h3><p>K-Means和LVQ都是试图以类中心作为原型指导聚类，高斯混合聚类采用<strong>高斯分布</strong>来描述原型。</p>
<p>假设每个类簇中的样本都服从一个多维高斯分布，那么空间中的样本可以看作由$k$个多维高斯分布混合而成。</p>
<p>多维高斯分布的概率密度函数：</p>
<p>$p(\pmb x) = \frac{1}{(2\pi)^{\frac{n}{2}} |\sum|^{\frac{1}{2}}} e^{ -\frac{1}{2}(\pmb x-\pmb \mu)^T \sum^{-1}(\pmb x- \pmb \mu)      }$</p>
<p>其中$\mu$表示均值向量，$\sum$表示协方差矩阵，可以看出一个多维高斯分布完全由这两个参数所确定。</p>
<p>定义高斯混合分布：</p>
<p>$p_{\mathcal{M}}(\pmb x) = \sum \limits_{i=1}^k \alpha_i ·p(\pmb x| \pmb  \mu_i, \Sigma_i)$</p>
<p>其中$\alpha$称为混合系数，这样空间中样本的采集过程可以抽象为：</p>
<p>（1）选择一个类簇（高斯分布）</p>
<p>（2）再根据相应的高斯分布的密度函数进行采样</p>
<p>此时结合贝叶斯公式，有：</p>
<p>$p_{\mathcal{M}}(z_j=i|\pmb x_j) = \frac{P(z_j =i)·p_{\mathcal{M}}(\pmb x_j| z_j =i)}{p_{\mathcal{M}}(\pmb x_j)} = \frac{\alpha_i ·p(\pmb x_j |\pmb \mu_i,\Sigma_i)}{\sum\limits_{l=1}^k \alpha_l·p(\pmb x_j| \pmb \mu_l, \Sigma_l)}$</p>
<p>此时只需要选择$p_{\mathcal{M}}$最大时的类簇并将该样本划分到其中，与贝叶斯分类类似，都是通过贝叶斯公式展开，然后计算类先验概率$P(z_j=i)$和类条件概率$p_{\mathcal{M}}(\pmb x_j|z_j = i)$。</p>
<p>但是这里面没有真实类标信息，所以不能像贝叶斯分类那样通过最大似然法 计算出来，这里的样本可能属于所有的类簇，这里的似然函数变为：</p>
<p>$LL(D)=\ln \left( \prod \limits_{j=1}^m p_{\mathcal{M}}(\pmb x_j)\right) = \sum\limits_{j=1}^m \ln \left( \sum\limits_{i=1}^k \alpha_i ·p(\pmb x_j|\pmb \mu_i,\Sigma_i)\right)$</p>
<p>这里使用简单的最大似然法无法求出所有的参数，需要使用$EM$算法：</p>
<p>首先对高斯分布参数及混合系数进行随机初始化，计算出各个$p_{\mathcal{M}}$（即$\gamma_{ji}$,第$i$个样本属于$j$类），再最大化似然函数（即$LL(D)$分别对$\alpha,\mu,\Sigma$求偏导)，然后对参数进行迭代更新。</p>
<p>$\pmb \mu_i = \frac{\sum\limits_{j=1}^m \gamma_{ji}\pmb x_j}{\sum\limits_{j=1}^m \gamma_{ji}}$ ,$\Sigma_i = \frac{\sum\limits_{j=1}^m \gamma_{ji}(\pmb x_j-\pmb \mu_i)(\pmb x_j-\pmb \mu_i)^T}{\sum\limits_{j=1}^m \gamma_{ji}}$,$\alpha_i = \frac{1}{m}\sum\limits_{j=1}^m \gamma_{ji}$</p>
<p>具体算法流程如下：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/14.png" title="高斯混合聚类">
<h2 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h2><p>基于密度的聚类，从样本分布的角度来考察样本之间的可连接性，并基于可连接性（密度可达）不断拓展类簇。其中最著名的是DBSCAN算法，首先定义以下几个概念：</p>
<ul>
<li>$\epsilon-$领域：对于$x_j \in D$，其$\epsilon-$领域包含样本集$D$中与$x_j$的距离不大于$\epsilon$的样本，即$N_{\epsilon}(x_j) = \{ x_i \in D| \rm dist(x_i,x_j) \le \epsilon\}$;</li>
</ul>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/15.png" title="密度聚类">
<img src="/blog/2019/06/18/机器学习课程笔记_科大/16.png" title="密度聚类">
<p>简单理解DBSCAN就是：找出一个核心对象所有密度可达的样本集合形成簇。</p>
<p>首先从数据集中任意选择一个核心对象$A$，找出所有$A$密度可达的样本集合，将这些样本形成一个密度相连的类簇，直到所有的核心对象都遍历完。</p>
<p>DBSCAN算法的流程如下：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/17.png" title="DBSCAN算法">
<h2 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h2><p>是一种基于树形结构的聚类方法，常用是自底向上的结合策略（AGNES算法）。</p>
<p>假设有$N$个待聚类的样本，基本步骤如下：</p>
<blockquote>
<ol>
<li>初始化：把每一个样本归为一类，计算每两个类之间的距离，即样本与样本之间的相似度</li>
<li>寻找各个类之间最近的两个类，把他们归为一类（这样类的总数就少了一个）</li>
<li>重新计算新生成的这个类与各个旧类之间的相似度</li>
<li>重复2，3直到所有的样本点都归为一类，结束。</li>
</ol>
</blockquote>
<p>这里面最关键的一步就是<strong>计算两个类簇的相似度</strong>，这里有多种度量方法 ：</p>
<ul>
<li>单链接(single-linkage)：取类间最小距离。即：$d_{min} (C_i,C_j) = \min \limits_{x\in C_i,z\in C_j} \rm dist(x,z)$</li>
<li>全链接(complete-linkage): 取类间最大距离。即：$d_{max} (C_i,C_j) = \max \limits_{x\in C_i,z\in C_j} \rm dist(x,z)$</li>
<li>均链接(average-linkage): 取类间两两的平均距离。即：$d_{avg} (C_i,C_j) = \frac{1}{|C_i||C_j|} \sum\limits_{x\in C_i} \sum\limits_{z\in C_j} \rm dist(x,z)$</li>
</ul>
<p>可以看出：单链接包容性强，稍微有点联系就划为一类，全链接要求最为严格，均链接从全局出发。</p>
<p>层次聚类算法流程如下：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/18.png" title="层次聚类算法">
<h1 id="贝叶斯决策理论"><a href="#贝叶斯决策理论" class="headerlink" title="贝叶斯决策理论"></a>贝叶斯决策理论</h1><blockquote>
<p>参见《模式识别》（边肇祺）</p>
</blockquote>
<p>概念</p>
<p>bayes公式：$P(A|B)·P(B) =P(B|A)·P(A)$</p>
<p>类别$w \in \{w_1,w_2\}$</p>
<p>样本$X$</p>
<p>状态先验概率$P(w_i),i=1,2$</p>
<p>类条件概率密度$p(\pmb x|w_i),i=1,2$</p>
<p>状态后验概率$p(w_i|\pmb x)$</p>
<p>所以有：$p(X|w_i)·P(w_i) = p(w_i|X)·P(X),i=1,2$</p>
<p>$\implies p(w_i|\pmb x) = \frac{p(\pmb x|w_i)·P(w_i)}{\sum_{j=1}^2p( \pmb x|w_j)P(w_j)}$</p>
<p>Bayes本质</p>
<p>观察$\pmb x$（被识别的d维特征的测量），把状态的先验概率$P(w_i)$转化为状态的后验概率$p(w_i|\pmb x)$。</p>
<h2 id="最小错误率bayes决策规则"><a href="#最小错误率bayes决策规则" class="headerlink" title="最小错误率bayes决策规则"></a>最小错误率bayes决策规则</h2><p>若$p(w_1|\pmb x)&gt;p(w_2|\pmb x)$，则把$\pmb x$归为状态$w_1$;</p>
<p>若$p(w_1|\pmb x)&lt;p(w_2|\pmb x)$，则把$\pmb x$归为状态$w_2 $。</p>
<p>几种等价形式：</p>
<ul>
<li><p>$若p(w_i|\pmb x)=\underset{j=1,2}{max}  p(w_j|\pmb x),则\pmb x \in w_i$</p>
</li>
<li><p>$若p(\pmb x | w_i)P(w_i)=\underset{j=1,2}{max} p(\pmb x |w_j)P(w_j),则\pmb x \in w_i$</p>
</li>
<li><p>$若l(\pmb x) = \frac{p(\pmb x|w_1)}{p(\pmb x|w_2)} \underset{&lt;}{ &gt;} \frac{P(w_2)}{P(w_1)}，则 \pmb x \in \cases{w_1\\w_2}$   ,其中$l(\pmb x)$称为<strong>似然比</strong>。$\frac{P(w_2)}{P(w_1)}$表示<strong>似然比阈值</strong></p>
</li>
<li><p>$若h(\pmb x) =-ln[l(x)] = -ln[ p(\pmb x|w_i)] + ln[p(\pmb x|w_2)]  \underset{&gt;}{&lt;} ln \frac{P(w_1)}{P(w_2)},则 \pmb x \in \cases{w_1\\w_2}$</p>
</li>
</ul>
<blockquote>
<p>【说明】：</p>
<p>Bayes进行分类时要求：</p>
<p>​          各类别的总体的概率分布$P(w)$是已知的；</p>
<p>​          要决策的分类的类别是一定的</p>
</blockquote>
<blockquote>
<p>e.g. 某局部地区的细胞识别中正常为$w_1$和异常$w_2$两类，先验概率分别是$\cases{正常状态：P(w_1)=0.9\\异常状态：P(w_2) =0.1}$。</p>
<p>有一个待测的细胞：观察值为$\pmb x$，从类条件概率密度分布曲线上查得</p>
<p>$p(\pmb x|w_1)=0.2,p(\pmb x| w_2) =0.4$</p>
<p>解：</p>
<p>由$ p(w_1|\pmb x) = \frac{p(\pmb x|w_1)·P(w_1)}{\sum_{j=1}^2p( \pmb x|w_j)P(w_j)} =\frac{0.2\times0.9}{0.2\times0.9+0.4\times0.1} =0.818$</p>
<p>$p(w_2|\pmb x) = 1- p(w_1| \pmb x) =0.182$</p>
<p>$p(w_1|\pmb x)&gt; p(w_2|\pmb x)$，所以合理的决策是把$\pmb x$归类于正常状态$w_1$。</p>
</blockquote>
<h3 id="平均错误率"><a href="#平均错误率" class="headerlink" title="平均错误率"></a>平均错误率</h3><p>以$P(e)$表示，定义为：</p>
<p>$P(e) = \int_{-\infty}^{\infty} P(e,\pmb x)d \pmb x =\int_{-\infty}^{\infty} P(e|\pmb x) p(\pmb x) d \pmb x$</p>
<p>其中：</p>
<p>$\int_{-\infty}^{\infty} () d \pmb x$表示在整个d维特征空间上的积分。</p>
<p>对于两类别问题，根据最小概率bayes决策规则可知：</p>
<p>$若P(w_2|\pmb x)&gt;P(w_1| \pmb x),决策应该为w_1,此时做出决策错误概率为P(w_1|\pmb x)。反之应为P(w_2|\pmb x)$。</p>
<p>可表示为：</p>
<p>$P(e| \pmb x) = \cases{P(w_1|\pmb x),当P(w_2|\pmb x)&gt;P(w_1| \pmb x)   \  P(w_2|\pmb x),当P(w_1|\pmb x)&gt;P(w_2| \pmb x)}$</p>
<p>如果令$t$表示两类的分界面，将特征空间$\mathbb{R}$划分为两类$\mathbb{R_1} （  -\infty,t）,\mathbb{R_2} （ t,\infty）$，这样就有：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>P(e) &amp;=\int_{-\infty}^{t} P(w_2|\pmb x) p(\pmb x) d \pmb x +\int_{t}^{\infty} P(w_1|\pmb x) p(\pmb x) d \pmb x \\<br>&amp;= \int_{-\infty}^{t} p(\pmb x|w_2) P(w_2) d \pmb x +\int_{t}^{\infty} p(\pmb x| w_1) P(w_1) d \pmb x\\<br>&amp;=P(\pmb x \in \mathbb{R_1},w_2)+P(\pmb x \in \mathbb{R_2},w_1)\\<br>&amp;=P(\pmb x \in \mathbb{R_1}|w_2)P(w_2)+P(\pmb x \in \mathbb{R_2}|w_1)P(w_1)\\<br>&amp;=P(w_2) \int_{\mathbb{R_1}}p(\pmb x|w_2)d\pmb x +P(w_1) \int_{\mathbb{R_2}}p(\pmb x|w_1)d\pmb x \\<br>&amp;=P(w_2)P_2(e) +P(w_1)P_1(e)<br>\end{aligned}<br>\end{equation}<br>$$<br>可见：</p>
<p>最小错误率的决策规则实际上是对每个$\pmb x$都使得$P(e|\pmb x)$取得最小者，这就使得</p>
<p>$P(e) = \int_{-\infty}^{\infty} P(e,\pmb x)d \pmb x =\int_{-\infty}^{\infty} P(e|\pmb x) p(\pmb x) d \pmb x$取得最小，即</p>
<p>使得平均错误率$P(e)$达到最小。</p>
<h3 id="多类决策过程"><a href="#多类决策过程" class="headerlink" title="多类决策过程"></a>多类决策过程</h3><p>假设有c类别，即最小错误率贝叶斯决策规则：</p>
<p>$若p(w_i|\pmb x)=\underset{j=1,2,\dots,c}{max} p(w_j|\pmb x),则\pmb x \in w_i$</p>
<p>$若p(\pmb x | w_i)P(w_i)=\underset{j=1,2,\dots,c}{max}p(\pmb x |w_j)P(w_j),则\pmb x \in w_i$</p>
<p>多类别决策过程中，把特诊空间分割为$\mathbb{R_1},\mathbb{R_2},\dots,\mathbb{R_c}$个区域，可能错分的情况很多，平均错误概率$P(e)$将由$c(c-1)$项组成。即：<br>$$<br>\begin{equation}</p>
<p>\begin{aligned}<br>P(e)<br>&amp;=[P(\pmb x \in \mathbb{R_2}|w_1)+P(\pmb x \in \mathbb{R_3}|w_1) + \dots +P(\pmb x \in \mathbb{R_c}|w_1) ]P(w_1)\\<br>&amp;+[P(\pmb x \in \mathbb{R_1}|w_2)+P(\pmb x \in \mathbb{R_3}|w_2) + \dots +P(\pmb x \in \mathbb{R_c}|w_2) ]P(w_2)\\<br> \vdots\\<br>&amp;+[P(\pmb x \in \mathbb{R_1}|w_c)+P(\pmb x \in \mathbb{R_2}|w_c) + \dots +P(\pmb x \in \mathbb{R_{c-1}}|w_c) ]P(w_c)\\<br>&amp;= \sum_{\substack{i=1}}^c \sum_{\substack{i=1\\j \neq i}}^c [P(\pmb x \in \mathbb{R_j}|w_i)]P(w_i)<br>\end{aligned}</p>
<p>\end{equation}<br>$$<br>直接求$P(e)$计算量很大，代之以计算平均正确分类概率$P(c)$表示，即：</p>
<p>$P(e) =1-P(c) = 1- \sum_{j=1}^c P(\pmb x \in \mathbb{R_j}|w_j)P(w_j) =1-\sum_{j=1}^c \int_{\mathbb{R_i}} p(\pmb x|w_j)P(w_j)d \pmb x$</p>
<h2 id="最小风险的贝叶斯决策"><a href="#最小风险的贝叶斯决策" class="headerlink" title="最小风险的贝叶斯决策"></a>最小风险的贝叶斯决策</h2><p>是考虑到各种错误造成的损失不同而提出的决策规则。</p>
<p>用决策论的观点进行讨论：</p>
<p>在决策论中采取的行动称为<strong>决策或行动</strong>，所有可能的各种决策组成的集合称为<strong>决策空间或行动空间</strong>,记为$\Lambda$</p>
<ul>
<li><p>观察$\pmb x是d维随机向量： \pmb x =[x_1,x_2,\dots,x_d]^T$,其中$x_1,x_2,\dots,x_d为一维随机变量。$</p>
</li>
<li><p>状态空间$\Omega ，由c个自然状态（c类）组成。即，\Omega =\{w_1,w_2,\dots,w_c\}$</p>
</li>
<li><p>决策空间由$\alpha 个决策\alpha_i，i=1,2,\dots,a$组成，即$\Lambda = \{\alpha_1.\alpha_2,\dots,\alpha_a\}$【注:这里的$a不同于c，因为除了c个类别有c种不同的决策外$还有可能采取其他决策，比如“拒绝”的决策，此时$a=c+1$】</p>
</li>
<li><p>损失函数$\lambda(\alpha_i,w_j),i=1,2,\dots,a;j=1,2,\dots,c$。表示当真实状态为$w_j$时而采取的决策$\alpha_i$时所带来的损失。</p>
</li>
</ul>
<h3 id="条件期望损失"><a href="#条件期望损失" class="headerlink" title="条件期望损失"></a>条件期望损失</h3><p>$R(\alpha_i| \pmb x)$表示，定义为：</p>
<p>给定的$\pmb x$，如果采取决策$\alpha_i$，损失$\lambda 可以在c个\lambda(\alpha_i,w_j)，j=1,2,\dots,c$中任取一个，其相应的概率为$P(w_j|\pmb x)$。</p>
<p>在采取决策$\alpha_i$情况下的条件期望损失为：</p>
<p>$R(\alpha_i|\pmb x)=E[\lambda(\alpha_i,w_j)] =\sum_{j=1}^c \lambda(\alpha_i,w_j)P(w_j| \pmb x)，i=1,2,\dots,a$</p>
<p>也称为<strong>条件风险</strong>。</p>
<h3 id="期望风险"><a href="#期望风险" class="headerlink" title="期望风险"></a>期望风险</h3><p>由于$\pmb x$是随机向量的观察值，所以，对于不同的$\pmb x$采取的决策$\alpha_i$时，其条件风险不同。把决策$\alpha$看成随机向量$\pmb x$的函数，记为$\alpha(\pmb x)$，定义<strong>期望风险</strong>$R$。</p>
<p>$R=\int R(\alpha(\pmb x)|\pmb x)p(\pmb x)$，其中$d\pmb x$是$d$维度特征空间上的体积元，积分是在整个特征空间上进行。</p>
<blockquote>
<p>【说明】</p>
<p>$\cases{期望风险R反应的是整个特征空间上所有 \pmb x的取值采取相应的决策\alpha( \pmb x)所带来的平均风险。\\条件风险R(\alpha_i |x)只反应某一个随机变量x的取值，采取相应的决策\alpha_i所带来的风险。}$</p>
</blockquote>
<h3 id="决策规则"><a href="#决策规则" class="headerlink" title="决策规则"></a>决策规则</h3><p>如果$R(\alpha_k|\pmb x) = \underset{i=1,\dots,a}{min}  R(\alpha_i| \pmb x),则\alpha= \alpha_k$</p>
<p>步骤如下：</p>
<p>(1)已知$P(w_j),p(\pmb x| w_j),j=1,2,\dots,c及待识别的\pmb x的情况下$，根据贝叶斯公式计算出后验概率：</p>
<p>$p(w_j|\pmb x) = \large{\frac{p(\pmb x|w_j)·P(w_j)}{\sum_{i=1}^cp( \pmb x|w_i)P(w_i)}}，j=1,2,\dots,c$</p>
<p>(2)利用后验概率和决策表，计算出采取$\alpha_i,i=1,2,\dots,a$决策的条件风险$R(\alpha_i | \pmb x) ,i=1,2,\dots,a$</p>
<p>$R(\alpha_i|\pmb x)=E[\lambda(\alpha_i,w_j)] =\sum_{j=1}^c \lambda(\alpha_i,w_j)P(w_j| \pmb x)，i=1,2,\dots,a$</p>
<p>(3)对(2)中得到的$a$个条件风险值$R(\alpha_i | \pmb x) ,i=1,2,\dots,a$进行比较，找出使条件风险最小的决策$\alpha_k$，即：</p>
<p>$R(\alpha_k| \pmb x) = \underset{i=1,2,\dots,a}{min} R(\alpha_i| \pmb x)$</p>
<p>则$\alpha_k$就是最小风险饿贝叶斯决策。</p>
<blockquote>
<p>e.g.给定决策表，按最小风险贝叶斯决策进行分类。</p>
<table>
<thead>
<tr>
<th style="text-align:center">决策损失状态</th>
<th style="text-align:center">$w_1$</th>
<th style="text-align:center">$w_2$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$\alpha_1$</td>
<td style="text-align:center">0</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td style="text-align:center">$\alpha_2$</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
<p>已知条件：</p>
<p>$P(w_1)=0.9,P(w_2)=0.1;p(\pmb x| w_1) = 0.2,p(\pmb x| w_2) = 0.4;$</p>
<p>$\lambda_{11} =0,\lambda_{12} =6,\lambda_{21} =1,\lambda_{22} =0$</p>
<p>根据贝叶斯公式得到：</p>
<p>$P(w_1|\pmb x) =0.818,P(w_2| \pmb x) = 0.182$</p>
<p>根据$R(\alpha_i|\pmb x)=E[\lambda(\alpha_i,w_j)] =\sum_{j=1}^c \lambda(\alpha_i,w_j)P(w_j| \pmb x)，i=1,2,\dots,a$得到：</p>
<p>$R(\alpha_1|\pmb x)=\sum_{j=1}^2 \lambda_{1j}P(w_j| \pmb x)=\lambda_{12}P(w_2| \pmb x) = 1.092$</p>
<p>$R(\alpha_2|\pmb x)=\lambda_{21}P(w_1| \pmb x) = 0.818$</p>
<p>∵$R(\alpha_1| \pmb x) &gt; R(\alpha_2 | \pmb x)$</p>
<p>∴决策为$w_2 $的风险小于决策为$w_1$的风险，因此采取决策行$\alpha_2 $，即判断$\pmb x \in w_2$。</p>
</blockquote>
<blockquote>
<p>【说明】:</p>
<p>最小风险贝叶斯决策要求：</p>
<p>$ \cases{ 先验概率P(w_j)已知\\类条件概率密度p(\pmb x| w_j),j=1,2,\dots,c已知\\合适的损失函数\lambda(\alpha_i,w_j),i=1,2,\dots,a;j=1,2,\dots,c}$</p>
<p>合适的决策表需要根据所研究的具体问题来决定。</p>
</blockquote>
<h2 id="最小错误率和最小风险Bayes决策关系"><a href="#最小错误率和最小风险Bayes决策关系" class="headerlink" title="最小错误率和最小风险Bayes决策关系"></a>最小错误率和最小风险Bayes决策关系</h2><p>设损失函数为：<br>$$<br>\begin{equation}<br>\lambda(\alpha_i,w_j)=<br>\begin{cases}<br>1: i = j\\<br>0: {i \neq j}<br>\end{cases} \qquad i,j =1,2,\dots,c<br>\end{equation}<br>$$<br>称为<strong>0-1损失函数</strong>。不考虑”拒绝”情况</p>
<p>则有：</p>
<p>$R(\alpha_i|\pmb x)=E[\lambda(\alpha_i,w_j)] =\sum_{j=1}^c \lambda(\alpha_i,w_j)P(w_j| \pmb x)=\sum_{j=1\\j \neq i}^c P(w_j| \pmb x)$</p>
<p>其中：</p>
<p>$\sum_{j=1\\j \neq i}^c P(w_j| \pmb x)$表示对$\pmb x 采取决策  w_i 的条件错误概率$。在0-1损失函数时，使得：</p>
<p>最小风险贝叶斯决策$R(\alpha_k| \pmb x) = \underset{i=1,2,\dots,a}{min} R(\alpha_i| \pmb x)$</p>
<p>$\iff  \sum_{j=1\\j \neq i}^c P(w_j| \pmb x) = \underset{i=1,2,\dots,a}{min} R(\alpha_i| \pmb x)$</p>
<p>等价于最小错误率贝叶斯决策。</p>
<p>即：</p>
<p>最小错误率贝叶斯决策就是在0-1损失函数条件下的最小风险贝叶斯决策，前者是后者的一个特例。</p>
<h2 id="Neyman-Pearson准则"><a href="#Neyman-Pearson准则" class="headerlink" title="Neyman-Pearson准则"></a>Neyman-Pearson准则</h2><p>又称为 ：</p>
<p>在限定一类错误率$\varepsilon_2$为常数而使得另一类错误率$\varepsilon_1$最小的决策规则。</p>
<p>可看成：</p>
<p>在$P_2(e) = \varepsilon_0$条件下，求$P_1(e) $的极小值的条件极值问题。可以用<strong>Lagrande乘子法</strong>，建立数学模型为：</p>
<p>$\gamma = P_1(e) + \lambda(P_2(e)- \varepsilon_0)，其中\lambda 是拉格朗日乘子，目的是求\gamma的极小值。$</p>
<p>已知：</p>
<p>$P_1(e)= \int_{\mathbb{R_2}}p(\pmb x|w_1)d\pmb x ;P_2(e)= \int_{\mathbb{R_1}}p(\pmb x|w_2)d\pmb x$</p>
<p>$\mathbb{R_1} +\mathbb{R_2} = \mathbb{R},划分整个特征空间$，分界点（面）$t$，若被识别的样本$\pmb x落入 \mathbb{R_1}，属于w_1类，否则属于w_2类。$</p>
<p>根据类条件概率密度的性质有：</p>
<p>$ \int_{\mathbb{R_2}}p(\pmb x|w_1)d\pmb x =1- \int_{\mathbb{R_1}}p(\pmb x|w_1)d\pmb x$</p>
<p>所以有：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/公式1.PNG">
<p>所以Neyman-Pearson决策规则为：</p>
<p>$ \frac{p(\pmb x|w_1)}{p(\pmb x|w_2)}   \underset{&lt;}{ &gt;}  \lambda ,则 \pmb x \in \cases{w_1\\w_2}$</p>
<h3 id="高维情况分析"><a href="#高维情况分析" class="headerlink" title="高维情况分析"></a>高维情况分析</h3><p>在高维情况下，求解边界面不容易，此时可以利用<strong>似然比密度函数</strong>来确定$\lambda$的值。即：</p>
<p>似然比$l(\pmb x) = \frac{p(\pmb x|w_1)}{p(\pmb x|w_2)} $</p>
<p>似然密度函数$p(l|w_2) $:</p>
<p>​                      $P_2(e) = 1- \int_0^{\lambda}p(l|w_2) dl = \varepsilon_0  $</p>
<p>可见：</p>
<p>$ p(l|w_2) \ge 0,P_2(e) 是 \lambda 的单调函数，即，当\lambda =0时，P_2(e) =1;当\lambda  → \infty 时，P_2(e) =0$</p>
<p>采用试探法，对几个$\lambda $的值计算出$P_2(e)$后，可以找到一个合适的$\lambda$的值，刚好能满足$P_2(e) = \varepsilon_0$的条件，又使得$P_1(e) $尽可能的小。</p>
<h2 id="Neyman-Pearson决策规则与最小错误率Bayes决策规则对比"><a href="#Neyman-Pearson决策规则与最小错误率Bayes决策规则对比" class="headerlink" title="Neyman-Pearson决策规则与最小错误率Bayes决策规则对比"></a>Neyman-Pearson决策规则与最小错误率Bayes决策规则对比</h2><p>两者都是以<strong>似然比</strong>为基础的</p>
<p>不同的是：</p>
<p>最小错误率贝叶斯决策规则：</p>
<p>$若l(\pmb x) = \frac{p(\pmb x|w_1)}{p(\pmb x|w_2)} \underset{&lt;}{ &gt;} \frac{P(w_2)}{P(w_1)}，则 \pmb x \in \cases{w_1\\w_2}$   ,其中$l(\pmb x)$称为<strong>似然比</strong>。$\frac{P(w_2)}{P(w_1)}$表示<strong>似然比阈值</strong></p>
<p>Neyman-Pearson决策规则：</p>
<p>$ \frac{p(\pmb x|w_1)}{p(\pmb x|w_2)}   \underset{&lt;}{ &gt;}  \lambda ,则 \pmb x \in \cases{w_1\\w_2}$，其中用的阈值是Lagrange乘子$\lambda$。</p>
<p>最小风险贝叶斯决策规则也可以写成似然比形式：</p>
<p>$ \frac{p(\pmb x|w_1)}{p(\pmb x|w_2)}   \underset{&lt;}{ &gt;}  \frac{(\lambda_{12}-\lambda_{22})P(w_2)}{(\lambda_{21}-\lambda_{11})P(w_1)}$</p>
<p>其中:</p>
<p>$\lambda_{11} $——$当\pmb x \in w_1时，决策为\pmb x \in w_1的损失$</p>
<p>$\lambda_{21} $——$当\pmb x \in w_1时，决策为\pmb x \in w_2的损失$</p>
<p>$\lambda_{22} $——$当\pmb x \in w_2时，决策为\pmb x \in w_2的损失$</p>
<p>$\lambda_{12} $——$当\pmb x \in w_2时，决策为\pmb x \in w_1的损失$</p>
<h2 id="最小最大决策"><a href="#最小最大决策" class="headerlink" title="最小最大决策"></a>最小最大决策</h2><p>考虑$P(w_i)$变化的情况下，如何使得最大可能风险为最小，即在最差的条件下争取最好的结果。</p>
<p>对于两类问题，假定损失函数：</p>
<p>$\lambda_{11} $——$当\pmb x \in w_1时，决策为\pmb x \in w_1的损失$</p>
<p>$\lambda_{21} $——$当\pmb x \in w_1时，决策为\pmb x \in w_2的损失$</p>
<p>$\lambda_{22} $——$当\pmb x \in w_2时，决策为\pmb x \in w_2的损失$</p>
<p>$\lambda_{12} $——$当\pmb x \in w_2时，决策为\pmb x \in w_1的损失$</p>
<p>通常做出错误决策总比做出正确决策所带来的损失要大，即</p>
<p>$\lambda_{21} &gt;\lambda_{11}; \lambda_{12} &gt;\lambda_{22}$</p>
<p>假定决策域$\mathbb{R_1},\mathbb{R_2}$已确定，则风险为：</p>
<p>$R= \int R(\alpha(\pmb x) |\pmb x)p(\pmb x) d\pmb x =\int_{\mathbb{R_1}} R(\alpha_1(\pmb x) |\pmb x)p(\pmb x) d\pmb x+\int_{\mathbb{R_2}} R(\alpha_2(\pmb x) |\pmb x)p(\pmb x) d\pmb x$</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/公式2.PNG">
<p>我们可以在（0，1）区间内，对先验概率$P(w_1)$取若干个不同的值，分别按最小风险概率贝叶斯决策规则确定对应的决策域，从而计算出相应的最小风险R，这样可以得到关于最小贝叶斯风险R与先验概率$P(w_1)$的关系曲线。</p>
<p>找到决策域使得系数$b=0$，即：</p>
<p>$b=(\lambda_{11}-\lambda_{22}) + (\lambda_{21}-\lambda_{11}) \int_{\mathbb{R_2}}p(\pmb x|w_1)d\pmb x - (\lambda_{12}-\lambda_{22}) \int_{\mathbb{R_1}}p(\pmb x|w_2)d\pmb x=0$</p>
<p>这样风险变为：</p>
<p>$R=\lambda_{22} +(\lambda_{12}-\lambda_{22}) \int_{\mathbb{R_1}}p(\pmb x|w_2)d\pmb x=a$</p>
<p>该式子表示的直线平行于$P(w_1)$的坐标轴，这样无论$P(w_1)$怎么变化，风险$R$都不会发生变化，其最大风险为$a$,这时最大风险最小。</p>
<p>综上所述：</p>
<p>在作最小风险贝叶斯决策时，若考虑先验概率$P(w_1)$可能改变或者对先验概率毫无所知的情况下，应选择最小贝叶斯风险$R’$为最大值时的$P’(w_1)$来设计分类器。</p>
<p>因为此时，风险最大，能保证在不管$P(w_1)$怎么变化时，使得最大风险降为最小。——<strong>最大最小决策</strong>。</p>
<p>即：</p>
<p>最小最大决策的任务是找到使得<strong>贝叶斯风险为最大时的决策域</strong>$\mathbb{R_1},\mathbb{R_2}$,这也对应方程：</p>
<p>$b=(\lambda_{11}-\lambda_{22}) + (\lambda_{21}-\lambda_{11}) \int_{\mathbb{R_2}}p(\pmb x|w_1)d\pmb x - (\lambda_{12}-\lambda_{22}) \int_{\mathbb{R_1}}p(\pmb x|w_2)d\pmb x=0$</p>
<p>的解。</p>
<p>这是一种偏于保守的方法。</p>
<h2 id="序贯分类方法"><a href="#序贯分类方法" class="headerlink" title="序贯分类方法"></a>序贯分类方法</h2><p>考虑到，获取了$k$个特征（$k&lt;d$）就做判决分类更为合理，因为其余$d-k$个特征加入会使得分类错误的降低而造成的代价减小补偿不了这些特征花费的代价。</p>
<p>解决办法是:</p>
<p>先用一部分的特征来分类，逐步加入特征以减少分类损失，然后每步都要衡量加入新特征所花费的代价与所降低分类损失的大小，以便于决定是否继续再加新特征还是停止。</p>
<p>这种方法的计算量和存储容量要求大，因此发展了一系列次优的序贯方法，主要是：</p>
<p>假定在第$k$步做出决策时只考虑到$k+v$步，即决策一定停止在第$k$步和$k+v$之间。此外还有进行特诊的排序 。</p>
<h2 id="分类器的设计"><a href="#分类器的设计" class="headerlink" title="分类器的设计"></a>分类器的设计</h2><p>处理的主要问题是:应用这些决策规则对观察向量$\pmb x$进行分类。</p>
<p>几个名词概念：</p>
<ul>
<li>决策面：对于$c类问题$，按照决策规则可以把$d$维特征空间划分成$c$个决策域，将划分决策域的边界面称为<strong>决策面</strong>。</li>
<li>判别函数：用于表达决策规则的某些函数称为<strong>判断函数</strong>。</li>
</ul>
<h3 id="多类情况"><a href="#多类情况" class="headerlink" title="多类情况"></a>多类情况</h3><p>定义一组判别函数$g_i(\pmb x) ,i=1,2,\dots,c$用于表示多类决策规则。</p>
<p>（1）判别函数</p>
<p>如果对于$g_i(\pmb x) &gt; g_j(\pmb x),在所有j \neq i都成立，则将\pmb x 归于w_i类$。因此可以定义为：</p>
<ul>
<li>$g_i(\pmb x) =P(w_i| \pmb x)$</li>
<li>$g_i(\pmb x) =p( \pmb x | w_i)P(w_i)$</li>
<li>$g_i(\pmb x) =ln  p(\pmb x| w_i) +ln  P(w_i)$</li>
<li>更一般的可以定义为：$f(p(w_i| \pmb x)) +h(\pmb x)，其中f()为任一单调增函数$。</li>
</ul>
<p>（2）决策面方程</p>
<p>各区域$\mathbb{R_i}$被决策面分割，这些决策面是特征空间中的超曲面，相邻两个决策域在决策面上的判断函数值是相等的，即：</p>
<p>$若\mathbb{R_i} 和\mathbb{R_j}$相邻的，则分割它们的决策面方程满足$g_i(\pmb x) = g_j(\pmb x)$。</p>
<p>（3）分类器设计</p>
<p>功能是先计算出$c个判别函数g_i，$再从中选择对应于<strong>判别函数为最大值</strong>的类作为决策结果。</p>
<h3 id="两类情况"><a href="#两类情况" class="headerlink" title="两类情况"></a>两类情况</h3><p>（1）判别函数</p>
<p>定义为：$g(\pmb x) = g_1(\pmb x) -g_2(\pmb x)$</p>
<p>决策规则可以表示为：$\cases{g(\pmb x)&gt;0,则决策w_1\\g(\pmb x)&lt;0,则决策w_2}$</p>
<p>可定义出如下的判别函数：</p>
<ul>
<li>$g(\pmb x) = P(w_1|\pmb x)-P(w_2|\pmb x)$</li>
<li>$g(\pmb x) = p(\pmb x| w_1)P(w_1)- p(\pmb x|w_2)P(w_2)$</li>
<li>$g(\pmb x) = ln \frac{p(\pmb x| w_1)}{p(\pmb x| w_2)}-ln \frac{P(w_1)}{P(w_2)}$</li>
</ul>
<p>（2）决策面方程</p>
<p>​        $g(\pmb x) =0$</p>
<p>一般来说，$\pmb x$为一维时，决策面为一分界点；二维时，决策面为一曲面；三维时，是一曲面，$\pmb x是d维$时，决策面时一超曲面。</p>
<p>（3）分类器设计</p>
<p>计算判别函数$g(\pmb x)$，根据计算结果划分$\pmb x$的所属类别。</p>
<blockquote>
<p>e.g.给定决策表，按最小风险贝叶斯决策进行分类。</p>
<table>
<thead>
<tr>
<th style="text-align:center">决策损失状态</th>
<th style="text-align:center">$w_1$</th>
<th style="text-align:center">$w_2$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$\alpha_1$</td>
<td style="text-align:center">0</td>
<td style="text-align:center">6</td>
</tr>
<tr>
<td style="text-align:center">$\alpha_2$</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
<p>已知条件：</p>
<p>$P(w_1)=0.9,P(w_2)=0.1;p(\pmb x| w_1) = 0.2,p(\pmb x| w_2) = 0.4;$</p>
<p>$\lambda_{11} =0,\lambda_{12} =6,\lambda_{21} =1,\lambda_{22} =0$</p>
<p>根据贝叶斯公式得到：</p>
<p>$P(w_1|\pmb x) =0.818,P(w_2| \pmb x) = 0.182$</p>
<p>判别函数可以定义为：</p>
<p>$g(\pmb x) =R(\alpha_2|\pmb x) - R(\alpha_1| \pmb x) \ \qquad = \lambda_{21}P(w_1|\pmb x) - \lambda_{12}P(w_2| \pmb x) \ \qquad =\lambda_{21}p(\pmb x|w_1)P(w_1) - \lambda_{12}p(\pmb x |w_2)P(w_2) \ \qquad = 0.9p(\pmb x|w_1) -0.6p(\pmb x| w_2)=0$</p>
<p>即：$9p(\pmb x|w_1) -6p(\pmb x|w_2) =0$</p>
</blockquote>
<h2 id="正态分布的统计决策（参数估计决策）"><a href="#正态分布的统计决策（参数估计决策）" class="headerlink" title="正态分布的统计决策（参数估计决策）"></a>正态分布的统计决策（参数估计决策）</h2><h3 id="概率密度函数的定义和性质"><a href="#概率密度函数的定义和性质" class="headerlink" title="概率密度函数的定义和性质"></a>概率密度函数的定义和性质</h3><p>（1）单变量情况</p>
<p>单变量的正态分布概率密度函数定义：</p>
<p>$p(x) = N(\mu,\sigma^2)= \frac{1}{\sqrt{2\pi} \sigma} exp \{ -\frac{1}{2} (\frac{x-\mu}{\sigma})^2\}$</p>
<p>$方差\sigma^2 = \int_{-\infty}^{\infty}(x-\mu)^2p(x)dx$</p>
<p>离散情况$\sigma = E[(X-E(X))^2] = E(X^2)-(E(X))^2$</p>
<p>$期望\mu = E(x) = \int_{-\infty}^{\infty} xp(x)dx$</p>
<p>概率密度函数满足：</p>
<p>$\cases{p(\pmb x)\geq 0,(-\infty&lt;x&lt;\infty)\ \int_{-\infty}^{\infty}p(\pmb x)d\pmb x =1} $</p>
<blockquote>
<p>【说明】：</p>
<p>正态分布的样本主要集中在均值附近，其分散程度可以用标准差$\sigma$表示，越大则分散程度也越大。</p>
<p>正态分布的总体样本抽取样本，约有95%的样本落在区间$(\mu-2\sigma,\mu+2\sigma)$之间；也有$3\sigma$原理，99.7%的样本。</p>
</blockquote>
<p>（2）多元正态分布</p>
<p>多元正态分布的概率密度函数定义：</p>
<p>$p(\pmb x) = \frac{1}{(2\pi)^{d/2} |\sum|^{1/2}} exp \{ -\frac{1}{2} (\pmb x-\pmb \mu)^T \sum^{-1}(\pmb x-\pmb \mu)\}$</p>
<p>其中$\pmb x=[x_1,x_2,\dots,x_d]^T$</p>
<p>​       $\pmb \mu = [\mu_1,\mu_2,\dots,\mu_d]^T$</p>
<p>​      $ \sum 是d*d维协方差矩阵，\sum^{-1}是其逆矩阵，|\sum|是其行列式$。</p>
<p>​      $\pmb \mu = E(\pmb x) \ \sum= E\{(\pmb x-\pmb \mu)^T(\pmb x-\pmb \mu)\}$</p>
<p>即有：</p>
<p>$\mu_i = E(x_i) =\int_{E^d} x_ip(\pmb x) d\pmb x = \int_{-\infty}^{\infty}x_ip(x_i)dx_i$</p>
<p>其中$p(x_i)$是边缘分布，即：</p>
<p>$p(x_i) = \int_{-\infty}^{\infty} \dots \int_{-\infty}^{\infty}p(\pmb x)dx_1dx_2\dots dx_{i-1}dx_{i} \dots dx_d$</p>
<p>$协方差 \sigma_{ij}^2 = E[(x_i-\mu_i)(x_j-\mu_j)] \  \quad = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} (x_i-\mu_i)(x_j-\mu_j)p(x_i,x_j)dx_idx_j$</p>
<p><strong>协方差矩阵是对称非负定阵</strong>，且可以表示为：<br>$$<br>\sum= \begin{bmatrix}<br>  \sigma_{11}^2 &amp; \sigma_{12}^2&amp;\dots &amp; \sigma_{1d}^2 \\<br>  \sigma_{12}^2&amp;\sigma_{22}^2 &amp;\dots &amp; \sigma_{2d}^2 \\<br>  \vdots &amp; \vdots&amp; \ddots &amp; \vdots \\<br>  \sigma_{1d}^2 &amp;\sigma_{2d}^2&amp; \dots&amp; \sigma_{dd}^2<br>  \end{bmatrix}_{d\times d}<br>$$<br>其中对角元素是$x_i$的方差$\sigma_{ii}^2$，非对角元素$\sigma_{ij}^2是x_i和x_j的协方差。$只考虑正定情况下，即$|\sum|&gt;0$。</p>
<h3 id="多元正态-概率模型下的最小错误率贝叶斯判别函数和决策面"><a href="#多元正态-概率模型下的最小错误率贝叶斯判别函数和决策面" class="headerlink" title="多元正态 概率模型下的最小错误率贝叶斯判别函数和决策面"></a>多元正态 概率模型下的最小错误率贝叶斯判别函数和决策面</h3><p>正态概率型$p(\pmb x|w_i) = N(\mu_i,\sum_i),i=1,2,\dots,c$</p>
<p>判别函数为：</p>
<p>$g_i(\pmb x) =- \frac{1}{2}(\pmb x-\mu_i) \sum_i^{-1}(\pmb x-\mu_i)^T - \frac{d}{2}ln2\pi -\frac{1}{2}ln|\sum_i| +lnP(w_i)$</p>
<blockquote>
<p>【因为】：</p>
<p>$g_i(\pmb x) =ln  p(\pmb x| w_i) +ln  P(w_i)$</p>
<p>$p(\pmb x) = \frac{1}{(2\pi)^{d/2} |\sum|^{1/2}} exp \{ -\frac{1}{2} (\pmb x-\pmb \mu)^T \sum^{-1}(\pmb x-\pmb \mu)\}$</p>
</blockquote>
<p>决策面方程:</p>
<p>$g_i(\pmb x) = g_j(\pmb x)$</p>
<p>即得到：</p>
<p>$- \frac{1}{2}[(\pmb x-\mu_i) \sum_i^{-1}(\pmb x-\mu_i)^T -(\pmb x-\mu_j) \sum_j^{-1}(\pmb x-\mu_j)^T]- \frac{d}{2}ln2\pi -\frac{1}{2} ln \frac{|\sum_i|}{|\sum_j|} +ln \frac{P(w_i)}{P(w_j)} =0$</p>
<p>下面对一些特殊情况进行分析：</p>
<p>（1）第一种情况：$\sum_i = \sigma^2I,i =1,2,\dots,c;其中I为单位阵$</p>
<p>这种情况中的每类协方差矩阵都相等，而且类内各个特征空间相互独立，具有相等的方差$\sigma^2$。</p>
<ul>
<li><p>若先验概率不等，即$P(w_i) \neq P(w_j)$</p>
<p>此时协方差矩阵为：<br>$$<br>\sideset{}{_i} \sum  = \begin{bmatrix}<br>  \sigma^2 &amp;\dots &amp; 0 \\<br>  \vdots &amp; \ddots &amp; \vdots \\<br>  0 &amp; \dots&amp; \sigma^2<br>  \end{bmatrix}<br>$$<br>即：</p>
<p>$|\sum_i| = \sigma^{2d} \\\sum_i^{-1} = \frac{1}{\sigma^2}I \\因为\sum_i*\sum_i^{-1} =I$</p>
<p>则判别函数可以写为：</p>
<p>$g_i(\pmb x) =- \frac{1}{2}(\pmb x-\mu_i) \sum_i^{-1}(\pmb x-\mu_i)^T - \frac{d}{2}ln2\pi -\frac{1}{2}ln|\sum_i| +lnP(w_i)$</p>
<p>$ \qquad = - \frac{(\pmb x-\mu_i) (\pmb x-\mu_i)^T}{2\sigma^2}- \frac{d}{2}ln2\pi -\frac{1}{2}ln\sigma^{2d} +lnP(w_i) $</p>
<p>$ \qquad =- \frac{(\pmb x-\mu_i) (\pmb x-\mu_i)^T}{2\sigma^2} +lnP(w_i)  【因为第二、三项和类别i无关，可忽略】$</p>
<p>$式中：\ (\pmb x-\mu_i) (\pmb x-\mu_i)^T = ||\pmb x -\pmb \mu_i||^2 = \sum_{j=1}^{d} (x_j -\mu_{ij})^2,i=1,2,\dots,c $</p>
<p>$表示\pmb x到类w_i的均值向量\mu_i的欧式距离平方。$</p>
</li>
</ul>
<ul>
<li><p>若先验概率不等，即$P(w_i) \neq P(w_j)$</p>
<p>计算$||\pmb x -\mu_i||^2$,然后把$\pmb x归于具有\underset{1=1,2,\dots,c}{min}||\pmb x-\mu_i||^2$的类。这种分类器也称为<strong>最小距离分类器</strong>。</p>
</li>
</ul>
<p>（2）第二种情况：$\sum_i = \sum$</p>
<p>表示只要求各类的协方差矩阵都相等。</p>
<p>判别函数式可以简化为：</p>
<p>$g_i(\pmb x) =- \frac{1}{2}(\pmb x-\mu_i) \sum^{-1}(\pmb x-\mu_i)^T +lnP(w_i)$</p>
<p>若$c$类先验概率都相等，判别函数可以简化为：</p>
<p>$g_i(\pmb x) = \pmb\gamma^2=(\pmb x-\mu_i) \sum^{-1}(\pmb x-\mu_i)^T $,也称为$\pmb x 到\mu 的Mahalanobis距离（马氏距离）的平方$</p>
<p>此时<strong>决策规则</strong>为：</p>
<p>为了观察$\pmb x$进行分类，只要计算出$\pmb x$到每类的均值$\pmb \mu_i$的马氏距离的平方$\pmb \gamma^2$，最后把$\pmb x归类于\pmb \gamma^2最小的类别$。</p>
<p>（3）第三种情况：$\sum_i \neq \sum_j ,i,j=1,2,\dots,c$</p>
<p>即各类的协方差矩阵不相等。</p>
<p>此时判别函数可以表示为：</p>
<p>$g_i(\pmb x) =- \frac{1}{2}(\pmb x-\mu_i) \sum_i^{-1}(\pmb x-\mu_i)^T - \frac{d}{2}ln2\pi -\frac{1}{2}ln|\sum_i| +lnP(w_i) \ \qquad $</p>
<p>$g_i(\pmb x)=- \frac{1}{2}(\pmb x-\mu_i) \sum_i^{-1}(\pmb x-\mu_i)^T  -\frac{1}{2}ln|\sum_i| +lnP(w_i) 【忽略掉与i无关的项】 $</p>
<p>$ \qquad = \pmb x^TW_i\pmb x + \pmb w_i^T\pmb x +w_{i0} \ 其中：\ W_i = - \frac{1}{2}\sum_i^{-1} 【d*d矩阵】$</p>
<p>$ \pmb w_i = \sum_i^{-1} \mu_i【d维列向量】$</p>
<p>$ w_{i0}=- \frac{1}{2}(\mu_i) \sum_i^{-1}(\mu_i)^T  -\frac{1}{2}ln|\sum_i| +lnP(w_i) $</p>
<p>$ 若决策域\mathbb{R_1}与\mathbb{R_2}相邻，则决策面应满足：\ g_i(\pmb x) =g_j(\pmb x) $</p>
<p>$即：\ \pmb x^T(W_i-W_j)\pmb x + (\pmb w_i-\pmb w_j)^T\pmb x +w_{i0} -w_{j0} =0 $</p>
<h1 id="概率密度函数的估计"><a href="#概率密度函数的估计" class="headerlink" title="概率密度函数的估计"></a>概率密度函数的估计</h1><p>监督参数估计——样本所属的类别及类条件概率密度函数的形式已知，而表征概率密度函数的某些参数未知。</p>
<p>非监督参数估计——已知总体样本概率密度函数形式但未知样本的所属类别，要求推断出概率密度函数的某些参数。</p>
<p>非参数估计——已知样本所属类别，但未知总体概率密度函数的形似，要求我们直接推断概率密度函数本身。</p>
<p><strong>参数估计的两种典型方法对比</strong>: </p>
<p>最大似然估计——把参数看作是确定而未知的，最好的估计值是在获得实际观察样本的概率为最大的条件下得到的。</p>
<p>贝叶斯估计——把未知的参数当作是具有某种分布的随机变量，样本的观察结果使得先验分布转化为后验分布，再根据后验分布修正原先对参数的估计。</p>
<h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><p>（1）统计量：样本包含着总体的信息，通过样本集把有关信息抽取出来，根据不同的要求构造出样本的<strong>某种函数</strong>。</p>
<p>（2）参数空间：将总体分布未知参数$\theta$的全部可容许值组成的集合，记为$\Theta$。</p>
<p>（3）点估计、估计量和估计值：点估计问题就是构造一个统计量$d(\pmb x_1,\dots,\pmb x_N)$作为参数$\theta$的估计$\hat{\theta} $，在统计学中称$\hat{\theta}为\theta的统计量$。</p>
<p>​         如果$\pmb x_1^{i},\dots,\pmb x_N^{i}是属于类别w_i$的几个样本的估计值，代入统计量得到对于$i类的\hat{\theta}$的具体数值，这个数值称为$\theta$的估计值。</p>
<p>（4）区间估计：用区间（$d_1,d_2$）作为$\theta$的可能取值范围的一种估计。这个区间称为<strong>置信区间</strong>。</p>
<h3 id="最大似然估计（maximum-likehood-estimation-MLE）"><a href="#最大似然估计（maximum-likehood-estimation-MLE）" class="headerlink" title="最大似然估计（maximum likehood estimation,MLE）"></a>最大似然估计（maximum likehood estimation,MLE）</h3><p>是一种给定观察数据来评估模型参数的方法，即：<strong>模型已知，参数未知</strong></p>
<p>如：统计全国人口的身高，首先假设身高服从正态分布，但是该分布的均值和方差未知，无法统计全国每个人的身高，但是可以通过采样，获取部分人的身高，然后通过最大似然估计来获取上述假设中的正态分布的均值和方差。</p>
<p>采样需要满足一个假设：<strong>所有的采样都是独立同分布的</strong>。</p>
<p>假设$x_1,x_2,\dots,x_n$为独立同分布的采样，$\theta 为模型参数，f为所使用的模型$，则$参数\theta 的模型f产生的采样可以表示为：$</p>
<p>$p(x_1,x_2,\dots,x_n| \theta) = p(x_1|\theta) \cdot p(x_1|\theta)\dots p(x_n|\theta)$</p>
<p>其中$x_1,x_2,\dots,x_n$已知，$\theta$未知。</p>
<p>似然函数定义为：</p>
<p>$L(\theta|x_1,x_2,\dots,x_n) = p(x_1,x_2,\dots,x_n|\theta) = \prod_{i=1}^{n}p(x_i|\theta)$</p>
<p>对数似然（两边取对数）：</p>
<p>$lnL(\theta|x_1,x_2,\dots,x_n)  = \sum_{i=1}^{n}ln p(x_i|\theta)$</p>
<p>平均对数似然：</p>
<p>$\hat{l} = \frac{1}{n}ln L$</p>
<p><strong>最大似然函数</strong>：（最大的平均似然）</p>
<p>$\hat{\theta}_{mle} = \underset{\theta \in \Theta}{arg  max} \hat{l}(\theta|x_1,x_2,\dots,x_n)$</p>
<blockquote>
<p>【说明】：</p>
<p>$\underset{x}{arg  max} f(x)= \{x|\forall y:f(y) \leq f(x) \}$，表示$f(x)具有最大值M的x的值的集合。$</p>
<p>同理，$\underset{x}{arg  min} f(x)$表示$f(x)具有最小值m的x的值的集合。$</p>
</blockquote>
<p><strong>最大似然估计量</strong>：</p>
<p>令$l(\theta)$为样本集$\{x_1,x_2,\dots,x_n\}$的似然函数，如果$\hat{\theta}$是参数空间$\Theta$中能使得似然函数$l(\theta)极大化的\theta的值，称\hat{\theta}为参数\theta的最大似然估计量。$</p>
<p><strong>最大似然估计量的求解</strong>：</p>
<p>在似然函数满足连续、可微的正则条件下，最大似然估计量的解为：</p>
<p>$\frac{dl(\theta)}{d\theta} = 0，一般转化为对数求解更为容易，即：$</p>
<p>$令H(\theta)= ln  l(\theta) $</p>
<p>$ 此时最大似然估计量为:\ \frac{dH(\theta)}{d\theta} =0的解。$</p>
<p>如果未知参数不止一个，有s个，则：</p>
<p>$\pmb \theta = [\theta_1,\theta_2,\dots,\theta_s]^T $</p>
<p>$H(\pmb \theta) = ln[L(\theta)] = ln  p(x_1,x_2,\dots,x_n|\theta_1,\theta_2,\dots,\theta_s) $</p>
<p>$在样本独立抽出的条件下，可写为：$</p>
<p>$H(\pmb \theta) = ln \prod_{k=1}^n p(x_k| \pmb \theta) = \sum_{k=1}^n ln  p(x_k|\pmb \theta) $</p>
<p>$令：  \nabla_{\theta} = [\frac{\partial}{\partial \theta_1},\dots,\frac{\partial}{\partial \theta_s}]^T $</p>
<p>$则有：\  \nabla_{\theta}H(\pmb \theta) = \sum_{k=1}^n \nabla_{\theta}ln  p(x_k| \pmb\theta) =0 $</p>
<p>$由这s个方程可以获得\pmb \theta 的最大似然估计量 \hat{\pmb \theta}。$</p>
<p>$存在多解情况，但不是都使得似然函数最大，只有\hat{\pmb \theta}才使得似然函数最大。$</p>
<blockquote>
<p>e.g.1  假设一组连续采样值$(x_1,x_2,\dots,x_n)$，服从正态分布，标准差已知，问这个正态分布的期望值为多少时，产生这个已知数据的概率最大？</p>
<p>解：</p>
<p>$L(\theta|x_1,x_2,\dots,x_n) = p(x_1,x_2,\dots,x_n|\theta) = \prod_{i=1}^{n}p(x_i|\theta)$</p>
<p>可得：</p>
<p>$L(\theta|x_1,x_2,\dots,x_n)  = (\frac{1}{\sigma \sqrt{2\pi}})^nexp(-\frac{1}{2\sigma^2} \sum_{i=1}^n(x_i - \mu)^2)$</p>
<p>对$\mu$求导可得：</p>
<p>$(\frac{1}{\sigma \sqrt{2\pi}})^nexp(-\frac{1}{2\sigma^2} \sum_{i=1}^n(x_i - \mu)^2) \frac{(\sum_{i=1}^nx_i-n \mu)}{\sigma^2}$</p>
<p>令上式子等于零可得，最大似然估计的结果为：</p>
<p>$\hat{\mu} = \frac{x_1+x_2+\dots+x_n}{n}$</p>
<p>【结论】：</p>
<p>均值向量$\mu$的最大似然估计是样本均值，对于多元正态分布情况下即为：</p>
<p>$\hat{\mu} = \frac{1}{N}\sum_{k=1}^N \pmb x_k$。</p>
<hr>
<p>e.g.2  假设随机变量$x服从均匀分布$。但参数$\theta_1,\theta_2$未知</p>
<p>$p(x|\theta) = \cases{\frac{1}{\theta_2-\theta_1},\theta_1&lt;x&lt;\theta_2 \ 0, 其它}$</p>
<p>从总体中独立地抽取n个样本$x_1,x_2,\dots,x_n$,则似然函数为：</p>
<p>$l(\pmb \theta) = \cases{ p(x_1,x_2,\dots,x_n| \pmb \theta) =\frac{1}{(\theta_2-\theta_1)^n} \ 0            }$</p>
<p>对数似然函数为：</p>
<p>$H(\pmb \theta) = -N ln(\theta_2-\theta_1) \\\frac{\partial H}{\partial \theta_1}=N·\frac{1}{\theta_2-\theta_1}=0\\\frac{\partial H}{\partial \theta_2}=-N·\frac{1}{\theta_2-\theta_1}=0$</p>
<p>上述两式成立必然解出的参数$\theta_1,\theta_2$有一个是无穷大，结果无意义。</p>
<p>采取方法：</p>
<p>当$\theta_2-\theta_1越小，似然函数越大，对于观察样本x_1,x_2,\dots,x_n，假设其中最大的一个为x^{‘’}，最小的一个为x^{‘}，则：$</p>
<p>显然$\theta_2不能小于 x^{‘’}，\theta_1不能大于x^{‘}，因此\theta_2-\theta_1最小的可能值为x^{‘’}-x^{‘},此时\theta的最大似然估计量为：\ \hat{\theta_1}= x^{‘} \\\hat{\theta_2} = x^{‘’}$</p>
</blockquote>
<h3 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h3><h4 id="回顾贝叶斯决策："><a href="#回顾贝叶斯决策：" class="headerlink" title="回顾贝叶斯决策："></a>回顾贝叶斯决策：</h4><p>设状态空间为:$\Omega = \{w_1,w_2,\dots,w_c\}$</p>
<p>识别对象: $\pmb x = [x_1,x_2,\dots,x_d]^T$</p>
<p>设真实状态$w_j$，而采取的决策$\alpha_i$所造成的损失为$\lambda(\alpha_i,w_j)$。</p>
<p><strong>条件期望损失或条件风险</strong>为：</p>
<p>$R(\alpha_i|\pmb x)=E[\lambda(\alpha_i,w_j)] =\sum_{j=1}^c \lambda(\alpha_i,w_j)P(w_j| \pmb x)，i=1,2,\dots,a$</p>
<p>由于$\pmb x$是随机向量的观察值，所以，对于不同的$\pmb x$采取的决策$\alpha_i$时，其条件风险不同。把决策$\alpha$看成随机向量$\pmb x$的函数，记为$\alpha(\pmb x)$，定义<strong>期望风险</strong>$R$为：</p>
<p>$R=\int_{E^d} R(\alpha_i(\pmb x)|\pmb x)p(\pmb x) d\pmb x\ \quad = \int_{E^d} \lambda(\alpha_i,w_j)P(w_j| \pmb x)p(\pmb x)d\pmb x \ \quad =\int_{E^d} \sum_{j=1}^c \lambda(\alpha_i,w_j)P(\pmb x,w_j)d\pmb x $</p>
<p>$R称为贝叶斯风险，使得R最小的决策\alpha_k称为贝叶斯决策$</p>
<p>若决策空间为$A=(\alpha_1,\alpha_2,\dots,\alpha_a)$，当：</p>
<p>$\int_{E^d} R(\alpha_k(\pmb x)|\pmb x)p(\pmb x) d\pmb x = \underset{i=1,2,\dots,a}{min}\int_{E^d} R(\alpha_i(\pmb x)|\pmb x)p(\pmb x) d\pmb x$</p>
<p>则采取决策$\alpha_k$。</p>
<hr>
<h4 id="贝叶斯估计概念"><a href="#贝叶斯估计概念" class="headerlink" title="贝叶斯估计概念"></a>贝叶斯估计概念</h4><p>设有一个样本集$\mathcal{X}而不是一个x$，要求找出估计量$\hat{\theta}(而不是最佳决策\alpha_k)$，用来估计样本集所属总体分布的某个真实参数$\theta$（而不是真实状态$w_j $）使得带来的贝叶斯风险最小。</p>
<table>
<thead>
<tr>
<th style="text-align:center">决策问题</th>
<th style="text-align:center">估计问题</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">样本$x$</td>
<td style="text-align:center">样本集 $\mathcal{X}$</td>
</tr>
<tr>
<td style="text-align:center">决策 $\alpha_i$</td>
<td style="text-align:center">估计量 $\hat{ \theta }$</td>
</tr>
<tr>
<td style="text-align:center">真实状态$w_j$</td>
<td style="text-align:center">真实参数$ \theta $</td>
</tr>
<tr>
<td style="text-align:center">状态空间$A$是离散空间</td>
<td style="text-align:center">参数空间$\Theta $是连续空间</td>
</tr>
<tr>
<td style="text-align:center">先验概率$P(w_j)$</td>
<td style="text-align:center">参数的先验分布$p(\theta)$</td>
</tr>
</tbody>
</table>
<p>$R=\int_{E^d} \int_{\Theta}\lambda(\hat{\theta},\theta)p(\pmb x,\theta) d\theta d\pmb x  $</p>
<p>$\quad =\int_{E^d} \int_{\Theta}\lambda(\hat{\theta},\theta)p(\theta | \pmb x) p(\pmb x)d\theta d\pmb x $</p>
<p>$ \quad =\int_{E^d} p(\pmb x)\int_{\Theta}\lambda(\hat{\theta},\theta)p(\theta | \pmb x) d\theta d\pmb x $</p>
<p>$ \quad =\int_{E^d}R(\hat{\theta}| \pmb x)p(\pmb x)d\pmb x $</p>
<blockquote>
<p>$\ 因为：\ 根据贝叶斯公式：\ p(\theta| \pmb x) = \frac{p(\pmb x| \theta)p(\theta)}{ \int p(\pmb x| \theta)p(\theta)d\theta} = \frac{p(\pmb x| \theta)p(\theta)}{p(\pmb x)} \ 整理即得：\ p(\theta,\pmb x) = p(\theta| \pmb x)p(\pmb x) = p(\pmb x| \theta)p(\theta)$</p>
</blockquote>
<p>所以：</p>
<p>$R(\hat{\theta}| \pmb x) = \int_{\Theta}\lambda(\hat{\theta},\theta)p(\theta | \pmb x) d\theta$</p>
<p>其中$E^d为\pmb x 得取值的d维欧氏空间，\Theta 为\theta 的可能取值的参数空间。$</p>
<p>$R(\hat{\theta}| \pmb x)$为给定$\pmb x $条件下的估计量$\hat{\theta} $的期望损失。定义：</p>
<p>如果$\theta$的估计量$\hat{\theta}能使得$条件风险$R(\hat{\theta}| \pmb x)$最小，称$\hat{\theta}$是关于$\theta$的<strong>贝叶斯估计量</strong>。</p>
<hr>
<h4 id="求解贝叶斯估计量"><a href="#求解贝叶斯估计量" class="headerlink" title="求解贝叶斯估计量"></a>求解贝叶斯估计量</h4><p>必须定义适当损失函数，一般来说，不同的损失函数，得到不同的贝叶斯估计量$\hat{\theta}$。</p>
<p>规定损失函数为：</p>
<p>$\lambda(\hat{\theta},\theta) = (\theta - \hat{\theta})^2$，即<strong>平方误差损失函数</strong>。</p>
<p>【定理】：</p>
<p>如果损失函数为二次函数，即：$\lambda(\hat{\theta},\theta) = (\theta - \hat{\theta})^2$，则$\theta$的贝叶斯估计量$\hat{\theta}$是给定$\pmb x 时\theta的条件期望$，即：</p>
<p>$\hat{\theta} = E[\theta| \pmb x] = \int_{\Theta} \theta p(\theta | \pmb x)d\theta$</p>
<blockquote>
<p>proof:</p>
<p>贝叶斯估计使得贝叶斯风险R最小，即使得：</p>
<p>$R=\int_{E^d}R(\hat{\theta}| \pmb x)p(\pmb x)d\pmb x $达到最小，即使得：</p>
<p>$R(\hat{\theta}| \pmb x) = \int_{\Theta} \lambda(\hat{\theta},\theta) p(\theta | \pmb x)d\theta = \int_{\Theta} (\theta - \hat{\theta})^2 p(\theta | \pmb x)d\theta$达到最小。</p>
<p>因为：</p>
<p>$R(\hat{\theta}| \pmb x)  = \int_{\Theta} (\theta - \hat{\theta})^2 p(\theta | \pmb x)d\theta $</p>
<p>$ \qquad =  \int_{\Theta}[ (\theta - E(\theta| \pmb x) +E(\theta| \pmb x)-\hat{\theta})^2 p(\theta | \pmb x)d\theta $</p>
<p>$ \qquad =  \int_{\Theta}[ (\theta - E(\theta| \pmb x) ]^2p(\theta | \pmb x)d\theta+ \int_{\Theta}[ (E(\theta| \pmb x) - \hat{\theta} ]^2p(\theta | \pmb x)d\theta $</p>
<p>$+2\int_{\Theta}[ (\theta - E(\theta| \pmb x) ][E(\theta| \pmb x)-\hat{\theta}] p(\theta | \pmb x)d\theta $</p>
<p>$ 交叉项：$</p>
<p>$ \int_{\Theta}[ (\theta - E(\theta| \pmb x) ][E(\theta| \pmb x)-\hat{\theta}] p(\theta | \pmb x)d\theta $</p>
<p>$ =[E(\theta| \pmb x)-\hat{\theta}] \times  \int_{\Theta}[ (\theta - E(\theta| \pmb x) ] p(\theta | \pmb x)d\theta $</p>
<p>$ = [E(\theta| \pmb x)-\hat{\theta}] \times\{\int_{\Theta}\theta  p(\theta | \pmb x)d\theta -E(\theta| \pmb x)\int_{\Theta}  p(\theta | \pmb x)d\theta \} $</p>
<p>$ =[E(\theta| \pmb x)-\hat{\theta}] \times [E(\theta| \pmb x)-E(\theta| \pmb x)] =0 $</p>
<p>所以：</p>
<p>$R(\hat{\theta}| \pmb x)  =\int_{\Theta}[ (\theta - E(\theta| \pmb x) ]^2p(\theta | \pmb x)d\theta+ \int_{\Theta}[ (E(\theta| \pmb x) - \hat{\theta} ]^2p(\theta | \pmb x)d\theta  $</p>
<p>第一项非负，且与$\hat{\theta}$无关，第二项非负，当且仅当：</p>
<p>$\hat{\theta} = E[\theta| \pmb x] = \int_{\Theta} \theta p(\theta | \pmb x)d\theta$</p>
<p>时条件风险$R(\hat{\theta}| \pmb x)$最小。</p>
</blockquote>
<p>综上所述，求解平方误差损失函数情况下的贝叶斯估计量$\hat{\theta}$，步骤如下：</p>
<p>（1）确定$\theta的$先验分布$p(\theta)$</p>
<p>（2）有样本集$\mathcal{X}=\{x_1,x_2,\dots,x_n\}，求出样本联合分布p(\mathcal{X}| \theta)$</p>
<p>（3）利用贝叶斯公式，求出$\theta$的后验分布，即：</p>
<p>​           $\ p(\theta| \mathcal{X}) = \frac{p(\mathcal{X}| \theta)p(\theta)}{ \int p(\mathcal{X}| \theta)p(\theta)d\theta} $</p>
<p>（4）利用定理：$\hat{\theta} = E[\theta| \pmb x] = \int_{\Theta} \theta p(\theta | \pmb x)d\theta$求出贝叶斯估计量。</p>
<h3 id="贝叶斯学习"><a href="#贝叶斯学习" class="headerlink" title="贝叶斯学习"></a>贝叶斯学习</h3><p>相对于贝叶斯估计，前三步一致，当求出后验分布后，不再估计$\hat{\theta}$，而是直接通过联合密度求类条件概率密度，即：</p>
<p>$p(\pmb x| \mathcal{X}) = \int p(\pmb x,\theta| \mathcal{X})d\theta = \int p(\pmb x| \theta)p(\theta| \mathcal{X})d\theta$</p>
<p>其中参数$\theta 的后验概率密度p(\theta| \mathcal{X})$，根据贝叶斯公式：</p>
<p>$\ p(\theta| \mathcal{X}) = \frac{p(\mathcal{X}| \theta)p(\theta)}{ \int p(\mathcal{X}| \theta)p(\theta)d\theta} $</p>
<p>如果$p(\mathcal{X}|\theta)在\theta =\hat{\theta}处有尖锐凸峰$，根据最大似然法有：</p>
<p>$p(\pmb x| \mathcal{X}) \approx p(\pmb x| \hat{\theta})$，其中$\hat{\theta} 是\theta 的最大似然估计值$。</p>
<h3 id="最大似然估计-amp-贝叶斯估计-amp-贝叶斯学习关系"><a href="#最大似然估计-amp-贝叶斯估计-amp-贝叶斯学习关系" class="headerlink" title="最大似然估计&amp;贝叶斯估计&amp;贝叶斯学习关系"></a>最大似然估计&amp;贝叶斯估计&amp;贝叶斯学习关系</h3><p>（1）最大似然估计把参数$\theta$看成确定的未知参数，似然函数定义为：</p>
<p>$L(\theta|x_1,x_2,\dots,x_n) = p(x_1,x_2,\dots,x_n|\theta) = \prod_{i=1}^{n}p(x_i|\theta)$，其中$\mathcal{X} = \{x_1,x_2,\dots,x_n\}$</p>
<p>最大似然估计就是求使得似然函数$l(\theta)$为最大时的$\hat{\theta}$作为最大似然估计量。</p>
<p>（2）贝叶斯估计把参数$\theta$看成随机的未知参数，一般$\theta$具有先验分布$p(\theta)$。样本通过似然函数$p(\mathcal{X}| \theta)$，并利用贝叶斯公式将$\theta$的先验分布转为后验分布：</p>
<p>$\ p(\theta| \mathcal{X}) = \frac{p(\mathcal{X}| \theta)p(\theta)}{ \int p(\mathcal{X}| \theta)p(\theta)d\theta} $</p>
<p>$p(\theta| \mathcal{X}) $包含了关于$\theta$的先验信息及样本提供的后验信息，然后利用定理：</p>
<p>【如果损失函数为二次函数，即：$\lambda(\hat{\theta},\theta) = (\theta - \hat{\theta})^2$，则$\theta$的贝叶斯估计量$\hat{\theta}$是给定$\pmb x 时\theta的条件期望$，即：</p>
<p>$\hat{\theta} = E[\theta| \pmb x] = \int_{\Theta} \theta p(\theta | \pmb x)d\theta$】</p>
<p>求出贝叶斯估计量$\hat{\theta}$，使得平方误差损失函数的贝叶斯风险极小化。</p>
<p>（3）贝叶斯学习利用$\theta$的先验分布及样本提供的信息求出$\theta$的后验分布$p(\theta| \mathcal{X})$，然后直接求总体分布：</p>
<p>$p(\pmb x| \mathcal{X}) =  \int p(\pmb x| \theta)p(\theta| \mathcal{X})d\theta$</p>
<h2 id="非参数估计"><a href="#非参数估计" class="headerlink" title="非参数估计"></a>非参数估计</h2><h3 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h3><p>参数估计是在已知总体分布的形式，很多实际问题不知道总体分布，或者总体分布不是一些通常遇到的典型分布，不能写成某些参数的函数。</p>
<p>于是有了<strong>直接样本估计总体分布</strong>的方法，称之为<strong>估计分布的非参数方法</strong>。</p>
<p>【基本思想】：</p>
<p>每个样本都对估计$p(x)$有贡献，将这些贡献叠加（差分拟合），得到$p(x)$的一个估计。</p>
<h3 id="估计方法"><a href="#估计方法" class="headerlink" title="估计方法"></a>估计方法</h3><p>随机变量$\pmb x$落入区域$\mathcal{R}$的概率P为：</p>
<p>$p= \int_{\mathcal{R}} p(\pmb x)d\pmb x$</p>
<p>其中$p(\pmb x)$为总体概率密度函数。若从总体中独立抽取$n$个样本$x_1,x_2,\dots,x_n$,分别以$p(x_1),p(x_2),\dots,p(x_n)$出现，其中有$k$个样本落入区域$\mathcal{R}$的概率为$P_k$，服从二项分布。即：</p>
<p>$P_k = C_n^k p^k(1-p)^{n-k} = \frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}$</p>
<p>其中$p$是样本$\pmb x $落入区域$\mathcal{R}$的概率，$x_k$是随机抽取落入$\mathcal{R}$的样本，数目$k$也是随机的，。</p>
<p>则：</p>
<p>​     $k$的期望值为：$E(k) =np$</p>
<p>​     $p的估计为： \hat{p} \approx  \frac{k}{n}$</p>
<p>如果区域$\mathcal{R}$足够小，以至于$p(\pmb x)$在这个很小的区域内没有什么变化，可以认为是恒定不变的，则：</p>
<p>$p= \int_{\mathcal{R}} p(\pmb x)d\pmb x = p(\pmb x)*V$</p>
<p>其中$V$是区域$\mathcal{R}$的体积。即：</p>
<p>$\hat{p} = p= \hat{p}(\pmb x) V \approx \frac{k}{n}$</p>
<p>$\hat{p}(\pmb x) = \frac{k/n}{V}$</p>
<p>（1）如果体积$V$固定</p>
<p>$\frac{\hat{p}}{V}= \frac{\int_{\mathcal{R}}\hat{p}(\pmb x)d\pmb x}{\int_{\mathcal{R}}d\pmb x}$</p>
<p>（2）若训练样本$n$确定的，令$\mathcal{R}$不断缩小，此时会出现两种情况$\cases{\hat{p}(\pmb x)=0\\\hat{p}(\pmb x) \rightarrow \infty}$。</p>
<p>假设有无限多的样本，构造一串包括$\pmb x$的区域序列$\mathcal{R_1},\dots,\mathcal{R_n},\dots$，对$\mathcal{R_1}$采用一个样本估计，对$\mathcal{R_2}$采用两个样本估计，依此。</p>
<p>设$V_n是\mathcal{R_n}的体积，k_n是落入区域\mathcal{R_n}的样本数，\hat{p}_n(\pmb x) 是p(\pmb x)的第n次估计，$则：</p>
<p>​               $\hat{p}_n(\pmb x) = \frac{k_n/n}{V_n}$</p>
<p>添加限制条件：</p>
<p>$\cases{(1) \underset{n \rightarrow \infty}{\lim} V_n =0\ (2)\underset{n \rightarrow \infty}{\lim} k_n = \infty  \(3)\underset{n \rightarrow \infty}{\lim} \frac{k_n}{n} =0       } $</p>
<p>使得$\hat{p}_n(\pmb x)$收敛于$p(\pmb x)$。</p>
<p>为了满足这三个条件，区域$\mathcal{R}$序列的选择方法有两个基本途径：</p>
<p>$(1)、parzen窗法：把包含\pmb x 点的区域序列V_n选为训练样本数目n的某个函数（如：V_n = \frac{1}{\sqrt{n}}）\ \qquad 并且不断缩小，此时对k_n和\frac{k_n}{n}都要加限制条件。$</p>
<p>$(2)、k_n近邻法：让k_n为n的某个函数（如：k_n= \sqrt{n}），而V_n选取正好是使相应的\mathcal{R_n}包含\ \qquad \pmb x的k_n个近邻。$</p>
<h3 id="parzen窗法"><a href="#parzen窗法" class="headerlink" title="parzen窗法"></a>parzen窗法</h3><h4 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h4><p>假定围绕$\pmb x的区域\mathcal{R_n}$是一个超立方体，其棱长为$h_n$，$d$为特征空间的维数，则超立方体的体积为：</p>
<p>$V_n = h_n^d$</p>
<p>为考查训练样本是否落入超立方体的内部，则检查$x-x_k$的每个分量是否小于$h_n/2$，其中$x$窗函数的中心。</p>
<p>定义窗函数：</p>
<p>​                         $\phi(\mu)=\cases{1,当|\mu_j| \le \frac{1}{2},j=1,2,\dots,d \ 0,其它}$</p>
<p>其中$\phi(\mu)$是以原点为中心的一个超立方体。</p>
<p>所以：</p>
<p>$当 \pmb x_i 落入以\pmb x 为中心的，体积为V_n的超立方体内时，\phi(\mu)= \phi[\frac{\pmb x-\pmb x_i}{h_n}]=1，否则为0。$</p>
<p>即：</p>
<p>若令:$\mu = \frac{\pmb x-\pmb x_i}{h_n}$，则：</p>
<p>​                     $\phi( \frac{\pmb x-\pmb x_i}{h_n})=\cases{1,当|\pmb x-\pmb x_k|_j \le \frac{h_n}{2},j=1,2,\dots,d \ 0,其它}$</p>
<p>因此落入该超立方体的样本数为：</p>
<p>$k_n = \sum_{i=1}^n\phi[\frac{\pmb x-\pmb x_i}{h_n}] $</p>
<p>代入$\hat{p}_n(\pmb x) = \frac{k_n/n}{V_n}$可得到$parzen$窗函数的<strong>基本公式</strong>：</p>
<p>​                   $\hat{p}_n(\pmb x) = \frac{1}{n} \sum_{j=1}^n \frac{1}{V_n} \phi(\frac{\pmb x-\pmb x_i}{h_n})$</p>
<p>实质上：</p>
<p>窗函数的作用是内插，每一个样本对估计起到的作用依赖于它到窗函数中心$\pmb x $的距离，所以$h_n$对$\hat{p}(\pmb x)$的估计有重要影响。</p>
<h4 id="估计量-hat-p-n-pmb-x-为密度函数的条件"><a href="#估计量-hat-p-n-pmb-x-为密度函数的条件" class="headerlink" title="估计量$\hat{p}_n(\pmb x)$为密度函数的条件"></a>估计量$\hat{p}_n(\pmb x)$为密度函数的条件</h4><p>必须满足：</p>
<p>（1）$\phi(\mu ) \ge 0$</p>
<p>（2）$\int \phi(\mu) d\mu =1$</p>
<p>此时窗函数本身具有密度函数的形式，则$\hat{p}_n(\pmb x)$一定为密度函数。</p>
<h4 id="窗函数选择"><a href="#窗函数选择" class="headerlink" title="窗函数选择"></a>窗函数选择</h4><p>（1）矩形窗</p>
<p>​                         $\phi(\mu)=\cases{1,当|\mu| \le \frac{1}{2} \ 0,其它}$</p>
<p>（2）正态窗（高斯窗）</p>
<p>​                         $\phi(\mu)= \frac{1}{\sqrt{2\pi}}exp\{-\frac{1}{2}\mu^2\}$</p>
<p>（3）指数窗(曼哈顿函数)</p>
<p>​                         $\phi(\mu)=exp\{-|\mu|\}$</p>
<h4 id="窗宽-h-n-对估计量-hat-p-n-pmb-x-的影响"><a href="#窗宽-h-n-对估计量-hat-p-n-pmb-x-的影响" class="headerlink" title="窗宽$h_n$对估计量$\hat{p}_n(\pmb x)$的影响"></a>窗宽$h_n$对估计量$\hat{p}_n(\pmb x)$的影响</h4><p>在样本数有限的条件下，窗宽$h_n$对估计量的影响很大。</p>
<p>定义函数：</p>
<p>$\delta_n(\pmb x) = \frac{1}{V_n}\phi(\frac{\pmb x}{h_n})$</p>
<p>可以把$\hat{p}_n(\pmb x)$看成一个平均值，即：</p>
<p>$\hat{p}_n(\pmb x) = \frac{1}{n} \sum_{j=1}^n \delta_n(\pmb x-\pmb x_i)$</p>
<p>因为$V_n = h_n^d$，所以，$h_n影响\delta_n(\pmb x)$的幅度，即：</p>
<p>$(1)、若h_n很大，则\delta_n(\pmb x)的幅度很小，只有\pmb x_i离\pmb x较远时候才能使得\delta_n(\pmb x)和\delta(0)相差得多一些。\ 此时，\hat{p}_n(\pmb x)变成N个宽度较大且函数值变化缓慢得函数的叠加，从而使得它是p(\pmb x)的一个平均估计。$</p>
<p>$(2)、若h_n很小，则\delta_n(\pmb x -\pmb x_i)的幅度很大，此时\hat{p}_n(\pmb x)就成了n个以样本为中心的尖峰函数的叠加，\\估计的统计变动很大。此时，在h_n \rightarrow 0的极端条件下，\delta_n(\pmb x-\pmb x_i)趋于一个以\pmb x_i 为中心的\delta函数，\\从而使得\hat{p}_n(\pmb x)趋于以样本为中心的\delta函数的叠加。   $</p>
<p>【所以】:</p>
<p>$h_n$对$\hat{p}(\pmb x)$的估计有重要影响,可以让$V_n$随着$n$的不断增加而缓慢趋于零，这样使得$\hat{p}_n(\pmb x)收敛于p(\pmb x)$。</p>
<p>实际问题中样本有限，需要做适当折中考虑。</p>
<h3 id="K-近邻估计"><a href="#K-近邻估计" class="headerlink" title="K-近邻估计"></a>K-近邻估计</h3><h4 id="提出背景"><a href="#提出背景" class="headerlink" title="提出背景"></a>提出背景</h4><p>$parzen$窗估计存在一个具体问题是体积序列$V_1,\dots,V_n,\dots$的选择问题。对任何有限的样本数$n$，得到的结果对初值$V_1$很敏感，如果：</p>
<p>$（1）、V_1选太小，大部分体积为空，从而使得\hat{p}_n(\pmb x)估计不稳定 $</p>
<p>$（2）、V_1选太大，则\hat{p}_n(\pmb x)估计比较平坦，反映不出真实总体分布的变化。$</p>
<h4 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h4><p>使用体积为数据的函数，而不是样本数$n$函数。</p>
<p>即：</p>
<p>如为了从$n$个样本中估计$p(\pmb x)$，可以先确定$n$的某个函数$k_n$，然后在$\pmb x $的周围选择一个体积，并让它不断增长至捕获$k_n$个样本为止，这样样本为$\pmb x$的$k_n$个近邻。</p>
<p>如果附近的密度比较高，则包含$k_n$个样本的体积自然相对比较小，从而提高分辨力；如果附近密度较低，则体积较大，但一进入高密度区就会停止增大。</p>
<h4 id="最邻近规则"><a href="#最邻近规则" class="headerlink" title="最邻近规则"></a>最邻近规则</h4><p>假定有$c$个模式类别$w_1,w_2,\dots,w_c$，每类有标明类别的训练样本集有$N_i$个样本$i=1,2,\dots,c$,</p>
<p>规定$w_i$判别函数为：</p>
<p>$g_i(\pmb x)= \underset{k}{min} \Arrowvert \pmb x- \pmb x_i^k \Arrowvert ，k= 1,2,\dots,N_i$</p>
<p>其中：</p>
<p>$\pmb x_i^k中i表示w_i类，k表示w_i类N_i个样本中的第k个$。</p>
<p>若：</p>
<p>$g_j(\pmb x)= \underset{i}{min}  g_i(\pmb x)，i= 1,2,\dots,c$</p>
<p>则$\pmb x \in w_j$</p>
<h4 id="最邻近法的错误率分析"><a href="#最邻近法的错误率分析" class="headerlink" title="最邻近法的错误率分析"></a>最邻近法的错误率分析</h4><p>设$N$个样本下的平均错误率为$P_N(e)，且样本\pmb x的最近邻为\pmb x’则：$</p>
<p>$P_N(e) = \iint P_N(e|\pmb x,\pmb x’)p(\pmb x’| \pmb x)d\pmb x’p(\pmb x)d\pmb x$</p>
<p>定义最近邻法渐近平均错误率为$P$，则：</p>
<p>$P= \underset{N \rightarrow \infty}{\lim} P_N(e)$</p>
<p>存在以下关系：</p>
<p>$P’ \le P \le P’\times(2- \frac{c}{c-1}P’)$</p>
<p>其中$P’$表示贝叶斯错误率，$c$为分类数。</p>
<p>由于$P’$一般较小，所以上式可粗略表示为：</p>
<p>$P’ \le P \le 2P’$</p>
<p>即近邻法错误率在贝叶斯错误和两倍贝叶斯错误率之间。</p>
<h4 id="k-近邻规则​（KNN）"><a href="#k-近邻规则​（KNN）" class="headerlink" title="$k$-近邻规则​（KNN）"></a>$k$-近邻规则​（KNN）</h4><p>最近邻规则的一个推广即是”k-近邻规则”。取未知样本的$\pmb x $的$k$个近邻，看这个$k$个近邻多数属于哪一类，就把$\pmb x$归为哪一类。即：</p>
<p>假定有$c$个模式类别$w_1,w_2,\dots,w_c$，训练样本集有$N$个样本，每个样本记为$x_j,j=1,2,\dots,N$,确定一个常数$k$，记未知测试样本为$\pmb x $。</p>
<p>从未知测试样本点$\pmb x$开始生长，不断扩大区域，直至包含进$k$个训练样本点为止。把这个$k$个样本构成集合$\Omega(k)$，如果$\Omega(k)$中出现类别最多的类别是$w_i$，则$\pmb x \in w_i $。</p>
<h3 id="近邻法存在缺点"><a href="#近邻法存在缺点" class="headerlink" title="近邻法存在缺点"></a>近邻法存在缺点</h3><p>（1）需要将所有样本存入计算机，每次决策都要计算待识别的样本$\pmb x$和全部训练样本$\pmb x_i^k$，$i=1,2,\dots,c,k=1,2,\dots,N_i$之间的距离进行比较。<strong>存储量和计算量很大</strong>。</p>
<p>（2）虽然在所有情况下，对未知样本$\pmb x$都可以进行决策，但当错误代价很大时，会有较大风险。</p>
<p>（3）要求样本$N \rightarrow \infty$，这在实际场合中无法实现。</p>
<h3 id="近邻法改进算法"><a href="#近邻法改进算法" class="headerlink" title="近邻法改进算法"></a>近邻法改进算法</h3><p>（1）快速算法</p>
<p>基本考虑是将样本分级分成一些不相交的子集，并在子集的基础上进行搜索，对最近邻和k-近邻都适用。</p>
<p>（2）剪辑近邻法</p>
<p>基本思想：</p>
<p>​        将样本集分为两个独立的结合——设计集和考试集，并利用设计集设计分类器，用考试集估计错误率，在两个集合独立的条件下，对错误率的估计较为准确。</p>
<p>主要过程：</p>
<p>​        设$N$个样本分成$c$类，并用集合$\mathcal{X}^N = \{\mathcal{X_1}^{N_1},\mathcal{X_2}^{N_2},\dots,\mathcal{X_c}^{N_c} \}$表示，</p>
<p>其中一类表示为$\mathcal{X_i}^{N_i}= \{\pmb x_i^k\} (i=1,2,\dots,N_i)$。</p>
<p>第一步：利用已知的样本集$\mathcal{X}^N$中的样本进行预分类，并剪辑掉错误的分类的样本，留下样本构成的剪辑样本集$\mathcal{X}^{NE}$，显然$\mathcal{X}^{NE}$要比$\mathcal{X}^N$中的样本数要少（即剪辑）。</p>
<p>第二步：利用剪辑的样本集$\mathcal{X}^{NE}$和近邻规则对未知样本$\pmb x$进行分类。</p>
<p>（2）压缩近邻法</p>
<p>剪辑近邻法只能去掉两类边界附近的样本，而靠近两类中心的样本几乎没有去掉，而根据近邻规则，这些样本的大多数对分类决策没有什么用处，因此在剪辑的基础上，再去掉一部分这样的样本有助于进一步缩短计算时间和降低存储要求。</p>
<p>CONDENSING算法：</p>
<p>有两个存储器，STORE和GRABBAG，把第一个样本放入STORE中，其它所有样本放入GRABBAG中，</p>
<p>第一步：用当前STORE的中的样本以1近邻规则对GRABBAG的第$i$类样本进行分类。如果分类正确，则该样本仍然送回中GRABBAG，否则放入STORE中，对GARBBAG中的所有样本重复此过程。</p>
<p>第二步：若GRABBAG中所有样本在进行上述检验过程中没有一个样本从GRABBAG转到STORE或者当GRABBAG为空时，算法终止，否则转入第一步 。</p>
<h1 id="线性判别函数"><a href="#线性判别函数" class="headerlink" title="线性判别函数"></a>线性判别函数</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>实际问题中，由于样本特征空间的类条件概率密度的形式常常很难确定，利用parzen窗函数等非参数方法估计分布需要大量样本，而且随着样本特征空间的维数增加所需要样本数急剧增加。</p>
<p>在实际问题中，往往不需要去恢复类条件概率密度，而是<strong>利用样本集直接设计分类器</strong>。即：</p>
<p><u>首先给定一个判别函数类，然后利用样本集确定判别函数中的未知参数</u>。</p>
<p>线性判别函数是统计模式识别中基本方法之一，首先假定判别函数$g(\pmb x)$是$\pmb x$的线性函数，即$g(\pmb x) = \pmb w^T\pmb x+w_0$,对于$c$类问题，可以定义$c$个判别函数，$g_i(\pmb x) = \pmb w_i^T\pmb x +w_{i0},i=1,2,\dots,c$。利用样本去估计各$\pmb w_i$和$w_{i0}$，并把未知样本$\pmb x$归类到具有最大判别函数值的类别中去。</p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>一般形式:</p>
<p>$g(\pmb x) = \pmb w^T\pmb x + w_0$</p>
<p>其中$\pmb x $ 称为$d$维样本向量，$\pmb w$称为权向量，$w$是个常数，称为阈值权。</p>
<p>$\pmb x = [x_1,x_2,\dots,x_d]^T$</p>
<p>$\pmb w=[w_1,w_2,\dots,w_d]^T$</p>
<p>对于两类问题的线性分类器采用以下决策规则：</p>
<p>令$g(\pmb x) = g_1(\pmb x) - g_2(\pmb x)$，若：</p>
<p>$\cases{g(\pmb x) &gt; 0 ,则 \pmb x \in w_1 \ g(\pmb x)&lt;0 ,则\pmb x \in w_2 \ g(\pmb x) =0,则\pmb x任意分到某一类，或拒绝}$</p>
<p>方程$g(\pmb x) = 0$定义了一个决策面，把归类于$w_1$和$w_2$的点分隔开，当$g(\pmb x)$为线性函数时，这个决策面是<strong>超平面</strong>。</p>
<p>假设$\pmb x_1$和$\pmb x_2$都在决策面$H$上，则有：</p>
<p>$\pmb w^T\pmb x_1 + w_0 = \pmb w^T\pmb x_2 + w_0$</p>
<p>即：$\pmb w^T(\pmb x_1-\pmb x_2) =0$</p>
<p>上式表明：$\pmb w$与超平面$H$上任一向量正交，即是超平面的法向量。</p>
<p>超平面$H$把特征空间分成两个半空间，即对$w_1$的决策域$\mathcal{R_1} $和对$w_2$类的决策域$\mathcal{R_2} $。</p>
<h2 id="广义线性判别函数"><a href="#广义线性判别函数" class="headerlink" title="广义线性判别函数"></a>广义线性判别函数</h2><p>线性判别函数的局限性较大，不适用于非凸决策区域和多连通区域的划分问题。</p>
<p>二次判别函数的一般形式：</p>
<p>$g(x) = c_0 + c_1x+c_2x^2$</p>
<p>如果适当选择$\pmb x \rightarrow \pmb y$的映射，可以把二次判别函数化为$\pmb y$的线性函数，即：</p>
<p>$g(x) = \pmb a^T\pmb y = \sum \limits_{i=1}^3a_iy_i$</p>
<p>其中：<br>$$<br>\pmb y =\begin {bmatrix}<br>y_1\\y_2\\y_3<br>\end{bmatrix} =<br>\begin{bmatrix}<br>1\\x\\x^2<br>\end{bmatrix} ,\pmb a =<br>\begin{bmatrix}<br>a_1\\a_2\\a_3<br>\end{bmatrix} =<br>\begin{bmatrix}<br>c_0\\c_1\\c_2<br>\end{bmatrix}<br>$$<br>$g(x) = \pmb a^T \pmb y$称为广义线性判别函数，$\pmb a$称为广义权向量。</p>
<p>一般来说：</p>
<p>对于任意高次判别函数$g(x)$都可以进行适当的变换，化为广义判别函数来处理。【此时$g(x)$可以看作对任意判别函数作级数展开，取其结尾部分的逼近】，但是这样的变换会使得维数大大增加，带来“维数灾难”。</p>
<p>$\pmb a^T\pmb y =0$在$\pmb Y$空间确定了一个通过原点的超平面。</p>
<p>广义判别函数的一个特例：</p>
<p>$g(\pmb x) = \pmb w^T\pmb x + w_0 = w_0 + \sum\limits_{i=1}^dw_ix_i = \sum \limits_{i=1}^d a_iy_i = \pmb a^T\pmb y$</p>
<p>其中：<br>$$<br>\pmb y =\begin {bmatrix}<br>1\\x_1\\x_2\ \vdots \ x_d<br>\end{bmatrix} =<br>\begin{bmatrix}<br>1\ \pmb x<br>\end{bmatrix} ,\pmb a =<br>\begin{bmatrix}<br>w_0\\w_1\\w_2\ \vdots \ w_d<br>\end{bmatrix} =<br>\begin{bmatrix}<br>w_0\ \pmb w<br>\end{bmatrix}<br>$$<br>称为线性判别函数的齐次简化，$\pmb y=[1,\pmb x]^T$称为增广样本向量，$\pmb a$称为增广权向量。都是$\hat{d} =d+1$维向量。</p>
<p>虽然增加一维，但是样本间的欧式距离不变，仍然全部位于$d$维空间，即：</p>
<p>原$\pmb X$空间中，$\pmb a^T \pmb y =0$</p>
<p>在$\pmb Y$空间确定了一个通过原点的超平面$\hat{H}$,它对$d$维子空间的划分与原决策面$\pmb  w^T \pmb x +w_0 =0 $对原空间的划分完全相同。</p>
<p>$\pmb Y$空间内任意一点$\pmb y$ 到$\hat{H}$的距离为：</p>
<p>$\hat{r} = \frac{g(\pmb x)}{\Arrowvert{\pmb a} \Arrowvert} = \frac{\pmb a^T \pmb y}{\Arrowvert{\pmb a} \Arrowvert}$</p>
<h2 id="设计线性分类器的主要步骤"><a href="#设计线性分类器的主要步骤" class="headerlink" title="设计线性分类器的主要步骤"></a>设计线性分类器的主要步骤</h2><p>实际是寻找最好的$\pmb w$和$w_0$的过程，步骤：</p>
<p>（1）要有一组具有类别标志的样本集$\mathcal{X} = \{\pmb x_1,\pmb x_2,\dots,\pmb x_N\}$。</p>
<p>（2）根据实际情况确定一个准则函数$J$，满足：</p>
<ul>
<li>$J$是样本集$\mathcal{X}和\pmb w、w_0或\pmb a 的函数$</li>
<li>$J$的值反映分类器的性能，它的极值解则对应于“最好”的决策</li>
</ul>
<p>（3）用最优化技术求出准则函数的极值解$\pmb w^<em>和w_0^</em>或\pmb a^*$。</p>
<p>可以得到线性判别函数$g(\pmb x) = \pmb w^<em>+ w_0^</em>$或$g(\pmb x) = \pmb a^{*^T} \pmb y$。</p>
<p>对于未知样本$\pmb x_k$，只要计算$g(\pmb x)$，然后根据决策规则，判断$\pmb x_k$所属类别。</p>
<h2 id="Fisher​线性判别"><a href="#Fisher​线性判别" class="headerlink" title="Fisher​线性判别"></a>Fisher​线性判别</h2><p>应用统计方法解决模式识别问题时，降低维数是一个关键。</p>
<h3 id="Fisher的基本思想和问题"><a href="#Fisher的基本思想和问题" class="headerlink" title="Fisher的基本思想和问题"></a>Fisher的基本思想和问题</h3><p>（1）把$d$维空间的样本投影到一条直线上，形成一维空间，即把维数压缩为一维。</p>
<p>（2）投影到一条直线上，会存在样本的混叠无法识别情况</p>
<p>（3）总可以找到某个方向，使得在这个方向上的直线上的样本投影能最好的分开。</p>
<h3 id="基本参量"><a href="#基本参量" class="headerlink" title="基本参量"></a>基本参量</h3><p>（1）在$d$维$\pmb X $ 空间（原空间）</p>
<ul>
<li><p>各类样本的均值向量$\pmb m_i$</p>
<p>$\pmb m_i = \frac{1}{N_i} \sum\limits_{\pmb x \in \mathcal{X}} \pmb x,i=1,2$</p>
</li>
<li><p>样本内离散度矩阵$S_i$和总类内离散度矩阵$S_w$</p>
<p>$S_i = \sum \limits_{\pmb x \in \mathcal{X}}(\pmb x- \pmb m_i)(\pmb x-\pmb m_i)^T，i=1，2$</p>
<p>$S_w = S_1+S_2$</p>
</li>
<li><p>样本类间离散度矩阵$S_b$</p>
<p>$S_b = (\pmb m_1-\pmb m_2)(\pmb m_1-\pmb m_2)^T$</p>
</li>
</ul>
<p>其中$S_w$是对称半正定矩阵，而且当$N&gt;d$时通常时非奇异的。$S_b$也是对称半正定矩阵，在只有两类的条件下，秩最大等于1。</p>
<p>（2）在一维$\pmb Y$空间（投影）</p>
<ul>
<li><p>各类样本的均值向量$\widetilde{ m_i} $</p>
<p>$\widetilde{ m_i} = \frac{1}{N_i} \sum\limits_{ y \in \mathcal{Y}} y,i=1,2$</p>
</li>
</ul>
<ul>
<li><p>样本内离散度矩阵$\widetilde{S_i^2}$和总类内离散度矩阵$\widetilde{S_w}$</p>
<p>$\widetilde{S_i} = \sum \limits_{ y \in \mathcal{Y}}( y-  \widetilde{m_i})^2，i=1，2$</p>
<p>$\widetilde{S_w} = \widetilde{S_1^2}+\widetilde{S_2^2}$</p>
</li>
</ul>
<h3 id="Fisher准则函数"><a href="#Fisher准则函数" class="headerlink" title="Fisher准则函数"></a>Fisher准则函数</h3><p>我们希望在投影后，在一维$\pmb Y$空间里各类别样本尽可能分得开些，即希望两类均值之差$(\widetilde{m_1} - \widetilde{m_2})$越大越好；同时希望各类样本内部尽量密集，即希望类内离散度越小越好。</p>
<p>定义准则函数为：</p>
<p>$ J_F(\pmb w) = \frac{(\widetilde{m_1} - \widetilde{m_2})^2}{\widetilde{S_1^2}+\widetilde{S_2^2}}$</p>
<p>选择使得$J_F(\pmb w)$尽可能大的$\pmb w$作为投影方向，式子不含参数$\pmb w$，需要将其转变为$\pmb w$显函数。</p>
<p><strong>过程如下</strong>：</p>
<p>假设一集合$\mathcal{X}$包含$N$个$d$维样本$x_1,x_2,\dots,x_N$，其中$N_1$个属于$w_1$类别的样本子集记为$\mathcal{X_1}$,$N_2$个属于$w_2$类别的样本子集记为$\mathcal{X_2}$若对$x_n$分量作线性组合可得标量：</p>
<p>$y_n = \pmb w^Tx_n ,n=1,2,\dots,N_i$，其中权向量$\pmb w = [w_1,w_2,\dots,w_d]^T$</p>
<p>这样得到$N$个一维样本$y_n$组成的集合，如果$||\pmb w|| =1$，则每个$y_n$就是相对应的$x_n$到方向$\pmb w$的直线上的投影。</p>
<p>$\widetilde{ m_i} = \frac{1}{N_i} \sum\limits_{ y \in \mathcal{Y}} y= \frac{1}{N_i} \sum\limits_{\pmb x \in \mathcal{X}} \pmb w^T \pmb x = \pmb w^T \pmb m_i$</p>
<p>$(\widetilde{m_1} - \widetilde{m_2})^2 = (\pmb w^T \pmb m_1- \pmb w^T \pmb m_2)^2   \ = \pmb w^T (\pmb m_1 - \pmb m_2)(\pmb m_1 - \pmb m_2)^T \pmb w \ = \pmb w^TS_b \pmb w$</p>
<p>$\widetilde{S_i} = \sum \limits_{ y \in \mathcal{Y}}( y-  \widetilde{m_i})^2 = \sum \limits_{\pmb x \in \mathcal{X_i}}(\pmb w^T \pmb x -\pmb w^T\pmb m_i)^2 \\=\pmb w^T \left [   \sum \limits_{\pmb x \in \mathcal{X_i}} (\pmb x -\pmb m_i)(\pmb x -\pmb m_i)^T\right] \pmb w = \pmb w^T S_i \pmb w \ 因为上面:\ \widetilde{ m_i} = \frac{1}{N_i} \sum\limits_{ y \in \mathcal{Y}} y= \frac{1}{N_i} \sum\limits_{\pmb x \in \mathcal{X}} \pmb w^T \pmb x = \pmb w^T \pmb m_i$</p>
<p>所以：</p>
<p>$\widetilde{S_1^2}+\widetilde{S_2^2} = \pmb w^T(S_1+S_2)\pmb w = \pmb w^TS_w \pmb w$</p>
<p>代入准则函数有：</p>
<p>$J_F(\pmb w)= \frac{\pmb w^T S_b \pmb w}{\pmb w^T S_w \pmb w}$</p>
<p><strong>Lagrange乘子法</strong>求极值，得最优解：</p>
<p>由于$\pmb w$得幅值不会影响$\pmb w$得大小，不会影响$J_F$函数得值，因此可以蒋分母常数化而优化分子最大，把问题转化为如下约束条件：</p>
<p>$\max\{ \pmb w^TS_b \pmb w\}  \ s.t. \quad \pmb w^T S_w \pmb w = c \neq 0$</p>
<p>定义拉格朗日函数，引入拉格朗日乘子$\lambda$:</p>
<p>$L(\pmb w,\lambda) = \pmb w^TS_b \pmb w - \lambda(\pmb w^TS_w\pmb w -c) $</p>
<p>$ \frac{\partial L(\pmb w,\lambda)}{\partial\pmb w} = S_b\pmb w - \lambda S_w \pmb w =0$</p>
<p>$S_b\pmb w’ = \lambda S_w \pmb w’ $</p>
<p>$ 左乘S_w^{-1}得：$</p>
<p>$ S_w^{-1} S_b \pmb w’ = \lambda \pmb w’ $</p>
<p>$ 其中：\ S_b\pmb w’ = (\pmb m_1-\pmb m_2)(\pmb m_1-\pmb m_2)^T \pmb w’ $</p>
<p>$ 其中：\  (\pmb m_1-\pmb m_2)^T \pmb w’ = R(标量，矩阵乘法) $</p>
<p>$ 所以： \ \lambda \pmb w^*= S_w^{-1}(\pmb m_1-\pmb m_2)R $</p>
<p>$ \pmb w’ = \frac{R}{\lambda} S_w^{-1}(\pmb m_1 -\pmb m_2) 忽略比例因子可得：$</p>
<p>$ 准则函数取极大值时得解：$</p>
<p>$ \pmb w’ = S_w^{-1}(\pmb m_1-\pmb m_2)$</p>
<p>当维数$d$和样本数$N$都很大时，可采用贝叶斯决策规则。</p>
<h2 id="最小平方误差（LMSE）准则函数和H-K算法"><a href="#最小平方误差（LMSE）准则函数和H-K算法" class="headerlink" title="最小平方误差（LMSE）准则函数和H-K算法"></a>最小平方误差（LMSE）准则函数和H-K算法</h2><p>主要针对$w_i /w_j$两类问题</p>
<h3 id="MSE准则函数"><a href="#MSE准则函数" class="headerlink" title="MSE准则函数"></a>MSE准则函数</h3><p>把来自$w_j$类得训练样本的各分量均乘以（-1）,则所有模式样本$\pmb x$均满足：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/矩阵1.PNG">
<p>$b= [b_1,b_2,\dots,b_n]^T$</p>
<p>定义误差函数：$e= X*W-b$</p>
<p>定义平方误差准则函数：</p>
<p>$J_s(W,\pmb x,b )= ||e||^2 = ||X*W-b||^2 = \sum\limits_{i=1}^n (W^T\pmb x_i - b_i)^2$</p>
<p>为使得到的解$\pmb w$确实是解向量$\pmb w^*$，应保证：</p>
<p>$ W^T \pmb x_i - b_i \ge 0 ,i=1,2,\dots,n$</p>
<p>即：$e$的各分量应不小于0$(b_i &gt; 0 )$ 【<strong>一个重要条件</strong>】</p>
<hr>
<p>现求$J_s$对$\pmb w$的偏导数（求梯度）</p>
<p>$ \nabla J_s = \frac{\partial J_s}{\partial W} = 2( W^T \pmb x_i- b)\pmb x_i = 2X^T(X*W -b) \ 令\nabla J_s =0得到： \ X^TXW = X^T b$</p>
<p>其中$X^TX$是$(d+1)*(d+1)$维方阵，是非奇异阵（存在逆矩阵），有唯一解，即：</p>
<p>$W^* = X^{+}b $，其中$X^+ = (X^TX)^{-1}X^T$，称为伪逆解。</p>
<p>由于$W^*$依赖于$b$，现求$b$，即：</p>
<p>为使得$J_s$最小，用梯度下降法建立迭代式，有：</p>
<p>$b(k+1) = b(k) +(- c·\frac{\partial J_s}{\partial b})_{b=b(k)}$</p>
<p>负号表示梯度反向，$c&gt;0$为常量，用于修正(此处是采用固定增量)。</p>
<p>其中：$\frac{\partial J_s}{\partial b} = -2(X*W-b)$</p>
<p>要使得$J_s$最小，则需满足：$X*W-b =0$。同时：</p>
<p>考虑到$b(k)$的各个分量应取正值的约束条件，$b(k)$的增量$\delta b(k) =(- c·\frac{\partial J_s}{\partial b})$的各个分量取非负值，要求：</p>
<p>（1）若$X*W(k) -b(k) \le 0$,则$\delta b(k) =0$</p>
<p>（2）若$X*W(k) -b(k) &gt; 0 $，则：</p>
<p>​           $\delta b(k) = (- c·\frac{\partial J_s}{\partial b})_{b=b(k)} = 2c[X*W(k)-b(k)]$</p>
<p>​           误差向量$\pmb e_k = XW(k) -b(k)$,则$\delta b(k)$可统一表示为：</p>
<p>​           $\delta b(k) = c(\pmb e_k + |\pmb e_k|)$</p>
<p>$b(k)$的迭代式变为：</p>
<p>$b(k+1) = b(k) + \delta b(k) \ 代入：W’ = X^+b得：$</p>
<p>$ W’(k+1) = X^+b(k+1) = X^+ b(k) + X^+\delta b(k)$</p>
<p>$ =W’(k) +X^+\delta b(k)$</p>
<p>此时可建立一种最小平方差算法(LMSE)，也称为H-K算法。</p>
<h3 id="H-K算法步骤"><a href="#H-K算法步骤" class="headerlink" title="H-K算法步骤"></a>H-K算法步骤</h3><p>（1）由训练集样本构成增广矩阵$X$,求伪逆$X^+ = (X^TX)^{-1}X^T$。</p>
<p>（2）赋给初值$b(1)$，使得各分量均为正值，选择常数$c(c&gt;0)$，置$k=1$。</p>
<p>（3）计算：$W(k) = X^+b(k) \ \pmb e_k= XW(k) -b(k)$</p>
<p>（4）判断：若$\pmb e_k$各分量停止变为正值，或不全为0，则线性不可分，停止迭代；若$\pmb e_k$各分量接近于0，即$\pmb e_k \rightarrow 0$，则迭代完成，算法结束。否则继续。</p>
<p>（5）计算：$W(k+1) =W(k) +c·X^+[\pmb e_k +|\pmb e_k|] =W(k) +c·X^+|\pmb e_k| \ b(k+1) = b(k) +c·[\pmb e_k + |\pmb e_k|]$</p>
<p>（6）$k=k+1$；返回（3）。</p>
<p>H-K算法可监视迭代过程。</p>
<blockquote>
<p>e.g.1 两类训练样本</p>
<p>$w_1 : (0,0)^T,(0,1)^T$</p>
<p>$w_2:(1,0)^T,(1,1)^T$</p>
<p>用H-K算法求解向量。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/解1.PNG">
<p>令$c=1,b(1) = (1,1,1,1)^T$（要求各分量大于零）</p>
<p>$W(1) =X^+b = (-2,0,1)^T$</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/解2.PNG">
<p>由于$\pmb e_k$各个分量为零，即$W(1)$为解向量，即</p>
<p>$W^* =(-2,0,1)^T$</p>
<p>可知决策面方程为：$-2x_1+1=0$</p>
<p>e.g.2(线性不可分情况)</p>
<p>$w_1 : (0,0)^T,(1,1)^T$</p>
<p>$w_2:(1,0)^T,(0,1)^T$</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/解3.PNG">
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; \begin&#123;equation&#125;</span><br><span class="line">&gt; X=\left.\left[</span><br><span class="line">&gt; \begin&#123;array&#125;</span><br><span class="line">&gt; <span class="number">00</span>&amp;<span class="number">0</span>&amp;<span class="number">1</span>\\<span class="number">1</span>&amp;<span class="number">1</span>&amp;<span class="number">1</span>\\<span class="number">-1</span>&amp;<span class="number">0</span>&amp;<span class="number">-1</span>\\<span class="number">0</span>&amp;<span class="number">-1</span>&amp;<span class="number">-1</span></span><br><span class="line">&gt; \end&#123;array&#125;</span><br><span class="line">&gt; \right]\right\&#125;</span><br><span class="line">&gt; \end&#123;equation&#125;_&#123;w_2类（×（<span class="number">-1</span>））&#125;^&#123;w_1类&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>令$c=1,b(1) = (1,1,1,1)^T$（要求各分量大于零）</p>
<p>$W(1) =X^+b = (0,0,0)^T$</p>
<p>误差向量：</p>
<p>$\pmb e_1 = XW(1) -b(1) = (-1,-1,-1,-1)^T$，各分量均为负值，终止迭代。</p>
</blockquote>
<h1 id="特征选择与提取"><a href="#特征选择与提取" class="headerlink" title="特征选择与提取"></a>特征选择与提取</h1><h2 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>模式特征</strong>：</p>
<p>分为物理特征、结构特征（如汉字，几何形式等）、数字特征（均值，方差等）</p>
<ol>
<li>物理和结构特征：易于为人的直觉感知，但是有时难以定量描述，因此不利于机器判别</li>
<li>数学特征：易于用机器判别和分析，如统计特征。</li>
</ol>
<p><strong>原始特征</strong>：</p>
<p>在模式采集过程中形成的样本测量值，如一幅$512\times 512$的图像，原始特征维数：$512\times 512$</p>
<p>原始特征是我们直接测量获得的，但是往往不用于模式识别中，主要有以下几个原因：</p>
<ol>
<li>原始特征不能反映对象的本质特征；</li>
<li>高维的原始特征不利于分类器的设计。</li>
</ol>
<ul>
<li><strong>计算量大，</strong>如对于一幅1024*768的灰度图像，灰度级为256级，直接表示需要786432 bytes，进行训练识别所需的空间、时间和计算量都无法接受</li>
<li><strong>冗余</strong>，原始特征空间中，大量的特征都是相关性强的冗余特征</li>
<li><strong>样本分布十分稀疏</strong>，对于有限训练样本而言，在高维的原始特征空间中分布十分稀疏</li>
</ul>
<p>如果将数目过多的测量值不做分析，直接用于分类特征，不但耗时，而且会影响分类效果，产生<strong>“维数灾难”</strong>等问题。</p>
<p>针对原始特征以上的特性和不足，为了设计出更好的分类器，通常需要对原始特征的测量值集合进行分析，经过选择和变换处理，组成有效的识别特征。 处理方式主要有以下思路： </p>
<ul>
<li>在保证一定分类精度的前提下，减少特征维数，进行“降维”处理，使分类器实现快速、准确、高效的分类； </li>
<li>去掉模棱两可、不利于分类的特征，使得提供的特征具有更好的可分性，使分类器容易判别； 提供的特征不应重复，即去掉相关性强但是没有增加更多分类信息的特征。</li>
</ul>
<p><strong>特征提取(feature extraction)</strong>：</p>
<p>通过映射或变换的方法，把模式空间的高维特征变成特征空间的低维特征。即：$T: E_{D} \rightarrow E_d,d \ll D$。</p>
<p><strong>特征选择</strong>：</p>
<p>从一个特征集中挑选出最有利于分类的特征子集的过程。</p>
<p>【注】：对于特征提取，目标要求，方法差异非常大，很难有统一的方法，对任何目标都有效。</p>
<h2 id="类别可分离性判据"><a href="#类别可分离性判据" class="headerlink" title="类别可分离性判据"></a>类别可分离性判据</h2><p>把一个高维空间变换为低维空间的映射很多，哪种映射对分类更为有利，需要一个标准。</p>
<p>从$D$个原始特征中选择 $d$个特征的各种可能组合很多，哪种组合分类的效果最好，也要有个标准。</p>
<p>要求：</p>
<ol>
<li>与<strong>错误率</strong>（或错误概率的上界或者下界）有单调关系，这样使得判据取最大值的效果一般说来其错误概率也最小。</li>
<li>当特征独立时有<strong>可加性</strong>。即：$J_{ij}(x_1,x_2,\dots,x_d) = \sum\limits_{k=1}^d J_{ij}(x_k)$。其中$J_{ij}$是第$i$类和$j$类的可分性准则，其值越大，两类的分离程度越大。$x_1,x_2,\dots,x_d$是一定类别的相应特征的随机变量。</li>
<li><strong>度量特性</strong>。即：$\cases{J_{ij} &gt; 0;当i \neq j时 \ J_{ij} = 0;当i =j时 \ J_{ij} = J_{ji}}$</li>
<li><strong>单调性</strong>。即：新的特征加入时，判据不断减小，$J_{ij} (x_1,x_2,\dots,x_d) \leq J_{ij}(x_1,x_2,\dots,x_d,x_{d+1})$。</li>
</ol>
<h2 id="基于距离的可分性判据"><a href="#基于距离的可分性判据" class="headerlink" title="基于距离的可分性判据"></a>基于距离的可分性判据</h2><p>从类别的可分性看，同一类的样本相似度越大，不同类的样本的相似度越小对分类越有利，因此可以用样本之间的距离作为度量特征的可分性判据。</p>
<p>将$c$个类别的样本集分别表示为$D_1,D_2,\dots,D_c$，其中$D_i=\{x_1^{(i)},x_2^{(2)},\dots,x_{n_i}^{(i)}\}$，样本的上标表示所属类别$i$，$n_i$表示第$i$个类别的样本数，特征以集合的形式表示：$X = \{x_1,\dots,x_d\}$。</p>
<h3 id="类内距离"><a href="#类内距离" class="headerlink" title="类内距离"></a>类内距离</h3><p>类内距离度量的是在特定特征集合$X$上的同类别样本之间的相似程度。第$i$类样本集合中任意两个样本之间的均方距离为：</p>
<p>$d_i^2 = \frac{1}{2n_i^2} \sum \limits_{k=1}^{n_i} \sum\limits_{l=1}^{n_i} d^2(\pmb x_k^{(i)},\pmb x_l^{(i)})$</p>
<p>其中$\pmb x_k^{(i)},\pmb x_l^{(i)}$表示第$i$类的$D$维特征向量；$d^2(\pmb x_k^{(i)},\pmb x_l^{(i)})$表示两个向量之间的距离。</p>
<p>所有类别的样本的总的均方距离为：</p>
<p>$J_{msd} (X) =\sum\limits_{i=1}^c P_i d_i^2$</p>
<p>其中$P_i$表示第$i$类的先验概率，可以用第$i$个类别样本在全部样本中所占的比例来估计，即：$P_i \approx \frac{n_1}{n}$,$n = \sum\limits_{j=1}^c n_j$</p>
<p>当采用欧式距离度量时。总均方距离可表示为：</p>
<p>$J_{msd} (X)= \sum \limits_{i=1}^c \frac{P_i}{2n_i^2} \sum\limits_{k=1}^{n_i}\sum\limits_{l=1}^{n_i}(\pmb x_k^{(i)} - \pmb x_{l}^{(i)})^T(\pmb x_k^{(i)} - \pmb x_{l}^{(i)})$</p>
<p>类内距离判据的简化计算方式为：</p>
<p>$J_{msd}(X) = \frac{1}{n} \sum \limits_{i=1}^c \sum\limits_{k=1}^{n_i} (\pmb x_k^{(i)} - \pmb \mu^{(i)})^T(\pmb x_k^{(i)} - \pmb \mu^{(i)})$，$\pmb \mu^{(i)} = \frac{1}{n_i} \sum\limits_{k=1}^{n_i}\pmb x_k^{(i)}$</p>
<p>其中$\pmb \mu^{(i)}$表示第$i$类样本集的均值向量。</p>
<p>用$\pmb \mu$表示所有各类的样本集总平均向量为：$\pmb \mu = \sum\limits_{i=1}^c P_i \pmb \mu^{(i)}$</p>
<p>类内距离判据度量的是在特征集合$X$上的类内样本的距离程度。</p>
<h3 id="类间距离"><a href="#类间距离" class="headerlink" title="类间距离"></a>类间距离</h3><p>类间距离度量的是不同类别样本之间的差异程度。第$i$个类别和第$j$个类别之间的任意两个样本之间的均方距离为：</p>
<p>$d_{ij}^2 =\frac{1}{n_in_j} \sum \limits_{k=1}^{n_i}\sum\limits_{l=1}^{n_j} d^2(\pmb x_k^{(i)} - \pmb x_l^{(j)})$</p>
<p>所有不同类别样本之间的均方距离为：</p>
<p>$J_{bsd} = \frac{1}{2} \sum\limits_{i=1}^c P_i \sum\limits_{j=1,j \neq i}^c P_j ·\frac{1}{n_in_j} \sum \limits_{k=1}^{n_i}\sum\limits_{l=1}^{n_j} d^2(\pmb x_k^{(i)} - \pmb x_l^{(j)})$</p>
<p>在欧式距离下，总的类间均方距离有如下两种简化计算方式：</p>
<p>$J_{bsd} = \frac{1}{2} \sum\limits_{i=1}^c P_i \sum\limits_{j=1,j \neq i}^c P_j (\pmb \mu^{(i)} -\pmb \mu^{(j)})^T(\pmb \mu^{(i)} - \pmb \mu^{(j)})$</p>
<p>其中$\pmb \mu^{(i)} = \frac{1}{n_i} \sum\limits_{k=1}^{n_i}\pmb x_k^{(i)}$</p>
<p>$J_{bsd} = \sum\limits_{i=1}^c P_i (\pmb \mu^{(i)} -\pmb \mu)^T(\pmb \mu^{(i)} - \pmb \mu)$</p>
<p>其中$\pmb \mu = \frac{1}{n} \sum\limits_{i=1}^c \sum\limits_{k=1}^{n_i}\pmb x_k^{(i)}$</p>
<h2 id="基于散布矩阵的可分性判据"><a href="#基于散布矩阵的可分性判据" class="headerlink" title="基于散布矩阵的可分性判据"></a>基于散布矩阵的可分性判据</h2><p>第$i$个类内散布矩阵为：<br>$S_i = J_{msd}(X) = \frac{1}{n_i}  \sum\limits_{k=1}^{n_i} (\pmb x_k^{(i)} - \pmb \mu^{(i)})^T(\pmb x_k^{(i)} - \pmb \mu^{(i)})$</p>
<p>总的类内散布矩阵为：$S_w = \sum \limits_{i=1}^c P_i S_i$</p>
<p>类内散布矩阵描述的是同类样本在特征空间的分布情况。</p>
<p>类间散布矩阵描述的是不同类别样本在特征空间的分布情况，即：</p>
<p>$S_b = \sum\limits_{i=1}^c P_i(\pmb \mu^{(i)} -\pmb \mu)^T(\pmb \mu^{(i)} -\pmb \mu)$</p>
<p>其中$S_b,S_w$都是$d \times d$的对称矩阵，</p>
<p>$S_w$的主对角线元之和为欧式距离测度下的类内均方距离</p>
<p>$S_b$的主对角线元之和是欧式距离度量下的类间均方距离</p>
<p>$S_w,S_b$的非主对角线元分别描述同类样本和不同类样本对应的特征对之间的相关程度。</p>
<p>所有样本的总体散布矩阵为：</p>
<p>$S_t = \frac{1}{n} \sum\limits_{i=1}^c \sum\limits_{k=1}^{n_i} (\pmb x_k^{(i)} - \pmb \mu)^T(\pmb x_k^{(i)} -\pmb \mu)$</p>
<p>可以证明：$S_t = S_w +S_b$，总体的散布矩阵$S_t$即是训练样本集的协方差矩阵。</p>
<p>由三个散布矩阵可以定义很多可分性判据，常用有：</p>
<p>$J_1(X )= tr(S_w ^{-1}S_b)$，其中矩阵的迹是方阵的所有主对角线元之和。</p>
<p>$J_2(X) = \frac{tr(S_b)}{tr(S_w)}$</p>
<p>$J_3(X) = \frac{|S_b|}{|S_w|} = |S_w^{-1}S_b|$</p>
<p>$J_4(X) = \frac{|S_t|}{|S_w|}$</p>
<p>这里的类别可分性判据与聚类准则非常相似，两者都是评价样本集在一组特征上的区分程度。</p>
<p>区别是：</p>
<p>聚类分析中样本集是无监督的，每个样本没有所属类别的信息，建立聚类准则的目的是要评价将样本集划分为不同子集时，不同子集之间的区分度；</p>
<p>特征选择和提取的样本集是有监督的，可分性判据评价的是这个样本集在不同的特征子集上的区分程度。</p>
<h2 id="基于概率分布的可分性判据"><a href="#基于概率分布的可分性判据" class="headerlink" title="基于概率分布的可分性判据"></a>基于概率分布的可分性判据</h2><p>考虑各类的概率分布，以此确切表明各类交叠的情况。</p>
<p>对于两类情况$\omega_1$和$\omega_2$,</p>
<p>完全可分情况下：$p(\pmb x| \omega_1)$和$p(\pmb x| \omega_2)$没有交叠</p>
<p>完全不可分情况下：$p(\pmb x| \omega_1) =p(\pmb x| \omega_2)$</p>
<p>分布密度的交叠程度可用$p(\pmb x| \omega_1)$和$p(\pmb x| \omega_2)$这两个分布密度函数之间的距离$J_p$表示。则有如下条件：</p>
<ul>
<li><p>$J_p$非负</p>
</li>
<li><p>当两个完全不交叠事，$J_p$取最大值，即若对所有的$\pmb x$有$p(\pmb x| \omega_2)\neq 0$时$p(\pmb x| \omega_1) =0$，则$J_p = \max$</p>
</li>
<li><p>当两类分布密度相同时，即$p(\pmb x| \omega_1) =p(\pmb x| \omega_2)$时，$J_p =0$</p>
</li>
</ul>
<h3 id="常用的概率距离度量"><a href="#常用的概率距离度量" class="headerlink" title="常用的概率距离度量"></a>常用的概率距离度量</h3><h4 id="Bhattacharyya距离和Chernoff界限"><a href="#Bhattacharyya距离和Chernoff界限" class="headerlink" title="Bhattacharyya距离和Chernoff界限"></a>Bhattacharyya距离和Chernoff界限</h4><p>B-距离定义为：</p>
<p>$J_B = - \ln \int [p(\pmb x| \omega_1) p(\pmb x| \omega_2)]^{1/2} d \pmb x$</p>
<p>与错误概率上界有直接关系，因为：</p>
<p>$P_e = P(\omega_1) \int_{\mathcal{R}}p(\pmb x| \omega_1)d \pmb x + P(\omega_2) \int_{\mathcal{\overline{R}}}p(\pmb x| \omega_2) d \pmb x $</p>
<p>$ \quad = \int_{-\infty}^{\infty} \min \{ P(\omega_1)p(\pmb x| \omega_1),P(\omega_2)p(\pmb x| \omega_2)\}d \pmb x $</p>
<p>$ \quad \leq \int_{-\infty}^{\infty}\{P(\omega_1)P(\omega_2)p(\pmb x| \omega_1)p(\pmb x| \omega_2\}^{1/2} d \pmb x $</p>
<p>$ \quad =[P(\omega_1)P(\omega_2)]^{1/2} \int_{-\infty}^{\infty}\{p(\pmb x| \omega_1)p(\pmb x| \omega_2\}^{1/2} d \pmb x $</p>
<p>$ \quad = [P(\omega_1)P(\omega_2)]^{1/2} \exp \{-J_B\}$</p>
<p>其中$\mathcal{R}$表示的是$p(\pmb x| \omega_2) &gt; p(\pmb x| \omega_1)$的区域，$\mathcal{\overline{R}}$表示的是$p(\pmb x| \omega_2) &lt;p(\pmb x| \omega_1)$的区域。</p>
<p>与之相似的另一个判据是Chernoff界限$J_c$：</p>
<p>$J_c = - \ln \int p^s(\pmb x| \omega_1) p^{1-s}(\pmb x| \omega_2) d\pmb x$</p>
<p>其中$s \in [0,1]$，当$s=0.5$时，$J_c = J_B$</p>
<h4 id="散度"><a href="#散度" class="headerlink" title="散度"></a>散度</h4><p>设有两类$\omega_i$和$\omega_j$，其对数似然比为：</p>
<p>$l_{ij}(\pmb x) = \ln \frac{p(\pmb x| \omega_i)}{p(\pmb x| \omega_j)}$</p>
<p>可以提供$\omega_i$对$\omega_j$可分性信息，对$\omega_i$类的平均可分性信息为：</p>
<p>$I_{ij}(\pmb x) = E[l_{ij}(\pmb x)] = \int_{X}p(\pmb x| \omega_i) \ln \frac{p(\pmb x| \omega_i)}{p(\pmb x| \omega_j)} d\pmb x$</p>
<p>同样对$\omega_j$类的平均可分性信息为：</p>
<p> $I_{ji}(\pmb x) = E[l_{ji}(\pmb x)] = \int_{X}p(\pmb x| \omega_j) \ln \frac{p(\pmb x| \omega_j)}{p(\pmb x| \omega_i)} d\pmb x$</p>
<p>定义 散度$J_D$区分$\omega_i$和 $\omega_j$类的总平均信息，等于两类平均可分性信息之和：</p>
<p>$J_D = I_{ij} +I_{ji} = I_{ji}(\pmb x) = E[l_{ji}(\pmb x)] = \int_{X}[p(\pmb x| \omega_i)-p(\pmb x| \omega_j)] \ln \frac{p(\pmb x| \omega_i)}{p(\pmb x| \omega_j)} d\pmb x$</p>
<h4 id="正太分布时类别的可分性判据表达式"><a href="#正太分布时类别的可分性判据表达式" class="headerlink" title="正太分布时类别的可分性判据表达式"></a>正太分布时类别的可分性判据表达式</h4><p>当概率分布密度属于某种参数形式时（如指数分布），上面的复杂形式的$J_B,J_D$可进一步简化，特别是当满足是正太分布时：</p>
<p>假定二分类都是$d$维正太分布，$\omega_i$类为$N(\mu_i,\Sigma_i)$，$\omega_j$类为$N(\mu_j,\Sigma_j)$</p>
<p>$p(\pmb x| \omega_i) = \frac{1}{(2\pi)^{d/2} |\Sigma_i|^{1/2}} \exp \left[ -\frac{1}{2}(\pmb x -\mu_i)^T\Sigma_i^{-1}(\pmb x -\mu_i)\right]$</p>
<p>$p(\pmb x| \omega_j) = \frac{1}{(2\pi)^{d/2} |\Sigma_j|^{1/2}} \exp \left[ -\frac{1}{2}(\pmb x -\mu_j)^T\Sigma_j^{-1}(\pmb x -\mu_j)\right]$</p>
<p>求出对数似然比$l_{ij}$，得到两类的平均可分性信息$I_{ij}$，两类间的散度$J_D = I_{ij} +I_{ji}$。</p>
<p>当两类的协方差矩阵相等时$\Sigma_i = \Sigma_j = \Sigma$时，可进一步简化。</p>
<h2 id="基于熵函数的可分性判据"><a href="#基于熵函数的可分性判据" class="headerlink" title="基于熵函数的可分性判据"></a>基于熵函数的可分性判据</h2><p>最佳分类器由后验概率确定，可由后验概率分布来衡量它对分类的有效性。</p>
<p>如果对于某些特征，各类后验概率是相等的，即$P(\omega_i| \pmb x) = \frac{1}{c}$,其中$c$为类别数。</p>
<p>这样无法确定样本的所属类别，这只能任意确定$\pmb x$属于某一类（假定先验概率相等或不知），此时错误概率为：$P_e = 1- \frac{1}{c}$</p>
<p>另一个极端例子是，如果 有一组特征使得：</p>
<p>$P(\omega_i | \pmb x) = 1$，且$P(\omega_j | \pmb x) = 0 ,\forall j \neq i$</p>
<p>则此时$\pmb x$可以肯定划为$\omega_i$类，而错误概率为0。</p>
<p>可见：后验概率分布愈集中，错误概率越小。后验概率分布越平缓（接近均匀分布）则分类错误的概率越大。</p>
<p>为了衡量后验概率分布的集中程度，需要规定一个定量指标，引出<strong>熵</strong>的概念。</p>
<p>设$\omega$可能取值为$\omega_i ,i=1,2,\dots,c$的一个随机变量，它取值依赖于分布密度为$p(\pmb x)$的随机向量$\pmb x$(特征向量)，即给定$\pmb x$后的$\omega_i$的概率为$P(\omega_i| \pmb x)$。</p>
<p>从特征提取的角度看，用具有最小不确定性的那些特征进行分类是有利的，“熵”用作不确定性的度量，它是$P(\omega_i| \pmb x) ,P(\omega_2| \pmb x), \dots, P(\omega_c | \pmb x)$的函数，即：</p>
<p>$H = J_c[P(\omega_i| \pmb x) ,P(\omega_2| \pmb x), \dots, P(\omega_c | \pmb x)]$</p>
<p>熵函数具有如下性质：</p>
<ul>
<li>熵为正且对称：$H_c (P_1,P_2,\dots,P_c)=H_c(P_2,P_1,\dots, P_c) = \dots = H_c(P_c,\dots,P_1) \ge 0$</li>
<li>若$P_{i_0} =1$且$P_i =0(1 \le i\le c, i \neq i_0)$,则：$H_c(P_1,P_2,\dots,P_c) =0$</li>
<li>$H_c(P_1,P_2,\dots,P_c) = H_{c+1}(P_1,P_2,\dots,P_c,0)$</li>
<li>对于任意的概率分布，$P_i \ge 0,(i=1,\dots,c),\sum\limits_{i=1}^c P_i =1$，有：$H_c(P_1,P_2,\dots,P_c) \le H_c(\frac{1}{c} ,\frac{1}{c},\dots, \frac{1}{c})$</li>
<li>对所有的事件，熵函数是连续函数。</li>
</ul>
<p>满足上述性质的一族信息度量是如下形似的广义熵：</p>
<p>$J_c^{\alpha} [P(\omega_1| \pmb x),P(\omega_2| \pmb x),\dots, P(\omega_c| \pmb x)] = (2^{1-\alpha} -1)^{-1}\left[\sum\limits_{i=1}^c P^{\alpha}(\omega_i| \pmb x)-1\right]$</p>
<p>其中$\alpha$是一个实的正参数，且$\alpha \neq 1$。</p>
<p>不同的$\alpha$可以得到不同的熵分离度量，例如：</p>
<p>当$\alpha $趋近于1时，据L’Hospital准则有：</p>
<p>$J_c^{1} [P(\omega_1| \pmb x),P(\omega_2| \pmb x),\dots, P(\omega_c| \pmb x)] \\= \lim \limits_{\alpha \rightarrow 1}(2^{1-\alpha} -1)^{-1}\left[\sum\limits_{i=1}^c P^{\alpha}(\omega_i| \pmb x)-1\right] \ = - \sum\limits_{i=1}^c P(\omega_i | \pmb x) \log _2 P(\omega_i | \pmb x)$</p>
<p>称为<strong>Shannon熵</strong>（香农熵）。</p>
<p>当$\alpha =2$时，得到<strong>平方熵</strong>：</p>
<p>$J_c^{2} [P(\omega_1| \pmb x),P(\omega_2| \pmb x),\dots, P(\omega_c| \pmb x)] = 2\left[1-\sum\limits_{i=1}^c P^{2}(\omega_i| \pmb x)\right]$</p>
<p>为了对所提取的特征进行评价，需要计算空间每一点的熵函数，在熵函数取值较大的那一部分空间，不同的类的样本必然在较大的程度上互相交叠。</p>
<p>因此熵函数的期望值：$E\{J_c^{\alpha} [P(\omega_1| \pmb x),P(\omega_2| \pmb x),\dots, P(\omega_c| \pmb x)] \}$</p>
<p>可以表征类别的分离程度，用作所提取的特征的分类性能的评价指标。</p>
<h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><p>把高维空间变换为低维空间，并且能够在低维空间中更好的进行分类。</p>
<h3 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析(PCA)"></a>主成分分析(PCA)</h3><p>主成分分析（principal components analysis，PCA）是最重要的降维方法之一。在数据压缩消除冗余和数据噪音消除等领域都有广泛的应用。</p>
<p>一般来说数据降维后样本中的信息会有所丢失，新的特征对样本的描述也存在一定的误差，PCA就是从尽量减少信息损失的角度来实现特征降维。主成分分析是能保证最优性。</p>
<p><strong>PCA思想</strong></p>
<p>找出数据里最主要的方面，用数据的最主要的方面来代替原始数据。具体来说，假设数据集是$n$维，共有$m$个数据$(x^{(1)},x^{(2)},\dots,x^{(m)})$。目的是将这$m$个数据的维度从$n$维降为$n’$，希望这$m$个$n’$维数据集尽可能地代表原始数据集。</p>
<p>最简单地情况是将数据从二维降到一维，即$n=2,n’=1$，</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/19.png" title="PCA思想">
<p>希望找到一个维度方向，它可以代表这两个维度地数据，图中列出了两个向量方向$u_1,u_2$，直观上来说，$u_1$比$u_2$好，有两种解释：</p>
<ul>
<li>第一种解释是样本点到这个直线地距离足够近</li>
<li>第二种解释是样本点在这个直线上地投影能尽可能地分开</li>
</ul>
<p>加入把$n’$从1维推广到任意维，则希望降维的标准是：样本点到这个超平面的距离足够近，或者说样本点在这个超平面上的投影能尽可能地分开。</p>
<p><strong>PCA推导：基于最小投影距离</strong></p>
<p>假设m个n维数据$(x^{(1)},x^{(2)},\dots,x^{(m)})$都已经进行了中心化，即$\sum\limits_{i=1}^m x^{(i)} =0$。经过投影变换后得到新的坐标系为$\{w_1,w_2,\dots,w_n\}$,其中$w$是标准正交基，即$||w||_2 =1,w_i^Tw_j =0$。</p>
<p>将数据从$n$维降到$n’$维，丢弃新坐标系中的部分坐标，则新的坐标系维$\{w_1,w_2,\dots,w_{n’}\}$，样本点$x^{(i)}$在$n’$维坐标系中的投影为：$z^{(i)} = (z_1^{(i)},z_2^{(i)},\dots,z_{n’}^{(i)})^T$，其中，$z_j^{(i)} = w_j^Tx^{(i)}$是$x^{(i)}$是在低维空间坐标系里第$j$维的坐标。</p>
<p>如果用$z^{(i)}$来恢复原始数据$x^{(i)}$，则得到的恢复数据为：$\overline{x}^{(i)} = \sum \limits_{j=1}^{n’} z_j^{(i)}w_j = Wz^{(i)}$，其中，$W$标准正交基组成的矩阵。</p>
<p>考虑整个样本集，希望所有的样本到这个超平面的距离足够近，即最小化：$\sum\limits_{i=1}^m ||\overline{x}^{(i)} - x^{(i)}||_2^2$</p>
<p> 将这个式子整理，得到：</p>
<p>$\sum\limits_{i=1}^m ||\overline{x}^{(i)} - x^{(i)}||_2^2 = \sum \limits_{i=1}^m ||Wz^{(i)} -x^{(i)}||^2_2 【其中：\overline{x}^{(i)} = Wz^{(i)}】$</p>
<p>$ = \sum\limits_{i=1}^m (Wz^{(i)})^T(Wz^{(i)}) - 2\sum\limits_{i=1}^m (Wz^{(i)})^Tx^{(i)} + \sum\limits_{i=1}^m x^{(i)T}x^{(i)} 【平方和展开】$</p>
<p>$ = \sum\limits_{i=1}^m z^{(i)T}z^{(i)} - 2\sum\limits_{i=1}^m z^{(i)T}W^Tx^{(i)} + \sum\limits_{i=1}^m x^{(i)T}x^{(i)} 【矩阵转置：(AB)^T = B^TA^T,W^TW=I】$</p>
<p>$ = \sum\limits_{i=1}^m z^{(i)T}z^{(i)} - 2\sum \limits_{i=1}^m z^{(i)T}z^{(i)} + \sum \limits_{i=1}^m x^{(i)T}x^{(i)} 【其中：z^{(i)} = W^Tx^{(i)}】$</p>
<p>$ =- \sum\limits_{i=1}^m z^{(i)T}z^{(i)} + \sum \limits_{i=1}^m x^{(i)T}x^{(i)} 【合并同类项】$</p>
<p>$ =-tr\left(W^T (\sum\limits_{i=1}^m x^{(i)} x^{(i)T})W\right) + \sum\limits_{i=1}^m x^{(i)T}x^{(i)} 【其中：z^{(i)} = W^T x^{(i)} ，tr(BA^T) = A^T B】$</p>
<p>$ =-tr(W^T XX^TW)+ \sum\limits_{i=1}^m x^{(i)T}x^{(i)}【代数和转换为矩阵形式】$</p>
<p>注意到$\sum \limits_{i=1}^m x^{(i)}x^{(i)T}$是数据集的协方差矩阵，$W$的每一个向量$w_j$是标准正交基。$\sum\limits_{i=1}^m x^{(i)T}x^{(i)}$是一个常量【因为$x^{(i)}$是一个列向量】。最小化上式等价于：</p>
<p>$\underbrace{arg \min}_{W} -tr(W^T XX^T W)$，$s.t. W^TW = I$</p>
<blockquote>
<p>arg    是变元（即自变量argument）的英文缩写。<br>arg min 就是使后面这个式子达到最小值时的变量的取值<br>arg max 就是使后面这个式子达到最大值时的变量的取值</p>
<p>例如 函数F(x,y):</p>
<p>arg  min F(x,y)就是指当F(x,y)取得最小值时，变量x,y的取值</p>
</blockquote>
<p>直接观察可以发现最小值对应的$W$由协方差矩阵$XX^T$最大的$n’$个特征值对应的特征向量组成。数学推导，可以有以利用拉格朗日函数得到：</p>
<p>$J(W) = -tr \left(W^TXX^TW + \lambda(W^TW-I)\right)$</p>
<p>对$W$求导有$-2XX^T W +2\lambda W =0$，整理得到：$XX^T W = \lambda W$</p>
<p>【注】：这里面运用到矩阵迹求导</p>
<p>可以看到，$W$为$XX^T$的$n’$歌特征向量组成的矩阵，而$\lambda$为$XX^T$的若干特征值组成的矩阵，特征值在主对角线上，其余位置为0。</p>
<p>所以：</p>
<p>将数据集从$n$维降到$n’$维是，需要找到最大的$n’$歌特征值对应的特征向量。这$n’$个特征向量组成的矩阵$W$即为我们需要的矩阵。</p>
<p>对于原始的数据集，只需要用$z^{(i)} = W^Tx^{(i)}$，就可以把原始数据集降维到最小投影距离的$n’$维数据集。</p>
<p><strong>PCA推导：基于最大投影方差</strong></p>
<p>假设m个n维数据$(x^{(1)},x^{(2)},\dots,x^{(m)})$都已经进行了中心化，即$\sum\limits_{i=1}^m x^{(i)} =0$。经过投影变换后得到新的坐标系为$\{w_1,w_2,\dots,w_n\}$,其中$w$是标准正交基，即$||w||_2 =1,w_i^Tw_j =0$。</p>
<p>将数据从$n$维降到$n’$维，丢弃新坐标系中的部分坐标，则新的坐标系维$\{w_1,w_2,\dots,w_{n’}\}$，样本点$x^{(i)}$在$n’$维坐标系中的投影为：$z^{(i)} = (z_1^{(i)},z_2^{(i)},\dots,z_{n’}^{(i)})^T$，其中，$z_j^{(i)} = w_j^Tx^{(i)}$是$x^{(i)}$是在低维空间坐标系里第$j$维的坐标。</p>
<p>对于任意一个样本$x^{(i)}$，在新的坐标系下的投影为$W^Tx^{(i)}$，在新坐标系中的投影方差为$W^Tx^{(i)}x^{(i)T}W$，要使得所有的样本的投影方差和最大【即最能分开】，即最大化$\sum\limits_{i=1}^m W^Tx^{(i)}x^{(i)T}W$的迹，即：</p>
<p>$\underbrace{arg \max}_{W}  tr(W^T XX^T W)$，$s.t. W^TW = I$</p>
<p>利用拉格朗日函数可以得到：</p>
<p>$J(W) = tr \left(W^TXX^TW + \lambda(W^TW-I)\right)$，对$W$求导有：</p>
<p>$2XX^T W +2\lambda W =0$，整理可得：</p>
<p>$XX^TW = (-\lambda) W$</p>
<p>可以看到，$W$为$XX^T$的$n’$歌特征向量组成的矩阵，而$-\lambda$为$XX^T$的若干特征值组成的矩阵，特征值在主对角线上，其余位置为0。</p>
<p><strong>PCA算法流程</strong></p>
<p>求样本$x^{(i)}$的$n’$维的主成分其实就是求样本集的协方差矩阵$XX^T$的前$n’$个特征值对应的特征向量矩阵$W$，然后对于每个样本$x^{(i)}$，做如下的变换$z^{(i)} = W^T x^{(i)}$，以达到降维的PCA目的。</p>
<p>具体算法<a href="尖括号">^1</a>流程：</p>
<p>输入：$n$维样本集$D= \left( x^{(1)} ,x^{(2)},\dots,x^{(m)}\right)$，要降维到的维数$n’$。</p>
<p>输出：降维后的样本集$D’$</p>
<ol>
<li>对所有的样本进行中心化：$x^{(i)} = x^{(i)} - \frac{1}{m} \sum\limits_{j=1}^m x^{(j)}$</li>
<li>计算样本的协方差矩阵$XX^T$</li>
<li>对矩阵$XX^T$进行特征值分解</li>
<li>取出最大的$n’$个特征值对应的特征向量$(w_1,w_2,\dots,w_{n’})$，将所有的特征向量标准化后，组成特征向量矩阵$W$。</li>
<li>对样本集中的每一个样本$x^{(i)}$，转化为新的样本$z^{(i)} = W^T x^{(i)}$</li>
<li>得到输出样本集$D’= \left( z^{(1)},z^{(2)},\dots,z^{(m)}\right)$</li>
</ol>
<p>有时候，不指定降维后的$n’$的值，而是指定一个降维到的主成分比重阈值$t$。这个阈值$t \in (0,1]$之间。假如$n$个特征值为$\lambda_1 \ge \lambda_2\ge \dots \ge \lambda_n$，则$n’$可以通过下式得到：</p>
<p>​                                        $\frac{\sum\limits_{i=1}^{n’}\lambda_i}{\sum\limits_{i=1}^{n}\lambda_i} \ge t$</p>
<p><strong>PCA实例</strong></p>
<p>假设我们的数据集有10个二维数据(2.5,2.4), (0.5,0.7), (2.2,2.9), (1.9,2.2), (3.1,3.0), (2.3, 2.7), (2, 1.6), (1, 1.1), (1.5, 1.6), (1.1, 0.9)，需要用PCA降到1维特征。</p>
<p>首先我们对样本中心化，这里样本的均值为(1.81, 1.91),所有的样本减去这个均值后，即中心化后的数据集为(0.69, 0.49), (-1.31, -1.21), (0.39, 0.99), (0.09, 0.29), (1.29, 1.09), (0.49, 0.79), (0.19, -0.31), (-0.81, -0.81), (-0.31, -0.31), (-0.71, -1.01)。</p>
<p>现在我们开始求样本的协方差矩阵，由于我们是二维的，则协方差矩阵为：</p>
<p>$XX^T=\left(\begin{matrix}cov(x_1,x_1)&amp; cov(x_2,x_1)\\\\cov(x_1,x_2)&amp;cov(x_2,x_2)\end{matrix}\right)$
　　　</p>
<p>　对于我们的数据，求出协方差矩阵为：</p>
<p>$XX^T=\left(\begin{matrix}0.616555556 &amp;0.615444444 \\\\0.615444444&amp;0.716555556\end{matrix}\right)$
　　　　</p>
<p>求出特征值为（0.0490833989， 1.28402771）</p>
<p>对应的特征向量分别为：$(0.735178656,0.677873399)^T$和$(−0.677873399,−0.735178656)^T$</p>
<p>由于最大的k=1个特征值为1.28402771，对于的k=1个特征向量为$(−0.677873399,−0.735178656)^T$</p>
<p>则我们的$W=(−0.677873399,−0.735178656)^T$
　　　　</p>
<p>我们对所有的数据集进行投影$z^{(i)}=W^Tx^{(i)}$，得到PCA降维后的10个一维数据集为：(-0.827970186， 1.77758033， -0.992197494， -0.274210416， -1.67580142， -0.912949103， 0.0991094375， 1.14457216, 0.438046137， 1.22382056)</p>
<h3 id="核主成分分析KPCA介绍"><a href="#核主成分分析KPCA介绍" class="headerlink" title="核主成分分析KPCA介绍"></a>核主成分分析KPCA介绍</h3><p>以上的PCA算法中，假设存在一个线性超平面，可以对数据进行投影，但是有时候数据不是线性的，不能直接进行PCA降维。</p>
<p>这里需要用到核支持向量机一样的核函数思想，先把数据集从$n$维映射到线性可分的高维$N$，然后再从$N$维降维到一个低维度$n’$，这里的维度之间满足：$n’ &lt; n &lt; N$。</p>
<p>使用核函数的PCA称为核主成分分析(Kernellized PCA,简称KPCA)。假设高维空间的数据是由$n$维空间的数据通过映射$\phi$产生。</p>
<p>则对于$n$为空间的特征分解：</p>
<p>$\sum\limits_{i=1}^m x^{(i)}x^{(i)T}W = \lambda W$</p>
<p>映射为：</p>
<p>$\sum\limits_{i=1}^m \phi\left(x^{(i)}\right)\phi\left(x^{(i)}\right)^TW =\lambda W$</p>
<p>通过在高维空间进行协方差矩阵的特征值分解，然后用核PCA一样的方法进行降维。需要进行核函数运算，计算量要比PCA大很多。</p>
<h3 id="PCA算法总结"><a href="#PCA算法总结" class="headerlink" title="PCA算法总结"></a>PCA算法总结</h3><p>作为一个非监督学习得降维方法，只需要特征值分解，就可以对数据进行压缩，去噪。应用广泛。</p>
<p>为克服PCA的一些缺点，出现了很多PCA的变种，如解决非线性降维的KPCA，解决内存限制的增量PCA方法（Incremental PCA），以及解决稀疏数据降维的PCA方法Sparse PCA。</p>
<p>PCA算法的主要优点：</p>
<ul>
<li>仅仅需要以方差衡量信息量，不受数据集以外的因素影响</li>
<li>各主成分之间正交，可消除原始数据成分间的相互影响的因素</li>
<li>计算方法简单，主要运算是特征值分解，易于实现。</li>
</ul>
<p>PCA算法的主要缺点：</p>
<ul>
<li>主成分各个特征维度的含义具有一定的模糊性，不如原始样本特征的解释性强</li>
<li>方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响。</li>
</ul>
<hr>
<h3 id="K-L变换"><a href="#K-L变换" class="headerlink" title="K-L变换"></a>K-L变换</h3><p>K-L变换与PCA不同之处在于，PCA是一种无监督的特征变换，K-L变换能够考虑到不同的分类信息，实现有监督的特征提取。</p>
<p>随机过程中K-L展开理论，将随机过程描述为无数个正交函数的线性组合，在模式识别中，可以将一个样本看成是随机向量的某一次实现结果。假设有一$d$维随机向量$X$，可以写成一组正交基$\sigma_i, i=1,\dots,\infty$的线性组合，且模为1：</p>
<p>$ x= \sum\limits_{i=1}^{\infty} y_i \sigma_i$</p>
<p>变形得到：$y_i = \sigma_i^T x$</p>
<p>假设有用信息集中在其中的$q$维上，用$q$维去近似$x$：</p>
<p>$ x’=\sum \limits_{i=1} ^q y_i \sigma_i$</p>
<p>近似前后样本向量的差向量为：$x - x’$</p>
<p>上述差向量的均方误差（MSE）为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br> e&amp;= E\{ (x-x’)(x-x’)^T\} \\\\<br> &amp;= E\left\{ \left(\sum\limits_{i=q+1}^{\infty}y_i\sigma_i \right)\left(\sum\limits_{i=q+1}^{\infty}y_i\sigma_i \right) ^T \right\} \\\\<br> &amp;= E\left\{ \sum\limits_{i=q+1}^{\infty} y_i y_i^T   \right\}  \\\\<br> &amp;= \sum\limits_{i=q+1}^{\infty} \sigma_i^T E\{ xx^T\}\sigma_i \\\\<br> &amp;= \sum\limits_{i=q+1} ^{\infty} \sigma_i^T \Sigma_X \sigma_i<br>\end{aligned}<br>\end{equation}<br>$$<br>其中$\sigma_i^T \sigma_i =1$，正交基。变换矩阵$\Sigma_X$是原样本向量$X$的二阶矩阵（注意：这里还可以是其他矩阵，如协方差矩阵），<strong>与PCA相比较，当变换矩阵$\Sigma_X$是协方差矩阵时，K-L就是PCA。</strong></p>
<p>最小化上述MSE，同PCA的求解方法一致，得到下面拉格朗日目标函数：</p>
<p>$L(\sigma) = \sum\limits_{i=q+1}^{\infty} \sigma_i^T \Sigma_X \sigma_i - \sum\limits_{i=q+1}^{\infty} \lambda_i(\sigma_i^T\sigma_i -1)$</p>
<p>对$\sigma$求导并令其等于零，有：</p>
<p>$2(\Sigma_X -\lambda_i I)\sigma_i =0, i= q+1,\dots,\infty$</p>
<p>其中$\lambda_i$就是$\Sigma_X$的特征值，均方误差为：</p>
<p>$ e= \sum\limits_{i=q+1}^{\infty} \lambda_i$</p>
<p>所以：</p>
<p>想用$q$维来表示样本向量化并使得MSE最小化，合理的做法是：把变化矩阵$\Sigma_X$的特征值从大到小排列，然后选择前$q$个特征值对应的特征向量，此时的截断误差能够保证最小，其中$\sigma_i , i=1,\dots,\infty$中的前$q$个正交向量就组成了新的特征空间，而原样本向量$X$在这个新的特征空间上的展开系数$y_i$就组成了心得特征向量，这种变换称为<strong>K-L变换</strong>，对于其他不同形式，主要基于变换矩阵$\Sigma_X$的具体形式。</p>
<p><strong>K-L变换的几个重要性质</strong></p>
<ol>
<li><p>变换后得到的新特征满足零均值：</p>
<blockquote>
<p>proof：</p>
<p>设有如下K-L变换：$Y= A(X -m_x)$，其中矩阵$A$是变换核矩阵，$m_x$是$X$的均值；对$X$的变换结果$Y$求均值：</p>
<p>$m_y = E[Y] = E[A(X-m_x)] = AE[X-m_x] = AE[X] - Am_x = 0$</p>
</blockquote>
</li>
<li><p>K-L变换是一种正交变换</p>
</li>
<li><p>K-L变换的新特征彼此之间不相关</p>
</li>
<li><p>K-L变换信号的最佳压缩表示，用q维新特征表示原样本特征带来的误差在所有q维正交坐标变换中最小</p>
</li>
<li><p>K-L坐标系来表示数据，意味着熵最小，即样本的方差信息最大程度的集中在较少的维数上</p>
</li>
<li><p>K-L变换的新特征向量的二阶矩阵是对角阵，且对角线元素就是原特征的二阶矩阵的特征值，即$(\Sigma_X )^T = \Sigma_X $</p>
<blockquote>
<p>proof:<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\Sigma_{\xi} &amp;= E[\xi \xi^T] = E[A^T (x-u)(A^T(x-u))^T] \\\\<br>&amp;= E[A(x-u)(x-u)^TA^T]= AE[(x-u)(x-u)^T]A^T \\\\<br>&amp;= A\Sigma A^T \\\\<br>&amp;= \left[\begin{matrix} \gamma_1&amp; 0 &amp; \dots&amp; 0 \ 0 &amp;  \gamma_2 &amp; \dots &amp; 0 \ \vdots &amp; \vdots &amp; \ddots &amp;\vdots \ 0 &amp; 0&amp;\dots &amp; \gamma_p \end{matrix}\right]<br>\end{aligned}<br>\end{equation}<br>$$</p>
</blockquote>
</li>
</ol>
<h3 id="K-L变换与PCA联系与区别"><a href="#K-L变换与PCA联系与区别" class="headerlink" title="K-L变换与PCA联系与区别"></a>K-L变换与PCA联系与区别</h3><p><strong>联系</strong>：</p>
<ul>
<li>两者都属于正交变换，当对原特征$X$进行中心化时（即变换矩阵为协方差矩阵），K-L变换等价于PCA</li>
<li>PCA是离散的K-L变换，都可以实现降维变换</li>
</ul>
<p><strong>区别</strong>：</p>
<ul>
<li>K-L变换可以实现有监督的特征提取，但是PCA的变换是一种无监督的</li>
<li>K-L变换可以处理连续和离散的情况（较为广义），而PCA只针对离散情况（较为侠义）</li>
<li>K-L变换的变换矩阵可以是很多种，如二阶矩阵、协方差矩阵（总体散布矩阵）等，即变换矩阵是<strong>自相关矩阵</strong>。而PCA的变换矩阵只是协方差矩阵</li>
</ul>
<blockquote>
<p>协方差矩阵：</p>
<p>$C_x = E\{(x-m_x)(x-m_x)^T\}$</p>
<p>其中$m_x$是均值。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/自相关矩阵.PNG">
<p>其中$\pmb x^H$是共轭转置矩阵，当为实矩阵时，等价于转置矩阵。</p>
<p>协方差矩阵和自相关矩阵的关系：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>C_x &amp;= E[ (x-m_x)(x-m_x)^H ] \\\\<br>&amp;=E[ xx^H - xm_x^H-m_x x^H + m_xm_x^H]\\\\<br>&amp;= E[xx^H] - E[x]E[m_x^H] -E[m_x]E[x^H] - E[m_xm_x^H] \\\\<br>&amp;= E[xx^H] -m_x m_x^H - m_x m_x^H + m_xm_x^H \\\\<br>&amp;= R_x - m_x m_x^H<br>\end{aligned}<br>\end{equation}<br>$$</p>
</blockquote>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>特征选择的目的是从原始的特征集$X$中中挑选出一组最有利于分类的特征$X’$，由于类别可分性判据可以评价挑选出的一组特征对于分类问题的有效性，因此特征选择实际上是一个对某种选定的可分性判据的优化：</p>
<p>$X’ =arg \max \limits_{\widetilde{X} \subset X} J(\widetilde{X})$</p>
<p>其中原始特征集合$X$中包含$d$个特征，$X’$中包含$d’ &lt; d$个特征，$\widetilde{X}$是任意包含$d’$个元素的$X$的子集。</p>
<p>求解优化问题的一个简单的思路：用可分性判据$J$分别评价每一个特征，然后根据判据值得大小对特征重新排序，使得$J(x_1) \ge J(x_2) \ge \dots \ge J(x_{d’}) \ge \dots \ge J(x_d)$</p>
<p>其中有一个问题：单独使用使得$J$较大得前$d’$特征作为特征选择结果，不能保证是一个最优解。因为这个过程中没有考虑各个特征之间得相关性，只有当特征之间相互独立时才能保证是最优解。</p>
<p>另一个简单思路是对所有得$\widetilde{X} \subset X$的组合进行穷举，计算每一种组合判据值，选出最优组合。从$d$个特征中选择出$d’$个特征，所有可能得组合数为：</p>
<p>$q= C_d^{d’} = \frac{d!}{(d-d’)! \times{d’}!}$</p>
<p>穷举法可以保证最优性，但是需要巨大的计算量作为代价。</p>
<h3 id="分支定界法"><a href="#分支定界法" class="headerlink" title="分支定界法"></a>分支定界法</h3><p>分支定界法是一种能减小穷举法计算复杂度的最优特征组合搜索算法，但是依赖于类别可分性判据的一个重要性质——<strong>单调性</strong>，即对于两个特征子集$X_1 \subset X_2 \implies J(X_1) \le J(X_2)$。</p>
<p>单调性不是所有类别可分判据都有的性质，<em>只有当可分判据满足单调性时，分支定界法才能保证搜索到最优的特征组合。</em></p>
<p><strong>算法</strong>：</p>
<ul>
<li>初始化：根据原始特征维度$d$和选择特征维度$d’$构建搜索树，使用非对称树保证生成的叶节点不会出现重复的特征，树高$d-d’$，设置界值$B=0$</li>
<li>从右向左分支定界搜索：<ul>
<li>如果当前节点没有分支，则向下搜索，直到叶节点为止。计算叶节点代表的特征集合的可分性判据，如果大于界值$B$，则替换$B$，并记录这个特征集，作为当前的最优选择；向上回溯，直到有节点存在未搜索的分支，按照从右往左的顺序搜索其子节点</li>
<li>如果当前节点有分支，则计算当前节点代表特征集合的可分性判据，小于界值$B$，则终止该节点往下搜索，否则按照从右往左的顺序搜索其子节点。</li>
</ul>
</li>
<li>输出：最优特征集合</li>
</ul>
<p><strong>存在问题</strong>：</p>
<ul>
<li>算法能否搜索到最优的特征组合依赖于所采用的类别可分性判据是否具有单调性</li>
<li>分支定界法的计算复杂度是不确定的，与最优解分支的所在位置有关，如果最优解分支在最右端并且根节点的子节点判据值均小于最优解，则搜索效率最高；如果每个分支的可分性判据都大于其左端分支的可分性判据，那么需要计算搜索树上所有节点的判据值，实际的计算复杂度会超过穷举法。</li>
</ul>
<blockquote>
<p>以求解整数规划问题解释分支定界法</p>
<p>$max  z = 5x_1 +8x_2$</p>
<p>$ LIP0\cases{x_1 +x_2 \le 6 \\\ 5x_1 + 9x_2 \le 45 \\\ x_1 \ge 0,x2 \ge 0 ;x_1,x_2 \in Z} $</p>
<p>(1)首先不考虑整数限制条件，应用线性规划，得到$LIP0$的松弛问题：</p>
<p>得到最优解为：$x_1 = 2.25,x_2 =3.75，z_0 =41.25$</p>
<p>由此可得到最优解$0 \le z^<em> \le z_0 =41.25 $，且必须为整数，所以$0 \le z^</em> \le 41$。这一过程称为<strong>定界</strong>，即给出 $ILP0$问题目标函数最优解的$z^*$的上下界。</p>
<p>（2）但由于$x_1,x_2$都必须是整数，必须得去掉小数。对于$x_2$，最终的最优解不会在3和4之间取值，所以有：</p>
<p>$\max  z=5x_1+ 8x_2$</p>
<p>$ ILP1 = \cases{x_1 +x_2 \le 6 \\\ 5x_1 + 9x_2 \le 45 \\\ x_2 \le 3 \\\\x_1 \ge 0,x2 \ge 0 ;x_1,x_2 \in Z}$</p>
<p>或者：</p>
<p>$ ILP2= \cases{x_1 +x_2 \le 6 \\\ 5x_1 + 9x_2 \le 45 \\\ x_2 \ge 4 \\\\x_1 \ge 0,x2 \ge 0 ;x_1,x_2 \in Z}$</p>
<p>这样将可行域分成了$x_2 \le 3$或$x_2 \ge 4$，把原来线性规划的解点$(2.25,3.75)$排除出去，但没有排除任何整数可行解。这一过程称为<strong>分支</strong>，即用两个矛盾的约束条件代入原问题形成两个子问题$ILP1,ILP2$。</p>
<p>解$ILP1$的松弛问题得到：</p>
<p>$(x_1,x_2) = (3,3),z_{max} = 39$</p>
<p>解$IL2P$的松弛问题得到：</p>
<p>$(x_1,x_2) = (1.8,4),z_{max} = 41$</p>
<p>（3）修改上下界：从$ILP1,ILP2$的解得到$39 \le z^{*} \le 41$</p>
<p>（4）再分支：</p>
<p>针对于$x_1$，去掉其中的小数部分，增加约束$x_1 \le 1 ,x_1 \ge 2$对$ILP2$进一步分支，【注：因为在$ILP2$问题中得到的$z_{max}$取值最大，所以再对其进行分支】，即：</p>
<p>$\max  z=5x_1+ 8x_2$</p>
<p>$ ILP3 = \cases{x_1 +x_2 \le 6 \\\ 5x_1 + 9x_2 \le 45 \\\ x_2 \ge 4 \\\ x_1 \le 1 \\\\x_1 \ge 0,x2 \ge 0 ;x_1,x_2 \in Z}$</p>
<p>$ ILP4 = \cases{x_1 +x_2 \le 6 \\\ 5x_1 + 9x_2 \le 45 \\\ x_2 \ge 4 \\\ x_1 \ge 2 \\\\x_1 \ge 0,x2 \ge 0 ;x_1,x_2 \in Z}$</p>
<p>解$ILP3$得到：</p>
<p>$(x_1,x_2) =(1,4),z_{max} = 40$</p>
<p>$ILP4$无可行解。</p>
<p>（5）再修改界，有：$39 \le z^{*} \le 40$</p>
<p>（6）再分支，继续对$ILP3$进行分支【注：因为$ILP4$问题无解，不再分支，在$x_2\ge 4$的基础上再往前分支，计算$z_{max}$值】，得到：</p>
<p>$\max  z=5x_1+ 8x_2$</p>
<p>$ ILP5 = \cases{x_1 +x_2 \le 6 \\\ 5x_1 + 9x_2 \le 45 \\\ x_2 \ge 4 \\\ x_1 \le 1 \\\ x_2 \le 4 \\\\x_1 \ge 0,x2 \ge 0 ;x_1,x_2 \in Z}$</p>
<p>$ ILP6 = \cases{x_1 +x_2 \le 6 \\\ 5x_1 + 9x_2 \le 45 \\\ x_2 \ge 4 \\\ x_1 \le 1 \\\ x_2 \ge 5 \\\\x_1 \ge 0,x2 \ge 0 ;x_1,x_2 \in Z}$</p>
<p>解$ILP5$得到：</p>
<p>$(x_1,x_2) =(1,4),z_{max} =37$</p>
<p>解$IL6P$得到：</p>
<p>$(x_1,x_2) =(0,5),z_{max} =40$</p>
<p>至此，所有的子问题都已探明，$z$的最大值不再改变，求解结束。</p>
<p>寻找的 上下界为：$39 \le z^{*} \le 40$</p>
<p>最终找到的$ILP0$(原问题)的最优解：$z_{max} = 40$</p>
</blockquote>
<h3 id="次优搜索算法"><a href="#次优搜索算法" class="headerlink" title="次优搜索算法"></a>次优搜索算法</h3><p>很多的实际问题不再追求找到最优的特征组合，转而采用某种次优搜索算法，选出一组较好的特征。</p>
<h4 id="顺序前进法"><a href="#顺序前进法" class="headerlink" title="顺序前进法"></a>顺序前进法</h4><p>Sequential Forward Selection（SFS），也称为自下而上的搜索方法。从一个空集开始每次向选择的特征集合中加入一个特征，直到特征集合中的特征数满足要求为止，每次选择加入特征的原则是将其加入特征集合后能够使得可分性判据最大。</p>
<p><strong>算法</strong>：</p>
<ul>
<li>初始化：原始特征集合$X$，设置特征集合$X’ = \Phi$</li>
<li>循环直至$X’$中包含$d’$个特征为止：<ul>
<li>计算将任意未被选择的特征加入$X’$后的可分性判据值：$J\left( X’ \cup \{x_i\}\right), \forall x_i \in X-X’$</li>
<li>寻找最优特征：$x’= arg \max \limits_{x’ \in X-X’} J\left( X’ \cup \{x_i\}\right)$</li>
<li>将最优特征加入选择特征集合：$X’ =X’\cup \{x’\}$</li>
</ul>
</li>
<li>输出：特征集合$X’$</li>
</ul>
<p>循序前进法需要计算判据值的次数为:</p>
<p>$\sum\limits_{i=0}^{d’-1} (d-i) = \frac{d’(2d-d’ +1)}{2}$</p>
<h4 id="顺序后退法"><a href="#顺序后退法" class="headerlink" title="顺序后退法"></a>顺序后退法</h4><p>Sequential Backward Selection(SBS)，也称自上而下的搜索方法。从全集开始，每一轮从特征值中删除一个最差的特征，选择特征的原则是将其删除后使得特征集合的判据值下降得最少。</p>
<p><strong>算法</strong>：</p>
<ul>
<li>初始化：原始特征集合$X$，设置选择特征集合$X’ =X$</li>
<li>循环直到$X’$中包含$d’$个特征为止：<ul>
<li>计算将任何一个$X’$中元素删除后的可分性判据值：$J\left( X’ - \{x_i\}\right),\forall x_i \in X’$</li>
<li>寻找最优的删除特征：$x’ = arg \max\limits_{x’ \in X’} J\left( X’ - \{x_i\}\right)$</li>
<li>将选择的特征移出集合：$X’ = X’ -\{x’\}$</li>
</ul>
</li>
<li>输出：特征集合$X’$</li>
</ul>
<p>顺序后退法需要计算判据值的次数为$\sum\limits_{i=0}^{d-d’-1}(d-i) = \frac{(d-d’)(d+d’+1)}{2}$</p>
<h4 id="广义顺序前进（后退）法"><a href="#广义顺序前进（后退）法" class="headerlink" title="广义顺序前进（后退）法"></a>广义顺序前进（后退）法</h4><p>Generalized Sequential Forward(Backward) Selection，GSFS，GSBS。顺序前进和顺序后退法都是每次增删1个特征，而广义的顺序前进和顺序后退则是每次增删$r$个特征。</p>
<p>如果进行了$k$轮迭代，判据值的计算次数为$\sum\limits_{i=0}^{k-1} C_{d-i\times r}^r = \frac{1}{r!} \times \sum\limits_{i=0}^{k-1} \frac{(d-i \times r)!}{(d- i\times r -r)!}$</p>
<p>一般来说，广义的顺序前进（后退）法的计算量都要大于顺序前进（后退）法，但是由于考虑了特征之间的统计相关性，优化的结果一般要好于每次选择一个特征的顺序前进或后退法。</p>
<h4 id="增l-删r法（l-r法）"><a href="#增l-删r法（l-r法）" class="headerlink" title="增l-删r法（l-r法）"></a>增l-删r法（l-r法）</h4><p>顺序前进（后退）法中一旦某个特征被增（删）后，既不能被删（增）了，这对搜索最优二点特征组合是不利的，因为选择这些特征时只考虑了和当前$X’$中的特征的相关性和增（删）后的判据值大小，而没有考虑之后增（删） 的某些特征的情况。</p>
<p>$l-r$法允许对特征选择过程进行回溯，先用顺序前进法向$X’$加入$l$个特征，再用顺序后退法从$X’$中删除$r$个特征$(l&gt; r)$，循环这个过程直至满足特征数要求。</p>
<p><strong>算法</strong>：</p>
<ul>
<li>初始化：设置选择特征集合$X’ = \Phi$</li>
<li>循环直到$X’$中包含$d’$个特征为止：<ul>
<li>调用顺序前进法$l$次，向$X’$中添加$l$个特征</li>
<li>调用顺序后退法$r$次，向$X’$中删除$r$个特征</li>
</ul>
</li>
<li>输出：特征集合$X’$</li>
</ul>
<p>回溯过程也可以反方向进行，此时$l&lt;r$，从全集开始，先调用顺序后退法$r$次，再用顺序前进法$l$次，直到特征数满足要求为止。</p>
<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p>神经网络，一个广泛的定义是：</p>
<p>神经网络是由具有适应性的简单单元组成的广泛的并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所做出的交互反应。</p>
<p>神经网络是一种<strong>监督学习算法</strong>，也是一种线性分类模型。</p>
<h2 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h2><p>神经网中的基本单元是神经元$（neuron）$。每个神经元有多个树突$（dendrite）$,一个轴突$(axon)$和一个细胞体$(cell  body)$，树突短而多支，轴突长只有一个（1m长左右）。</p>
<p><strong>结构</strong>：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/1.png" title="神经元模型结构">
<p><strong>功能</strong>：</p>
<p>树突用于传入其它神经元传递的神经冲动，轴突用于将神经冲动传出到其它神经元，当树突或细胞体传入的神经冲动使得神经元兴奋时，该神经元就会通过轴突向其它神经元传递兴奋。</p>
<p><strong>形式化描述</strong>：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/2.png" title="形式化描述">
<p>树突对应输入部分，每个神经元收到$n$个其它神经元传递过来的输入信号，通过带权重的连接（有损失）传递给细胞体，权重称为连接权(connection weight)。</p>
<p>细胞体分为两部分，前一部分计算总输入值（即输入信号的加权和，或称为累计电平），后一部分先计算总输入值与该神经元阈值的差值，然后通过激活函数(activation function)的处理，产生输出从轴突传送给其它神经元。</p>
<p><strong>激活函数</strong>：</p>
<p>与线性分类类似，神经元最理想的激活函数是阶跃函数，即将神经元输入值与阈值的差值映射为输出值1或0，分别对应于兴奋和抑制。</p>
<p>阶跃函数不连续，不光滑，也采用sigmoid函数来近似，sigmoid函数将较大范围内变化的输入值挤压到（0，1）输出范围内，也称为挤压函数(squashing function)。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/3.png" title="激活函数">
<p>将多个神经元按一定的层次结构连接起来得到神经网络。是一种包含多个参数的模型，若将每个神经元都看作一个函数，则整个神经网络就是由这些函数相互嵌套而成。</p>
<h2 id="感知器"><a href="#感知器" class="headerlink" title="感知器"></a>感知器</h2><p>感知器(perceptron,1957)是由两层神经元组成的简单模型。</p>
<p><strong>感知器与线性模型区别</strong>：</p>
<p>两者都是对属性加权与另一个常数求和，再使用sigmoid函数将输出压缩在0-1之间，解决分类问题。</p>
<p>不同在于感知器的输出层可以有很多个神经元，从而实现多分类，两个模型所使用的参数估计方法不同。</p>
<p><strong>感知器结构</strong>：</p>
<p>输出层神经元进行激活函数处理，称为功能神经元(functional neuron)；输出层只接受外界信号（样本属性）并传递给输出层（输入层的神经元个数等于样本的属性数目），而没有激活函数。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/4.png" title="感知器结构">
<p><strong>感知器的学习规则</strong>：</p>
<p>给定训练集，感知器的$n+1$个参数($n$个参数和1个阈值)都可以通过学习得到，阈值可以看成输入$x_{n+1} = -1$，对应权重为$w_{n+1}$，使得权重和阈值统一为权重的学习。</p>
<p>学习规则如下：</p>
<p>对于训练样本$(x,y)$，每一个样本进入感知器产生一个输出值。若该输出值与样本的真实标记不一致，则感知器会对权重进行调整，若激活函数为为阶跃函数，则调整的方法（基于<strong>梯度下降法</strong>）为：</p>
<blockquote>
<p>对于样本$(x,y)$,其预测值为：</p>
<p>$\hat{y} = f\left(\sum \limits_{i=1}^{n} \omega_ix_i - \theta   \right) = f\left(\sum \limits_{i=1}^{n+1} \omega_ix_i   \right)$</p>
<p>其中$x_{i+1} =-1$为固定值。</p>
<p>均方误差为：$E= \frac{1}{2}(y-\hat{y})^2$</p>
<p>使用梯度下降法寻找最小的均方差误差$\min E $，负的梯度方向为最速下降方向。</p>
<p>$\frac{\partial E}{\partial \omega_i} = -(y-\hat{y})\frac{\partial \hat{y}}{\partial \omega_i} = -(y-\hat{y}) \frac{\partial f\left(\sum \limits_{i=1}^{n+1} \omega_ix_i   \right)}{\partial \omega_i}$</p>
<p>因为函数$f$为阶跃函数，即有：</p>
<p>$\frac{\partial f\left(\sum \limits_{i=1}^{n+1} \omega_ix_i   \right)}{\partial \omega_i} = x_i$</p>
<p>令下降步长为$\eta，\eta \in (0,1)$，则：</p>
<p>$\Delta \omega_i = - \frac{\partial E}{\partial \omega _i} \times \eta = \eta(y -\hat{y}) x_i$</p>
<p>其中$\eta \in (0,1)$表示学习速率。</p>
</blockquote>
<p>可见：</p>
<p>感知器是通过逐个样本输入来更新权重，首先设置好初始权重（一般随机设置），逐个地输入样本数据，若输出值与真实标记相同则继续输入下一个样本，若不一致则更新权重，然后再重新逐个检验，直到每个样本的数据的输出值都与真实标记相同。</p>
<p>感知器模型总能够将训练数据的每一个样本都预测正确，感知器模型很容易产生<strong>过拟合</strong>问题。</p>
<blockquote>
<p>过拟合（overfitting）</p>
<p>为得到一致假设而使得假设变得过度严格。为拟合一个模型，使用过多参数。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/5.jpg" title="过拟合图形化解释">
</blockquote>
<h2 id="多层网络"><a href="#多层网络" class="headerlink" title="多层网络"></a>多层网络</h2><p>感知器只有一层功能神经元，功能有限，只能处理线性可分问题，这个过程感知器一定收敛(converge)。</p>
<p>解决非线性问题，需要使用多层功能神经元，多层神经网络的拓扑结构如下：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/6.png" title="多层神经网络的拓扑结构">
<p>结构满足以下特点：</p>
<ul>
<li>每层神经元与下一层神经元之间完全互连</li>
<li>神经元之间不存在同层连接</li>
<li>神经元之间不存在跨层连接</li>
</ul>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/7.png" title="前馈神经网络">
<p>常用的神经网络为“多层前馈神经网络”(multi-layer feedforward neural network)。</p>
<p>其中，“<strong>前馈</strong>”指的是在网络拓扑结构中不存在环或者回路。</p>
<p>神经网络的学习过程是根据训练数据来调整神经元之间的连接权以及每一个神经元的阈值，即：<strong>神经网络学习到的东西都蕴含在网络的连接权和阈值中。</strong></p>
<h2 id="BP神经网络算法"><a href="#BP神经网络算法" class="headerlink" title="BP神经网络算法"></a>BP神经网络算法</h2><p>BP神经网络是基于前馈神经网络增加了<strong>反馈调节</strong>机制。</p>
<p>多层网络使用简单感知器的权重调整规则显然不够用，BP神经网络算法（即误差反向传播算法（error backpropagation））是针对多层前馈神经网络设计的。也适用于其它类型的神经网络，如训练递归神经网络。</p>
<h3 id="基本思想-1"><a href="#基本思想-1" class="headerlink" title="基本思想"></a>基本思想</h3><p>给定训练集$D= \{ (x_1,y_1),(x_2,y_2),\dots,(x_m,y_m)\},x_i \in \mathbb{R}^d,y_i \in \mathbb{R}^l$，输入示例由$d$个输入神经元，输出$l$维实值向量。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/8.png" title="BP算法拓扑结构">
<p>$d$个输入神经元、$l$个输出神经元、$q$个隐含层神经元的多层前馈网络结构，其中输出层第$j$个神经元阈值为$\theta_j$，隐含层第$h$个神经元阈值为$\gamma_h$。</p>
<p>输入层第$i$个神经元与隐含层第$h$个神经元的连接权重为$v_{ih}$，隐含层第$h$个神经元与输出层第$j$个神经元之间的连接权重为$w_{hj}$。</p>
<p>记：隐含层第$h$个神经元接收到的输入为$\alpha_h = \sum \limits_{i=1}^dv_{ih}x_i$</p>
<p>输出层第$j$个神经元接收到的输入为$\beta_j = \sum\limits_{h=1}^q w_{hj}b_h$，其中$b_h$为隐含层第$h$个神经元的输出。</p>
<p>假设隐含层和输出层都使用sigmoid函数，则对训练例$(x_k,y_k)$，假定网络输出为$\hat{y_k} = (\hat{y_1}^k,\hat{y_2}^k,\dots,\hat{y_l}^k)$，即：</p>
<p>$\hat{y_j}^k =f(\beta_j - \theta_j)$</p>
<p>隐含层输出：$b_h = f(\alpha_h- \gamma_h)$</p>
<p>在$(x_k.y_k)$上的均方误差为：</p>
<p>$E_k = \frac{1}{2} \sum \limits_{j=1}^l (\hat{y_j}^k - y_j^k)^2$</p>
<p>其中有：输入层到隐含层$d \times q$个权值、隐层到输出层$q \times l$个权值、$q$个隐含层神经元的阈值、$l$个输出层神经元的阈值 参数需要确定。</p>
<p>任意参数$v$的更新估计为：$v \leftarrow v+ \Delta v$。</p>
<blockquote>
<p>BP算法基于梯度下降（gradient descent），以目标负梯度方向对参数进行调整。</p>
<p>$E_k = \frac{1}{2} \sum \limits_{j=1}^l (\hat{y_j}^k - y_j^k)^2$</p>
<p>$\hat{y_j} = f\left( \sum\limits_{h=1}^q w_{hj}b_h-\theta_j\right)$</p>
<p>令：$b_{q+1} = -1$，则：$\hat{y_j} = f\left( \sum\limits_{h=1}^{q+1} w_{hj}b_h\right)$</p>
<p>令：$\beta_j = \sum\limits_{h=1}^q w_{hj}b_h$</p>
<p>根据链式法则：$E_k$首先受到$\hat{y_j}$的影响，接着$\hat{y_j}$受到$\beta_j$的影响，$\beta_j$直接受到$w_{hj}$的影响。即：</p>
<p>$\frac{\partial E_k}{\partial w_{hj}} = \frac{\partial E_k}{\partial \hat{y_j}} · \frac{\partial \hat{y_j}}{\partial \beta_{j}} · \frac{\partial \beta_j}{\partial w_{hj}}   $</p>
<p>$ \qquad= (\hat{y_j} -y_j)·f’(\beta_j)·b_h $</p>
<p>$ \qquad =(\hat{y_j} -y_j)·\frac{1}{ 1+ e^{-\beta_j}}·(1- \frac{1}{1+e^{-\beta_j}})·b_h $</p>
<p>$\qquad = (\hat{y_j} -y_j)·\hat{y_j}·(1-\hat{y_j})·b_h$</p>
<p>sigmoid函数一个性质：$f’(x) = f(x)[1-f(x)]$</p>
<p>对于误差$E_k$，给定学习率$\eta$，有：</p>
<p>$\Delta w_{hj} = - \eta \frac{\partial E_k}{\partial w_{hj}}$,其中：$\eta \in (0,1)$</p>
<p>令：$g_j =-\frac{\partial E_k}{\partial \hat{y_j}}·\frac{\partial \hat{y_j}}{\partial \beta_j}  \ \quad= \hat{y_j}·(1-\hat{y_j})·(y_j - \hat{y_j})$</p>
<p>其中$g_j$表示梯度项。</p>
<p>所以有：</p>
<p>$\Delta w_{hj} = \eta g_j b_h$</p>
<p>$\Delta \theta_j = -\eta g_j$，即：$b_h =-1$</p>
<p>类似可得：</p>
<p>$\Delta v_{ih} = \eta e_h x_i$</p>
<p>$\Delta \gamma_h = - \eta e_h$，其中：$e_h = b_h(1-b_h)\sum\limits_{j=1}^l w_{hj}g_j$</p>
<p>$e_h = - \frac{\partial E_k}{\partial b_h}·\frac{\partial b_h}{\partial \alpha_h} \ \quad= -\sum\limits_{j=1}^l  \frac{\partial E_k}{\partial \beta_j}·\frac{\partial \beta_j}{\partial b_h} ·\frac{\partial b_h}{\partial \alpha_h}$</p>
<p>因为$\frac{\partial b_h}{\partial \alpha_h} = f’(\alpha_h-\gamma_h)$，利用sigmoid函数性质可得：</p>
<p>$\frac{\partial b_h}{\partial \alpha_h} = f’(\alpha_h - \gamma_h)=f(\alpha_h - \gamma_h)·[1-f(\alpha_h -\gamma_h)] \ \qquad = b_h·(1-b_h)$</p>
<p>$\frac{\partial E_k}{\partial \beta_j} = -g_j$</p>
<p>$\frac{\partial \beta_j}{\partial b_h} =w_{hj}$</p>
<p>所以：$e_h = b_h(1-b_h)\sum\limits_{j=1}^l w_{hj}g_j$</p>
</blockquote>
<p>学习率$\eta \in (0,1)$控制着沿反向梯度方向下降的步长，若：</p>
<p>步长太大则下降太快容易发生振荡；步长太小则收敛速度太慢。一般令$\eta = 0.1$，有时更新权重时会将输出层和隐含层设置不同的学习率。</p>
<h3 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h3><hr>
<p>输入：训练集$D=\{(x_k,y_k)\}_{k=1}^m$</p>
<p>过程：</p>
<p>1：在$(0,1)$范围内随机初始化网络中所有连接权值和阈值</p>
<p>2：repeat{</p>
<p>​                     3： for all $(x_k,y_k) \in D$  do</p>
<p>​                     4：根据当前参数计算当前样本输出$\hat{y_k}$</p>
<p>​                     5：计算输出层神经元梯度项$g_j$</p>
<p>​                     6：计算隐含层神经元梯度项$e_h$</p>
<p>​                     7：更新连接权重$w_{hj},v_{ih}$与阈值$\theta_j,\gamma_h$</p>
<p>​                     8：end for </p>
<p>​               }</p>
<p>9：until 达到停止条件</p>
<p>输出：连接权重和阈值确定的多层前馈神经网络</p>
<hr>
<h3 id="相关说明"><a href="#相关说明" class="headerlink" title="相关说明"></a>相关说明</h3><p>标准BP算法：</p>
<p>更新规则是基于每一个样本的预测值与真实输出的均方误差来进行调节，每次更新只针对单个样例，所实现的最终目标是：最小化整个训练集$D$上的累积误差，即：</p>
<p>$E= \frac{1}{m} \sum \limits_{k=1}^m E_k$</p>
<p>累积BP算法：</p>
<p>基于累计误差最小化的更新规则，得到累积误差逆传播算法(accumulated error backpropagation)，即每次读取全部的数据集一遍，进行一轮学习，从而基于当前的累积误差进行权值调整，因此参数的更新频率相比标准BP算法低很多。</p>
<p>当数据量很大时，往往标准BP算法会获得较好的结果。</p>
<p>BP神经网络的强大的学习能力容易造成<strong>过拟合</strong>问题，有以下两种策略缓解BP网络的过拟合问题：</p>
<ul>
<li><p><strong>早停</strong>：将数据分为训练集和测试集，训练集用于学习，测试集用于评估性能，若在训练过程中，训练集的累积误差降低，测试集的累积误差增加，则停止训练。</p>
</li>
<li><p><strong>引入正则化</strong>(regularization)：在累积误差函数中增加一个用于描述网络复杂度的部分，如所有权值与阈值的平方和，其中$\lambda \in (0,1)$，用于对累积经验误差与网络复杂度这两项进行折中，常通过交叉验证法来估计。其中误差目标函数变为：</p>
<p>$E= \lambda \frac{1}{m}\sum\limits_{k=1}^m E_k + (1+\lambda)\sum\limits_i w_i^2$，增加连接权与阈值平方和这一项，训练过程将会偏好较小的连接权重和阈值，使得网络输出更加“光滑”，缓解过拟合。</p>
</li>
</ul>
<h2 id="全局最小与局部最小"><a href="#全局最小与局部最小" class="headerlink" title="全局最小与局部最小"></a>全局最小与局部最小</h2><p>模型学习的过程实质是：寻找最优参数的过程。</p>
<p>在BP算法试图通过最速下降来寻找使得累积误差最小的权值和阈值时，谈到最优时，一般会提到局部最小(local minimum)和全局最小(global minimum)。</p>
<ul>
<li>局部极小解：参数空间中的某个点，其领域点的误差函数值均不小于该点的误差函数值。</li>
<li>全局最小解：参数空间的某个点，所有其他点的误差函数值均不小于该点的误差函数值。</li>
</ul>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/10.png" title="局部极小和全局最小解">
<p>局部极小点，只要满足该点在参数空间中的梯度为零。局部极小可以有多个，但全局最小只有一个。</p>
<p>梯度下降法的主要思想就是沿着负梯度方向去搜索最优解，负梯度方向是函数值下降最快的方向，若迭代到某处梯度为0，则表示达到一个局部最小，参数更新停止。</p>
<p>如果误差函数仅有一个局部极小，即为全局最小。但是如果具有多个局部极小，则不能保证找到的解是全局最小，陷入局部极小情况。</p>
<p>现实任务中，常采用以下策略尽可能的去接近全局最小：</p>
<ul>
<li>以多组不同参数初始化多个神经网络，按标准方法，迭代停止后，取其中误差最小的解作为最终参数。可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。</li>
<li>使用“模拟退火”(simulated annealing)算法，在每一步都以一定的概率接受比当前解更差的结果，从而有助于“跳出”局部极小。在每步迭代过程中，接受“次优解”的概率要随着时间的推移而逐渐降低，从而保证算法稳定。</li>
<li>使用随机梯度下降法，即在计算梯度时加入随机因素，使得在局部最小时，计算的梯度可能不为0，从而有机会跳出局部极小，迭代可以继续进行。</li>
</ul>
<h2 id="其他常见神经网络"><a href="#其他常见神经网络" class="headerlink" title="其他常见神经网络"></a>其他常见神经网络</h2><h3 id="RBF网络"><a href="#RBF网络" class="headerlink" title="RBF网络"></a>RBF网络</h3><p>径向基函数(radial basis function)网络是一种单隐含层前馈神经网络，使用径向基函数作为隐含层神经元激活函数，而输出层则是对隐含层神经元输出的线性组合。</p>
<p>假定输入为$d$维向量$\pmb x$，输出为实数值，则RBF网络可以表示为：</p>
<p>$\varphi(\pmb x) = \sum\limits_{i=1}^q w_i \rho(\pmb x,c_i)$</p>
<p>其中$q$是隐含层神经元个数，$c_i$和$w_i$分别是第$i$个隐含层神经元所对应的中心和权重，$\rho(\pmb x,c_i)$是径向基函数，是某种沿径向对称的标量函数，通常定义为样本$\pmb x$到数据中心$c_i$之间的欧式距离的单调函数。常用的高斯径向基函数形如：</p>
<p>$\rho(\pmb x,c_i) =e^{-\beta_i ||\pmb x-c_i||^2}$</p>
<p>【park and sandberg,1991】已证明。具有足够多的隐含层神经元的RBF网络能以任意精度逼近任意连续函数。</p>
<p>训练RBF网络步骤：</p>
<p>1、确定神经元中心$c_i$，常用的方式包括随机采样、聚类等。</p>
<p>2、利用BP算法等来确定参数$w_i,\beta_i$。</p>
<hr>
<h3 id="RBF函数网络补充"><a href="#RBF函数网络补充" class="headerlink" title="RBF函数网络补充"></a>RBF函数网络补充</h3><p><strong>径向基函数</strong>：</p>
<p>径向基函数(Radical Basis Function,RBF)，由Powell在1985年提出，径向基函数是某种沿径向对称的标量函数。通常定义为空间中任一点$x$到某一个中心$c$之间的欧氏距离的单调函数，记作$\phi_j(x-c_j)$，其作用往往是局部的，即当$x$远离$c$时函数取值很小，例如高斯径向基函数（也称为<strong>高斯核函数</strong>（Kernel Function）)：</p>
<p>$\phi_j(x-c_j) = \exp \left[ - \frac{(x-c_j)^T(x-c_j)}{2\sigma_j^2}\right]$，其中$\sigma_j$是第$j$个RBF神经元的参数（标准差，高斯函数窗大小）。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/20.jpg" title="径向基函数">
<p><strong>径向基网络</strong>：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/21.jpg" title="径向基网络">
<p>区别于BP网络，BP网络使用的是sigmoid函数作为激活函数，RBF使用的高斯核函数是钟型。</p>
<p>输出：$y_k(x) = \sum\limits_{j=1}^J w_{kj} \phi_j(x-c_j)，j=1,2,\dots,J$</p>
<p>其中$J$是RBF中间层神经元的数目，由聚类得到；$c_j$是RBF的第$j$个中心向量。</p>
<p>核函数有很多形式，通常用到的就是Gaussian核。即：</p>
<p>$\phi_j(x-c_j) = \exp \left[ - \frac{(x-c_j)^T(x-c_j)}{2\sigma_j^2}\right]$</p>
<p><strong>RBF两阶段学习算法</strong>：</p>
<hr>
<ol>
<li>聚类中心向量初始化。确定$J$的初始聚类中心向量$c_{10},c_{20},\dots,c_{J0}$，数据集中通常把最初的$J$个数据作为初期聚类中心向量。</li>
<li>数据输入及对应的聚类选择。输入$x_i$，而且选择最近的聚类$j^<em>$，其中：$c_j^</em> = \arg  \max |x_i - c_j| \implies $表示当$|x_i - c_j|$取最小值时的$x_i$的取值。这一步对全部数据执行。</li>
<li>聚类中心向量更新。$c_j^{new} = \frac{1}{N_j} \sum X，X \in cluster(j)$。这一步对全部数据执行。</li>
<li>判断。如果全部聚类中心向量没有变化，即聚类中心确定，进入第Ⅱ阶段，否则，进入第2步。</li>
</ol>
<p>第Ⅰ阶段</p>
<hr>
<p>第Ⅱ阶段</p>
<ol>
<li><p>中间层与输出层数值初始化。$w_{kj}$用较小的随机数设定。</p>
</li>
<li><p>网络输出计算。输入样本（数据），由$y_k(x)，\phi_j(x-c_j)$计算出网络输出。其中：$\sigma_j^2 = \frac{1}{N_j} \sum\limits_{X\in cluster(j)}(X-c_j)^T(X-c_j)$</p>
</li>
<li><p>权值更新。首先求出各个输出神经元的误差，即：$e_k = d_k - y_k$。其中$d_k$表示期望输出，$y_k$表示实际输出。</p>
<p>接下来更新：</p>
<p>$w_{kj}^{new} = w_{kj}^{old} + \eta \times e_k \times \phi_j(X-c_j)$，$\eta$是一可调常数。</p>
</li>
<li><p>判定。如果满足事先确定的条件，训练结束，否则，返回步骤2。</p>
</li>
</ol>
<hr>
<p>RBF网络<strong>只训练中间层和输出层</strong>。</p>
<h3 id="ART网络"><a href="#ART网络" class="headerlink" title="ART网络"></a>ART网络</h3><p>竞争学习(competitive learning)是神经网络中一种常用的无监督学习策略。网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制。(<strong>胜者通吃</strong>，winner-take-all)原则。</p>
<p>ART(adaptive resonance theory,自适应谐振理论)网络是竞争学习的一个重要代表，</p>
<p><strong>网络构成</strong>：比较层、识别层、识别阈值和重置模块构成。</p>
<p>其中，比较层接收输入样本，并将其传递给识别层神经元；识别层每个神经元对应一个模式类，神经元数目可在训练过程中动态增长以增加新的模式类。</p>
<p>接收到比较层的输入信号后，识别层神经元之间相互竞争以产生获胜神经元。</p>
<p><strong>竞争机制</strong>：计算输入向量和每个识别层神经元所对应的模式类的代表向量之间的距离，小者获胜，获胜神经元向其他识别层神经元发送信号，抑制其激活。</p>
<p>若输入向量与获胜神经元所对应的代表向量之间的相似度大于识别阈值，则当前输入样本归入该代表向量所属类别，同时网络连接权值更新，使得以后在接收相似输入样本式该模式类会计算出更大的相似度，从而使得获胜神经元有更大可能获胜。</p>
<p>若相似度不大于识别阈值，则重置模块将在识别层增设一个新的神经元，其代表向量设置为当前输入向量。</p>
<p><strong>识别阈值作用</strong>：较高，输入样本会被分成更多，分类较为精细；识别阈值较低，会产生比较少、比较粗略的模式类。</p>
<p>ART网络更好的缓解竞争学习中的<strong>可塑性-稳定性窘境</strong>(stability-plasticity dilemma)。</p>
<p>可塑性：神经网络要有学习新知识的能力</p>
<p>稳定性：神经网络在学习新知识时要保持对旧知识的记忆</p>
<p>这就使得ART网络具有一个很重要的优点：可进行增量学习(incremantal learning)或在线学习(online learning)。</p>
<p>现在ART网络发展成了一个算法族，包括能处理实值输入的ART2网络、结合模糊处理的FuzzyART网络，以及可进行监督学习的ARTMAP网络等。</p>
<h3 id="SOM网络"><a href="#SOM网络" class="headerlink" title="SOM网络"></a>SOM网络</h3><p>SOM(self-organizing map，自组织映射)网络是一种竞争学习型的<strong>无监督</strong>神经网络，能将高维输入数据映射到低维空间（二维），同时保持输入数据在高维空间的拓扑结构，即：</p>
<p>将高维空间中的相似样本点映射到网络输出层中的邻近神经元。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/1554814626931.png" title="SOM网络">
<p>SOM网络中的输出层神经元以矩阵方式排列在二维空间，每个神经元有一个权向量，网络在接收到输入向量后，会确定输出层获胜神经元，它决定了该输入向量在低维空间中的位置。</p>
<p>SOM训练的目标时为每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的。</p>
<p><strong>作用：</strong></p>
<ul>
<li>聚类</li>
<li>特征提取</li>
<li>类似性和典型性的表现</li>
<li>输入数据的相互关系</li>
<li>信息压缩</li>
</ul>
<p><strong>训练过程</strong>：</p>
<p>接收到一个训练样本后，每个输出层神经元会计算该样本与自身携带的权向量之间的距离，距离最近的神经元成为获胜者，最佳匹配单元(best matching unit)；</p>
<p>最佳匹配单元及其邻近神经元的权向量被调整，以使得这些权向量与当前输入样本的距离缩小，不断迭代，直至收敛。</p>
<p><strong>算法步骤：</strong></p>
<ol>
<li>网络初始化：对权值用较小的随机数设定</li>
<li>输入向量的加载：对输入向量$\pmb X = [x_1,x_2,\dots,x_N]^T$</li>
<li>计算映射层的权值和输入向量的距离，映射层第$j$个神经元和输入向量的距离为：$d_j = \sum\limits_{i=1}^M (x_i-w_{ji})$，$w_{ji}$为权值。</li>
<li>与权值向量的距离最小的神经元选择，若$d_j$最小，则称之为“胜出神经元”，即为$d_j^*$</li>
<li>权值学习，胜出的神经元和位于其领域的其他神经元的权值更新：$\Delta w_{ji} = \eta \times h(j,j^<em>)\times (x_i-w_{ji})$。其中$\eta$为学习常数，$h(j,j^</em>)$为领域函数，$h(j.j^<em>) = \exp \left[ - \frac{|j -j^</em>|^2}{\sigma^2}\right]$，$\sigma$是高斯窗函数的窗大小，随着学习进行而减小。</li>
<li>返回2，重复2-5步骤，直至收敛。</li>
</ol>
<h3 id="级联相关网络"><a href="#级联相关网络" class="headerlink" title="级联相关网络"></a>级联相关网络</h3><p>一般的神经网络模型：假定网络的结构事先固定，训练的目的是利用训练样本来确定合适的连接权重、阈值等参数。</p>
<p>结构自适应网络：网络的结构也是学习的目标之一，并希望能在训练过程中找到最符合数据特点的网格结构，级联相关(cascade-correlation)网络是其中代表。【ART网络的隐含层神经元数目在训练过程中可以增长，也是一种结构自适应神经网络】</p>
<p>级联相关网络的训练过程如下图所示：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/1554815556746.png" title="级联相关网络">
<p>新的隐节点加入时，红色的连接权通过最大化新节点的输出与网络误差之间的相关性来进行训练。</p>
<p>级联相关网络两个主要成分：“级联”和“相关”。</p>
<p>级联是指建立层次连接的层级结构。开始训练时，网络只有输入层和输出层，处于最小拓扑结构；随着训练的进行，新的隐层神经元逐渐加入，从而创建起层级结构。</p>
<p>相关是指通过最大化新的神经元的输出与网络误差之间的相关性来训练相关参数。</p>
<p>与一般前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经元数目，且训练速度较快，但在数据较小时容易陷入过拟合。</p>
<h3 id="Elman网络"><a href="#Elman网络" class="headerlink" title="Elman网络"></a>Elman网络</h3><p>递归神经网络(recurrent neural networks)允许网络中出现环状结构，从而使得一些神经元输出反馈回来作为输入信号，这使得网络在$t$时刻的输出状态不仅与$t$时刻的输入有关，还与$t-1$时刻的网络状态有关，从而能处理与时间有关的动态变化。</p>
<p>Elman网络是递归神经网络之一，其结构如下图所示：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/1554816215904.png" title="Elman网络结构">
<p>隐含层的输出被反馈回来，与下一时刻输入层神经元提供的信号一起，作为隐含神经元在下一时刻的输入，隐含层神经元通常采用sigmoid激活函数，网络的训练常通过推广的BP算法进行。</p>
<h3 id="Boltzmann机"><a href="#Boltzmann机" class="headerlink" title="Boltzmann机"></a>Boltzmann机</h3><p>神经网络中有一类型是为网络状态定义一个“能量”，能量最小化时网络达到理想状态，网络的训练过程就是在最小化这个能量函数。</p>
<p>Boltzmann机是一种“基于能量的模型”(energy-based-model)，常见结构如下图所示：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/1554816600696.png" title="玻尔兹曼机和受限玻尔兹曼机">
<p>神经元分为两层：隐层和显层</p>
<p>显层用于表示数据的输入和输出，隐层可以理解为数据的内在表达。</p>
<p>Boltzmann机中的神经元都是布尔型，只能取0、1两种状态，状态1表示激活，状态0表示抑制。令向量$\pmb s \in \{0,1\}^n$表示$n$个神经元状态，$w_{ij}$表示神经元$i$与$j$之间的连接权，$\theta_i$表示神经元$i$的阈值，则状态向量$\pmb s$所对应的Boltzmann机能量定义为：</p>
<p>$E(\pmb s) = - \sum\limits_{i=1}^{n-1} \sum\limits_{j=i+1}^{n}w_{ij}s_is_j - \sum\limits_{i=1}^n \theta_is_i$</p>
<p>若网络中的神经元以任意不依赖于输入值的顺序进行更新，则网络最终将达到Boltzmann分布，此时状态向量$\pmb s$出现的概率将仅由其能量与所有可能状态向量的能量决定，即：</p>
<p>$P(\pmb s) = \frac{e^{-E(\pmb s)}}{\sum\limits_{\pmb t} e^{-E(\pmb t)}}$</p>
<p>Boltzmann机训练过程就是将每个训练样本视为一个状态向量，使其出现的概率尽可能大。</p>
<p>标准Boltzmann机是一个全连接图，训练网络的复杂度很高，现实中常使用受限Boltzmann机(Restricted Boltzmann Machine，RBM)，仅保留显层和隐层之间的连接，将Boltzmann机结构由完全图简化为二部图。</p>
<p>RBM通常采用“<strong>对比散度</strong>”(contrastive divergence，CD)算法进行训练。假定网络中有$d$个显层神经元和$q$个隐层神经元，令$\pmb v$和$\pmb h$分别表示显层和隐层的状态向量，则由于同一层内不存在连接，有：</p>
<p>$P(\pmb v|\pmb h) = \prod\limits_{i=1}^d P(v_i| \pmb h)$</p>
<p>$P(\pmb h|\pmb v) = \prod\limits_{j=1}^q P(h_i| \pmb v)$</p>
<p>CD算法对每个训练样本$\pmb v$，先计算出隐层神经元状态的概率分布，然后据此采样得到$\pmb h$；此后，类似从$\pmb h$产生$\pmb v’$，再从$\pmb v’$产生$\pmb h’$；连接权更新公式为：</p>
<p>$\Delta w= \eta\left( \pmb v \pmb h^T - \pmb v’ \pmb h^{‘T}\right)$</p>
<h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p>理论上，参数越多，模型复杂度越高，容量(capability)越大，从而能完成更复杂的学习任务。</p>
<p>增加模型复杂度方法：</p>
<ul>
<li>增加隐含层数目</li>
<li>增加隐含层神经元数目</li>
</ul>
<p>前者更有效些，不仅增加了功能神经元的数量，还增加了激活函数嵌套的层数。</p>
<p>对于多隐含层神经网络，经典算法如标准BP算法往往会在误差逆传播时发散(diverge)，无法收敛到稳定状态。</p>
<p>有效训练多隐含层神经网络方法一般有以下两种：</p>
<ul>
<li>无监督逐层训练(unsupervised layer-wise training)：每次训练一层隐节点，把上一层隐节点的输出当作输入来训练，本层隐节点训练完，输出作为下一层的输出来训练，称为预训练(pre-training)。全部预训练结束，再对整个网络进行微调(fine-tuning)训练。一个典型例子：深度信念网络(deep belief network,DBN)，把大量参数进行分组，先找出每组较好的设置，再基于这些局部最优的结果来训练全局最优。</li>
<li>权共享(weight sharing)：令同一层神经元使用完全相同的连接权重，典型的例子是卷积神经网络(convolutional neural network,CNN)，这样做大大减小需要训练的参数数目。</li>
</ul>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/11.png" title="卷积神经网络结构图">
<p>深度学习可以理解为一种特征学习(feature learning)或者表示学习(representation learning)，无论DBN还是CNN，都是通过多个隐含层来把与输出目标联系不大的初始输入转化为与输出目标更加密切的表示，使得原来的只是通过单层映射难以完成的任务变为可能。</p>
<p>即通过多层处理，逐渐将初始“低层”特征表示转化为“高层”特征表示，从而使得最后可以用简单模型来完成复杂的学习任务。</p>
<p>传统任务，样本的特征需要人类专家来设计，特征的好坏对泛化性能至关重要，而深度学习为全自动数据分析带来可能，可以通过学习自动产生更好的特征。</p>
<p><a href="/download/吴恩达深度学习笔记.pdf">吴恩达深度学习笔记</a></p>
<h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><h2 id="支持向量机基础"><a href="#支持向量机基础" class="headerlink" title="支持向量机基础"></a>支持向量机基础</h2><p>SVM（support vector machine），通俗来讲是一种二类分类器，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略是<strong>间隔最大化</strong>，最终转化为一个<strong>凸二次规划问题</strong>的求解。</p>
<h3 id="分类标准的起源：logistic回归"><a href="#分类标准的起源：logistic回归" class="headerlink" title="分类标准的起源：logistic回归"></a>分类标准的起源：logistic回归</h3><p>给定一些数据点，分别属于两个不同的类，找到一个线性分类器将其分为两类，用$x$表示数据点，$y$表示类别（$y\in \{-1,1\}$，分别代表两个不同的类），一个线性分类器的学习目标是要在$n$维的数据空间找到一个<strong>超平面（hyper plane）</strong>,这个超平面的方程表示 为：<br>$$<br>\begin{equation}<br>w^Tx +b=0<br>\end{equation}<br>$$</p>
<blockquote>
<p>定义（Logistic回归）：</p>
<p>从特征学习出一个0/1模型，该模型是将特性的线性组合作为自变量，由于自变量的取值范围是$[-\infty , \infty]$，因此使用sigmoid函数将自变量映射到$(0,1)$上，映射后的值被认为是属于$y=1$的概率。</p>
</blockquote>
<p>假设函数：<br>$$<br>h_{\theta}(x) = g(\theta^T x)= \frac{1}{1+e^{-\theta^Tx}}<br>$$<br>其中，$x$是$n$维特征向量，函数$g$是Logistic函数。而$g(z) = \frac{1}{1+e^{-z}}$图像如下图所示，将无穷映射到$(0,1)$。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/22.png" title="Logistic回归">
<p>假设 就是属于$y=1$的概率：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>&amp; P(y=1|x;\theta)=h_{\theta}(x) \\<br>&amp; P(Y=0|X;\theta)=1-h_{\theta}(x)<br>\end{aligned}<br>\end{equation}<br>$$<br>当判断一个新的特征属于哪一类时，只需要求出$h_{\theta}(x)$即可，若$h_{\theta}(x) &gt;0.5 \implies y=1$，否则$y=0$。</p>
<p>线性分类函数和Logistic回归形式化表示为：<br>$$<br>h_{\theta}(x) = g(\theta^Tx)=g(w^Tx+b)<br>$$<br>进一步简化为$g(z)=g(w^Tx+b)$，将其简单映射到$y=-1$和$y=1$上。映射关系如下：<br>$$<br>\begin{equation}<br>g(x)=\begin{cases}<br>1 &amp;z \ge 0\\<br>-1 &amp; z&lt;0<br>\end{cases}<br>\end{equation}<br>$$</p>
<h3 id="线性分类一个例子"><a href="#线性分类一个例子" class="headerlink" title="线性分类一个例子"></a>线性分类一个例子</h3><p>一个二维平面，两种不同的数据，这些数据线性可分，用一条直线将这两类数据分开，这条直线相当于一个超平面，超平面一边的数据点所对应的$y=-1$，另一边对应$y=1$。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/23.png" title="线性分类">
<p>这个超平面可以用分类函数$f(x) = w^Tx +b$表示，有：</p>
<p>$f(x)=0 \qquad x位于超平面上$<br>       $f(x)&gt;0 \qquad y=1$<br>       $f(x)&lt;0 \qquad y=-1$</p>
<p>几点说明：</p>
<ul>
<li>二类问题，分类标签$y$只取任意两个值。</li>
<li>大部分数据不是线性可分，这个时候满足条件的超平面不存在。</li>
<li>进行分类时，遇到一个新的数据点$x$，代入$f(x)$，如果$f(x)&gt;0$，则将$x$类别划为-1，反之，划为1。</li>
<li>如何确定超平面，这个超平面应该是最适合分类两类数据的直线，“最合适”的标准是这条直线离直线的两边的数据的<strong>间隔最大</strong>。即要寻找最大间隔的超平面。</li>
</ul>
<h3 id="函数间隔与几何间隔"><a href="#函数间隔与几何间隔" class="headerlink" title="函数间隔与几何间隔"></a>函数间隔与几何间隔</h3><p>在超平面$w^Tx+b=0$确定的情况下，$|w^Tx+b|$能够表示点$x$到距离超平面的远近<a href="尖括号">^1</a></p>
<p><a href="尖括号">^1</a>: 这里“远近”是一个相对概念，如果计算点到超平面的距离为：$\frac{w^Tx +b}{||w||}$</p>
<p>通过观察$w^Tx+b$的符号与类标记$y$的符号是否一致可判断分类是否正确，即可以用$y(w^Tx+b)$的正负性来判定或表示分类的正确性。</p>
<p>==函数间隔（function margin）==</p>
<p>定义为：<br>$$<br>\hat{\gamma} = y(w^T x +b)=yf(x)<br>$$<br>超平面$(w,b)$关于$T$中所有样本点$(x_i,y_i)$的函数间隔最小值便是超平面$(w,b)$关于训练数据集$T$的函数间隔，即：<br>$$<br>\hat{\gamma} = \min \hat{\gamma}_i,(i=1,\dots,n)<br>$$<br>这种定义存在一个问题：当$w,b$成比例的改变，如$2w,2b$，则函数间隔的值变为原来的2倍，但是超平面没有改变。需要对法向量加一些约束条件。这样得到：</p>
<p>==几何间隔（geometrical margin）==</p>
<p>定义为：</p>
<p>假定对于一个点$x$，令其垂直投影到超平面上的对应点为$x_0$，$w$是垂直于超平面的一个向量，$\gamma$是样本$x$到分类间隔的距离。如下图所示：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/24.png" title="分类间隔示意">
<p>有：$x=x_0 + \gamma \frac{w}{||w||}$，其中$||w||$表示的是二阶范数。</p>
<p>因为$x_0$是超平面上的点，满足$f(x_0) =0$，代入超平面的方程$w^Tx +b =0$，即：<br>$$<br>\gamma = \frac{w^Tx +b}{||w||}= \frac{f(x)}{||w||}<br>$$<br>为了得到$\gamma$的绝对值，令$\gamma$乘上对应的类别$y$，即可得到几何间隔$\tilde{\gamma}$：<br>$$<br>\tilde{\gamma} = y\gamma = \frac{\hat{\gamma}}{||w||}<br>$$<br>可见：几何间隔$\tilde{ \gamma }$就是函数间隔$\hat{\gamma}$除以$||w||$，而且函数间隔$y(w^Tx+b) = yf(x)$实际上就是$|f(x)|$。$\frac{|f(x)|}{||w||}$是直观上的点到超平面的距离。</p>
<h3 id="最大间隔分类器定义"><a href="#最大间隔分类器定义" class="headerlink" title="最大间隔分类器定义"></a>最大间隔分类器定义</h3><p>对一个数据点进行分类，当超平面离数据点的“间隔”越大，分类的<strong>确信度</strong>（confidence）越大。因此，为了使得分类的确信度尽量高，需要让所选择的超平面能够最大化这个间隔值。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/25.png" title="最大间隔分类器">
<p>函数间隔不适合用来最大化间隔值，因为超平面固定后，可以等比例的缩放$w,b$的值，这样使得$f(x) = w^Tx +b$的值任意大。几何间隔因为除了$||w||$，使得缩放的时候几何间隔$\tilde{\gamma}$的值不会改变，只是随着超平面变动而变动，所以，==要找的最大间隔分类超平面是找的几何间隔==。</p>
<p>最大间隔分类器(maximum margin classifier)的目标函数定义为：<br>$$<br>\max \tilde{\gamma}<br>$$<br>同时需要满足一些条件，有：<br>$$<br>y_i(w^Tx_i +b) = \hat{\gamma}_i \ge \hat{\gamma},i=1,\dots,n<br>$$<br>由于几何间隔$\tilde{\gamma} = y\gamma = \frac{\hat{\gamma}}{||w||}$，如果令函数间隔$\hat{\gamma}=1$<a href="令$\hat{\gamma}=1$，是为了方便推导和优化。">^2</a>，则有$\tilde{\gamma} = \frac{1}{||w||}$，且$y_i(w^Tx_i +b) \ge 1,i=1,\dots,n$，因此上述目标函数转化为：<br>$$<br>\max \frac{1}{||w||} ,\quad s.t.\quad y_i(w^Tx_i +b) \ge 1,i=1,\dots,n<br>$$</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/26.png" title="最优超平面">
<p>中间实线即是寻找到的<strong>最优超平面<a href="在线性可分的情况下，建立一个超平面，使得可分的两类数据到该平面的距离最小，称为**最优超平面**。对于非线性问题，通过一个非线性映射，把原始数据映射到另一个特征空间的新的数据集上，使得新的数据集在该空间上线性可分没有此建立的超平面在原空间是一个**超曲面**。">^3</a>（Optional Hyper Plane)</strong>，其到两条虚线的距离相等，这个距离即是几何间隔$\tilde{\gamma}$，两条虚线之间的距离等于$2\tilde{\gamma}$，虚线上的点即是==支持向量==，它们满足$y(w^Tx +b) =1$，而对于所有不支持向量的点，则显然有$y(w^Tx+b) &gt;1$。</p>
<h2 id="支持向量机深入"><a href="#支持向量机深入" class="headerlink" title="支持向量机深入"></a>支持向量机深入</h2><h3 id="从线性可分到线性不可分"><a href="#从线性可分到线性不可分" class="headerlink" title="从线性可分到线性不可分"></a>从线性可分到线性不可分</h3><p>给定训练样本集：<br>$$<br>\Omega = \{(x_i,y_i)|i=1,2\dots,n\}\subset \mathcal{R}^m \times\{-1,1\}<br>$$<br>其中，$x_i$表示样本，$y_i$表示标签，分为-1和1两类。</p>
<p>假设样本集$\Omega$是线性可分的，即存在超平面：<br>$$<br>w^Tx +b =0 ,\quad x \in\mathcal{R}^m<br>$$<br>对任意一个$(x_i,y_i) \in \Omega$，满足：<br>$$<br>\begin{cases}<br>w^Tx_i +b \ge +1,当y_i = +1\\<br>w^Tx_i +b \le -1,当y_i = -1<br>\end{cases}<br>$$<br>称该平面为==最优超平面==。</p>
<p>上式可统一写为：<br>$$<br>y_i (w^Tx_i +b) \ge 1,\quad s.t. \quad i=1,2,\dots,n<br>$$<br>其中，$w=(w_1,w_2,\dots,w_m)^T \in \mathcal{R}^m$，$x_i =(x_{i1},x_{i2},\dots,x_{im})^T \in \mathcal{R}^m$</p>
<p>内积：$w^Tx_i = \sum\limits_{j=1}^m w_j x_{ij}$</p>
<p>空间$\mathcal{R}^m$的点$t=(t_1,\dots,t_m)^T \in \mathcal{R}^m$到超平面的距离为：<br>$$<br>d= \frac{|w^T·t+b|}{||w||},\quad ||w|| = \sqrt{w^Tw}<br>$$<br>超平面“margin”定义：记margin = $d_+ + d_{-}$，表示正负两类样本。有：<br>$$<br>d_{+} = \min \left\{\frac{|w^Tx_i +b|}{||w||}   \right\},\quad s.t. \quad i \in \{1,2,\dots,m|y_i = +1\}<br>$$</p>
<p>$$<br>d_{-} = \min \left\{\frac{|w^Tx_i +b|}{||w||}   \right\},\quad s.t. \quad i \in \{1,2,\dots,m|y_i = -1\}<br>$$</p>
<p>当存在点使得$w^Tx_i +b = \pm 1$时，$d_{+} = d_{-} = \frac{1}{||w||}$，此时：<br>$$<br>{\rm margin} = \frac{2}{||w||}<br>$$<br>【<strong>定义</strong>】：对于给定的线性可分样本集$\Omega$，如果存在分离超平面$w^Tx+b=0$，使得margin最大，则称该平面为最优超平面。即目标函数转化为：<br>$$<br>\min \frac{1}{2}||w||^2 \implies margin 最大,\quad s.t. \quad y_i(w^Tx_i +b)\ge 1,i=1,\dots,n<br>$$<br>此时，目标函数是二次，约束条件是线性的，即是一个凸二次规划问题。所以，在一定的约束条件下，目标最优，损失最小。</p>
<p>由于这个问题结构的特殊性，可以通过拉<strong>格朗日对偶性(Lagrange Duality)</strong>变换到<strong>对偶变量(Dual Variable)</strong>的优化问题，即通过求解与原问题等价的<strong>对偶问题(Dual Problem)</strong>得到原始问题的最优解<a href="即是线性可分条件下支持向量机的对偶算法，优点在于：①对偶问题往往更容易求解；②可以自然引入**核函数**，进而推广到非线性分类问题。">^4</a>。</p>
<p>具体过程如下：</p>
<p>给每个约束条件加上拉格朗日乘子$\alpha$，得到：<br>$$<br>\mathcal{L}(w,b,\alpha) = \frac{1}{2}||w||^2-\sum\limits_{i=1}^n \alpha_i[y_i(w^Tx_i +b)-1]<br>$$<br>令：<br>$$<br>\min\limits_{w,b}\theta(w) =\min\limits_{w,b} \max \limits_{\alpha_i \ge 0}\mathcal{L}(w,b,\alpha) = p’<br>$$<br>显然当所有目标函数满足时，有$\theta(w) = \frac{1}{2}||w||^2$，当然$\alpha_i \ge 0 ,(i=1,\dots,n)$，否则$\theta(w)$会无穷大。</p>
<p>此处$p’$是这个问题的最优值，且和最初的问题是等价的，如果直接求解，有$w,b$两个参数，且$\alpha_i$是不等式约束，求解过程不好做。将上式改为：<br>$$<br>\max\limits_{\alpha_i \ge 0}\min\limits_{w,b}  \mathcal{L}(w,b,\alpha) = d’<br>$$<br>这样可以先求$\mathcal{L}$对$w,b$的极小，再求$\mathcal{L}$对$\alpha$的极大。</p>
<p>交换后的新问题是原始问题的对偶问题，最优值用$d’$表示，且有$d’ \le p’$，在满足某些条件下，这两者相等<a href="满足的某些条件称为**KKT条件**。">^5</a>，这样就可以通过求解对偶问题来间接求解原始问题[^6]。</p>
<p>[^6]: 关于对偶问题的最优等价性问题，参见Stephen Boyd的《Convex Optimization》中第五章。</p>
<h3 id="K-K-T条件"><a href="#K-K-T条件" class="headerlink" title="K.K.T条件"></a>K.K.T条件</h3><p>一般地，一个最优化数学模型能够表示成下列标准形式：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\min \quad &amp; f(x)\\\\<br>s.t.\quad &amp; h_j(x) =0, \quad j=1,\dots,p \\\\<br>\quad &amp;  g_k(x)\le 0,\quad k=1,\dots,q \\\\<br>\quad &amp;x \in \mathcal{X} \subset \mathcal{R}^n<br>\end{aligned}<br>\end{equation}<br>$$<br>其中$f(x)$是需要最小化的函数，$h(x)$是等式约束，$g(x)$是不等式约束，$p,q$分别是等式约束和不等式约束的数量。</p>
<p>两点说明：</p>
<ul>
<li>凸优化的概念：$\mathcal{X} \subset \mathcal{R}^n$为一个凸集，$f:\mathcal{X} \rightarrow \mathcal{R}$为一凸函数。凸优化就是要找出一点$x’ \in \mathcal{X}$，使得每一个$x \in \mathcal{X}$满足$f(x’) \le f(x)$。</li>
<li>KKT条件的意义：它是一个非线性规划(Nonlinear Programming)问题能有最优化解法的充要条件。</li>
</ul>
<p>【<strong>定义</strong>】（<strong>K.K.T条件</strong>）：</p>
<p>对于上面的优化问题，满足：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>&amp;h_j(x’) = 0,\quad j=1,\dots,p\\\\<br>&amp;g_k(x’) \le 0,\quad k=1,\dots,q\\\\<br>&amp;\Delta f(x’) + \sum\limits_{j=1}^{p} \lambda_j \Delta h_j(x’) + \sum\limits_{k=1}^q \mu_k\Delta g_k(x’)=0\\\\<br>&amp;\lambda_j \ne 0,\mu_k \ge 0\\\\<br>&amp;\mu_k g_k(x’) =0<br>\end{aligned}<br>\end{equation}<br>$$<br>则为满足$KKT$条件。</p>
<p>求解这个对偶问题，分为三个步骤：首先让$\mathcal{L}$关于$w,b$最小化，然后求对$\alpha$的极大，最后利用SMO算法求解对偶问题中的拉格朗日乘子。</p>
<h3 id="对偶问题求解"><a href="#对偶问题求解" class="headerlink" title="对偶问题求解"></a>对偶问题求解</h3><p>$$<br>\mathcal{L}(w,b,\alpha) = \frac{1}{2}||w||^2-\sum\limits_{i=1}^n \alpha_i[y_i(w^Tx_i +b)-1]<br>$$</p>
<p>（1）首先固定$\alpha$，然$\mathcal{L}$关于$w,b$的最小化。<br>$$<br>\begin{equation}<br>\begin{aligned}<br>&amp;\frac{\partial \mathcal{L}}{\partial w}=0 \implies w= \sum\limits_{i=1}^n \alpha_iy_ix_i \\\\<br>&amp;\frac{\partial \mathcal{L}}{\partial b}=0 \implies \sum\limits_{i=1}^n \alpha_iy_i=0<br>\end{aligned}<br>\end{equation}<br>$$<br>代入原式有：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\mathcal{L}(w,b,\alpha)&amp;=\frac12 w^Tw -\sum\limits_{i=1}^n \alpha_iy_iw^Tx_i -\sum\limits_{i=1}^n \alpha_iy_ib +\sum\limits_{i=1}^n \alpha_i \\\\<br>&amp;= \frac12 w^T\sum\limits_{i=1}^n \alpha_iy_ix_i -\sum\limits_{i=1}^n \alpha_iy_iw^Tx_i -\sum\limits_{i=1}^n \alpha_iy_ib +\sum\limits_{i=1}^n \alpha_i \\\\<br>&amp;= \frac12 w^T\sum\limits_{i=1}^n \alpha_iy_ix_i -w^T\sum\limits_{i=1}^n \alpha_iy_ix_i -\sum\limits_{i=1}^n \alpha_iy_ib +\sum\limits_{i=1}^n \alpha_i \\\\<br>&amp;= -\frac12 w^T\sum\limits_{i=1}^n \alpha_iy_ix_i  -\sum\limits_{i=1}^n \alpha_iy_ib +\sum\limits_{i=1}^n \alpha_i \\\\<br>&amp;= -\frac12 w^T\sum\limits_{i=1}^n \alpha_iy_ix_i  -b\sum\limits_{i=1}^n \alpha_iy_i +\sum\limits_{i=1}^n \alpha_i \\\\<br>&amp;= -\frac12 \left(\sum\limits_{i=1}^n \alpha_iy_ix_i\right)^T\sum\limits_{i=1}^n \alpha_iy_ix_i  -b\sum\limits_{i=1}^n \alpha_iy_i +\sum\limits_{i=1}^n \alpha_i \\\\<br>&amp;= -\frac12 \sum\limits_{i=1}^n \alpha_iy_i(x_i)^T \sum\limits_{i=1}^n \alpha_iy_ix_i  -b\sum\limits_{i=1}^n \alpha_iy_i +\sum\limits_{i=1}^n \alpha_i \\\\<br>&amp;= -\frac12 \sum\limits_{i,j=1}^n \alpha_iy_i(x_i)^T \alpha_jy_jx_j  -b\sum\limits_{i=1}^n \alpha_iy_i +\sum\limits_{i=1}^n \alpha_i \\\\<br>&amp;=\sum\limits_{i=1}^n \alpha_i -\frac{1}{2}\sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jx_i^Tx_j<br>\end{aligned}<br>\end{equation}<br>$$<br>此时拉格朗日函数只包含一个变量$\alpha_i$。</p>
<p>（2）求对$\alpha$的极大。<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\max\limits_{\alpha}&amp;\quad \sum\limits_{i=1}^n \alpha_i - \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jx_i^Tx_j\\\\<br>s.t. &amp;\quad \alpha_i \ge 0,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$<br>求出$\alpha_i$，从而根据：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>w’ &amp;= \sum\limits_{i=1}^n \alpha_i y_ix_i\\\\<br>b’ &amp;= -\frac{\max\limits_{i:y_i=-1}{w’}^Tx_i +\min\limits_{i:y_i=-1}{w’}^Tx_i}{2}<br>\end{aligned}<br>\end{equation}<br>$$<br>即可求出$w,b$，最终得到最优分离超平面和分类决策函数。</p>
<p>（3）利用SMO算法<a href="算法详细说明见SMO算法部分。">^7</a>求解对偶问题中的拉格朗日乘子$\alpha$。</p>
<h3 id="线性不可分"><a href="#线性不可分" class="headerlink" title="线性不可分"></a>线性不可分</h3><p>对于一个数据点$x$进行分类，实际上就是通过代入到$f(x) = w^Tx +b$算出结果，然后根据正负号来进行类别划分。</p>
<p>前面推导出：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>w’ &amp;= \sum\limits_{i=1}^n \alpha_i y_ix_i\\\\<br>b’ &amp;= -\frac{\max\limits_{i:y_i=-1}{w’}^Tx_i +\min\limits_{i:y_i=-1}{w’}^Tx_i}{2}<br>\end{aligned}<br>\end{equation}<br>$$<br>因此分类函数为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>f(x)&amp;= (\sum\limits_{i=1}^n \alpha_i y_ix_i)^Tx +b \\\\<br>&amp;=\sum\limits_{i=1}^n \alpha_i y_i\left&lt;x_i,x\right&gt; +b<br>\end{aligned}<br>\end{equation}<br>$$<br>其中$\left&lt;x_i,x\right&gt;$表示向量内积。</p>
<p>可见，==对于新点$x$的预测，只需要计算它与训练数据点的内积即可，这也是之后使用Kernel进行非线性推广的前提==。</p>
<p>事实上，所有非Support Vector所对应的系数$\alpha$都是等于零，因此对于新点的内积计算实际上只是针对少量的“支持向量”而不是所有的训练数据。</p>
<p>因为，分类完全是由超平面决定的，非支持向量的样本点不会参与分类问题的计算，所以非支持向量所对应的拉格朗日乘子$\alpha$等于零。</p>
<p><strong>所谓的支持向量机就是maximum margin hyper plane classifier</strong>。到目前为止，SVM还很弱，只能处理线性情况。通过<strong>Kernel</strong>可以推广到非线性的情况。</p>
<h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><h4 id="特征空间的隐式映射"><a href="#特征空间的隐式映射" class="headerlink" title="特征空间的隐式映射"></a>特征空间的隐式映射</h4><p>通过将数据映射到高维空间，来解决原始空间上线性不可分问题。</p>
<p>在线性不可分的情况下，支持向量机首先在低维空间中完成计算，然后通过核函数将输入空间映射到高维特征空间，最终在高维特征空间中构造出最优分离超平面，从而把平面上本身不好分的非线性数据分开。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/27.png" title="特征空间的隐式映射">
<p>==原始方法==：</p>
<p>线性学习器学习一个非线性关系，需要选择一个非线性特征集，将数据写成新的表达形式，等价于应用一个固定的非线性映射，将数据映射到特征空间，在特征空间中使用线性学习器。</p>
<p>假设：<br>$$<br>f(x) = \sum\limits_{i=1}^N w_i \phi_i(x) +b<br>$$<br>其中$\phi : \mathcal{X} \rightarrow \mathcal{F}$是从输入空间到某个特征空间的映射。</p>
<p>建立非线性学习器分两步：</p>
<ol>
<li>首先使用非线性映射将数据变换到一个特征空间$\mathcal{F}$</li>
<li>然后在特征空间使用线性学习分类器</li>
</ol>
<p>由于对偶形式是线性学习器的一个重要性质，因此，决策规则可以用测试点和训练点的内积表示：<br>$$<br>f(x)=\sum\limits_{i=1}^l \alpha_i y_i \left&lt; \phi(x_i),\phi(x)\right&gt; +b<br>$$<br>==核方法==：</p>
<p>在特征空间直接计算内积$\left&lt; \phi(x_i),\phi(x)\right&gt; $，将上面两个步骤融合在一起建立一个非线性的学习器。</p>
<p>【<strong>定义</strong>】（<strong>核：Kernel</strong>）：</p>
<p>核是一个函数$K$，对所有的$x,z \in \mathcal{X}$，满足$K(x,z) = \left&lt; \phi(x_i),\phi(x)\right&gt; $，其中$\phi : \mathcal{X} \rightarrow \mathcal{F}$是从输入空间$\mathcal{X}$到内积特征空间$\mathcal{F}$的映射。</p>
<h4 id="核函数：如何处理非线性数据"><a href="#核函数：如何处理非线性数据" class="headerlink" title="核函数：如何处理非线性数据"></a>核函数：如何处理非线性数据</h4><img src="/blog/2019/06/18/机器学习课程笔记_科大/28.png" title="线性不可分的两类数据">
<p>如图所示两类数据，线性不可分，理想的分界应该是一个圆圈而不是一条直线（超平面）。用$X_1,X_2$表示这个二维平面的两个坐标。一条二次曲线（圆是一种特殊的二次曲线）的方程可以写成：<br>$$<br>a_1X_1+a_2X_1^2+a_3X_2+a_4X_2^2+a_5X_1X_2+a_6=0<br>$$<br>构造成一个五维空间，其中五个坐标值分别为：<br>$$<br>Z_1 =X_1,Z_2 = X_1^2,Z_3 =X_2 ,Z_4 = X_2^2,Z_5 =X_1X_2<br>$$<br>上式可以写成：<br>$$<br>\sum\limits_{i=1}^5a_iZ_i +a_6 =0<br>$$<br><img src="/blog/2019/06/18/机器学习课程笔记_科大/29.gif" title="Matlab画出一张张图片然后用 Imagemagick 拼贴成的 gif 动画"></p>
<p>关于新的坐标$Z$，正是一个hyper plane方程。即做一个映射$\phi : \mathcal{R}^2 \rightarrow \mathcal{R}^5$，将$X$按照上面的规则映射为$Z$，那么在新的空间中原来的数据变成线性可分，从而能够使用之前的线性分类算法进行处理。==$Kernel$方法处理非线性问题的基本思想==。</p>
<p>假设两个向量$x_1 = (\eta_1,\eta_2)^T$和$x_2 = (\xi_1,\xi_2)^T$，而$\phi(·)$即五维空间的映射，则映射过后的内积为：<br>$$<br>\left&lt;\phi(x_1),\phi(x_2)\right&gt; = \eta_1\xi_1 + \eta_1^2\xi_1^2 + \eta_2\xi_2+\eta_2^2\xi_2^2 +\eta_1\eta_2\xi_1\xi_2<br>$$<br>又因为：<br>$$<br>(\left&lt;x_1,x_2\right&gt; +1)^2 =2\eta_1\xi_1 + \eta_1^2\xi_1^2 + 2\eta_2\xi_2+\eta_2^2\xi_2^2 +2\eta_1\eta_2\xi_1\xi_2 +1   \tag{Ⅰ}<br>$$<br>可见，将某几个维度线性缩放一下，再加上一个常数维度，该式就等于上式。</p>
<p>这个式子和映射：<br>$$<br>\phi(x_1,x_2) = (\sqrt{2}x_1,x_1^2,\sqrt{2}x_2,x_2^2,\sqrt{2}x_1x_2,1)^T \tag{Ⅱ}<br>$$<br>之后的内积$\left&lt;\phi(x_1),\phi(x_2)\right&gt;$的结果一致的，两者的区别再于：</p>
<ol>
<li>一个（Ⅱ）是映射到高维空间中，然后再根据内积公式进行计算</li>
<li>另一个（Ⅰ）直接再原来的低维空间进行计算，不需要显式地写出映射后的结果</li>
</ol>
<p>当维度爆炸时，（Ⅱ）已经无法计算，然而（Ⅰ）依旧能够处理，甚至时无穷维度的情况也没有问题。</p>
<p>==把计算两个向量在隐式映射过后的空间中的内积的函数叫做核函数(Kernel Function)==，例如，上面例子中的，核函数为：<br>$$<br>K(x_1,x_2) =(\left&lt;x_1,x_2\right&gt; +1)^2<br>$$</p>
<p><font color="red">核函数能简化映射空间中的内积运算</font>，在SVM中需要计算的数据向量总是以内积形式出现。有：<br>$$<br>f(x)=\sum\limits_{i=1}^n\alpha_iy_iK(x_i,x)+b<br>$$<br>转化为如下对偶问题计算而得：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\max\limits_{\alpha}&amp;\quad \sum\limits_{i=1}^n \alpha_i - \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jK(x_i,x_j)\\\\<br>s.t. &amp;\quad \alpha_i \ge 0,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$</p>
<h4 id="几个核函数"><a href="#几个核函数" class="headerlink" title="几个核函数"></a>几个核函数</h4><ul>
<li><font face="楷体">多项式核</font> $K(x_1,x_2) = (\left&lt;x_2,x_2\right&gt; +R)^d$。所对应的映射空间的维度是$C_{m+d}^d$，其中$m$是原始空间的维度。</li>
<li><font face="楷体">高斯核</font> $K(x_1,x_2) = \exp (-\frac{||x_1-x_2||^2}{2\sigma^2})$。通过调控参数$\sigma$，高斯核具有相当高的灵活性。如将$\sigma$选的很小，理论上可以将任意数据映射为线性可分，但是可能会有严重的过拟合问题。<img src="/blog/2019/06/18/机器学习课程笔记_科大/30.png" title="高斯核"></li>
<li><font face="楷体">线性核</font> $K(x_1,x_2) = \left&lt;x_1,x_2\right&gt;$。即原始空间上的内积。主要目的是将“映射后的空间中的问题”和“映射前空间中的问题”两者的形式上统一起来。(意思是说，咱们有的时候，写代码，或写公式的时候，只要写个模板或通用表达式，然后再代入不同的核，便可以了，于此，便在形式上统一了起来，不用再分别写一个线性的，和一个非线性的。</li>
</ul>
<h4 id="核函数本质"><a href="#核函数本质" class="headerlink" title="核函数本质"></a>核函数本质</h4><ol>
<li>实际中遇到的线性不可分的样本，把样本特征映射到高维空间上，相关特征在高维空间被分开，达到分类的目的。</li>
<li>但是映射到高维空间，会造成维度爆炸问题。</li>
<li>此时需要核函数，核函数存在的价值是，虽然将特征从低维到高维的转换，但是它事先在低维上计算，将实质的分类效果表现在高维上，这样避免了直接在高维空间上的复杂计算。</li>
</ol>
<h3 id="使用松弛变量处理outliers方法"><a href="#使用松弛变量处理outliers方法" class="headerlink" title="使用松弛变量处理outliers方法"></a>使用松弛变量处理outliers方法</h3><img src="/blog/2019/06/18/机器学习课程笔记_科大/31.png" title="outliers">
<p>因为数据本身带有噪声，而不是数据的非线性结构，如上图中黑圈圈起来的点，偏离正常位置很远的数据点，称之为<strong>outlier</strong>。</p>
<p>在原来的SVM模型中，outlier存在有可能会造成很大的影响，因为hyper plane本身只有少数的support vector组成的，如果这些support vector中又存在outlier，影响很大。</p>
<p>如上图所示，这个outlier的出现，使得分离超平面不得不被挤歪，变成图中的黑色虚线所示，同时margin也相应的变小。更严重的是，如果这个outlier再往右移动一些距离，将无法构造出能将数据分开的超平面来。</p>
<p>在SVM中，允许数据点在一定的程度上偏离超平面，（上图中的黑色实线所对应的距离即outlier的偏离距离）。如果把这个outlier移动回来，刚好落在原来的超平面上，而不会使得超平面发生变形。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/32.png">
<p>在有松弛的情况下，outlier点也属于支持向量，同时对于不同的支持向量，拉格朗日参数的值也不同。对于远离分离平面的点值为0；对于在边缘上的点值在$[0,\frac1L]$之间，其中$L$为训练数据集的大小；对于outlier数据和内部的数据值为$\frac1L$。</p>
<p>原来的约束条件为：<br>$$<br>y_i(w^Tx_i +b) \ge 1，\quad i=1,\dots,n<br>$$<br>现在考虑到outlier问题，约束条件变为：<br>$$<br>y_i(w^Tx_i +b) \ge 1 - \xi_i，\quad i=1,\dots,n<br>$$<br>其中$\xi_i$称为<strong>松弛变量(slack variable)</strong>，==对应数据点$x_i$允许偏离(functional margin)的的量。==</p>
<p>同时在原来的目标函数后加上一项，使得$\xi_i$的总和最小。（因为如果允许$\xi_i$任意大，则任意的超平面都是符合条件了）。即：<br>$$<br>\min \quad \frac12||w||^2 + C\sum\limits_{i=1}^n \xi_i<br>$$<br>其中$C$是一个参数，用于==控制目标函数的”寻找margin最大的超平面“和”保证数据点偏差量最小“之间的权重。==</p>
<p>注意到，$\xi$是需要优化的变量之一，$C$是一个事先确定好的常量。完整式子为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\min &amp;\quad \frac12||w||^2 +C\sum\limits_{i=1}^n \xi_i\\\\<br>s.t. &amp;\quad y_i(w^Tx_i +b) \ge 1 - \xi_i，\quad i=1,\dots,n\\\\<br>&amp;\quad \xi_i \ge 0,\quad i=1,\dots,n<br>\end{aligned}<br>\end{equation}<br>$$<br>将约束条件加入到目标函数中，得到新的拉格朗日函数，如下：<br>$$<br>\mathcal{L}(w,b,\alpha,r) = \frac12 ||w||^2 +C\sum\limits_{i=1}^n \xi_i - \sum\limits_{i=1}^n \alpha_i [y_i(w^Tx_i +b)-1+\xi_i]-\sum\limits_{i=1}^n r_i \xi_i<br>$$<br>先是$\mathcal{L}$对$w,b$和$\xi$的最小化：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>&amp;\frac{\partial \mathcal{L}}{\partial w}=0 \implies w= \sum\limits_{i=1}^n \alpha_iy_ix_i \\\\<br>&amp;\frac{\partial \mathcal{L}}{\partial b}=0 \implies \sum\limits_{i=1}^n \alpha_iy_i=0 \\\\<br>&amp;\frac{\partial \mathcal{L}}{\partial \xi_i}=0 \implies C-\alpha_i -r_i =0, \quad i=1,\dots,n<br>\end{aligned}<br>\end{equation}<br>$$<br>然后将$w$带回$\mathcal{L}$化简得到：<br>$$<br>\max\limits_{\alpha}\quad \sum\limits_{i=1}^n \alpha_i - \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jx_i^Tx_j<br>$$<br>但是增加了约束条件：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\begin{cases}<br>C-\alpha_i -r_i =0 \\\\<br>r_i \ge 0 \\\\<br>\end{cases}<br>\quad\implies&amp; \alpha_i \le C<br>\end{aligned}<br>\end{equation}<br>$$<br>综上，整个问题转变为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\max\limits_{\alpha}&amp;\quad \sum\limits_{i=1}^n \alpha_i - \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jx_i^Tx_j\\\\<br>s.t. &amp;\quad 0 \le\alpha_i \le C,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$<br>唯一的区别是，多了个约束条件$\alpha_i \le C$的上限。</p>
<p>同样Kernel化的非线性形式同样，即为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\max\limits_{\alpha}&amp;\quad \sum\limits_{i=1}^n \alpha_i - \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jK(x_i,x_j)\\\\<br>s.t. &amp;\quad 0 \le \alpha_i \le C,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$<br>==【<strong>小结</strong>】：==</p>
<p>通俗来说，SVM本质上是一个分类方法，用$w^Tx+b$定义分类函数，然后求$w,b$，为寻找最大margin，找到最优分离超平面，引出$ \min \frac{1}{2}||w||^2$，继而引入拉格朗日乘子$\alpha$，转化为对拉格朗日乘子$\alpha$的求解。</p>
<p>求解过程涉及一系列的最优化或凸二次规划问题。这样求$w,b$与求$\alpha$等价，而$\alpha$的求解可以使用一种快速学习算法SMO。</p>
<p>至于核函数，是为了处理非线性情况，若直接映射到高维空间计算会有维度爆炸问题，因此在低维计算，然后将实质效果在高维表现。</p>
<h3 id="SMO算法"><a href="#SMO算法" class="headerlink" title="SMO算法"></a>SMO算法</h3><p>SMO算法用于求解对偶问题的序列最小最优化算法。<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\max\limits_{\alpha}&amp;\quad \sum\limits_{i=1}^n \alpha_i - \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jx_i^Tx_j\\\\<br>s.t. &amp;\quad 0 \le\alpha_i \le C,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$<br>等价于求解：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\min\limits_{\alpha}\Psi(\overrightarrow{\alpha})&amp;=\min\limits_{\alpha} \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jK(x_i,x_j)-\sum\limits_{i=1}^n \alpha_i \\\\<br>s.t. &amp;\quad 0 \le \alpha_i \le C,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$</p>
<blockquote>
<p>参考John C. Platt的文章《Sequential Minimal Optimization: A Fast Algorithm for Training SVM》。</p>
</blockquote>
<p><strong>SMO算法推导：</strong></p>
<p>定义特征到结果的输出函数：<br>$$<br>u=\overrightarrow{w}·\overrightarrow{x}-b<br>$$<br>与$f(x) = w^Tx +b$性质一样。</p>
<p>重新定义原始优化问题如下：<br>$$<br>\min\limits_{w,b}\frac12 ||w||^2 ,\quad s.t. \quad y_i(\overrightarrow{w}·\overrightarrow{x}-b) \ge 1,\forall i<br>$$<br>求导得：<br>$$<br>\overrightarrow{w} = \sum\limits_{i=1}^N y_i \alpha_i\overrightarrow{x_i}\\\\<br>b= \overrightarrow{w}·\overrightarrow{x_k}-y_k ,\quad \alpha_k &gt;0<br>$$<br>代入$u=\overrightarrow{w}·\overrightarrow{x}-b$中，可得：<br>$$<br>u= \sum\limits_{j=1}^Ny_j \alpha_jK(\overrightarrow{x_j},\overrightarrow{x})-b<br>$$<br>引入拉格朗日乘子转化为对偶问题，得到：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\min\limits_{\alpha}\Psi(\overrightarrow{\alpha})&amp;=\min\limits_{\alpha} \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_j\left&lt;x_i,x_j\right&gt;-\sum\limits_{i=1}^n \alpha_i \\\\<br>s.t. &amp;\quad 0 \le \alpha_i ,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$<br>加入松弛变量后，模型修改为：<br>$$<br>\min\limits_{w,b,\xi} \frac12 ||\overrightarrow{w}||^2 +C\sum\limits_{i=1}^n \xi_i \quad s.t. \quad y_i(\overrightarrow{w}·\overrightarrow{x}-b) \ge 1-\xi_i,\forall i \\\\<br>0\le \alpha_i \le C, \forall i<br>$$<br>最终问题变为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\min\limits_{\alpha}\Psi(\overrightarrow{\alpha})&amp;=\min\limits_{\alpha} \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jK(x_i,x_j)-\sum\limits_{i=1}^n \alpha_i \\\\<br>s.t. &amp;\quad 0 \le \alpha_i \le C,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$<br>接下来要解决的问题是：==在$\alpha_i =\{ \alpha_1,\dots,\alpha_n\}$上求上述目标函数的最小值==。</p>
<p>每次从中任意抽取两个乘子$\alpha_1$和$\alpha_2$，然后固定除去这两个以外的其他乘子$\{\alpha_3,\dots,\alpha_n\}$，使得目标函数只是关于$\alpha_1$和$\alpha_2$的函数。这样不断从一堆乘子中任意抽取两个求解，不断地迭代求解子问题，最终达到求解原问题的目的<a href="参考此文&lt;http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html">^8</a>。</p>
<p>如果存在不满足K.K.T条件的$\alpha_i$，则需要更新这些$\alpha_i$，这是第一个约束条件。此外，还要满足：<br>$$<br>\sum\limits_{i=1}^n \alpha_i y^{(i)} =0<br>$$<br><strong>具体过程如下：</strong></p>
<p>假设选取了初始值$\{\alpha_1,\alpha_2,\dots,\alpha_n\}$中的$\alpha_1，\alpha_2$，固定剩余参数$\{\alpha_3,\dots,\alpha_n\}$，此时$\Psi$就是$\alpha_1,\alpha_2$的函数。并假定两个乘子再更新之前分别是 $\alpha_1^{old},\alpha_2^{old}$，更新之后分别是$\alpha_1^{new},\alpha_2^{new}$，并且满足条件：<br>$$<br>\alpha_1^{old} y^{(1)} + \alpha_2^{old} y^{(2)} =\alpha_1^{new} y^{(1)} + \alpha_2^{new} y^{(2)}= -\sum\limits_{i=3}^n\alpha_iy^{(i)} = \zeta<br>$$<br>其中，$\zeta$为常数，因为$\{\alpha_3,\dots,\alpha_n\}$为固定值，且有约束条件$\sum\limits_{i=1}^n \alpha_i y^{(i)} =0$。</p>
<p>这两个因子不好同时求解，先求解乘子$\alpha_2^{new}$，再用其表示$\alpha_1^{new}$。</p>
<p>==首先要确定$\alpha_2^{new}$的取值范围。==</p>
<p>假设它的上下边界分别为$H$和$L$。有：<br>$$<br>L \le \alpha_2^{new} \le H \tag{1}<br>$$<br>结合约束条件<br>$$<br>0 \le  \alpha_i \le C,i=1,\dots,n \\\ \tag{2}<br>$$</p>
<p>$$<br>\alpha_1^{old} y^{(1)} + \alpha_2^{old} y^{(2)} =\alpha_1^{new} y^{(1)} + \alpha_2^{new} y^{(2)}= \zeta \tag{3}<br>$$</p>
<p>求取$\alpha_2^{new}$的取值范围。</p>
<p>① 当$y^{(1)} \ne y^{(2)}$时，即一个等于-1，一个等于1，根据约束条件$(3)$可得：$\alpha_1^{old} - \alpha_2^{old} = \zeta$。可以表示为一条斜率为1的直线。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/34.png">
<p>$\alpha_1,\alpha_2$既要在矩形方框内，也要在直线上，所以有：$L= \max \{0,-\zeta \}$，$H=\min \{C, C-\zeta\}$</p>
<p>② 当$y^{(1)} = y^{(2)}$时，根据约束条件$(3)$可得：$\alpha_1^{old} +\alpha_2^{old} = \zeta$。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/35.png">
<p>所以有：$L= \max \{0,\zeta -C\}$，$H=\min \{C,\zeta\}$</p>
<p>因此根据$y^{(1)},y^{(2)}$异同号，可以得到$\alpha_2^{new}$的上下界分别为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\begin{cases}<br>L=\max \{0,\alpha_2^{old} -\alpha_1^{old}\} ,H=\min\{ C,C+\alpha_2^{old} -\alpha_1^{old}\} \quad {\rm if} \quad y^{(1)} \ne y^{(2)} \\\\<br>L=\max \{0,\alpha_2^{old} +\alpha_1^{old} -C\} ,H=\min\{ C,\alpha_2^{old} +\alpha_1^{old}\} \quad {\rm if} \quad y^{(1)} = y^{(2)}<br>\end{cases}<br>\end{aligned}<br>\end{equation}<br>$$</p>
<p>==然后再分析目标函数==。<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\min\limits_{\alpha}\Psi(\overrightarrow{\alpha})&amp;=\min\limits_{\alpha} \frac12 \sum\limits_{i,j=1}^n \alpha_i \alpha_jy_iy_jK(x_i,x_j)-\sum\limits_{i=1}^n \alpha_i \\\\<br>s.t. &amp;\quad 0 \le \alpha_i \le C,i=1,\dots,n \\\\<br>&amp;\quad \sum\limits_{i=1}^n \alpha_iy_i =0<br>\end{aligned}<br>\end{equation}<br>$$<br>这个目标函数的子问题（即只含有$\alpha_1,\alpha_2$当作参数）可以表达为：<br>$$<br>\Psi = \frac12 K_{11}\alpha_1^2 + \frac12 K_{22}\alpha_2^2 +sK_{12}\alpha_1\alpha_2 + y_1 \alpha_1v_1 +y_2\alpha_2v_2-\alpha_1-\alpha_2 +\Psi_{constant} \tag{4}<br>$$<br>其中：<br>$$<br>K_{ij} = K(\overrightarrow{x_i}，\overrightarrow{x_j}) \\\\<br>v_i = \sum\limits_{j=1}^n y_i \alpha_j’ K_{ij} = u_i +b’ -y_1\alpha_1’K_{1i} - y_2\alpha_2’K_{2i}<br>$$<br>其中，$\alpha_1’,\alpha_2’$表示某次迭代之前的原始值，因此是常数，$\alpha_1,\alpha_2$是待求的变量。$\Psi_{constant}$是常数。</p>
<p>与之对应的K.K.T条件为：<br>$$<br>\alpha_i =0 \iff y_iu_i \ge 1 \\\\<br>0 &lt; \alpha_i  &lt; C \iff y_iu_i =1 \\\\<br>\alpha_i =C \iff y_iu_i \le 1<br>$$<br>这个K.K.T条件说明，在两条间隔线外面的点，对应的前面的系数$\alpha_i =0$，在两条间隔线里面的对应的$\alpha_i =C$，在两条间隔线上的对应的系数$\alpha_i$在0与$C$之间。</p>
<p>考虑到对于第二个约束条件$\alpha_1^{old} y^{(1)} + \alpha_2^{old} y^{(2)} =\alpha_1^{new} y^{(1)} + \alpha_2^{new} y^{(2)}= -\sum\limits_{i=3}^n\alpha_iy^{(i)} = \zeta$，两边乘以$y^{(1)}$，可得：<br>$$<br>y^{(1)}[\alpha_1^{old} y^{(1)} + \alpha_2^{old} y^{(2)} ]=y^{(1)}[\alpha_1^{new} y^{(1)} + \alpha_2^{new} y^{(2)}]= -y^{(1)}\sum\limits_{i=3}^n\alpha_iy^{(i)}<br>$$<br>可简写成：<br>$$<br>\alpha_1 + s\alpha_2 = \alpha_1’ + s\alpha_2’ =w<br>$$<br>其中，$w= -y^{(1)}\sum\limits_{i=3}^n\alpha_i’ y^{(i)}$</p>
<p>因此，可以用$\alpha_2$来表示$\alpha_1$，即$\alpha_1 = w- s\alpha_2$。</p>
<p>然后把式子$\alpha_1 = w- s\alpha_2$代入式子$(4)$可得：<br>$$<br>\Psi = \frac12 K_{11}(w-s\alpha_2)^2 + \frac12 K_{22}\alpha_2^2 +sK_{12}(w-s\alpha_2)\alpha_2  \\\ \quad+ y_1 (w-s\alpha_2)v_1 +y_2\alpha_2v_2-w+s\alpha_2-\alpha_2 +\Psi_{constant} \tag{5}<br>$$<br>这样式$(5)$只有变量$\alpha_2$，然后对其求导可得：<br>$$<br>\frac{d\Psi}{d\alpha_2} = -sK_{11}(w-s\alpha_2) +K_{22}\alpha_2 -s^2K_{12}\alpha_2 +sK_{12}(w-s\alpha_2)-y_1v_1s+s+y_2v_2-1<br>$$<br>如果$\Psi$的二阶导大于0（凹函数），那么一阶导数为0，即极小值，假设一阶导数为0，上式可简化为：<br>$$<br>\alpha_2(K_{11} +K_{22} -2K_{22})=s(K_{11} -K_{12})w +y_2(v_1-v_2) +1-s<br>$$<br>其中：<br>$$<br>s=y_1y_2 \\\\<br>\alpha_1 +s\alpha_2= \alpha_1’ +s\alpha_2’ =w \\\\<br>K_{ij} = K(\overrightarrow{x_i},\overrightarrow{x_j})\\\\<br>v_i =\sum\limits_{j=3}^{n}y_j \alpha_j’ K_{ij} = u_i +b’ -y_i \alpha_1’K_{1i} -y_2\alpha_2’ K_{2i}<br>$$<br>代入上式可得到：<br>$$<br>\alpha_2^{new,unclipped} (K_{11}+K_{22} -2K_{22})=\alpha_2^{old}(K_{11}+K_{22} -2K_{22}) +y_2(u_1-u_2+y_2-y_1)<br>$$<br>令$E_i = u_i -y_i$（表示预测值和真实值之差），$\eta =K(\overrightarrow{x_1},\overrightarrow{x_1}) +K(\overrightarrow{x_2}),\overrightarrow{x_1} -2K(\overrightarrow{x_1},\overrightarrow{x_2})$</p>
<p>上式两边同时除以$\eta$，得到一个关于单变量$\alpha_2$的为剪辑的解：<br>$$<br>\alpha_2^{new,unclipped} = \alpha_2 + \frac{y_2(E_1-E_2)}{\eta}<br>$$<br>==这个解没有考虑到约束条件$0 \le \alpha_2 \le C$，即是为剪辑时的解。==</p>
<p>加入该约束条件后，得到剪辑过后的$\alpha_2^{new}$的解为：<br>$$<br>\begin{equation}<br>\alpha_2^{new} =\begin{cases}<br>H,\quad \alpha_2^{new,unclipped}&gt;H \\\\<br>\alpha_2^{new.unclipped}, L \le \alpha_2^{new,unclipped } \le H \\\\<br>L, \quad \alpha_2^{new,unclipped}&lt; L<br>\end{cases}<br>\end{equation}<br>$$<br>其中，$L,H$分别是$\alpha_2^{new}$的上下界，即：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\begin{cases}<br>L=\max \{0,\alpha_2^{old} -\alpha_1^{old}\} ,H=\min\{ C,C+\alpha_2^{old} -\alpha_1^{old}\} \quad {\rm if} \quad y^{(1)} \ne y^{(2)} \\\\<br>L=\max \{0,\alpha_2^{old} +\alpha_1^{old} -C\} ,H=\min\{ C,\alpha_2^{old} +\alpha_1^{old}\} \quad {\rm if} \quad y^{(1)} = y^{(2)}<br>\end{cases}<br>\end{aligned}<br>\end{equation}<br>$$</p>
<p>求出$\alpha_2^{new}$后，则$\alpha_1^{new} = \alpha_1^{old} +s(\alpha_2^{old} - \alpha_2^{new}) = \alpha_1^{old} +y_1y_2(\alpha_2^{old} - \alpha_2^{new}) $</p>
<p>==选择乘子$\alpha_1,\alpha_2$步骤：==</p>
<ul>
<li>对于$\alpha_1 $，即第一个乘子，可以通过如下办法：</li>
</ul>
<blockquote>
<p>因为K.K.T条件为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\alpha_i =0 &amp;\iff y_iu_i \ge 1 \quad表明\alpha_1在边界内部，因为正确分类点满足y_if(x_i) \ge 0。\\\ <br>0 &lt; \alpha_i  &lt; C &amp;\iff y_iu_i =1 \quad 表明\alpha_i是支持向量，在边界上。\\\\<br>\alpha_i =C &amp;\iff y_iu_i \le 1 \quad 表明\alpha_i在两条边界之间。<br>\end{aligned}<br>\end{equation}<br>$$<br>而最优解需要满足K.K.T条件，即上述三个条件都得满足，以下几种情况出现将会不满足：</p>
<ul>
<li>$y_iu_i \le 1$，但是$\alpha_i &lt; C$，则是不满足的，而原本$\alpha_i =C$。</li>
<li>$y_iu_i \ge 1$，但是$\alpha_i &gt; 0$，则是不满足的，而原本$\alpha_i =0$。</li>
<li>$y_iu_i = 1$，但是$\alpha_i = C$或$\alpha_i = 0$，则是不满足的，而原本$0&lt;\alpha_i &lt;C$。</li>
</ul>
<p>也就是，如果存在不满足K.K.T条件的$\alpha_i$，那么需要更新这些$\alpha_i$。</p>
</blockquote>
<ul>
<li>对于$\alpha_2$，可以寻找满足条件：$\max |E_i -E_j|$的乘子。</li>
</ul>
<p>==更新$b$==</p>
<p>对于$b$，在满足下述条件：<br>$$<br>\begin{equation}<br>b =\begin{cases}<br>b_1,\quad 0&lt; \alpha_1^{new} &lt; C \\\\<br>b_2,\quad  0&lt; \alpha_2^{new} &lt; C\\\\<br>\frac{(b_1+b_2)}{2}, \quad otherwise<br>\end{cases}<br>\end{equation}<br>$$<br>进行如下更新：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>b_1^{new} = b^{old} -E_1-y_1(\alpha_1^{new} -\alpha_1^{old})K(x_1,x_1) -y_2(\alpha_2^{new} -\alpha_2^{old})K(x_1,x_2) \\\\<br>b_2^{new} = b^{old} -E_2-y_1(\alpha_1^{new} -\alpha_1^{old})K(x_1,x_2) -y_2(\alpha_2^{new} -\alpha_2^{old})K(x_2,x_2)<br>\end{aligned}<br>\end{equation}<br>$$<br>且每次更新完两个乘子的优化后，都需要再重新计算$b$，及对应的$E_i$的值。</p>
<p>最优更新完所有的$\alpha_i,y$和$b$，得到模型，即可求出分类函数：<br>$$<br>f(x) = \sum\limits_{i=1}^n \alpha_i y_i \left&lt;x_i,x\right&gt; +b<br>$$</p>
<p><strong>SMO算法的步骤 ：</strong></p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/33.png">
<p>假定在某一次迭代中，需要更新$x_1,x_2$所对应的拉格朗日乘子$\alpha_1,\alpha_2$，这个小规模的二次规划问题可以写成：<br>$$<br>L_s =\max\limits_{\alpha} \left\{(\alpha_1+\alpha_2) + \sum\limits_{i=3}^n \alpha_i - \frac12 || \alpha_1 y_1 \phi(x_1) + \alpha_2y_2\phi(x_2) + \sum\limits_{i=3}^n \alpha_iy_i\phi(x_i)|| \right\} \\\\<br>s.t. \quad \alpha_1y_1 +\alpha_2y_2 = -\sum\limits_{i=3}^n \alpha_iy_i \quad 0&lt; \alpha_i &lt; C, \forall i<br>$$<br>==首先选取要更新的乘子：==</p>
<p>step1：先“扫描”所有乘子，把第一个违反K.K.T条件的作为更新对象，令其为$\alpha_2$。</p>
<p>step2：在所有不违反K.K.T条件的乘子中，选取使得$|E_1-E_2|$最大的$\alpha_1$进行更新，使得能在最大限度增大目标函数的值。类似梯度下降法。【==其中，$E_i = u_i -y_i$，而$u= \overrightarrow{w}·\overrightarrow{x} -b$。所以得到的$E$代表函数$u_i$对输入$x_i$的预测值与真实输出类标记$y_i$之差。==】</p>
<p>==然后更新拉格朗日乘子$\alpha_1,\alpha_2$：==</p>
<p>step1：计算上下界$L$和$H$：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>\begin{cases}<br>L=\max \{0,\alpha_2^{old} -\alpha_1^{old}\} ,H=\min\{ C,C+\alpha_2^{old} -\alpha_1^{old}\} \quad {\rm if} \quad y^{(1)} \ne y^{(2)} \\\\<br>L=\max \{0,\alpha_2^{old} +\alpha_1^{old} -C\} ,H=\min\{ C,\alpha_2^{old} +\alpha_1^{old}\} \quad {\rm if} \quad y^{(1)} = y^{(2)}<br>\end{cases}<br>\end{aligned}<br>\end{equation}<br>$$<br>step2：计算$L_s$的二阶导数：<br>$$<br>\eta =2\phi(x_1)^T\phi(x_2) -\phi(x_1)^T\phi(x_1) -\phi(x_2)^T\phi(x_2)<br>$$<br>step3：更新$L_s$：<br>$$<br>\alpha_2^{new} = \alpha_2^{old} -\frac{y_2(e_1-e_2)}{\eta} \\\\<br>e_i = g^{old}(x_i) -y_i<br>$$<br>step4：计算变量$\alpha_2$：<br>$$<br>\begin{equation}<br>\alpha^{temp} =\begin{cases}<br>H,\quad \alpha_2^{new}&gt;H \\\\<br>\alpha_2^{new}, L \le \alpha_2^{new} \le H \\\\<br>L, \quad \alpha_2^{new}&lt; L<br>\end{cases}<br>\end{equation}<br>$$<br>step5：更新$\alpha_1$：<br>$$<br>\alpha_1^{new} = \alpha_1^{old} +y_1y_2(\alpha_2^{old} - \alpha^{temp})<br>$$</p>
<p>==最后每次更新完两个乘子优化后，都需要再重新计算$b$，以及对应的$E_i$的值。==</p>
<p>==小结：==</p>
<p>SMO算法基本思想是将Vapnik在1982年提出的Chunking方法推到极致，SMO算法每次迭代只选出两个分量$\alpha_i$和$\alpha_j$进行调整，其它分量 则保持不变，在得到解$\alpha_i$和$\alpha_j$后，再利用$\alpha_i$和$\alpha_j$进行改进其它分量。</p>
<p>与通常的分解算法相比较，尽管需要更多的迭代次数，但是每次迭代的计算量比较小，所以该算法表现出快速的收敛性，且不需要存储核矩阵，没有矩阵运算。</p>
<p><a href="/download/支持向量机通俗导论_理解SVM的三层境界.pdf">支持向量深入理解</a></p>
<h1 id="优化搜索"><a href="#优化搜索" class="headerlink" title="优化搜索"></a>优化搜索</h1><h2 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h2><p><strong>算法思想</strong></p>
<p>贪心算法总是做出在<font color="#F00"><strong>当前看来最好的选择（贪心选择）</strong></font>，并不从整体上进行最优考虑，所作出的选择只是<font color="#F00"><strong>局部最优选择</strong></font>。</p>
<p>虽不能对所有的问题都得到整体最优解，但对很多问题能产生整体最优解，如最小生成树问题。在一些情况下，即使贪心算法不能得到整体最优解，其最终结果却是最优解的很好的近似。</p>
<p>贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须是具备==无后效性==，即某个状态以后的过程不会影响以前的状态，至于当前状态有关。</p>
<p>贪心策略<font color="#f00"><strong>适用的前提</strong></font>是：局部最优策略能导致产生全局最优解。</p>
<p><font color="#f00"><strong>最优子结构</strong></font>：当一个问题的最优解包括其子问题的最优解时，称此问题具有最优子结构性质。</p>
<p><strong>基本思路</strong></p>
<ol>
<li>建立数学模型来描述问题</li>
<li>把求解的问题分成若干个子问题</li>
<li>对每一个子问题求解，得到子问题的局部最优解</li>
<li>把子问题的局部最优解合成原来解问题的一个解</li>
</ol>
<p><strong>实现过程</strong></p>
<p>从问题的某一个初始解出发；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>（能朝着给定总目标前进一步）</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">​    利用可行的决策，求出可行解的一个解元素；</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">由所有解元素组合成问题的一个可行解。</span><br></pre></td></tr></table></figure>
<h2 id="旅行商问题"><a href="#旅行商问题" class="headerlink" title="旅行商问题"></a>旅行商问题</h2><p>TSP(Traveling Salesman Problem)即旅行商问题，假设假设有一个旅行商人要拜访n个城市，他必须选择所要走的路径，路径的限制是每个城市只能拜访一次，而且最后要回到原来出发的城市。路径的选择目标是要求得的路径长度为所有路径之中的最小值。TSP是一个典型的组合优化问题，且是一个==NP完全难题==。即TSP问题目前尚不能找到一个多项式时间复杂度算法来求解。</p>
<blockquote>
<p><strong>P类问题</strong>：所有可以在多项式时间内求解的判定问题。</p>
<p><strong>判定问题</strong>：回答结果输出为<code>yes</code>或<code>no</code>的问题。</p>
<p><strong>时间复杂度</strong>：衡量当问题规模变大后，程序执行的所需时间增长多快。如$O(1)$表示常数级别，即不管问题规模变大多少倍，所耗时间不会改变；$O(n^2)$表示平方级别，即当问题规模增大至2倍时，所耗费时间则放大到4倍；$O(2^n)$表示指数级别，即当问题规模倍数扩大时，所用时间会呈指数放大。</p>
<p><strong>多项式时间</strong>：指$O(1),O(\log n),O(n^2)$等这类可用多项式表示的时间复杂度，通常认为计算机可解决的问题只限定于多项式时间内，而$O(2^n),O(n!)$这类非多项式级别的问题，其复杂度计算机接受不了。</p>
<p><strong>NP类问题</strong>：所有非确定性多项式时间内可解的判定问题。</p>
<p>NP类问题将问题分为<strong>求解</strong>和<strong>验证</strong>两个阶段，问题的求解是非确定性的，无法在多项        式时间内得到答案，而问题的验证却是确定的，能够在多项式时间里确定结果。</p>
<p>如：是否存在一个公式可以计算下一个质数？这个问题的答案是无法直接计算出来，但是一旦某人给出了一个公式，可以在多项式时间里对这个公式进行验证。</p>
<p><strong>NP完全问题</strong>：NP(Non-deterministic Polynomial)的缩写，即多项式复杂程度的非确定性问题，也称为NP-C问题。是NP中一类特殊的问题。</p>
<p>这类问题的每个问题的复杂度与整个类的复杂度有关联性，假如其中任意一个问题在多项式时间内可解，则这一类问题都是多项式时间可解。</p>
<p>在决策树算法中，寻找最优决策树是一个NP完全问题，决策树问题无法利用计算机在多项式时间内，找出全局最优的解。因此，大多数决策树算法都采用==启发式算法==，如贪心算法，来指导对假设空间的搜索。即决策树算法最后的结果，是在每一步、每一个节点上做局部最优选择，无法保证为全局最优。                     </p>
</blockquote>
<p><strong>解决方案</strong></p>
<p>最优的方法是==穷举法==，但是穷举法效率不高。目前针对于如何通过一个多项式时间复杂度的算法快速求出先后次序，主流方法是采用一些随机的、启发式的搜索算法，比如==遗传算法、模拟退火算法、粒子群算法等==。</p>
<p>但上述的这些算法都有一个缺点，不一定能找到最优解，只能收敛（近似逼近）最优解，得到一个次优解，因为本质上都是随机算法，都以类似“一定概率接受或舍去”的思路去筛选解。</p>
<p>TSP问题求解大概是由两步构成的：</p>
<ol>
<li><strong><em>计算两两城市之间的最短路径</em></strong>：利用类似Dijkstra、Flord、A星的算法找出最短路线。</li>
<li><strong><em>计算最短巡回路径</em></strong>：利用类似遗传算法、蚁群算法的搜索算法求巡回拜访的次序。</li>
</ol>
<p><strong>动态规划算法</strong></p>
<p>DP(Dynamic Programming)通常用于求解具有某种最优性质的问题，其基本思想是将待求解问题分解为若干个子问题，先求子问题，然后由这些子问题再得到原问题的解。【类似贪心算法】</p>
<p>DP是一种求解TSP问题的很好的方法。</p>
<p><strong>实例操作</strong></p>
<p>假设现在有四个城市，分别是0，1，2，3。之间的来往代价如下图所示：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/36.png" title="动态规划算法">
<p>写成矩阵的形式：<br>$$<br>C=\pmatrix{0 &amp;3 &amp;6 &amp;7\ 5&amp;0&amp;2&amp;3\\6&amp;4&amp;0&amp;2\\3&amp;7&amp;5&amp;0}<br>$$<br>其中第一行表示从城市0到城市0，1，2，3四个的代价。以此类推。</p>
<p>==下面简单推导一下动态规划问题==：</p>
<p>用$V’$表示一个点的集合，假如从定点$s$出发，$d(i,V’)$表示当前到达顶点$i$，经过$V’$集合中所有顶点一次最小花费。</p>
<ol>
<li><p>当$V’$为仅包含起点的集合，即：$d(s,\{s\}) =0$。</p>
</li>
<li><p>其它情况，则对子问题求最优解。需要在$V’$这个城市集合中，尝试每一个城市的结点，并求出最优解。<br>$$<br>d(i,V’+\{i\}) =\min\limits_{k\in V’}\{d(k,V’) +c_{ki}\}<br>$$</p>
</li>
<li><p>最后的求解方式：<br>$$<br>Answer = \min\limits_{i\in S}\{d(i,S) +c_{is}\}<br>$$<br>其中$S$为包含所有点的集合。</p>
</li>
</ol>
<h2 id="模拟退火算法"><a href="#模拟退火算法" class="headerlink" title="模拟退火算法"></a>模拟退火算法</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>爬山法是一种贪心算法，对于一个优化问题，其大致图像如下所示：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/37.png" title="爬山法">
<p>其目标是找到函数的最大值，若初始化时，初始点的位置在$C$处，则会寻找附近的局部最大值$A$处，由于$A$点是一个局部最大值，对于爬山法来讲，该算法无法跳出局部最大值。</p>
<p>若初始点选在$D$处，则根据爬山法，则会找到全局最大值点$B$点。这也说明基于贪婪的爬山法是否能够取得全局最优解与初始值选取有很大的关系。</p>
<p>模拟退火算法(Simulated Annealing，SA)的思想借鉴于固体的退火原理。当固体的温度很高的时候，内能比较大，固体的内部粒子处于快速无序运动，当温度慢慢降低的过程中，固体的内能减小，粒子慢慢趋于由徐，最终，当固体处于常温时，内能达到最小，此时，粒子最为稳定。</p>
<p>SA从某一个较高的温度出发，称为初始温度。伴随着温度参数不断下降，算法中的解趋于稳定，但是，这个稳定解可能是局部最优解，此时，SA会以一定的概率跳出这个局部最优解，以寻找目标函数的全局最优解。如上图所示，寻找到$A$点处的解，SA会以一定的概率跳出这个解，如跳到$D$点重新寻找，这样在一定程度上增加了寻找全局最优解的可能性。==即局部最优解能概率性地跳出并最终趋于全局最优。==</p>
<h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a><strong>相关概念</strong></h3><p><strong>退火</strong>：将固体加热到足够高的温度，使得分子呈随机排列状态，然后逐步降温使之冷却，最后分子以低能状态排列，达到某种稳定状态。</p>
<p><strong>退火过程</strong>：</p>
<ul>
<li>加温过程：增强粒子运动，消除系统原先可能存在的非均匀态。</li>
<li>等温过程：对于与环境换热而温度不变的封闭系统，系统的状态自发变化总是朝着自由能减少的方向进行，当自由能达到最小时，系统达到平衡。</li>
<li>冷却过程：使粒子热运动减弱并渐趋下降，从而得到低能的晶体结构。</li>
</ul>
<p><strong>Boltzmann分布</strong>：</p>
<ul>
<li>同一温度，分子停留在能量小的状态的概率大于停留在能量大的概率。</li>
<li>温度越高，不同能量状态对应的概率相差越小，温度足够高时，各状态对应的概率基本相同。</li>
<li>随着温度下降，能量最低状态对应的概率越来越大，温度趋于0时，其状态趋于1。</li>
</ul>
<p><strong>Metropolis准则</strong>：</p>
<p>固体在恒定温度下达到热平衡的过程可以用<em>Metropolis</em>方法加以模拟。</p>
<p>==温度恒定时==：若温度为$T$，当前状态$i$ ，新状态$j$，若$E_i &lt; E_j$，则接受$j$为当前状态；否则，若概率$p= e^{ \frac{-(E_j-E_i)} {k_B \times T}}$大于$[0,1)$区间的随机数，则仍接受状态$j$为当前状态；若不成立则保留状态 $i$为当前状态。</p>
<p>==温度变化时：==在高温下，可接受当前状态能量差较大的新状态；在低温下，只接受与当前状态能量差较小的新状态。</p>
<h3 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h3><p>SA算法来源于固体退火原理，将固体加温到充分高，再让其逐渐冷却，加温时，固体内部粒子随温度升高变为无序状态，内能增大，逐渐冷却的粒子渐趋有序，在每一个温度都达到平衡态，最后在常温时达到基态，内能减为最小。</p>
<p>根据<em>Metropolis</em>准则，粒子温度在$T$时趋于平衡的概率为$e^{-\frac{\Delta E}{kT}}$，其中$E$为温度$T$时的内能，$\Delta E$为其变化量，$k$为<em>Boltzmann</em>常数。</p>
<p>用固体退火模拟组合优化问题，将内能$E$模拟为目标函数值$f$，温度$T$演化为控制参数$t$，即得到解组合优化问题的模拟退火算法：</p>
<blockquote>
<p>由初始解$i$和控制参数初始值$t$开始，对当前解重复”产生新解 →计算目标函数差→接受或舍弃“的迭代，并逐步衰减$t$值，算法终止时的当前解即为所得的近似最优解。</p>
</blockquote>
<p>这是==基于蒙特卡洛迭代求解发的一种启发式随机搜索过程==。</p>
<p>退火过程由冷却进度表(Cooling Schedule)控制，包括控制参数的初值$t$及其衰减因子$\Delta t$、每个$t$值时的迭代次数$L$和停止条件$S$。</p>
<h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><p>step 1：<strong>由一个产生函数从当前解产生一个位于解空间的新解</strong>。为便于后续的计算和接受，减少算法的耗时，通常选择由当前新解经过简单地变换即可产生新解的方法，如对构成新解的全部或部分元素进行置换、互换等，注意到产生新解的变换方法决定了当前新解的领域结构，因而对冷却进度表的选取有一定的影响。</p>
<p>step 2：<strong>计算新解所对应的目标函数差</strong>。目标函数差仅由变换部分产生，所以目标函数差的计算最好按增量计算。这也是计算目标函数差最快的方法。</p>
<p>step 3：<strong>判断新解是否被接受，判断的依据时一个接受准则</strong>。常用的是<em>Metropolis</em>准则：若$\Delta t’ &lt;0$则接受$S’$作为当前新的解$S$，否则以概率$e^{-\frac{\Delta t’}{T}}$接受$S’$作为新的当前解$S$。</p>
<p>step 4：<strong>新解被确定后，用新解代替当前解</strong>。只需要将当前解对应于产生新解时的变换部分予以实现，同时修正目标函数值即可。</p>
<p>此时，当前解实现了一次迭代，在此基础上开始下一轮试验，而当新解被判定为舍弃时，则在原当前解的基础上继续下一轮试验。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/38.png" title="SA算法流程图">
<p>==附一matlab源码==：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[xo,fo]</span> = <span class="title">Opt_Simu</span><span class="params">(f,x0,u,l,kmax,q,TolFun)</span></span></span><br><span class="line"><span class="comment">% 模拟退火算法求函数 f(x)的最小值点， 且 l &lt;= x &lt;= u</span></span><br><span class="line"><span class="comment">% f为待求函数，x0为初值点，l，u分别为搜索区间的上下限，kmax为最大迭代次数</span></span><br><span class="line"><span class="comment">% q为退火因子，TolFun为函数容许误差</span></span><br><span class="line"><span class="comment">%%%%算法第一步根据输入变量数，将某些量设为缺省值</span></span><br><span class="line"><span class="keyword">if</span> nargin &lt; <span class="number">7</span></span><br><span class="line">    TolFun = <span class="number">1e-8</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">if</span> nargin &lt; <span class="number">6</span></span><br><span class="line">    q = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">if</span> nargin &lt; <span class="number">5</span></span><br><span class="line">    kmax = <span class="number">100</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">%%%%算法第二步，求解一些基本变量</span></span><br><span class="line">N = <span class="built_in">length</span>(x0); <span class="comment">%自变量维数</span></span><br><span class="line">x = x0;</span><br><span class="line">fx = feval(f,x); <span class="comment">%函数在初始点x0处的函数值</span></span><br><span class="line">xo = x;</span><br><span class="line">fo = fx;</span><br><span class="line"><span class="comment">%%%%%算法第三步，进行迭代计算，找出近似全局最小点</span></span><br><span class="line"><span class="keyword">for</span> k =<span class="number">0</span>:kmax</span><br><span class="line">    Ti = (k/kmax)^q;</span><br><span class="line">    mu = <span class="number">10</span>^(Ti*<span class="number">100</span>); <span class="comment">% 计算mu</span></span><br><span class="line">    dx = Mu_Inv(<span class="number">2</span>*<span class="built_in">rand</span>(<span class="built_in">size</span>(x))<span class="number">-1</span>,mu).*(u - l);<span class="comment">%步长dx</span></span><br><span class="line">    x1 = x + dx; <span class="comment">%下一个估计点</span></span><br><span class="line">    x1 = (x1 &lt; l).*l +(l &lt;= x1).*(x1 &lt;= u).*x1 +(u &lt; x1).*u; <span class="comment">%将x1限定在区间[l,u]上</span></span><br><span class="line">    fx1 = feval(f,x1);</span><br><span class="line">    df = fx1- fx;</span><br><span class="line">    <span class="keyword">if</span> df &lt; <span class="number">0</span>||<span class="built_in">rand</span> &lt; <span class="built_in">exp</span>(-Ti*df/(<span class="built_in">abs</span>(fx) + <span class="built_in">eps</span>)/TolFun) <span class="comment">%如果fx1&lt;fx或者概率大于随机数z</span></span><br><span class="line">        x = x1;</span><br><span class="line">        fx = fx1;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span> fx &lt; fo</span><br><span class="line">        xo = x;</span><br><span class="line">        fo = fx1;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">x</span> = <span class="title">Mu_Inv</span><span class="params">(y,mu)</span></span></span><br><span class="line">x = (((<span class="number">1</span>+mu).^<span class="built_in">abs</span>(y)- <span class="number">1</span>)/mu).*<span class="built_in">sign</span>(y);</span><br></pre></td></tr></table></figure>
<h1 id="进化计算"><a href="#进化计算" class="headerlink" title="进化计算"></a>进化计算</h1><h2 id="进化计算概述"><a href="#进化计算概述" class="headerlink" title="进化计算概述"></a>进化计算概述</h2><p>Darwin被认为是进化理论和共同起源法则的奠基人，Lamarck可能是把生物进化理论化的第一人。</p>
<p>Larmarck的进化理论是关于遗传的，如获得性状的遗传，其主要观点是生物个体在生命周期中逐渐适应环境，并将性状传给后代，后代也能不断适应。</p>
<p>Darwin理论认为：自然选择发生在繁殖算子中，即”最好“的父代个体有更多的机会被选择来产生后代，形成新的种群；随机改变通过<strong>变异(mutation)</strong>算子来实现。</p>
<p>进化计算(Evolutionary Computing)是指进化过程中作为计算模型的问题的解决系统，如自然选择、适者生存、繁殖等都是这个问题解决系统的组成部分。</p>
<h2 id="一般进化算法"><a href="#一般进化算法" class="headerlink" title="一般进化算法"></a>一般进化算法</h2><p>主要受以下几个部分的影响：</p>
<ul>
<li>编码：与染色体一样，对问题进行解编码</li>
<li>适应度函数：用于求适应度的函数，表征个体的生存能力</li>
<li>初始化：种群的初始化</li>
<li>选择：选择算子</li>
<li>繁殖(reproduction)：繁殖算子</li>
</ul>
<hr>
<p>==一般进化算法步骤==</p>
<hr>
<p>令代数计数器$t=0$：</p>
<p>创建和初始化$n_x$维群体$\Phi(0)$，包含$n_s$个个体</p>
<p><strong>while</strong> 终止条件不为真 <strong>do</strong></p>
<p>​            获得每个个体$x_i(t)$的适应度值$f(x_i(t))$；</p>
<p>​            采用复制算法来产生后代；</p>
<p>​             选择新群体$\Phi(t+1)$；</p>
<p>​             进入下一代，即$t=t+1$；</p>
<p><strong>end</strong></p>
<hr>
<p>进化算法这些步骤不断迭代，直到满足某个终止条件。每一次的迭代称为一个世代(generation)。</p>
<p>进化算法各部分实现的不同，形成不同的进化计算方法：</p>
<ul>
<li><strong>遗传算法</strong>(Genetic Algorithms,GA)，以基因进化为模型。</li>
<li><strong>遗传编程</strong>(Genetic Programming,GP)，以遗传算法为模型，但个体为程序（表示为树）。</li>
<li><strong>进化规划</strong>(Evolutionary Programming,EP)，来源于对进化中自适应行为的模拟（如表型进化）。</li>
<li><strong>进化策略</strong>(Evolution Strategies,ES)，用于对进化过程中的控制变量进行建模，如进化的进化。</li>
<li><strong>差分进化</strong>(Differential Evolution,DE)，类似于遗传算法，不同之处在其所使用繁殖机制。</li>
<li><strong>文化进化</strong>(Cultural Evolution,CE)，用于对种群文化的进化以及对文化如何影响个体的基因和表现型的进化的建模。</li>
<li><strong>协同进化</strong>(Co-evolution,CoE)，模拟初始”愚蠢的“个体如何通过合作或竞争来获取必要的性状以求得生存的演化过程。</li>
</ul>
<p>==染色体表示==</p>
<p>生物体拥有某些能影响生存和繁殖能力的性状，是由包含在生物细胞核中的染色体的一长串信息决定的。每个染色体包含大量的基因，基因是一种遗传单位，通过控制蛋白质的合成来决定生物个体的生理和解剖表现。每个生物个体都有唯一的基因序列。基因的另一种形式称为等位基因(allele)。</p>
<p>进化计算中，每个个体都代表是一个优化问题的备选解，个体的性状由染色体（或称基因组）表示。</p>
<p>性状是指最优化问题所搜索的变量，每个需要优化的变量称为基因——携带信息的最小单位。</p>
<p>个体的性状分为两类进化信息：基因型和表现型。</p>
<p>基因型描述了个体的基因组成，继承于父代；表现型是一个个体在特定环境中所表现出的行为特征，定义了个体的样貌。</p>
<p>设计进化算法的一个重要步骤就是找到备选解的合适的表示方案（如染色体）。搜索算法的效率与复杂程度依赖于这个表示方案。不同的方法往往使用不同的表示方案。多数进化算法把解表示为<strong>某种数据类型的向量</strong>，但遗传编程是把个体表示为<strong>树</strong>的形式。</p>
<p>==初始化种群==</p>
<p>进化算法是一种基于种群的随机搜索算法，每个进化算法都会维护一个由备选解构成的种群。</p>
<p>产生初始种群的标准方法是在可行域中产生随机值，并分配到每个染色体的每个基因。</p>
<p>随机选择的目标是确保初始种群为整个搜索空间的均匀表示。</p>
<p>初始种群的大小会影响计算复杂性和空间探索能力。大量的个体能增加多样性，进而提高种群的空间探索能力。当然，计算量也会 更大。</p>
<p>在使用小个体数量的种群时，如果增加变异频率，则可迫使进化算法探索更多的搜索空间。</p>
<p>==适应度函数==</p>
<p>在进化算法中，为确定一个个体的生存能力，用一个数学函数来表征染色体所表示的解有多好，即适应度函数。</p>
<p>进化算子，如选择、交叉、变异和精英选择，都会用适应度函数来评估染色体。如选择父代个体用于交叉时，选择算子会更倾向最适应的个体，而变异算子会倾向最不适应的个体。</p>
<p>==选择==</p>
<p>选择算子的主要目标是获得更好的解，通过进化算法的两个步骤来完成：</p>
<ul>
<li>新种群的选择：在每一代的结束，一个由备选解构成的新种群会被选择作为下一代种群。新种群可以仅从后代中选择，或者同时从后代与父代中选择，选择算子的目标是确保优良个体能存活到下一代。</li>
<li>繁殖：后代通过交叉或变异算子生成。在交叉中，优良个体应该有更多的机会去繁殖，以确保后代包含最好个体的基因，在变异中，选择机制关注”劣势“个体，目的是引入更好的性状，以增加劣势个体的生存能力。</li>
</ul>
<p>选择方法包括：随机选择、比例选择、锦标赛选择、排序选择、玻尔兹曼选择、$(\mu^+,\lambda)$选择、精英选择和名人堂(hall of fame)。</p>
<p>==繁殖算子==</p>
<p>繁殖是从选择的父代中应用交叉和变异算子生存子代的过程。</p>
<p>交叉是通过组合随机选择两个或多个父代个体的基因物质生成新个体的过程</p>
<p>变异是随机改变染色体基因值得过程，主要目标是使得种群引入新得基因物质，提高基因得多样性，注意不能破坏高适应度个体的优良基因，因此变异通常都是以较低的概率进行。另一方面，变异的概率与个体的适应度成反比：适应度越低的个体，变异越高</p>
<p>繁殖可以使用替换机制，即当且仅当新产生的子代个体的适应度优于它的父代个体时，才进行替换。</p>
<p>==终止条件==</p>
<p>最简单的终止条件是限制进化算法执行的代数或是调用适应度函数的次数。</p>
<p>其他收敛准则有：</p>
<ul>
<li>当连续几代内都没有提高时则终止</li>
<li>当种群中没有改变时终止</li>
<li>当得到一个可接受的解时终止</li>
<li>当目标函数斜率接近0时终止</li>
</ul>
<h2 id="遗传算法"><a href="#遗传算法" class="headerlink" title="遗传算法"></a>遗传算法</h2><h3 id="遗传算法概念"><a href="#遗传算法概念" class="headerlink" title="遗传算法概念"></a>遗传算法概念</h3><p>遗传算法(Genetic Algorithm,GA)起源于对生物系统所进行研究的计算机模拟。它是模仿自然界生物进化机制发展起来的随机全局搜索和优化方法，借鉴于达尔文的进化论和孟德尔的遗传学说。</p>
<p>其本质是一种高效、并行、全局搜索的方法，能在搜索过程中自动获取和积累有关搜索空间的知识，并自适应地控制搜索过程以求得最佳解。</p>
<blockquote>
<p>一些相关术语：</p>
<p>基因型(genotype)：性状染色体的内部表现</p>
<p>表现型(phenotype)：染色体决定的性状的外部表现，或者说，根据基因型形成的个体的外部表现</p>
<p>进化(evolution)：种群逐渐适应生存环境，品质不断得到改良。生物的进化是以种群的形式进行</p>
<p>适应度(fitness)：度量某个物种对于生存环境的适应程度</p>
<p>选择(selection)：以一定的概率从种群选择若干个个体，一般，选择过程是一种基于适应度的优胜劣汰的过程。</p>
<p>复制(reproduction)：细胞分裂时，遗传物质DNA通过复制而转移到新产生的细胞中，新细胞就继承就细胞的基因</p>
<p>交叉(crossover)：两个染色体在某一个相同位置处DNA被切断，前后两串分别交叉组合形成两个新的染色体。或称为基因重组或杂交</p>
<p>变异(mutation)：复制时可能(很小的概率)产生某些复制差错，变异产生新的染色体，表现出新的性状</p>
<p>编码(coding)：DNA中遗传信息在一个长链上按一定的模式排列。遗传编码可看作从表现型到基因型的映射</p>
<p>解码(decoding)：基因型到表现型的映射</p>
<p>个体(individual)：染色体带有特征的实体</p>
<p>种群(population)：个体的集合，该集合内个体数为种群的大小</p>
</blockquote>
<h3 id="遗传算法的应用"><a href="#遗传算法的应用" class="headerlink" title="遗传算法的应用"></a>遗传算法的应用</h3><p>诸如询路问题，8数码问题，囚犯困境，动作控制，找圆心问题（在一个不规则的多边形中，寻找一个包含在该多边形内的最大圆圈的圆心），TSP问题，生产调度问题，人工生命模拟等。</p>
<p>以袋鼠为例：</p>
<p>遗传算法中每一条染色体，对应着遗传算法的一个解决方案，一用适应性函数(fitness function)来衡量这个解决方案的优劣。从一个基因组到其解的适应度形成的一个映射，可以把遗传算法的过程看成一个在多元函数里面求最优解的过程。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/42.png" title="遗传算法使用">
<p>在这个多维曲面里有很多的“山峰 ”，而这些“山峰”所对应的就是局部最优解，其中会有一个“山峰”的海拔最高，即是全局最优解。遗传算法的任务就是尽量爬到最高峰，而不是陷落在小山峰。（如果问题的适应度评价越小越好，那么全局最优解就是函数的最小值，遗传算法要找的就是“最深的谷底”。</p>
<p>如求解函数$f(x) = xsin(10\pi x) +2 , x\in[1,2]$，的函数最大值：</p>
<p><strong>“袋鼠跳”问题</strong>：</p>
<p>把函数曲线可以看成一个个山峰和山谷组成的山脉，把设想所得到的每一个解就是一只袋鼠（能跳），希望不断的向着更高处跳去，直到跳到最高的山峰。</p>
<p><strong>几种“袋鼠跳”的方式</strong>：</p>
<ol>
<li>爬山法(最速上升爬山法)：从搜索空间中随机产生邻近的点，从中选择对应解最优的个体，替换原来的个体，不断重复上述过程。爬山法只对“邻近”的点作比较，常常只能收敛到离开初始位置比较近的局部最优解上。对于存在很多局部最优点的问题，通过一个简单的迭代找出全局最优解的机会很小。</li>
<li>模拟退化法：在金属热加工过程中，当金属的温度超过它的熔点(melting point)时，原子会激烈地随机运动。原子的这种运动趋向于寻找能力极小状态。在这个能力变迁过程中，开始时，温度会非常高，使得原子具有很高的能量。随着温度不断降低，金属逐渐冷却，金属中的原子的能量越来越小，最后达到所有可能的最低点。利用模拟退火时候，让算法从较大的跳跃开始，使得它具有足够的“能量”逃离可能“路过”的局部最优解而不至于限制在其中，当它停在全局最优解附近的时候，逐渐地减小跳跃量，以便得到全局最优解。</li>
<li>遗传算法：模拟物竞天择地生物进化过程，通过维护一个潜在解的群体执行多方向的搜索，并支持这些方向上的信息构成和交换。是以面为单位的搜索，比以点为单位的搜索，更能发现全局最优解。</li>
</ol>
<h3 id="遗传算法实现过程"><a href="#遗传算法实现过程" class="headerlink" title="遗传算法实现过程"></a>遗传算法实现过程</h3><p>首先寻找一种对问题的潜在解进行“数字化”编码的方案。然后用随机数初始化一个种群（建立表现型和基因型的映射关系 ），种群里面的个体即是这些数字化的编码。</p>
<p>接下来，通过适当的解码过程之后，用适应度函数对每一个基因个体做一次适应度评价。</p>
<p>用选择函数按照某种规定择优选择。</p>
<p>让个体基因变异，然后产生子代。</p>
<p>遗传算法并不保证能获得问题的最优解，但是使用遗传算法的最大优点在于不必去了解和操心如何去“找”最优解，而只要简单的“否定”一些表现不好的个体就行。</p>
<p><strong>一般步骤：</strong></p>
<p>开始循环直至找到满意的解：</p>
<ol>
<li>评估每条染色体所对应的个体的适应度。</li>
<li>遵照适应度越高，选择概率越大的原则，从种群中选择两个个体作为父方和母方。</li>
<li>抽取父母双方的染色体，进行交叉，产生子代。</li>
<li>对子代的染色体进行变异。</li>
<li>重复2，3，4步骤，直至新种群的产生。</li>
</ol>
<blockquote>
<ol>
<li>生成候选方案的初始群体。生成初始群体最简单的办法就是随机生成大量“个体”（个体基因）。</li>
<li>计算当前群体中各个个体的适应度。</li>
<li>选择一定数量适应度最高的个体作为下一代的父母。</li>
<li>将选出的父母进行配对。用父母进行重组产生出后代，伴有一定的随机突变概率，后代加入形成新一代群体。选出的父母不断产生后代，直到新的群体数量达到上限（即与初始群体数量一样）。新的群体成为当前群体。</li>
<li>转到第2步。</li>
</ol>
</blockquote>
<p>结束循环。</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/43.jpg" title="算法流程图">
<p><strong>基因编码方式：</strong></p>
<p>假设只有“0”和“1”两种碱基，用一条链条把它们有序地串连在一起，因为每一个单位都能表现出1 bit的信息量，所以一条足够长的染色体就能勾勒出一个个体的所有的特征。即==二进制编码法==</p>
<p>当个体特征较为复杂时，需要大量的编码才能精确地描述 ，相应的解码过程（相当于生物学中的DNA翻译过程，把基因型映射到表现型的过程。）将过于复杂，为改善遗传算法的计算复杂性、提高运算效率，提出了==浮点数编码==，还有一种编码方式是==符号编码==。</p>
<p>编码的目的是建立表现型到基因型的映射关系，而表现型一般就被理解为个体的特征。</p>
<p><strong>适应度函数(fitness function)：</strong></p>
<p>自然界生物竞争过程往往包括两个方面：生物间相互搏斗以及生物与客观环境的搏斗过程。需要指定一个衡量标准（比如选择袋鼠所在的海拔高度作为它们的适应度评分，适应度函数直接返回函数值。）</p>
<p><strong>选择函数(selection):</strong></p>
<p>越适应的个体就越可能繁衍后代（概率上来说）。包括轮盘赌(Roulette Wheel Selection)选择法，精英选择机制。</p>
<p><strong>遗传变异</strong></p>
<p>是子代区别于父代的根本原因。包括基因重组(recombination)(交叉(crossover))与基因突变(mutation)。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>基因编码、基因适应度评估、基因选择、基因变异。</p>
<p><strong>编码原则：</strong></p>
<p>完备性（completeness)：问题空间的所有解都能表示为所设计的基因型。</p>
<p>健全性(soundness)：任何一个基因型都对应于一个可能的解。</p>
<p>非冗余性(non-redundancy)：问题空间和表达空间一一对应。</p>
<p><strong>适应度函数重要性：</strong></p>
<p>适应度函数的选取直接影响遗传算法的收敛速度以及能否找到最优解，一般而言，适应度函数是由目标函数变换而得的。</p>
<p>适应度函数设计不当可能会出现欺骗问题：</p>
<ul>
<li>进化初期，个别超常个体控制选择过程；</li>
<li>进化末期，个体差异太小导致陷入局部极值。</li>
</ul>
<p><strong>选择作用：</strong>优胜劣汰，适者生存。</p>
<p><strong>交叉作用：</strong>保证种群的稳定性，朝着最优解的方向进化。</p>
<p><strong>进化作用：</strong>保证种群的多样性，避免交叉可能产生的局部收敛。</p>
<h2 id="差分进化算法"><a href="#差分进化算法" class="headerlink" title="差分进化算法"></a>差分进化算法</h2><h3 id="概念-3"><a href="#概念-3" class="headerlink" title="概念"></a>概念</h3><p>差分进化算法(Differential Evolution,DE)是一种基于群体差异的<strong>启发式随机搜索算法</strong>，通过群体内个体之间的相互合作与竞争产生的群体智能来指导优化搜索的方向。</p>
<p>相比于进化算法，DE保留了基于种群的全局搜索策略，采用实数编码、基于差分的简单变异操作和一对一的竞争生存策略，降低了遗传操作的复杂性。同时，DE特有的记忆能力使得其可以动态跟踪当前的搜索情况，以调整其搜索策略，具有较强的全局收敛能力和鲁棒性，且不需要借助问题的特征信息，适用于求解一些利用常规的数学规划方法无法求解的复杂环境中的优化问题。</p>
<p>该算法的<strong>基本思想</strong>是：从一个随机产生的初始种群开始，通过把种群中任意两个个体的向量差与第三个个体求和来产生新个体，该操作称为变异。然后变异产生的新个体与当代种群中相应的个体相比较，进行参数混合，生成试验个体，这一过程称为交叉。如果试验个体的适应度优于当前个体的适应度，则在下一代中就用试验个体取代旧个体，否则保存旧个体，这一过程称为选择。通过不断地进化，保留优良个体，淘汰劣质个体，引导搜索向最优解逼近。</p>
<h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>一般演化算法的过程：</p>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/40.png" title="演化算法流程">
<p>标准DE流程：</p>
<ol>
<li><p>初始化种群</p>
<p>$x_{i,j}(0) = x_{ij}^L +rand_{ij}(0,1)(x_{ij}^U - x_{ij}^L),i=1,2,\dots,M;j=1,2,\dots,n$</p>
<p>其中$x_{ij}^L$是$x$下限，$x_{ij}^U$是$x$上限，$rand$表示随机规则。</p>
</li>
<li><p>变异</p>
<p>从群体中随机选择3个染色体$x_{p1},x_{p2},x_{p3}$且$(i \ne p_1 \ne p_2 \ne p_3)$，则：</p>
<p>$v_{ij}(t+1) = x_{p_{1j}}(t) +\eta(x_{p_{2j}}(t) -x_{p_{3j}}(t))$</p>
<p>其中$v_{ij}(t+1)$表示变异后的个体，第$t+1$代。$\eta$表示随机化规则。</p>
</li>
<li><p>交叉</p>
<p>交叉操作是为了增加群体的多样性，具体操作如下：</p>
<p>$u_{ij}(t+1) = \cases{v_{ij}(t+1) ,rand_{ij} \le CR 或j = rand(i)  \ x_{ij}(t) ,rand_{ij} &gt; CR 且j \ne rand(i)}$</p>
<p>其中$u_{ij}(t+1)$是试验个体，$v_{ij}(t+1)$是变异个体，$x_{ij}(t)$是目标个体（第t代）,$CR$是交叉概率，$rand_{ij}$是在[0,1]之间的随机小数，$CR$为交叉概率，$CR \in [0,1]$，$rand(i) \in [1,n]$之间的随机整数，这种交叉策略可确保$x_i(t+1)$至少有一分量由$x_i(t)$的相应分量贡献。</p>
</li>
<li><p>选择</p>
<p>为了确定$x_i(t)$是否成为下一代的成员，比较向量$u_i(t+1)$和目标向量$x_i(t)$的评价函数：</p>
<p>$x_i(t+1) = \cases{u_i(t+1),f(u_i(t+1))\le f(x_i(t))  ,i=1,2,\dots,M\ x_i(t)，otherwise}$</p>
</li>
</ol>
<img src="/blog/2019/06/18/机器学习课程笔记_科大/39.png" title="标准DE算法流程图">
<img src="/blog/2019/06/18/机器学习课程笔记_科大/41.png" title="DE算法">
<p>DE主要涉及群体规模popsize、缩放因子F以及交叉概率cr三个参数的设定。</p>
<p>popsize：一般介于5×n与10×n之间，不能烧鱼，否则无法进行变异操作。</p>
<p>F：决定了偏差向量的放大倍数。过小可能导致局部早熟，一般在[0,2]之间选择。</p>
<p>cr：控制着一个实验个体参数来自于随机选择的变异个体而不是原来个体的概率，cr越大该发生交叉的概率越大。</p>
<h3 id="DE应用实例"><a href="#DE应用实例" class="headerlink" title="DE应用实例"></a>DE应用实例</h3><p>利用差分进化算法求函数$Z=3\times cos(xy) +x+y$，其中$x \in [-4,4],y\in[-4,4]$。</p>
<p><strong>step1:</strong></p>
<p>计算目标函数值</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">z</span> = <span class="title">obj_function</span><span class="params">(pop)</span></span></span><br><span class="line"><span class="comment">%计算目标函数值</span></span><br><span class="line"><span class="comment">% pop input 种群</span></span><br><span class="line"><span class="comment">% z   output 目标函数值</span></span><br><span class="line"></span><br><span class="line">z = <span class="number">3</span> * <span class="built_in">cos</span>(pop(:,<span class="number">1</span>).*pop(:,<span class="number">2</span>)) +pop(:,<span class="number">1</span>) +pop(:,<span class="number">2</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><strong>step2:</strong></p>
<p>初始化种群，目标函数有两个参数，生成每个个体有两个基因的种群。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">unction pop = init(popsize,chromlength,xl,xu)</span><br><span class="line"><span class="comment">%生成初始种群</span></span><br><span class="line"><span class="comment">% popsize   input  种群规模</span></span><br><span class="line"><span class="comment">% chromlength  input 染色体长度</span></span><br><span class="line"><span class="comment">% xl  input x下限</span></span><br><span class="line"><span class="comment">% xu  input x上限</span></span><br><span class="line"><span class="comment">% pop  output 种群</span></span><br><span class="line">pop = <span class="built_in">rand</span>(popsize,chromlength) * (xu-xl) +xl;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><strong>step3:</strong></p>
<p>变异操作</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">mutationpop</span> = <span class="title">mutation</span><span class="params">(pop,F)</span></span></span><br><span class="line"><span class="comment">%变异函数</span></span><br><span class="line"><span class="comment">% pop   input  种群</span></span><br><span class="line"><span class="comment">% F     input   缩放因子</span></span><br><span class="line"><span class="comment">% mutationpop   output 变异后种群</span></span><br><span class="line">[popsize,chromlength] = <span class="built_in">size</span>(pop);</span><br><span class="line">mutationpop = <span class="built_in">zeros</span>(popsize,chromlength);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:popsize</span><br><span class="line">    r = randperm(popsize);</span><br><span class="line">    index = <span class="built_in">find</span>(r ~= <span class="built_in">i</span>);</span><br><span class="line">    rn = r(index(<span class="number">1</span>:<span class="number">3</span>));</span><br><span class="line">    r0 = rn(<span class="number">1</span>);r1 = rn(<span class="number">2</span>);r2 = rn(<span class="number">3</span>);</span><br><span class="line">    mutationpop(<span class="built_in">i</span>,:) = pop(r0,:) +F .* (pop(r1,:) - pop(r2,:));</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><strong>step4:</strong></p>
<p>交叉操作</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">crossoverpop</span> = <span class="title">crossover</span><span class="params">(pop,mpop,cr)</span></span></span><br><span class="line"><span class="comment">% 交叉</span></span><br><span class="line"><span class="comment">% pop  input  种群</span></span><br><span class="line"><span class="comment">% mpop input  变异后的种群</span></span><br><span class="line"><span class="comment">% cr   input  交叉概率</span></span><br><span class="line"><span class="comment">% crossoverpop output 交叉后的种群</span></span><br><span class="line">[popsize,chromlength] = <span class="built_in">size</span>(pop);</span><br><span class="line">crossoverpop = mpop;</span><br><span class="line">r = <span class="built_in">rand</span>(popsize,chromlength);</span><br><span class="line">index =  <span class="built_in">find</span>(r &gt; cr);</span><br><span class="line">crossoverpop(index) = pop(index);</span><br><span class="line">jrand = randi(chromlength,<span class="number">1</span>,popsize);</span><br><span class="line">crossoverpop(<span class="built_in">sub2ind</span>(<span class="built_in">size</span>(crossoverpop),[<span class="number">1</span>:popsize],jrand))=mpop(<span class="built_in">sub2ind</span>(<span class="built_in">size</span>(mpop),[<span class="number">1</span>:popsize],jrand));</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>交叉操作后约束边界</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">newpop</span> = <span class="title">constrictboundary</span><span class="params">(pop,xl,xu)</span></span></span><br><span class="line"><span class="comment">%约束边界（边界吸收）</span></span><br><span class="line"><span class="comment">% pop   input 种群</span></span><br><span class="line"><span class="comment">% xl    input 自变量最小值（包含）</span></span><br><span class="line"><span class="comment">% xu    input 自变量最大值（包含）</span></span><br><span class="line"><span class="comment">%newpop output 约束边界后的种群</span></span><br><span class="line">newpop = pop ;</span><br><span class="line">newpop(newpop &lt; xl) = xl;</span><br><span class="line">newpop(newpop &gt; xu) = xu;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><strong>step5:</strong></p>
<p>选择操作来寻找最优值</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">newpop</span> = <span class="title">selection</span><span class="params">(pop,npop)</span></span></span><br><span class="line"><span class="comment">%选择（最小值优化）</span></span><br><span class="line"><span class="comment">% pop      input  种群1（原始种群）</span></span><br><span class="line"><span class="comment">% npop     input  种群2（变异-交叉后的种群）</span></span><br><span class="line"><span class="comment">% newpop   output 选择后的种群</span></span><br><span class="line">newpop = pop;</span><br><span class="line">index = <span class="built_in">find</span>(obj_function(npop) &lt;= obj_function(pop));</span><br><span class="line">newpop(index,:) = pop(index,:);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p><strong>实验结果</strong></p>
<p>输出结果为：</p>
<p>bestX = -1.772014</p>
<p>bestY = 1.945060</p>
<p>bestZ = -2.688422</p>
<h2 id="进化规划-EP"><a href="#进化规划-EP" class="headerlink" title="进化规划(EP)"></a>进化规划(EP)</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>一个全局最小化问题可以用一对$(S,f)$来形式化，其中$S\in R^n$为有限集。</p>
<p>$f: S \rightarrow R$是一个$n$维实函数。</p>
<p>问题为寻找一个点$x_{min} \in S$，使得$f(x_{min})$是$S$上的全局最小，即：</p>
<p>$\forall x \in S:f(x_{min}) &lt; f(x)$</p>
<p>$f$不一定是连续的，但一定是有限的。</p>
<h3 id="经典EP"><a href="#经典EP" class="headerlink" title="经典EP"></a>经典EP</h3><p>Back Schwefd提出的经典进化规划算法：</p>
<ol>
<li><p>产生$\mu$个个体，并设$k=1$，每个个体都是一个实向量对$(x_i,\eta_i)$，$\forall i \in \{1,2,\dots,\mu \}$，其中$x_i$为目标变量，$\eta_i$为高斯变量的标准差。</p>
</li>
<li><p>对每一个个体$(x_i,\eta_i)$，$\forall i \in \{1,2,\dots,\mu \}$，度量其适应值，即$f(x_i)$。</p>
</li>
<li><p>每一个父代$(x_i,\eta_i),i=1,2,\dots,\mu$，由如下方法产生单个后代$(x_i’,\eta_i’)$：</p>
<p>变异 ：$\cases {x_i’(j) = x_i(j) + \eta_i(j) \times N_j(0,1) \ \eta_i’(j) = \eta_i(j) \exp (\tau’ N(0,1) + \tau N_j(0,1))}$。</p>
<p>其中$j$表示向量的第$j$个分量，$N(0,1)$表示一维<strong>高斯随机数</strong>；$\tau ‘= \left(\sqrt{2\sqrt{n}}\right)^{-1}$，$\tau = \left(\sqrt{2n}\right)^{-1}$</p>
</li>
<li><p>计算每个子代$(x_i’,\eta_i’)$的适应值。</p>
</li>
<li><p>选择。对于每个个体，在所有的父代和子代中，随机选择$g$个对手比较适应度大小，如果该个体的适应度不差于对手，则得分一次。</p>
</li>
<li><p>在$(x_i,\eta_i)$和$(x_i’,\eta_i’)$总集合中选择$\mu$个得分最多的个体进入下一代。</p>
</li>
<li><p>若满足算法停止准则，则停止；否则，$k=k+1$，转入3。</p>
</li>
</ol>
<h3 id="方法改进"><a href="#方法改进" class="headerlink" title="方法改进"></a>方法改进</h3><p>1999年，Yao引入了<strong>柯西随机数</strong>，即：</p>
<p>$f_t(x) = \frac{1}{\pi} ·\frac{t}{t^2 +x^2}$，$-\infty &lt;x &lt; \infty$。</p>
<p>变异：$x_i’(j) = x_i(j) + \eta_i(j) \times \delta_j$。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/blog/tags/机器学习/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2019/05/25/搭建FTP服务器教程/" rel="next" title="搭建FTP服务器教程">
                <i class="fa fa-chevron-left"></i> 搭建FTP服务器教程
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2020/01/11/回归问题简介/" rel="prev" title="回归问题简介">
                回归问题简介 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        
    <!--MOB SHARE BEGIN-->
                                <div class="-mob-share-ui-button -mob-share-open">分享</div>
                                <div class="-mob-share-ui -mob-share-ui-theme -mob-share-ui-theme-slide-left" style="display: none">
                                    <ul class="-mob-share-list">
                                        <li class="-mob-share-weibo"><p>新浪微博</p></li>
                                       
                                        <li class="-mob-share-qzone"><p>QQ空间</p></li>
                                        <li class="-mob-share-qq"><p>QQ好友</p></li>
                                        <li class="-mob-share-weixin"><p>微信</p></li>
                                        <li class="-mob-share-douban"><p>豆瓣</p></li>
                                   
                                        <li class="-mob-share-facebook"><p>Facebook</p></li>
                                        <li class="-mob-share-twitter"><p>Twitter</p></li>
                                       
                                    </ul>
                                    <div class="-mob-share-close">取消</div>
                                </div>
                                <div class="-mob-share-ui-bg"></div>
                                <script id="-mob-share" src="http://f1.webshare.mob.com/code/mob-share.js?appkey=2aeca9171540c"></script>
                                <!--MOB SHARE END-->


      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/blog/images/avatar.png" alt="jiangxj">
            
              <p class="site-author-name" itemprop="name">jiangxj</p>
              <p class="site-description motion-element" itemprop="description">岁月对坐，落子无悔</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/blog/archives/">
              
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/blog/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/blog/tags/index.html">
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/blog/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jiangxjun" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jiangxj0530@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.linkedin.com/in/xuejun-j-8b04a0180/" target="_blank" title="LinkedIn">
                      
                        <i class="fa fa-fw fa-linkedin"></i>LinkedIn</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/wan-si-qing-qian/activities" target="_blank" title="Zhihu">
                      
                        <i class="fa fa-fw fa-heart-o"></i>Zhihu</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                link
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.biglong.top/" title="yanglong" target="_blank">yanglong</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://redstonewill.com/" title="RedStone" target="_blank">RedStone</a>
                  </li>
                
              </ul>
            </div>
          
		  
          <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="360" height="86" src="//music.163.com/outchain/player?type=2&id=419877515&auto=0&height=66"></iframe>
		  

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习的几种定义"><span class="nav-number">1.</span> <span class="nav-text">机器学习的几种定义</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习中的数学基础"><span class="nav-number">2.</span> <span class="nav-text">机器学习中的数学基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#梯度下降法"><span class="nav-number">2.1.</span> <span class="nav-text">梯度下降法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#链式法则"><span class="nav-number">2.2.</span> <span class="nav-text">链式法则</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#常用距离度量方法"><span class="nav-number">2.3.</span> <span class="nav-text">常用距离度量方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#欧式距离（Euclidean-distance）"><span class="nav-number">2.3.1.</span> <span class="nav-text">欧式距离（Euclidean distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#标准化欧式距离（standardized-Euclidean-distance）"><span class="nav-number">2.3.2.</span> <span class="nav-text">标准化欧式距离（standardized Euclidean distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#曼哈顿距离（Manhattan-distance）"><span class="nav-number">2.3.3.</span> <span class="nav-text">曼哈顿距离（Manhattan distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#切比雪夫距离（chebyshev-distance）"><span class="nav-number">2.3.4.</span> <span class="nav-text">切比雪夫距离（chebyshev distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#闵科夫斯基距离（minkowski-distance）"><span class="nav-number">2.3.5.</span> <span class="nav-text">闵科夫斯基距离（minkowski distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#马氏距离（mahalanobis-distance）"><span class="nav-number">2.3.6.</span> <span class="nav-text">马氏距离（mahalanobis distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#余弦距离（cosine-distance"><span class="nav-number">2.3.7.</span> <span class="nav-text">余弦距离（cosine distance)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#汉明距离（hamming-distance）"><span class="nav-number">2.3.8.</span> <span class="nav-text">汉明距离（hamming distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#杰卡德距离（Jaccard-distance）"><span class="nav-number">2.3.9.</span> <span class="nav-text">杰卡德距离（Jaccard distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关距离（correlation-distance）"><span class="nav-number">2.3.10.</span> <span class="nav-text">相关距离（correlation distance）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信息熵（Information-Entropy）"><span class="nav-number">2.3.11.</span> <span class="nav-text">信息熵（Information Entropy）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#聚类算法"><span class="nav-number">3.</span> <span class="nav-text">聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#概念"><span class="nav-number">3.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#距离度量"><span class="nav-number">3.2.</span> <span class="nav-text">距离度量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#性能度量"><span class="nav-number">3.3.</span> <span class="nav-text">性能度量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#外部指标"><span class="nav-number">3.3.1.</span> <span class="nav-text">外部指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内部指标"><span class="nav-number">3.3.2.</span> <span class="nav-text">内部指标</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#原型聚类"><span class="nav-number">3.4.</span> <span class="nav-text">原型聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#K-means"><span class="nav-number">3.4.1.</span> <span class="nav-text">K-means</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习向量量化-LVQ"><span class="nav-number">3.4.2.</span> <span class="nav-text">学习向量量化(LVQ)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#高斯混合聚类"><span class="nav-number">3.4.3.</span> <span class="nav-text">高斯混合聚类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#密度聚类"><span class="nav-number">3.5.</span> <span class="nav-text">密度聚类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#层次聚类"><span class="nav-number">3.6.</span> <span class="nav-text">层次聚类</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#贝叶斯决策理论"><span class="nav-number">4.</span> <span class="nav-text">贝叶斯决策理论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#最小错误率bayes决策规则"><span class="nav-number">4.1.</span> <span class="nav-text">最小错误率bayes决策规则</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#平均错误率"><span class="nav-number">4.1.1.</span> <span class="nav-text">平均错误率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多类决策过程"><span class="nav-number">4.1.2.</span> <span class="nav-text">多类决策过程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最小风险的贝叶斯决策"><span class="nav-number">4.2.</span> <span class="nav-text">最小风险的贝叶斯决策</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#条件期望损失"><span class="nav-number">4.2.1.</span> <span class="nav-text">条件期望损失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#期望风险"><span class="nav-number">4.2.2.</span> <span class="nav-text">期望风险</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#决策规则"><span class="nav-number">4.2.3.</span> <span class="nav-text">决策规则</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最小错误率和最小风险Bayes决策关系"><span class="nav-number">4.3.</span> <span class="nav-text">最小错误率和最小风险Bayes决策关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Neyman-Pearson准则"><span class="nav-number">4.4.</span> <span class="nav-text">Neyman-Pearson准则</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#高维情况分析"><span class="nav-number">4.4.1.</span> <span class="nav-text">高维情况分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Neyman-Pearson决策规则与最小错误率Bayes决策规则对比"><span class="nav-number">4.5.</span> <span class="nav-text">Neyman-Pearson决策规则与最小错误率Bayes决策规则对比</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最小最大决策"><span class="nav-number">4.6.</span> <span class="nav-text">最小最大决策</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#序贯分类方法"><span class="nav-number">4.7.</span> <span class="nav-text">序贯分类方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分类器的设计"><span class="nav-number">4.8.</span> <span class="nav-text">分类器的设计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#多类情况"><span class="nav-number">4.8.1.</span> <span class="nav-text">多类情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#两类情况"><span class="nav-number">4.8.2.</span> <span class="nav-text">两类情况</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正态分布的统计决策（参数估计决策）"><span class="nav-number">4.9.</span> <span class="nav-text">正态分布的统计决策（参数估计决策）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概率密度函数的定义和性质"><span class="nav-number">4.9.1.</span> <span class="nav-text">概率密度函数的定义和性质</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多元正态-概率模型下的最小错误率贝叶斯判别函数和决策面"><span class="nav-number">4.9.2.</span> <span class="nav-text">多元正态 概率模型下的最小错误率贝叶斯判别函数和决策面</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#概率密度函数的估计"><span class="nav-number">5.</span> <span class="nav-text">概率密度函数的估计</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#参数估计"><span class="nav-number">5.1.</span> <span class="nav-text">参数估计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#最大似然估计（maximum-likehood-estimation-MLE）"><span class="nav-number">5.1.1.</span> <span class="nav-text">最大似然估计（maximum likehood estimation,MLE）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#贝叶斯估计"><span class="nav-number">5.1.2.</span> <span class="nav-text">贝叶斯估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#回顾贝叶斯决策："><span class="nav-number">5.1.2.1.</span> <span class="nav-text">回顾贝叶斯决策：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#贝叶斯估计概念"><span class="nav-number">5.1.2.2.</span> <span class="nav-text">贝叶斯估计概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#求解贝叶斯估计量"><span class="nav-number">5.1.2.3.</span> <span class="nav-text">求解贝叶斯估计量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#贝叶斯学习"><span class="nav-number">5.1.3.</span> <span class="nav-text">贝叶斯学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最大似然估计-amp-贝叶斯估计-amp-贝叶斯学习关系"><span class="nav-number">5.1.4.</span> <span class="nav-text">最大似然估计&amp;贝叶斯估计&amp;贝叶斯学习关系</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#非参数估计"><span class="nav-number">5.2.</span> <span class="nav-text">非参数估计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概念-1"><span class="nav-number">5.2.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#估计方法"><span class="nav-number">5.2.2.</span> <span class="nav-text">估计方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#parzen窗法"><span class="nav-number">5.2.3.</span> <span class="nav-text">parzen窗法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#概念-2"><span class="nav-number">5.2.3.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#估计量-hat-p-n-pmb-x-为密度函数的条件"><span class="nav-number">5.2.3.2.</span> <span class="nav-text">估计量$\hat{p}_n(\pmb x)$为密度函数的条件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#窗函数选择"><span class="nav-number">5.2.3.3.</span> <span class="nav-text">窗函数选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#窗宽-h-n-对估计量-hat-p-n-pmb-x-的影响"><span class="nav-number">5.2.3.4.</span> <span class="nav-text">窗宽$h_n$对估计量$\hat{p}_n(\pmb x)$的影响</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-近邻估计"><span class="nav-number">5.2.4.</span> <span class="nav-text">K-近邻估计</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#提出背景"><span class="nav-number">5.2.4.1.</span> <span class="nav-text">提出背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基本思想"><span class="nav-number">5.2.4.2.</span> <span class="nav-text">基本思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最邻近规则"><span class="nav-number">5.2.4.3.</span> <span class="nav-text">最邻近规则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最邻近法的错误率分析"><span class="nav-number">5.2.4.4.</span> <span class="nav-text">最邻近法的错误率分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#k-近邻规则​（KNN）"><span class="nav-number">5.2.4.5.</span> <span class="nav-text">$k$-近邻规则​（KNN）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#近邻法存在缺点"><span class="nav-number">5.2.5.</span> <span class="nav-text">近邻法存在缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#近邻法改进算法"><span class="nav-number">5.2.6.</span> <span class="nav-text">近邻法改进算法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性判别函数"><span class="nav-number">6.</span> <span class="nav-text">线性判别函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#背景"><span class="nav-number">6.1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本概念"><span class="nav-number">6.2.</span> <span class="nav-text">基本概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#广义线性判别函数"><span class="nav-number">6.3.</span> <span class="nav-text">广义线性判别函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#设计线性分类器的主要步骤"><span class="nav-number">6.4.</span> <span class="nav-text">设计线性分类器的主要步骤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fisher​线性判别"><span class="nav-number">6.5.</span> <span class="nav-text">Fisher​线性判别</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Fisher的基本思想和问题"><span class="nav-number">6.5.1.</span> <span class="nav-text">Fisher的基本思想和问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基本参量"><span class="nav-number">6.5.2.</span> <span class="nav-text">基本参量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fisher准则函数"><span class="nav-number">6.5.3.</span> <span class="nav-text">Fisher准则函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最小平方误差（LMSE）准则函数和H-K算法"><span class="nav-number">6.6.</span> <span class="nav-text">最小平方误差（LMSE）准则函数和H-K算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MSE准则函数"><span class="nav-number">6.6.1.</span> <span class="nav-text">MSE准则函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#H-K算法步骤"><span class="nav-number">6.6.2.</span> <span class="nav-text">H-K算法步骤</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征选择与提取"><span class="nav-number">7.</span> <span class="nav-text">特征选择与提取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本概念-1"><span class="nav-number">7.1.</span> <span class="nav-text">基本概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#类别可分离性判据"><span class="nav-number">7.2.</span> <span class="nav-text">类别可分离性判据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于距离的可分性判据"><span class="nav-number">7.3.</span> <span class="nav-text">基于距离的可分性判据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#类内距离"><span class="nav-number">7.3.1.</span> <span class="nav-text">类内距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#类间距离"><span class="nav-number">7.3.2.</span> <span class="nav-text">类间距离</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于散布矩阵的可分性判据"><span class="nav-number">7.4.</span> <span class="nav-text">基于散布矩阵的可分性判据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于概率分布的可分性判据"><span class="nav-number">7.5.</span> <span class="nav-text">基于概率分布的可分性判据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#常用的概率距离度量"><span class="nav-number">7.5.1.</span> <span class="nav-text">常用的概率距离度量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Bhattacharyya距离和Chernoff界限"><span class="nav-number">7.5.1.1.</span> <span class="nav-text">Bhattacharyya距离和Chernoff界限</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#散度"><span class="nav-number">7.5.1.2.</span> <span class="nav-text">散度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#正太分布时类别的可分性判据表达式"><span class="nav-number">7.5.1.3.</span> <span class="nav-text">正太分布时类别的可分性判据表达式</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于熵函数的可分性判据"><span class="nav-number">7.6.</span> <span class="nav-text">基于熵函数的可分性判据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征提取"><span class="nav-number">7.7.</span> <span class="nav-text">特征提取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#主成分分析-PCA"><span class="nav-number">7.7.1.</span> <span class="nav-text">主成分分析(PCA)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核主成分分析KPCA介绍"><span class="nav-number">7.7.2.</span> <span class="nav-text">核主成分分析KPCA介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PCA算法总结"><span class="nav-number">7.7.3.</span> <span class="nav-text">PCA算法总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-L变换"><span class="nav-number">7.7.4.</span> <span class="nav-text">K-L变换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-L变换与PCA联系与区别"><span class="nav-number">7.7.5.</span> <span class="nav-text">K-L变换与PCA联系与区别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征选择"><span class="nav-number">7.8.</span> <span class="nav-text">特征选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#分支定界法"><span class="nav-number">7.8.1.</span> <span class="nav-text">分支定界法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#次优搜索算法"><span class="nav-number">7.8.2.</span> <span class="nav-text">次优搜索算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#顺序前进法"><span class="nav-number">7.8.2.1.</span> <span class="nav-text">顺序前进法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#顺序后退法"><span class="nav-number">7.8.2.2.</span> <span class="nav-text">顺序后退法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#广义顺序前进（后退）法"><span class="nav-number">7.8.2.3.</span> <span class="nav-text">广义顺序前进（后退）法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#增l-删r法（l-r法）"><span class="nav-number">7.8.2.4.</span> <span class="nav-text">增l-删r法（l-r法）</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#神经网络"><span class="nav-number">8.</span> <span class="nav-text">神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#神经元模型"><span class="nav-number">8.1.</span> <span class="nav-text">神经元模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#感知器"><span class="nav-number">8.2.</span> <span class="nav-text">感知器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多层网络"><span class="nav-number">8.3.</span> <span class="nav-text">多层网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BP神经网络算法"><span class="nav-number">8.4.</span> <span class="nav-text">BP神经网络算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本思想-1"><span class="nav-number">8.4.1.</span> <span class="nav-text">基本思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基本流程"><span class="nav-number">8.4.2.</span> <span class="nav-text">基本流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关说明"><span class="nav-number">8.4.3.</span> <span class="nav-text">相关说明</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#全局最小与局部最小"><span class="nav-number">8.5.</span> <span class="nav-text">全局最小与局部最小</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他常见神经网络"><span class="nav-number">8.6.</span> <span class="nav-text">其他常见神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RBF网络"><span class="nav-number">8.6.1.</span> <span class="nav-text">RBF网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RBF函数网络补充"><span class="nav-number">8.6.2.</span> <span class="nav-text">RBF函数网络补充</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ART网络"><span class="nav-number">8.6.3.</span> <span class="nav-text">ART网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SOM网络"><span class="nav-number">8.6.4.</span> <span class="nav-text">SOM网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#级联相关网络"><span class="nav-number">8.6.5.</span> <span class="nav-text">级联相关网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Elman网络"><span class="nav-number">8.6.6.</span> <span class="nav-text">Elman网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Boltzmann机"><span class="nav-number">8.6.7.</span> <span class="nav-text">Boltzmann机</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习"><span class="nav-number">8.7.</span> <span class="nav-text">深度学习</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机"><span class="nav-number">9.</span> <span class="nav-text">支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#支持向量机基础"><span class="nav-number">9.1.</span> <span class="nav-text">支持向量机基础</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#分类标准的起源：logistic回归"><span class="nav-number">9.1.1.</span> <span class="nav-text">分类标准的起源：logistic回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性分类一个例子"><span class="nav-number">9.1.2.</span> <span class="nav-text">线性分类一个例子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#函数间隔与几何间隔"><span class="nav-number">9.1.3.</span> <span class="nav-text">函数间隔与几何间隔</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最大间隔分类器定义"><span class="nav-number">9.1.4.</span> <span class="nav-text">最大间隔分类器定义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#支持向量机深入"><span class="nav-number">9.2.</span> <span class="nav-text">支持向量机深入</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#从线性可分到线性不可分"><span class="nav-number">9.2.1.</span> <span class="nav-text">从线性可分到线性不可分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-K-T条件"><span class="nav-number">9.2.2.</span> <span class="nav-text">K.K.T条件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对偶问题求解"><span class="nav-number">9.2.3.</span> <span class="nav-text">对偶问题求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性不可分"><span class="nav-number">9.2.4.</span> <span class="nav-text">线性不可分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核函数"><span class="nav-number">9.2.5.</span> <span class="nav-text">核函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#特征空间的隐式映射"><span class="nav-number">9.2.5.1.</span> <span class="nav-text">特征空间的隐式映射</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#核函数：如何处理非线性数据"><span class="nav-number">9.2.5.2.</span> <span class="nav-text">核函数：如何处理非线性数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#几个核函数"><span class="nav-number">9.2.5.3.</span> <span class="nav-text">几个核函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#核函数本质"><span class="nav-number">9.2.5.4.</span> <span class="nav-text">核函数本质</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用松弛变量处理outliers方法"><span class="nav-number">9.2.6.</span> <span class="nav-text">使用松弛变量处理outliers方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SMO算法"><span class="nav-number">9.2.7.</span> <span class="nav-text">SMO算法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#优化搜索"><span class="nav-number">10.</span> <span class="nav-text">优化搜索</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#贪心算法"><span class="nav-number">10.1.</span> <span class="nav-text">贪心算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#旅行商问题"><span class="nav-number">10.2.</span> <span class="nav-text">旅行商问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模拟退火算法"><span class="nav-number">10.3.</span> <span class="nav-text">模拟退火算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简介"><span class="nav-number">10.3.1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关概念"><span class="nav-number">10.3.2.</span> <span class="nav-text">相关概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法原理"><span class="nav-number">10.3.3.</span> <span class="nav-text">算法原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法步骤"><span class="nav-number">10.3.4.</span> <span class="nav-text">算法步骤</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#进化计算"><span class="nav-number">11.</span> <span class="nav-text">进化计算</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#进化计算概述"><span class="nav-number">11.1.</span> <span class="nav-text">进化计算概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一般进化算法"><span class="nav-number">11.2.</span> <span class="nav-text">一般进化算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#遗传算法"><span class="nav-number">11.3.</span> <span class="nav-text">遗传算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#遗传算法概念"><span class="nav-number">11.3.1.</span> <span class="nav-text">遗传算法概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#遗传算法的应用"><span class="nav-number">11.3.2.</span> <span class="nav-text">遗传算法的应用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#遗传算法实现过程"><span class="nav-number">11.3.3.</span> <span class="nav-text">遗传算法实现过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#小结"><span class="nav-number">11.3.4.</span> <span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#差分进化算法"><span class="nav-number">11.4.</span> <span class="nav-text">差分进化算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概念-3"><span class="nav-number">11.4.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法流程"><span class="nav-number">11.4.2.</span> <span class="nav-text">算法流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DE应用实例"><span class="nav-number">11.4.3.</span> <span class="nav-text">DE应用实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#进化规划-EP"><span class="nav-number">11.5.</span> <span class="nav-text">进化规划(EP)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述"><span class="nav-number">11.5.1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#经典EP"><span class="nav-number">11.5.2.</span> <span class="nav-text">经典EP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#方法改进"><span class="nav-number">11.5.3.</span> <span class="nav-text">方法改进</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jiangxj</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">211.8k</span>
  
</div>








<script src="https://cdn.jsdelivr.net/npm/meting@1.1.0/dist/Meting.min.js"></script>
        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/blog/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/blog/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/blog/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/blog/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/blog/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/blog/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/blog/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/blog/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/blog/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/blog/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


  

  

</body>
</html>
