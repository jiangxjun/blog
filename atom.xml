<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ataraxia</title>
  
  <subtitle>Hi, I&#39;m Jiang.</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://jiangxj.top/blog/"/>
  <updated>2021-06-29T02:48:43.994Z</updated>
  <id>https://jiangxj.top/blog/</id>
  
  <author>
    <name>jiangxj</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2021北京智源大会</title>
    <link href="https://jiangxj.top/blog/2021/06/28/2021%E5%8C%97%E4%BA%AC%E6%99%BA%E6%BA%90%E5%A4%A7%E4%BC%9A/"/>
    <id>https://jiangxj.top/blog/2021/06/28/2021北京智源大会/</id>
    <published>2021-06-28T14:13:53.000Z</published>
    <updated>2021-06-29T02:48:43.994Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="一、科研技能提升讲座：如何撰写高质量科技论文"><a href="#一、科研技能提升讲座：如何撰写高质量科技论文" class="headerlink" title="一、科研技能提升讲座：如何撰写高质量科技论文"></a>一、科研技能提升讲座：如何撰写高质量科技论文</h2><p>刘洋教授做的报告</p><p><a href="/blog/download/Practical Black-Box Attacks against Machine Learning.pdf">机器翻译学术论文写作方法和技巧</a></p>]]></content>
    
    <summary type="html">
    
      北京智源大会一些报告内容的整理
    
    </summary>
    
      <category term="会议报告" scheme="https://jiangxj.top/blog/categories/%E4%BC%9A%E8%AE%AE%E6%8A%A5%E5%91%8A/"/>
    
    
      <category term="学术会议" scheme="https://jiangxj.top/blog/tags/%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>算法基础（一）——算法时间复杂度理解</title>
    <link href="https://jiangxj.top/blog/2021/06/02/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://jiangxj.top/blog/2021/06/02/算法基础（一）/</id>
    <published>2021-06-01T16:00:00.000Z</published>
    <updated>2021-06-10T08:51:36.842Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>算法是独立存在的一种解决问题的方法和思路，是计算机处理信息的本质，通过一个算法来告诉计算机确切的步骤来执行一个指定的任务。</p><p><strong>程序=数据结构+算法</strong></p><p>算法是为解决实际问题设计；数据结构是算法需要处理问题的载体，是指数据对象中数据元素之间的关系。</p><p>以Python为例，内置的数据结构（如：list，tuple，dictionary）是不用我们自己定义的；需要我们自己去定义实现这些数据的组织方式，这些称为Python的扩展数据结构，如栈、队列。</p><h2 id="算法特性"><a href="#算法特性" class="headerlink" title="算法特性"></a>算法特性</h2><p>输入：0个或多个输入</p><p>输出：至少1个或多个输出</p><p>有穷性：在有限步骤之后会自动结束而不会无限循环，并且每一个步骤可以在可接受时间内完成</p><p>确定性：算法的每一个步骤有确定的含义，不会出现二义性</p><p>可行性：算法每一步都是可行的，即每一步都能够执行有限的次数完成</p><h2 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h2><p><strong>程序的执行时间=基本的运算总数*基本的运算单位时间</strong></p><p>基本运行单位时间：与运行的计算机环境有关</p><p>基本的运算总数是衡量程序执行时间标准</p><p>算法时间复杂度可以理解为算法的运行时间，如果算法运行时间太长，这个算法就无法使用。</p><p><strong>时间复杂度</strong>：考虑的是基本运算总数，即假设存在函数$g$，使得算法$A$处理规模为$n$的问题所用的时间$T(n) = g(n)=O(g(n))$，则$O(g(n))$为算法$A$的渐进时间复杂度，简称为时间复杂度，记为$T(n)$。</p><p>$g(n)$表示每行代码执行次数之和，$O$表示正比例关系。</p><p><strong>时间复杂度计算规则</strong></p><p>1、基本操作。只有常数项，时间复杂度为$O(1)$</p><p>2、顺序结构。时间复杂度按加法进行计算</p><p>3、循环结构。时间复杂度按乘法进行计算</p><p>4、分支结构。时间复杂度取最大值</p><p>5、判断算法的效率，往往只需要关注操作数量的最高次项</p><p>6、无特殊说明下，分析算法的时间复杂度都是指最坏时间复杂度</p><p>常见的时间复杂度量级有：</p><ul><li>常数阶O(1)</li><li>对数阶$O(\log N)$</li><li>线性阶O(n)</li><li>线性对数阶O(nlogN)</li><li>平方阶O(n²)</li><li>立方阶O(n³)</li><li>K次方阶O(n^k)</li><li>指数阶(2^n)</li></ul><p>$$<br>O(1)\lt O(\log n)\lt O(n) \lt O(n\log n) \lt O(n^2) \lt O(n^3) \lt O(2^n) \lt O(n!) \lt O(n^n)<br>$$</p><div style="width:70%;margin:auto"><img src="/blog/2021/06/02/算法基础（一）/复杂度大小比较.jpg" title="复杂度大小对比"></div><div style="width:70%;margin:auto"><img src="/blog/2021/06/02/算法基础（一）/算法复杂度量级.jpg" title="算法复杂度量级"></div><p>举例如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> j = <span class="number">2</span>;</span><br><span class="line">++i;</span><br><span class="line">j++;</span><br><span class="line"><span class="keyword">int</span> m = i + j;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">在执行的时候，它消耗的时候并不随着某个变量的增长而增长，那么无论这类代码有多长，即使有几万几十万行，都可以用O(1)来表示它的时间复杂度</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;=n;++i)  <span class="comment">// 1(n?)</span></span><br><span class="line">&#123;</span><br><span class="line">    j=i;           <span class="comment">// n</span></span><br><span class="line">    j++;           <span class="comment">// n</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>假设每行代码执行时间一样，都是1颗粒时间，上述代码：$T(n) = (1+2n)$</p><p>算法的耗时是随着$n$的变化而变化，算法的时间复杂度可表示为：$T(n)=O(n)$</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span>(i&lt;n)</span><br><span class="line">&#123;</span><br><span class="line">    i = i * <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">假设循环x次之后，i 就大于 2 了，此时这个循环就退出了，也就是说 2 的 x 次方等于 n，那么 x = log2(n),也就是说当循环 log2(n) 次以后，这个代码就结束了,代码的时间复杂度为：O(logn)</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(m=<span class="number">1</span>; m&lt;n; m++)</span><br><span class="line">&#123;</span><br><span class="line">    i = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;n)</span><br><span class="line">    &#123;</span><br><span class="line">        i = i * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">将时间复杂度为O(logn)的代码循环N遍的话，那么它的时间复杂度就是 n * O(logN)，也就是了O(nlogN)。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(x=<span class="number">1</span>; x&lt;=n; x++)</span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">for</span>(i=<span class="number">1</span>; i&lt;=n; i++)</span><br><span class="line">    &#123;</span><br><span class="line">       j = i;</span><br><span class="line">       j++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">嵌套了2层n循环，它的时间复杂度就是 O(n*n)，即 O(n²)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(x=<span class="number">1</span>; x&lt;=m; x++)</span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">for</span>(i=<span class="number">1</span>; i&lt;=n; i++)</span><br><span class="line">    &#123;</span><br><span class="line">       j = i;</span><br><span class="line">       j++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">时间复杂度就变成了 O(m*n)</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">O(n³)相当于三层n循环</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h2 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h2><p>定义为该算法消耗的存储空间，也是问题规模为$n$的函数，如今的设备完全可以忽略空间复杂度的影响。</p><p><a href="https://zhuanlan.zhihu.com/p/50479555" target="_blank" rel="noopener">算法时间与空间复杂度</a></p><p><a href="https://blog.csdn.net/qq_37812673/article/details/102802440" target="_blank" rel="noopener">算法复杂度理解</a></p>]]></content>
    
    <summary type="html">
    
      对算法时间复杂度的理解
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="时间复杂度" scheme="https://jiangxj.top/blog/tags/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/"/>
    
      <category term="算法基础" scheme="https://jiangxj.top/blog/tags/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>核能科学与技术导论</title>
    <link href="https://jiangxj.top/blog/2021/03/31/%E6%A0%B8%E8%83%BD%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AF%BC%E8%AE%BA/"/>
    <id>https://jiangxj.top/blog/2021/03/31/核能科学与技术导论/</id>
    <published>2021-03-31T07:54:01.000Z</published>
    <updated>2021-03-31T08:06:12.401Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>参考资料:</p><p>①《资源革命：如何抓住一百年来最大的商机》（美）斯蒂芬·赫克（Stefen Heck）等</p></blockquote><h1 id="1、序言"><a href="#1、序言" class="headerlink" title="1、序言"></a>1、序言</h1><h2 id="1-1-能量与能源"><a href="#1-1-能量与能源" class="headerlink" title="1.1 能量与能源"></a>1.1 能量与能源</h2><h2 id="1-2-能源与人类社会"><a href="#1-2-能源与人类社会" class="headerlink" title="1.2 能源与人类社会"></a>1.2 能源与人类社会</h2><h2 id="1-3-什么是核能"><a href="#1-3-什么是核能" class="headerlink" title="1.3 什么是核能"></a>1.3 什么是核能</h2><h1 id="2、核能物理基础"><a href="#2、核能物理基础" class="headerlink" title="2、核能物理基础"></a>2、核能物理基础</h1><h2 id="2-1-原子核性质基础"><a href="#2-1-原子核性质基础" class="headerlink" title="2.1 原子核性质基础"></a>2.1 原子核性质基础</h2><h2 id="2-2-核能物理基础"><a href="#2-2-核能物理基础" class="headerlink" title="2.2 核能物理基础"></a>2.2 核能物理基础</h2>]]></content>
    
    <summary type="html">
    
      核能科学与技术导论
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="核能" scheme="https://jiangxj.top/blog/tags/%E6%A0%B8%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>（一）人工智能与专家系统概述</title>
    <link href="https://jiangxj.top/blog/2021/03/24/%EF%BC%88%E4%B8%80%EF%BC%89%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"/>
    <id>https://jiangxj.top/blog/2021/03/24/（一）人工智能与专家系统概述/</id>
    <published>2021-03-23T16:00:00.000Z</published>
    <updated>2021-03-24T03:51:35.321Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>参考资料：</p><p>①《人工智能及其应用》（第五版）蔡自兴等著</p><p>②《人工智能——一种现代的方法》（第三版）Stuart J·Russell &amp; Peter Norvig著</p><p>③《高级专家系统——原理、设计及应用》（第二版）蔡自兴 [美]约翰·德尔金 龚涛著</p><p>④《专家系统——原理与编程》（第四版）[美]Joseph C·Giarratano &amp; Gary D·Riley著</p><p>分为两大部分，第一部分包括逻辑、概率、数据结构、人工智能概念和其他形式的专家系统理论的内容；第二部分介绍CLIPS专家系统工具。</p></blockquote><h1 id="对AI的概述"><a href="#对AI的概述" class="headerlink" title="对AI的概述"></a>对AI的概述</h1><p>人工智能（artificial intelligence，AI）是最新兴的科学与工程领域之一，自1956年创造了“人工智能”一词算起，经过60十多年的发展，AI目前包含了大量各种各样的子领域，范围从通用领域，如学习和感知，到专门领域，如下棋，证明数学定理，诊断疾病，自动驾驶等。成为了一门广泛的交叉和前沿科学。</p><blockquote><p>没有一种人工智能技术能成功解决所有问题，一些组合的方法会更有效一些。</p></blockquote><p>人工智能尚无一个统一定义，人类的许多活动，如解题、讨论、编制计划、编程、驾驶等，都需要“智能”。如果机器能执行这样的任务，可以认为机器已具有某种性质的“人工智能”，它所包含的“智能”是人为制造的或由机器或计算机表现出来的一种智能（区别于自然智能）。</p><p><strong>智能（intelligence）</strong>：人的智能是人类理解和学习事物的能力，智能是思考和理解的能力而不是本能的做事的能力。</p><p>另一种定义：智能是一种应用知识处理环境的能力或由目标准则衡量的抽象思考能力。</p><p><strong>智能机器（intelligent machine）</strong>：一种能够呈现出人类智能行为的机器，而这种智能行为是人类用大脑考虑问题或创造思想。</p><p>另一种定义：智能机器是一种能够在不确定环境中执行各种拟人任务（anthropomorphic tasks）达到预取目标的机器。</p><p><strong>人工智能（学科）</strong>；人工智能（学科）是计算机科学中涉及研究、设计和应用智能机器的一个分支，近期目标是在于研究用机器来模仿和执行人脑的某些智力功能，并开发相关理论和技术。（<em>是计算机科学还是智能科学？？？有待探讨和实践</em>）</p><p><strong>人工智能（能力）</strong>：智能机器所执行的通常与人类智能有关的智能行为，这些智能行为涉及学习、思考、感知、理解、识别、判断、推理、证明、通信、设计、规划和问题求解等活动。</p><h2 id="人工智能的定义"><a href="#人工智能的定义" class="headerlink" title="人工智能的定义"></a>人工智能的定义</h2><p>人工智能一个最早的定义之一：“<strong>使计算机像人类一样思考</strong>”。该定义来源于“图灵测试（1950）”。</p><p>“<strong>图灵测试（Turing test）</strong>”：一个人试图判断和其通过键盘交谈的对象是人类还是计算机程序，如果计算机能在交谈过程中顺利回答问题而不被发现其是计算机，则说明计算机已经具有<strong>强人工智能</strong>（strong AI）。</p><p><strong>强人工智能</strong>：基于严格逻辑基础。</p><p><strong>弱人工智能</strong>：基于ANN、遗传算法、进化方法等。</p><blockquote><p>定义1. 人工智能是一种使计算机能够思维，使机器具有智力的激动人心的尝试，字面意思：有头脑的机器（Haugeland 1985）</p><p>定义2. 与人类思维相关的活动，诸如决策、问题求解、学习等活动的自动化（Bellman 1978）</p><p><strong>“像人一样思考”——认知建模的途径</strong></p><hr><p>定义3. 创造执行一些功能的技艺，当由人来执行这些功能时需要智能（Kurzweil 1990）</p><p>定义4. 研究如何使计算机做那些目前人比计算机更擅长的事情（Rich &amp; Knight 1991）</p><p><strong>“像人一样行动”——图灵测试的途径</strong></p><hr><p>定义5. 通过使用计算机模型来研究智力（Charniak &amp; McDermott 1985）</p><p>定义6. 使感知、推理和行动成为可能的计算的研究（Winston 1992）</p><p><strong>“合理的思考”——思维法则的途径</strong></p><hr><p>定义7. 计算智能研究智能Agent的设计（Poole等 1998）</p><p>定义8. AI…关心人工制品的智能行为（Nilsson 1998）</p><p><strong>“合理的行动”——合理Agent的途径</strong></p><p>Agent就是能够行动的某种东西，计算机程序在做某些事情，但期望计算机Agent做更多的事：自主的操作、感知环境、长期持续、适应变化并能创建与追求目标。合理的Agent就是为了实现最佳效果。</p><hr></blockquote><p>计算机尚需具有一下功能：</p><ul><li>自然语言处理（natural language processing）使之能成功的交流</li><li>知识表示（knowledge representation）以存储它知道的或听到的信息</li><li>自动推理（automated reasoning）运用存储的信息来回答问题并推出新结论</li><li>机器学习（machine learning）适应新情况并检测和预测模式</li><li>计算机视觉（computer vision）感知物体</li><li>机器人学（robotics）操纵和移动对象。</li></ul><h2 id="人工智能起源与发展"><a href="#人工智能起源与发展" class="headerlink" title="人工智能起源与发展"></a>人工智能起源与发展</h2><p><strong>1、孕育时期（1956前）</strong></p><p>人工智能开拓者们在数理逻辑、计算本质、控制论、信息论、自动化理论、神经网络模型和电子计算机方面的创造性贡献，奠定了AI发展的理论基础。</p><p><strong>2、形成时期（1956-1970年）</strong></p><p>1956年，达特茅斯会议，提出“人工智能”这一术语；</p><p>巴贝奇、图灵、冯·诺伊曼等研制的计算机本身，在机器应用成为可行之后，编程解决智力问题、数学定理和其他命题的自动证明；</p><p>1965年，“专家系统和知识工程之父”的费根鲍曼（Feigenbaum）开始研制专家系统；</p><p>1968年，第一个专家系统DENDRAL用于分析有机化合物分子结构；</p><p>1969年，召开了第一届国际人工智能联合会议（IJCAI）</p><p><strong>3、暗淡时期（1966-1974年）</strong></p><p>主要是存在以下三个局限性：</p><p>①知识局限性。缺乏足够的专业知识和常识</p><p>②解法局限性。设计的程序实际上无法得到问题的解答，或者得到简单问题的解答。</p><p>③结构局限性。用于产生智能行为的人工智能系统或程序存在一些基本结构上的严重局限。</p><p><strong>4、知识应用时期（1970-1988年）</strong></p><p>一些专家系统的出现，如DENDRAL、MYCIN、PROSPECTOR、CASNET、MACSYMA、ELAS等。费根鲍姆于1977年第五届国际人工智能联合会议上，正式提出了知识工程（knowledge engineering）。</p><p>在开发专家系统过程中，也认识到：<strong>人工智能系统是一个知识处理系统，而知识表示、知识利用和知识获取是AI的三个基本问题</strong>。</p><p><strong>5、集成发展时期（1986年至今）</strong></p><p>已有的专家系统存在缺乏常识知识，应用领域狭窄、知识获取困难、推理机制单一、未能分布处理等问题。人工智能和知识工程的一些根本问题，如交互问题、扩展问题和体系问题等，都没有得到很好解决。</p><p>1980年后期以来，机器学习、计算智能、人工神经网络和行为主义等研究深入。区别于符号主义的连接主义和行为主义的人工智能学派获得新的发展。</p><blockquote><p><strong>人工智能三大学派：</strong></p><p>（1）符号主义（symbolicism）：也称为逻辑主义（logicism）、心理学派（psycologism）或计算机学派（computerism），其原理主要为物理符号系统假设和有限合理性原理。认为认知的过程是符号操作过程，认为人是一个物理符号系统。认为AI的研究方法是功能模拟方法。</p><p>（2）连接主义（connectionism）：也称为仿生学派（bionicsism）或生理学派（physiologism），其原理主要是神经网络及神经网络间的连接机制和学习算法。认为人的思维基元是神经元。认为AI应着重于结构模拟。</p><p>（3）行为主义（actionism）：也称为进化主义（evolutionism）或控制论学派（cyberneticsism），其原理为控制论及感知-动作型控制系统。认为智能取决于感知和行动。认为AI应采用行为模拟方法。</p></blockquote><p>传统人工智能（AI）：以数理逻辑为基础的符号主义，从命题逻辑到谓词逻辑再到多值逻辑，包括模糊逻辑，粗糙集理论，为AI发展做出历史性贡献，符号主义也在发展中不断寻找新的理论、方法和实现途径。</p><p><strong>计算智能（computational intelligence, CI）</strong>：模仿人的思维、自然特征和生物行为的计算方法（如神经计算、进化计算、自然计算、免疫计算、群计算等）已被引入人工智能学科。CI弥补了传统AI的数学理论和计算的不足，更新并丰富了人工智能的理论框架。</p><p><strong>神经网络发展突起：</strong></p><ul><li>1943年，麦卡洛克和皮茨提出“似脑机器”，构造一个表示大脑基本组成的神经元模型，由于硬件的局限性，使得ANN在20世纪70年代进入低潮。</li><li>1982年，Hopfield提出离散神经网络模型，1984年，又提出连续神经网络模型，促进了ANN研究的复兴。</li><li>Bryson和He提出的反向传播（BP）算法及Rumelhart和McClelland在1986年提出的并行分布处理（PDP）理论使得ANN复兴的真正推动力</li><li>1987年召开的第一届神经网络国际会议，并成立国际神经网络学会（INNS），ANN正式成为AI的一个重要子学科。</li><li>深度学习（deep learning）的研究，并在计算机视觉，自然语言处理和人机博弈等领域较为广泛应用。</li><li>超限学习（extreme leaning）是在深度学习的基础上发展而来，推动机器学习的发展。</li></ul><h2 id="人类智能和人工智能"><a href="#人类智能和人工智能" class="headerlink" title="人类智能和人工智能"></a>人类智能和人工智能</h2><p>人的认知过程是一个复杂行为，人的心理活动具有不同的层次，可与计算机的层次相比较：</p><table><thead><tr><th>人类</th><th>计算机</th></tr></thead><tbody><tr><td>生理过程</td><td>计算机硬件</td></tr><tr><td>初级信息处理</td><td>计算机语言</td></tr><tr><td>思维策略</td><td>计算机程序</td></tr></tbody></table><p><strong>研究认知的主要任务</strong>：探求高层次思维决策与初级信息处理的关系，并用计算机程序来模拟人的思维策略水平，用计算机语言模拟人的初级信息处理过程。</p><p><strong>智能计算机系统</strong>：以人的思维方式为模型进行智能信息处理。</p><p><strong>研究认知的目标</strong>：设计适用于特定领域的高水平智能信息处理系统。如一个具有智能信息处理能力的自动控制系统就是一个智能控制系统，可以是专家系统，或者是智能决策系统等。</p><p>人可以看成一个<strong>智能信息处理系统（也称符号操作系统）</strong>。符号就是模式（pattern）。一个完善的符号系统包括：</p><p>（1）输入符号（input）</p><p>（2）输出符号（output）</p><p>（3）存储符号（store）</p><p>（4）复制符号（copy）</p><p>（5）建立符号结构：通过找到各种符号之间的关系，在符号系统中形成符号结构。</p><p>（6）条件下迁移（conditional transfer）：根据已有的符号，继续完成活动过程。</p><p><strong>任何一个系统能表现出智能，必定能够执行上述6个功能。反之，任何系统如果具有这6种功能，能够表现出智能（人所具有的智能）</strong>。</p><blockquote><p><strong>认知生理学</strong>：研究认知行为的生理过程，主要是研究神经系统（神经元，中枢神经系统和大脑）的活动，是认知科学的研究底层。</p><p><strong>认知心理学</strong>：研究认知行为在人体内的初级信息处理，主要研究人的认知行为如何通过初级信息自然处理，由生理活动变为心理活动及其逆过程（心理变为生理行为），是认知活动的中间层，承上启下。</p><p><strong>认知工程学</strong>：研究认知行为的信息加工处理，主要是研究如何通过计算机为核心的人工信息处理系统，对人的各种认知行为（如知觉，思维，记忆，语言，学习、理解、推理、识别等）进行信息处理。是研究认知活动的工具。</p></blockquote><p><strong>机器智能的研究发展</strong></p><p>智能计算机：</p><p>计算机技术日新月异，包括自学习、并行处理、启发式搜索、机器学习、智能决策等AI技术已用于博弈程序设计，使得“计算机棋手”水平大为提高。如1997年，IBM公司的深蓝（deep blue）智能计算机，2016年谷歌的alphaGo。</p><p>神经计算机（neural computer）：</p><p>能够以类似人的方式进行“思考”，力图重建人脑的形象。日本MITI报道，对神经计算机系统的可行性研究早于1989年4月底完成。神经网络热已然持续30多年。</p><p>量子计算机，光子计算机等基础研究也取得突破。</p><h2 id="人工智能系统的分类"><a href="#人工智能系统的分类" class="headerlink" title="人工智能系统的分类"></a>人工智能系统的分类</h2><table><thead><tr><th>系统</th><th>说明</th></tr></thead><tbody><tr><td>专家系统（expert system）</td><td>把专家系统技术和方法，尤其是工程控制论的反馈机制有机结合而建立，广泛应用于故障诊断、工业设计和过程控制。一般由知识库、推理、控制规则集和算法等组成。专家系统所研究一般是不确定性问题。</td></tr><tr><td>模糊系统</td><td>提出了一种新机制用于实现基于知识（规则）甚至语义描述的表示、推理和操作规律。模糊系统为非线性系统提出一种比较容易的设计方法，尤其是当系统包含不确定性且很难用常规非线性理论处理时。</td></tr><tr><td>神经网络系统</td><td>主要涉及模式识别、图像处理、自动控制、机器人、信号处理、医疗、军事、商业管理等领域</td></tr><tr><td>学习系统</td><td>机器学习的研究，尤其是一些新的学习方法为学习系统注入新活力</td></tr><tr><td>仿生系统</td><td>模仿与模拟人类和生物行为的智能系统。生物通过个体间的选择、交叉、变异来适应环境，把进化算法，尤其是遗传算法机制用于人工系统和过程，可实现仿生智能系统（bionic intelligent systems）</td></tr><tr><td>群智能系统</td><td>某种交互作用的组合或Agent的结构集合</td></tr><tr><td>多真体系统（Multiple Agent system）</td><td>并行计算和分布式处理技术（包括分布式AI）的发展，多真体系统应运而生。真体（Agent）可以看成是通过传感器感知环境，并借助执行器作用于该环境的任何事物。</td></tr><tr><td>混合智能系统</td><td>单一智能机制往往不能满足一些复杂、未知或动态系统的要求，需要开发混合（集成的、综合的、复合的）智能技术和方法</td></tr></tbody></table><p>按应用领域分：智能机器人系统、智能决策系统、智能加工系统、智能控制系统、智能规划系统、智能交通系统、智能管理系统、智能家电系统等。</p><h2 id="人工智能研究基本内容"><a href="#人工智能研究基本内容" class="headerlink" title="人工智能研究基本内容"></a>人工智能研究基本内容</h2><table><thead><tr><th>分类</th><th>说明</th></tr></thead><tbody><tr><td>认知建模</td><td>Houston等把认知归纳为5种类型：（1）信息处理；（2）心理上的符号运算；（3）问题求解；（4）思维；（5）诸如知觉、记忆、思考、判断、推理、想象、学习、问题求解、概念形成和语言使用等关联活动</td></tr><tr><td>知识表示（Knowledge representation，KB）</td><td>把人类知识概念化、形式化和模型化。一般地，运用符号知识、算法和状态图等来描述待解决问题。已提出的知识表示方法主要包括：符号表示、神经网络表示。</td></tr><tr><td>知识推理</td><td>让机器从一些已知判断或前提推导出一个新的判断或结论的思维过程。形式逻辑中的推理分为：演绎推理、归纳推理和类比推理。</td></tr><tr><td>知识应用</td><td>专家系统，以及现在的机器学习和自然语言处理应用研究，自动规划，智能控制等</td></tr><tr><td>机器感知</td><td>使机器具有类似于人的感觉，如视、听、力、触、嗅、痛觉，接近感和速度感。主要在计算机视觉和机器听觉上的应用有较多进展</td></tr><tr><td>机器思维</td><td>对传感信息和机器内部的工作信息进行有目的的处理，综合应用知识表示、知识推理、认知建模（启发式搜索和控制策略）和机器感知（人脑结构和神经网络的工作机制）等方面研究</td></tr><tr><td>机器学习</td><td>继专家系统后AI一个重要研究领域，是AI和神经计算的核心研究之一。使机器（计算机）具有学习新知识新技术，并能在实践中不断改进和完善的能力。</td></tr><tr><td>机器行为</td><td>智能系统（计算机、机器人）具有表达和行为能力。机器思维是机器行为的基础。</td></tr><tr><td>智能系统构建</td><td>一些能简化演绎、机器人操作和认知模型的专用程序设计以及计算机的分布式系统、并行处理、多机协同和计算机网络等的发展，有益于AI的开发。</td></tr></tbody></table><h2 id="人工智能研究和计算方法"><a href="#人工智能研究和计算方法" class="headerlink" title="人工智能研究和计算方法"></a>人工智能研究和计算方法</h2><table><thead><tr><th>研究方法</th><th>计算方法</th></tr></thead><tbody><tr><td>功能模拟法（符号主义）</td><td>概率计算</td></tr><tr><td>结构模拟法（连接主义）</td><td>符号规则逻辑运算</td></tr><tr><td>行为模拟法（行为主义）</td><td>模糊计算</td></tr><tr><td>集成模拟法（取长补短）</td><td>神经计算</td></tr><tr><td></td><td>进化计算与免疫计算</td></tr><tr><td></td><td>群优化计算，蚁群算法</td></tr></tbody></table><h2 id="人工智能研究和应用领域"><a href="#人工智能研究和应用领域" class="headerlink" title="人工智能研究和应用领域"></a>人工智能研究和应用领域</h2><table><thead><tr><th>分类</th><th>说明</th></tr></thead><tbody><tr><td>问题求解与博弈</td><td>目前AI程序能够搜索解答空间，寻找较优解答</td></tr><tr><td>逻辑推理和定理证明</td><td></td></tr><tr><td>计算智能</td><td>涉及神经计算、模糊计算、进化计算、粒子群计算、自然计算、免疫计算和人工生命等领域</td></tr><tr><td>分布式人工智能（DAI）与Agent</td><td>DAI系统以鲁棒性为控制系统质量的标准，并具有互操作性，即不同的异构系统在快速变化的环境中具有交换信息和协同工作的能力。目标是创建一种能够描述自然系统和社会系统的精确概念模型</td></tr><tr><td>自动程序设计</td><td>能够以各种不同的目的的描述来编写计算机程序</td></tr><tr><td>专家系统</td><td>一个智能计算机程序系统，内部具有大量专家水平的某个领域知识和经验，能够利用人类专家的知识和解决问题的方法来解决该领域的问题</td></tr><tr><td>机器学习</td><td>自动获取新的事实及新的推理算法，使计算机具有智能的根本途径。近年也发展了基于解释的学习、基于实例的学习、基于概念的学习、基于神经网络的学习、遗传学习、增强学习、深度学习、超限学习、迁移学习以及数据挖掘和知识发现等</td></tr><tr><td>自然语言理解</td><td></td></tr><tr><td>机器人学</td><td>具有广泛的学科交叉</td></tr><tr><td>模式识别</td><td>利用计算机代替人类或帮助人感知模式，是对人类感知外界功能的模拟，研究的是计算机模式识别模拟，使得计算机系统具有模拟人类通过感官接受外界信息、识别和理解周围环境的感知能力</td></tr><tr><td>机器视觉/计算机视觉</td><td></td></tr><tr><td>神经网络</td><td></td></tr><tr><td>智能控制</td><td>同时具有以知识表示的非数学广义世界模型和以数学公式模型表示的混合控制过程，任务在于实际环境或过程进行组织（决策和规划），以实现广义问题求解</td></tr><tr><td>智能调度和指挥</td><td>一个典型是旅行商问题（TSP）</td></tr><tr><td>智能检索</td><td></td></tr><tr><td>系统与语言工具</td></tr></tbody></table><h2 id="最新的发展水平"><a href="#最新的发展水平" class="headerlink" title="最新的发展水平"></a>最新的发展水平</h2><p>待补充</p><h1 id="专家系统概述"><a href="#专家系统概述" class="headerlink" title="专家系统概述"></a>专家系统概述</h1><p>20世界60年代开始，专家系统作为一种研究工具而被开发，作为AI的一个特定部分，可以成功解决某些领域的复杂问题（包括：医疗、商业、科学、工程、制造和其它很多具有<strong>良定义问题</strong>的领域）</p><blockquote><p>良定义：基本含义是人类专家可以确定解决一个问题的推理步骤，那么专家系统也可以做到。</p></blockquote><p>专家系统在AI技术领域有很多非常成熟的应用，如遗传算法、ANN等和专家系统结合。</p><p><strong>智能系统</strong>（intelligent system）：使用了人工智能的系统。</p><p><strong>领域</strong>（domain）：规划的要解决问题的范围。是解决任何问题的第一步。</p><p>人工智能和人工生命：从计算机角度来说，生命就如同软件一样，从29世纪90年代开始，可以成功克隆动物，改进生命体，这些是自然界所没有的，是人工生命。但同时这些生物是有智能的，也就具有了人工智能。只是不是通过计算机的形式表现的。</p><p><strong>创造进化系统</strong>（creative evolutionary system）：人工生命的拓展领域，该系统中人工生命系统可以根据进化压力改变自己的程序，如遗传算法。</p><p>智能的一个定义（de Silva）：<strong>学习、获取、适应、修正和扩展知识以便解决问题的能力</strong>。通过机器、工厂、工具和其他硬件建立能和现实世界交互的智能机器。其中的挑战是把现实世界中复杂的人类思维融合到机器中，包括：歧义、含糊、一般、不精确、不确定、模糊、信任、似然等。</p><p>同时具有人工智能和意识的系统：对于人脑工作原理的了解。</p><h2 id="专家系统（expert-system）定义"><a href="#专家系统（expert-system）定义" class="headerlink" title="专家系统（expert system）定义"></a>专家系统（expert system）定义</h2><p>专家系统的开拓者费根鲍姆1982年对专家系统的定义：</p><blockquote><p>Expert system is “ an intelligent computer  program that uses knowledge and inference procedures to solve problems that are different enough to require significant human expertise for their solutions.” That is , an expert system is a computer system tha emulates the decision-making ability of a human expert. The term emulate means that the expert system is intended to act in all respects like a human expert.</p></blockquote><p>专家系统（expert system）：是对传统人工智能问题中智能程序设计一个非常成功的近似解决办法。Stanford的Edward Feigenbaum教授定义为：“<strong>一种智能的计算机程序</strong>，运用知识和推理过程来解决只有专家才能解决的复杂问题。”</p><p>专家系统是一<strong>种模拟专家决策能力的计算机系统</strong>，大量利用专业知识以解决只有专家才能解决的问题，模拟（emulate）比模仿（simulation）更进一步。</p><p>20世纪80年代中期，专家系统一直由基于规则的系统主宰；80年代后期，开始向面向对象的系统转变。</p><p>明斯基提出基于框架（frame）的专家系统，具有更容易表示描述性和行为性对象信息的能力以及一套强有力的表工具，能够处理比基于规则的专家系统更复杂的问题。</p><p>1982年Hopfield提出Hopfield模型神经系统，第一次建立了动态稳定网络中存储信息的原理；BP算法的发展，成为训练神经网络最流行的学习算法，是解决实际数据分类的有效工具。</p><p>1965年扎德提出模糊逻辑，20世纪70年代，曼达尼和阿斯里安建立第一个模糊专家系统，以控制蒸汽机。</p><p>20世纪80年代后期，已有的专家系统存在缺乏常识知识、应用领域狭窄、知识获取困难、推理机制单一、不能分布处理等问题。对存在的这些问题探讨和基本观点的争论，有助于人工智能摆脱困境，迎来新的发展机遇。</p><h2 id="专家系统分类"><a href="#专家系统分类" class="headerlink" title="专家系统分类"></a>专家系统分类</h2><table><thead><tr><th>问题求解类型</th><th>描述</th></tr></thead><tbody><tr><td>控制</td><td>管理系统行为以满足要求</td></tr><tr><td>设计</td><td>按约束配置对象</td></tr><tr><td>诊断</td><td>从观察到的现象推断出系统的故障</td></tr><tr><td>教学</td><td>诊断、调试并修复</td></tr><tr><td>解释</td><td>从数据推断出现状描述</td></tr><tr><td>监视</td><td>把观察的对象与期望进行比较</td></tr><tr><td>规划</td><td>设计行为</td></tr><tr><td>预测</td><td>推断给定的情况下的可能结论</td></tr><tr><td>调试</td><td>推荐系统故障的解决方案</td></tr><tr><td>筛选</td><td>从一组可能性中挑选最好的选择</td></tr><tr><td>仿真</td><td>对系统组件之间的交互进行建模</td></tr><tr><td>决策</td><td>为用户各种请求寻找最佳的实施方案</td></tr></tbody></table><h2 id="专家系统结构与特点"><a href="#专家系统结构与特点" class="headerlink" title="专家系统结构与特点"></a>专家系统结构与特点</h2><p>专家系统技术包括：专门的专家系统语言、程序、辅助专家系统开发和执行而设计的硬件。</p><p>专家系统内部包括两个部分：<strong>知识库（knowledge base）和推理机（inference engine）</strong>。知识库包含有让推理机得出结论而使用的专家知识。这些结论是专家系统对用户询问的响应。</p><p>专家知识是指<strong>特定问题域（problem domain）方面的知识</strong>（与通用问题求解技术方面知识不同），解决特定问题的专家知识称为专家的知识域（knowledge domain）。</p><blockquote><p>知识库：专家系统内包含领域知识的部分</p><p>工作内存：专家系统内包含执行任务时发现的问题事实的部分</p><p>推理机：知识处理器，将工作内存中的事实和知识库的领域知识相匹配，以得出问题的结论。推理机处理工作内存中的事实和知识库中的领域知识，以提取新信息。它搜寻约定在工作内存里信息之间的匹配，当找到匹配时，就把规则的结论加入工作内存中，并继续扫描，寻求新的匹配。</p></blockquote><p>专家系统主要组成部分归纳如下：</p><p><strong>（1）知识库（knowledge base，KB）</strong></p><p>用于存储某领域专家系统的专门知识，包括事实、可行操作与规则等。需要解决知识获取和知识表示问题。</p><blockquote><p>知识获取：知识工程师（knowledge engineer）如何从专家那里获得专门知识的问题</p><p>知识表示：解决如何用计算机能够理解的形式表达和存储知识的问题</p></blockquote><p><strong>（2）综合数据库（global database）</strong></p><p>用于存储领域或问题的初始数据和推理过程中得到的中间数据（信息），即被处理对象的一些当前事实。</p><p><strong>（3）推理机（reasoning machine）</strong></p><p>用于记忆所采用的规则和控制策略的程序，使得整个专家系统能够以逻辑方式协调地工作。推理机能够根据知识进行推理和导出结论。</p><p><strong>（4）解释器（interpreter）</strong></p><p>能够向用户解释专家系统行为，包括解释推理结论的正确性以及系统输出其他候选解的原因</p><p><strong>（5）接口（interface）</strong></p><p>即界面，能够使系统与用户进行对话，使用户能够输入必要的数据、提出问题和了解推理过程及推理结果等。系统可以通过接口，回答用户，进行必要解释。</p><p><strong>专家系统的特点</strong></p><table><thead><tr><th>特点</th><th>描述</th></tr></thead><tbody><tr><td>符号推理</td><td>按符号形式表示知识，运用专家的知识与经验推理、判断和决策</td></tr><tr><td>启发式推理</td><td>擅长提取经验，凭经验形成对问题的实际理解，并把经验运用于启发信息中</td></tr><tr><td>透明性</td><td>能够解释本身的推理过程和回答用户提出的问题，让了解推理过程，提高信赖感</td></tr><tr><td>灵活性</td><td>能不断增、改、更新知识</td></tr><tr><td>知识与控制分离</td><td>把系统知识与其控制分离，知识库和推理机是专家系统独立的模块</td></tr><tr><td>允许非精确推理</td><td>这类应用特征有不确定、模糊或不可行的信息和本来就不精确的领域知识</td></tr><tr><td>擅长复杂推理</td><td></td></tr><tr><td>会犯错误</td></tr></tbody></table><p><strong>专家系统和传统程序的比较</strong></p><table><thead><tr><th>传统程序</th><th>专家系统</th></tr></thead><tbody><tr><td>数字式</td><td>符号表示</td></tr><tr><td>算法式</td><td>启发式</td></tr><tr><td>信息与控制集成</td><td>知识与控制分离</td></tr><tr><td>难于修改</td><td>易于修改</td></tr><tr><td>精确信息</td><td>不确定信息</td></tr><tr><td>指令界面</td><td>带解释自然对话</td></tr><tr><td>给出最终结果</td><td>解释性建议</td></tr><tr><td>最优解</td><td>可接受解</td></tr></tbody></table><p><strong>专家系统特点</strong>：高性能（给出建议的质量要高）、适当的响应时间（时间限制问题）、可靠性（不易崩溃）、可解释性（系统能解释推理步骤，而不是黑盒子）、灵活性（增加、修改、删除知识的高效机制）、列出所有支持和反对某个假设的原因、列出所有可解释观测证据的假设、解释假设的所有推断结果、给出当假设是正确时将发生的一个预测（prognosis）、提供程序需要用户进一步信息的问题的依据、提供程序所用知识正确的依据。</p><p><strong>专家系统的主要优点</strong>：<strong>解释、说明性</strong>，系统稳定，可靠性强。</p><h2 id="专家系统构建步骤"><a href="#专家系统构建步骤" class="headerlink" title="专家系统构建步骤"></a>专家系统构建步骤</h2><p><strong>专家系统的开发一般步骤</strong>：知识工程师通过与专家进行对话获取专家知识（类似于传统程序设计人员与用户讨论需求），然后知识工程师将知识编码到知识库中，随后专家评估系统并返回意见给知识工程师。推理机不停循环工作，直到某种执行终止的判定标准出现。</p><p>（<strong>1）设计初是数据库</strong>。包括</p><ul><li>①问题知识化：辨别所研究问题的实质，如要解决什么问题，如何定义该问题，可否能分解为子问题或子任务，包含哪些典型数据等。</li><li>②知识概念化：概括知识表示所需要的关键概念及其关系，如数据类型、已知条件（状态）和目标（状态）、提出的假设以及控制策略等。</li><li>③概念形式化：确定用来组织知识的数据结构形式，应用AI中各种知识表示方法把关键概念、子问题及信息流特性等转换为比较正式的表达，包括假设空间、过程模型和数据特性等。</li><li>④形式规则化：编制规则，把形式化的知识变换为由编程语言表示的可供计算机执行的语句和程序</li><li>⑤规则合法化：确定规则化的知识的合理性，检验规则的有效性。</li></ul><p><strong>（2）原型机（prototype）的开发与试验</strong></p><p>选定知识表示方法后，着手建立整个系统所需要的实验子集，包括整个模型的典型知识，且只涉及与试验有关的足够简单的任务和推理过程</p><p><strong>（3）知识库的改进和归纳</strong></p><p>反复对知识库及推理规则进行改进试验，归纳出更完善的结果，经过一段时间后，使得系统在一定范围内达到人类专家的水平</p><p>专家系统问题求解通常没有算法求解，而是依靠推理获得一个合理的解决方法。算法是一种理想解决方案，它会在有限时间内给出答案。专家系统依赖于推理，必须能解释这个过程，推理过程是可以检查的。<strong>解释机（explanation facility）</strong>是复杂专家系统的一个必要部分。</p><h2 id="专家系统的局限性"><a href="#专家系统的局限性" class="headerlink" title="专家系统的局限性"></a>专家系统的局限性</h2><p><strong>专家系统一个不足是知识的局限性</strong>：当问题达到未知界限（limits of ignorance）时，专家系统会给建议打上一个折扣。专家系统缺乏因果知识（causal knowledge），它不能真正理解系统中隐含的原因和结果。用<strong>基于经验和启发性的浅（shallow）知识</strong>设计专家系统比用<strong>基于对象的基本结构、功能和行为的深（deep）知识</strong>容易些。</p><blockquote><p><strong>启发性知识（heuristic knowledge）</strong>：一种从实践中获得经验性知识，可以对问题的求解有帮助作用，但不能保证一定有效。启发性知识能够提供有价值的捷径，可以帮助减少时间和花费。</p></blockquote><p><strong>专家系统的另一个不足是知识受限于系统的知识域</strong>：典型的专家系统不能像人类一样，通过<strong>类比（analogy）</strong>来一般化知识以获得求解新的问题的方法。专家系统可以通过规则的归纳，获得少量新知识，但是把人类知识转为专家系统过程中存在一个<strong>知识获取瓶颈（knowledge acquisition bottleneck）</strong>，限制专家系统的创建。</p><h2 id="人在专家系统中的作用"><a href="#人在专家系统中的作用" class="headerlink" title="人在专家系统中的作用"></a>人在专家系统中的作用</h2><p>主要作用：领域专家、知识工程师和终端用户</p><p>（1）领域专家（domain expert）：具有以超越他人的方式求解特定问题的知识和技能的人。是专家系统的知识来源。</p><p>（2）知识工程师：主要职责是获取知识、处理知识，并对知识进行编码</p><p>（3）终端用户（end-user）：应用专家系统进行工作的人员，主要职责包括：规定接口技术规范、辅助知识获取等。</p><h2 id="专家系统语言"><a href="#专家系统语言" class="headerlink" title="专家系统语言"></a>专家系统语言</h2><p>IF-THEN规则：Newell和simon证明的一个重要结果：大部分人类问题求解或认知（cognition）可以用IF-THEN类型的产生式规则（production rule）表达。与一个小的、模块化的知识集相对应的规则称为一<strong>块（chunk）</strong>，块以松散的形式连接、组织，并与相关的知识有联系。人类的记忆是都以块的形式组织。</p><p><strong>现代基于规则的专家系统基础</strong>：Newell和Simon把人类问题求解的模型归纳为：<strong>长期记忆（规则）、短期记忆（工作内存）、认知处理器（推理机）</strong>。</p><p>设计专家系统的过程中，一个重要的因素是<strong>知识的数量和规则的粒度（granularity）</strong>。粒度太小，则在没有其他规则参考的情况下很难理解规则，粒度太大，专家系统很难修改。</p><p>专家系统基本是为符号推理而设计的，虽然一些经典的人工智能语言LISP和PROLOG也可用作符号操作的语言，但它们的应用并不局限于专家系统外壳。很多专家系统是用PROLOG和LISP建造的。PROLOG用于诊断系统有很多优点（内含反向链推理）。使用专门为专家系统建造而设计的外壳和实用程序来建造大型专家系统更为方便，效率高，不必从头做起。</p><p><strong>专家系统语言</strong>：和SQL一样，专家系统语言是一种比LISP或C语言层次更高的语言，但能解决的问题的范围更小一些，使得适合专家系统而不适合一般的编程。甚至有时候需要从专家系统语言中暂时退出以便去执行过程语言的一个函数。（LISP特意设计了这一种转换）</p><blockquote><p><strong>过程语言</strong>：提供一种灵活的、健壮的技术表示数据。如线性表、记录、链表、队列和树的数据结构很容易被创建并熟练操作。现代语言如Java和C#等，通过面向对象、方法和软件包的形式更好的辅助数据抽象。数据和操纵它的方法紧密交织在对象中。</p><p><strong>专家系统语言</strong>：提供灵活、健壮的方法去表示知识。允许有两个抽象层，数据抽象和知识抽象（knowledge abstraction），专家系统语言把数据和操作数据的方法分离。如在一个基于规则的专家系统语言中，事实（数据抽象）和规则（知识抽象）是分离的。</p></blockquote><p>专家系统语言的选择：CLIPS是一种程序规模小，在实时响应要求严格时执行速度快，是入门较好选择。</p><blockquote><p><strong>语言</strong>：按照某种特定语法书写命令的编译器。专家系统会提供一个推理机去执行该语言的语句。推理机会提供正向链、反向链或者两者都提供。</p><p><strong>工具</strong>：语言加上有关的实用程序，以使应用程序的开发、调试、交付更加方便。实用程序可能包括文本图形编译器、调试器、文件管理器、代码生成器等。</p><p><strong>外壳（shell）</strong>：一种专门工具，为某些类型的应用而设计。在这些应用中用户仅仅提供所需的知识库。一个典例是EMYCIN外壳，是通过去除MYCIN专家系统中的医学知识库而建立的。</p></blockquote><h2 id="基于规则的专家系统"><a href="#基于规则的专家系统" class="headerlink" title="基于规则的专家系统"></a>基于规则的专家系统</h2><p><strong>产生式系统</strong></p><p>基于规则的专家系统是以多个规则的方式说明在不同的情况下有什么样的结果，而不是采用静态的断言来表达知识。</p><p>一个基于规则的系统包括：IF…THEN规则、事实、解释器。解释器根据工作记忆中的事实来决定哪条规则被激活。</p><p>基于规则的系统分为：正向链、反向链。</p><blockquote><p>规则的流行原因：</p><p>（1）模块化特征。规则使得知识容易封装并不断扩充</p><p>（2）解释机制。规则容易建立解释机，一个规则的前件指明了激活这个规则的条件，追踪已触发的规则，解释机可以得到某个结论的推理链。</p><p>（3）类似人类认知的过程。IF-THEN便于解释知识的结构。</p></blockquote><p><strong>Post产生式系统</strong></p><p>Post基本思想：任何数学或逻辑系统都只是一组特定规则，用来将一组符号转换为另一组符号。提供一个输入（前件），产生式规则能够产生一个新的输出串（结果）。</p><p>产生式系统字符串的使用是基于语法结构而非语义，不必让产生式系统懂其中含义，人知道在现实世界里这些字符串所代表的含义，但一个产生式系统只需要将一个字符串转换为另一个字符串。</p><p>Post产生式系统根本缺陷：缺乏控制策略（control strategy）来指导规则的应用。</p><p><strong>马尔可夫算法</strong></p><p>Markov给出了一个产生式系统的控制结构。Markov algorithm就是一组按优先级排序的产生式顺序作用于输入串。若最高优先级的规则不适用，则尝试次高优先权的规则，如此类推。</p><p><strong>Rete算法</strong></p><p>Markov算法对具有大量规则的系统来说是低效的。效率问题的解决办法之一是Rete算法（Rete algorithm）。Rete算法通过在网络上存储规则信息来提高反应和规则激发速度。Rete算法是一个动态的数据存储结构，类似标准的B+树，可以自发优化查询。</p><p>Rete算法是一个非常快速的模式匹配器，通过把有关规则的信息在存储器中以网络的形式存放来获取速度。Rete算法通过限制一个规则激发后重新计算冲突集合的耗费来提高正向链规则系统的速度。缺点是需要较多存储空间（现已不存问题）</p><p>推理机在每个识别动作循环中，Rete算法不是用事实去匹配每一个规则，而是仅仅考察哪些有变化的匹配，没有变化的匹配可忽略，大大提高了事实与前件的匹配速度。</p><blockquote><p><strong>快速匹配算法</strong>，如Rete算法等奠定了专家系统走向实际应用的基础。</p></blockquote><p>专家系统可以认为是一个说明性程序设计，程序员不必要详细说明如何完成目标的具体算法。如在一个基于规则的专家系统中，任何一个规则，只要其左部与事实匹配，那就可以被激发并加入到议程中。规则的顺序不影响其激活。</p><p>专家系统经常用于处理不确定性问题，<strong>推理是处理不确定最好的工具之一</strong>。</p><p><strong>使用人工神经网络建立专家系统是可能的</strong>。ANS（artificial neural system）可以作为一个知识库，该知识库通过训练有关案例来构建。</p><blockquote><p>专家系统根据训练得到的疾病症状来分类疾病，推理机也称为MACIE（matrix controlled inference engine，阵列控制推理机）是用ANS知识库设计的，系统用正向链的方式来进行推理，用反向链的方式来询问用户所需要的数据。虽然ANS自身不能解释权值是如何设置的，但是MACIE能解释ANS并生成IF…THEN型规则来解释它的知识。</p></blockquote><h2 id="专家系统知识表示概述"><a href="#专家系统知识表示概述" class="headerlink" title="专家系统知识表示概述"></a>专家系统知识表示概述</h2><p>知识表示（knowledge representation，KR）被看作是人工智能的核心，类似数据库设计，利用数据挖掘技术提取知识。</p><blockquote><p>数据挖掘使用存储在数据仓库（data warehouse）中的档案数据（archival data）来预测未来趋势。</p></blockquote><p>KR在专家系统中重要的原因：一是专家系统是专为某一类基于逻辑规则（推理）的知识表示设计的。二是影响着专家系统的开发、效率、速度和维护，如同程序设计中对数据结构的选择。</p><p>在CLIPS中，KR可以是规则、自定义模板、对象和事实。</p><p>关于知识的分类，其中有两个特别的类别：<strong>先验知识（priori）和后验知识（posteriori）</strong>。</p><p>先验知识不依赖于源于感官所获得的知识，被认为是普遍正确的，没有反例。</p><p>后验知识是由感官所获得的知识，正确与否可以用感觉经验来证明。但感官所得不是一直可信，后验知识可以在新知识的基础上被否定。</p><p><strong>知识表示技术</strong>：包括产生式规则、语义网、框架、脚本、逻辑、概念组等，以及KL-1知识表示语言（包括其模型基础发展CLASSIC），可视化语言等。</p><blockquote><p>产生式规则常被作为知识库用在专家系统中。定义产生式的一种形式方法是Backus-Naur范式（BNF）。这种方法是一种定义语法的元语言（metalanguage），语法（syntax）定义了形式，语义（semantics）指出含义。</p><p>语义网络（semantic network）：用于表示命题信息的一种经典的人工智能表示技术。</p><p>对象-属性-值三元组（OAV，objected-attribute-value  triple）可以用来表示语义网中的所有知识。在MYCIN专家系统使用诊断传染病。</p><p>语义网很容易翻译成<strong>PROLOG语句</strong>。PROLOG是一种带有可执行语句的计算机语言。</p><p><strong>语义网的难点</strong>：①缺乏连接命名标准，难以理解语义网的设计意图以及是否是以一种一致的方法来设计；结点的命名会存在歧义。语义网表示确切知识（definitive knowledge），知识是能够定义的，必须严格定义连接和结点名字。（XML可扩展标记语言和本体论解决这个问题，XML提供一种标准的方法把形式语义编码进任何语言方面。）②搜索结点时的组合爆炸，尤其是查询的回答是否定的时候。对一个产生否定结点的查询，可能要在语义网络中搜索很多或所有的连接。</p><p>语义网络是一种<strong>浅知识结构</strong>（shallow knowledge structure），语义网的所有知识都包含在连接和结点中。</p></blockquote><blockquote><p>模式（schema）：用来描述比语义更复杂的知识结构。是一种<strong>深知识结构</strong>，可表示因果关系，解释一些事情发生的原因。通常模式有关于结点的内在结构信息而语义网没有。</p></blockquote><blockquote><p>框架（frame）：提供一个方便的结构表示在特定环境中的典型对象。特别地，框架适合模拟常识。</p></blockquote><blockquote><p>逻辑（logic）：表示知识。逻辑主要研究规则的精确推理，推理主要是从假设中推出结论。运用计算机进行推理出现了逻辑程序设计（logic programming）和基于逻辑的语言开发，如PROLOG。</p></blockquote><h2 id="专家系统推理方法概述"><a href="#专家系统推理方法概述" class="headerlink" title="专家系统推理方法概述"></a>专家系统推理方法概述</h2><p>专家系统广泛地应用于没有合适的算法或无算法的情况下，特别是在信息不完整或缺乏的情况下，专家系统应该像人类一样能够从一系列的推理中得到结论。</p><p>一个简单的使用算法的计算机程序在缺乏参数的情况下是不能够得到问题的解的。当无法找到最优解的时候，专家系统能能够像人类一样做出最好的猜测。有比没有好的原则。</p><p><strong>专家系统推理策略</strong>：常用的正向链（forward chaining）和反向链（background chaining）。一些特殊需要使用：手段—目的分析、问题简化、回溯、规则-生成-测试、逐级规划和最小满足原则、约束处理。</p><blockquote><p><strong>正向链</strong>：从事实到结论的推理。从已知的初始事实出发，通过使用规则得到新的结论或做出某种行动。以<strong>数据驱动</strong>为主。</p><p><strong>反向链</strong>：从假设（要证明的结论）到事实的推理。从某个假设或要证明的目标出发，不断寻找能使假设成立的规则。过程中可能产生新的子目标便于把大问题分解成更容易证明的小问题。以<strong>目标驱动</strong>。</p><p>OPSS和CLIPS是正向链推理，PROLOG是反向链推理，Eclipse两者都提供。</p><p>推理机的选择取决于问题的类型，诊断问题最好是反向链推理；预测、监视、控制最好使用正向链推理。</p></blockquote>]]></content>
    
    <summary type="html">
    
      初步对AI和专家系统有一个宏观的认识
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>理解Fourier变换</title>
    <link href="https://jiangxj.top/blog/2020/11/10/%E7%90%86%E8%A7%A3Fourier%E5%8F%98%E6%8D%A2/"/>
    <id>https://jiangxj.top/blog/2020/11/10/理解Fourier变换/</id>
    <published>2020-11-10T03:58:49.000Z</published>
    <updated>2020-11-10T04:07:28.644Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
    
    <summary type="html">
    
      傅里叶变换理解
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="信号处理" scheme="https://jiangxj.top/blog/tags/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>计算机科学和人工智能专业课程整理</title>
    <link href="https://jiangxj.top/blog/2020/07/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    <id>https://jiangxj.top/blog/2020/07/15/计算机科学/</id>
    <published>2020-07-14T16:00:00.000Z</published>
    <updated>2020-07-19T07:58:42.489Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="计算机科学"><a href="#计算机科学" class="headerlink" title="计算机科学"></a>计算机科学</h1><p>该部分内容引用来源如下所述：</p><blockquote><p>本文档是对<a href="https://teachyourselfcs.com" target="_blank" rel="noopener">TeachYourselfCS</a>内容的中文翻译，原作者为<a href="https://twitter.com/oznova_" target="_blank" rel="noopener">Ozan Onay</a>和<a href="https://twitter.com/quackingduck" target="_blank" rel="noopener">Myles Byrne</a>。</p><p>This document is a Chinese translation of <a href="https://teachyourselfcs.com" target="_blank" rel="noopener">TeachYourselfCS</a>, which is written by <a href="https://twitter.com/oznova_" target="_blank" rel="noopener">Ozan Onay</a> and <a href="https://twitter.com/quackingduck" target="_blank" rel="noopener">Myles Byrne</a>. For more information about this translation, please refer to <a href="#这份指引是谁翻译的">the end of this document</a>.</p></blockquote><h2 id="课程索引"><a href="#课程索引" class="headerlink" title="课程索引"></a>课程索引</h2><table><thead><tr><th>科目</th><th>为何要学？</th><th>最佳书籍</th><th>最佳视频</th></tr></thead><tbody><tr><td><strong><a href="#编程">编程</a></strong></td><td>不要做一个“永远没彻底搞懂”诸如递归等概念的程序员。</td><td>_<a href="https://book.douban.com/subject/1148282/" target="_blank" rel="noopener">《计算机程序的构造和解释》</a>_</td><td>Brian Harvey’s Berkeley CS 61A</td></tr><tr><td><strong><a href="#计算机架构">计算机架构</a></strong></td><td>如果你对于计算机如何工作没有具体的概念，那么你所做出的所有高级抽象都是空中楼阁。</td><td>_<a href="https://book.douban.com/subject/26912767/" target="_blank" rel="noopener">《深入理解计算机系统》</a>_</td><td>Berkeley CS 61C</td></tr><tr><td><strong><a href="#算法和数据结构">算法与数据结构</a></strong></td><td>如果你不懂得如何使用栈、队列、树、图等常见数据结构，遇到有难度的问题时，你将束手无策。</td><td>_<a href="https://book.douban.com/subject/4048566/" target="_blank" rel="noopener">《算法设计手册》</a>_</td><td>Steven Skiena’s lectures</td></tr><tr><td><strong><a href="#数学知识">数学知识</a></strong></td><td>计算机科学基本上是应用数学的一个“跑偏的”分支，因此学习数学将会给你带来竞争优势。</td><td>_<a href="https://book.douban.com/subject/33396340/" target="_blank" rel="noopener">《计算机科学中的数学》</a>_</td><td>Tom Leighton’s MIT 6.042J</td></tr><tr><td><strong><a href="#操作系统">操作系统</a></strong></td><td>你所写的代码，基本上都由操作系统来运行，因此你应当了解其运作的原理。</td><td>_<a href="https://book.douban.com/subject/33463930/" target="_blank" rel="noopener">《操作系统导论》</a>_</td><td>Berkeley CS 162</td></tr><tr><td><strong><a href="#计算机网络">计算机网络</a></strong></td><td>互联网已然势不可挡：理解工作原理才能解锁全部潜力。</td><td>_<a href="https://book.douban.com/subject/30280001/" target="_blank" rel="noopener">《计算机网络：自顶向下方法》</a>_</td><td>Stanford CS 144</td></tr><tr><td><strong><a href="#数据库">数据库</a></strong></td><td>对于多数重要程序，数据是其核心，然而很少人理解数据库系统的工作原理。</td><td>_<a href="https://book.douban.com/subject/2256069/" target="_blank" rel="noopener">《Readings in Database Systems》</a> （暂无中译本）_</td><td>Joe Hellerstein’s Berkeley CS 186</td></tr><tr><td><strong><a href="#编程语言与编译器">编程语言与编译器</a></strong></td><td>若你懂得编程语言和编译器如何工作，你就能写出更好的代码，更轻松地学习新的编程语言。</td><td>_<a href="https://craftinginterpreters.com/" target="_blank" rel="noopener">《Crafting Interpreters》</a>_</td><td>Alex Aiken’s course on Lagunita</td></tr><tr><td><strong><a href="#分布式系统">分布式系统</a></strong></td><td>如今，_多数_ 系统都是分布式的。</td><td>_<a href="https://book.douban.com/subject/30329536/" target="_blank" rel="noopener">《数据密集型应用系统设计》</a>_</td><td>MIT 6.824</td></tr></tbody></table><p>如果花几年时间自学 9 门科目让人望而却步，我们建议你只专注于两本书：_《深入理解计算机系统》_ 和 _《数据密集型应用系统设计》_。根据我们的经验，投入到这两本书的时间可以获得极高的回报率，特别适合从事网络应用开发的自学工程师。这两本书也可以作为上面表格中其他科目的纲领。</p><h2 id="分科目指引"><a href="#分科目指引" class="headerlink" title="分科目指引"></a>分科目指引</h2><h3 id="编程"><a href="#编程" class="headerlink" title="编程"></a>编程</h3><p>大多数计算机专业本科教学以程序设计“导论”作为开始。这类课程的最佳版本不仅能满足初学者的需要，还适用于那些在初学编程阶段遗漏了某些有益的概念和程序设计模式的人。</p><p>对于这部分内容，我们的标准推荐是这部经典著作：<a href="https://book.douban.com/subject/1148282/" target="_blank" rel="noopener">《计算机程序的构造和解释》</a>。在网络上，这本书既可供<a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book.html" target="_blank" rel="noopener">免费阅读（英文版）</a>，也作为<a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-001-structure-and-interpretation-of-computer-programs-spring-2005/video-lectures/" target="_blank" rel="noopener">MIT的免费视频课程</a>。不过尽管这些视频课程很不错，我们对于视频课程的推荐实际上是<a href="https://archive.org/details/ucberkeley-webcast-PL3E89002AA9B9879E?sort=titleSorter" target="_blank" rel="noopener">Brian Harvey 开设的 SICP 课程</a>（即 Berkeley 的 61A 课程）。比起MIT的课程，它更加完善，更适用于初学者。</p><p>我们建议至少学完SICP的前三章，并完成配套的习题。如果需要额外的练习，可以去解决一些小的程序设计问题，比如<a href="http://exercism.io" target="_blank" rel="noopener">exercism</a>。</p><blockquote><p><strong>中文翻译新增：</strong>  </p><ul><li>关于SICP国内视频观看地址  <ul><li><a href="https://www.bilibili.com/video/av8515129/" target="_blank" rel="noopener">MIT的免费视频课程（中英字幕）</a>  </li><li><a href="https://www.bilibili.com/video/av40460492/" target="_blank" rel="noopener">Brian Harvey 开设的 SICP 课程（英文字幕）</a>  </li></ul></li><li>Scheme 学习的相关资源参见：<a href="https://github.com/DeathKing/Learning-SICP" target="_blank" rel="noopener">https://github.com/DeathKing/Learning-SICP</a>  </li><li>更详细的补充说明：<a href="https://github.com/keithnull/TeachYourselfCS-CN/issues/3" target="_blank" rel="noopener">#3</a>  </li></ul></blockquote><p>自从 2016 年首次发布这份指南以来，最常被问到的一个问题是，我们是否推荐由 John DeNero 讲授的更新的 CS 61A 课程，以及配套的书籍 _<a href="https://composingprograms.com/" target="_blank" rel="noopener">《Composing Programs》</a>_，这本书“继承自 SICP” 但使用 Python 讲解。我们认为 DeNero 的课程也很不错，有的学生可能更喜欢，但我们还是建议把 SICP, Scheme 和 Brian Harvey 的视频课程作为首选。</p><p>为什么这么说呢？因为 SICP 是独一无二的，它可以——至少很有可能——改变你对计算机和编程的基本认识。不是每个人都有这样的体验。有的人讨厌这本书，有的人看了前几页就放弃了。但潜在的回报让它值得一读。</p><p>如果你觉得SICP过于难，试试 _《Composing Programs》_。如果还是不合适，那我们推荐 _《程序设计方法》（<a href="https://book.douban.com/subject/1140942/" target="_blank" rel="noopener">中文版</a>，<a href="http://www.htdp.org/" target="_blank" rel="noopener">英文版</a>）_ ；如果你觉得SICP过于简单，那我们推荐 _<a href="https://book.douban.com/subject/1782316/" target="_blank" rel="noopener">《Concepts, Techniques, and Models of Computer Programming》</a>_ 。如果读这些书让你觉得没有收获，也行你应该先学习其他科目，一两年后再重新审视编程的理念。</p><blockquote><p>新版原文删除了对 _《Concepts, Techniques, and Models of Computer Programming》_ 一书的推荐，但这本书对各种编程模型有深入的见解，值得一读。所以译文中依然保留。<br>— 译者注</p></blockquote><p>最后，有一点要说明的是：本指南<strong>不适用</strong>于完全不懂编程的新手。我们假定你是一个没有计算机专业背景的程序员，希望填补一些知识空白。事实上，我们把“编程”章节包括进来只是提醒你还有更多知识需要学习。对于那些从来没有学过编程，但又想学的人来说，这份<a href="https://www.reddit.com/r/learnprogramming/wiki/faq#wiki_getting_started" target="_blank" rel="noopener">指南</a>更合适。</p><p><a href="https://book.douban.com/subject/1148282/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66758473-ef7bff80-eed0-11e9-944a-15ae5c8542ca.jpg" alt="计算机程序的构造和解释"></a> </p><h3 id="计算机架构"><a href="#计算机架构" class="headerlink" title="计算机架构"></a>计算机架构</h3><p>计算机架构——有时候又被称为“计算机系统”或者“计算机组成”——是了解软件底层的的重要视角。根据我们的经验，这是自学的软件工程师最容易忽视的领域。</p><p>我们最喜欢的入门书是 _<a href="https://book.douban.com/subject/26912767/" target="_blank" rel="noopener">《深入理解计算机系统》</a>_。典型的<a href="http://csapp.cs.cmu.edu/3e/courses.html" target="_blank" rel="noopener">计算机体系结构导论课程</a>会涵盖本书的 1 - 6 章。</p><p>我们喜爱《深入理解计算机系统》，因为它的实用性，并且站在程序员的视角。虽然计算机体系结构的内容比本书所涉及的内容多得多，但对于那些想了解计算机系统以求编写更快、更高效、更可靠的软件的人来说，这本书是很好的起点。</p><p>对于那些既想了解这个主题又想兼顾硬件和软件的知识的人来说，我们推荐 _<a href="https://book.douban.com/subject/1998341/" target="_blank" rel="noopener">《计算机系统要素》</a>_，又名“从与非门到俄罗斯方块”（“Nand2Tetris”），这本书规模宏大，让读者对计算机内的所有部分如何协同工作有完全的认识。这本书的每一章节对应如何构建计算机整体系统中的一小部分，从用HDL（硬件描述语言）写基本的逻辑门电路出发，途经CPU和汇编，最终抵达诸如俄罗斯方块这般规模的应用程序。</p><p>我们推荐把此书的前六章读完，并完成对应的项目练习。这么做，你将更加深入地理解，计算机架构和运行其上的软件之间的关系。</p><p>这本书的前半部分（包括所有对应的项目）均可从<a href="http://www.nand2tetris.org" target="_blank" rel="noopener">Nand2Tetris的网站上</a>免费获得。同时，在Coursera上，这是一门<a href="https://www.coursera.org/learn/build-a-computer" target="_blank" rel="noopener">视频课程</a>。</p><p>为了追求简洁和紧凑，这本书牺牲了内容上的深度。尤其值得注意的是，流水线和存储层次结构是现代计算机架构中极其重要的两个概念，然而这本书对此几乎毫无涉及。</p><p>当你掌握了Nand2Tetris的内容后，我们推荐要么回到《深入理解计算机系统》，或者考虑Patterson和Hennessy二人所著的 _<a href="https://book.douban.com/subject/26604008/" target="_blank" rel="noopener">《计算机组成与设计》</a>_，一本优秀的经典著作。这本书中的不同章节重要程度不一，因此我们建议根据Berkeley的<a href="http://inst.eecs.berkeley.edu/~cs61c/sp15/" target="_blank" rel="noopener">CS61C课程</a> “计算机架构中的伟大思想”来着重阅读一些章节。这门课的笔记和实验在网络上可以免费获得，并且在<a href="https://archive.org/details/ucberkeley-webcast-PL-XXv-cvA_iCl2-D-FS5mk0jFF6cYSJs_" target="_blank" rel="noopener">互联网档案</a>中有这门课程的过往资料。</p><p><a href="https://book.douban.com/subject/26912767/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20510068/82109944-12270d00-976d-11ea-85a9-774e4f762ec9.png" alt="深入理解计算机系统"></a> <a href="http://www.nand2tetris.org" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66758695-60231c00-eed1-11e9-8422-a4acfb10a390.jpg" alt="计算机系统要素"></a> </p><blockquote><p>硬件是平台。</p><p>— Mike Acton, Engine Director at Insomniac Games<br>(<a href="https://www.youtube.com/watch?v=rX0ItVEVjHc" target="_blank" rel="noopener">观看他在CppCon上的演说</a>)</p></blockquote><h3 id="算法与数据结构"><a href="#算法与数据结构" class="headerlink" title="算法与数据结构"></a>算法与数据结构</h3><p>正如几十年来的共识，我们认为，计算机科学教育所赋予人们的最大能量在于对常见算法和数据结构的熟悉。此外，这也可以训练一个人对于各种问题的解决能力，有助于其他领域的学习。</p><p>关于算法与数据结构，有成百上千的书可供使用，但是我们的最爱是Steven Skiena编写的 _<a href="https://book.douban.com/subject/4048566/" target="_blank" rel="noopener">《算法设计手册》</a>_。显而易见，他对此充满热爱，迫不及待地想要帮助其他人理解。在我们看来，这本书给人一种焕然一新的体验，完全不同于那些更加经常被推荐的书（比如Cormen，Leiserson，Rivest 和 Stein，或者 Sedgewick的书，后两者充斥着过多的证明，不适合以 _解决问题_ 为导向的学习）。</p><p>如果你更喜欢视频课程，<a href="https://www.youtube.com/watch?v=A2bFN3MyNDA&amp;list=PLOtl7M3yp-DX32N0fVIyvn7ipWKNGmwpp" target="_blank" rel="noopener">Skiena慷慨地提供了他的课程</a>。此外，Tim Roughgarden的课程也很不错，<br>在Stanford的MOOC平台Lagunita，或者<a href="https://www.coursera.org/specializations/algorithms" target="_blank" rel="noopener">Coursera</a>上均可获得。Skiena和Roughgarden的这两门课程没有优劣之分，选择何者取决于个人品味。</p><p>至于练习，我们推荐学生在<a href="https://leetcode.com" target="_blank" rel="noopener">Leetcode</a>上解决问题。Leetcode上的问题往往有趣且带有良好的解法和讨论。此外，在竞争日益激烈的软件行业，这些问题可以帮助你评估自己应对技术面试中常见问题的能力。我们建议解决大约100道随机挑选的Leetcode问题，作为学习的一部分。</p><p>最后，我们强烈推荐 _<a href="https://book.douban.com/subject/2124114/" target="_blank" rel="noopener">《怎样解题》</a>_。这本书极为优秀且独特，指导人们解决广义上的问题，因而一如其适用于数学，它适用于计算机科学。</p><p><a href="https://book.douban.com/subject/4048566/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66759121-361e2980-eed2-11e9-913c-8fc48c67122a.jpg" alt="算法设计手册"></a> <a href="https://book.douban.com/subject/2124114/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66759282-8e552b80-eed2-11e9-89de-16b1f8d82e78.jpg" alt="怎样解题"></a> </p><blockquote><p>我可以广泛推荐的方法只有一个： 写之前先思考。</p><p>— Richard Hamming</p></blockquote><h3 id="数学知识"><a href="#数学知识" class="headerlink" title="数学知识"></a>数学知识</h3><p>从某个角度说，计算机科学是应用数学的一个“发育过度”的分支。尽管许多软件工程师试图——并且在不同程度上成功做到——忽视这一点，我们鼓励你用学习来拥抱数学。如若成功，比起那些没有掌握数学的人，你将获得巨大的竞争优势。</p><p>对于计算机科学，数学中最相关的领域是“离散数学”，其中的“离散”与“连续”相对立，大致上指的是应用数学中那些有趣的主题，而不是微积分之类的。由于定义比较含糊，试图掌握离散数学的全部内容是没有意义的。较为现实的学习目标是，了解逻辑、排列组合、概率论、集合论、图论以及密码学相关的一些数论知识。考虑到线性代数在计算机图形学和机器学习中的重要性，该领域同样值得学习。</p><p>学习离散数学，我们建议从<a href="http://www.cs.elte.hu/~lovasz/dmbook.ps" target="_blank" rel="noopener">László Lovász的课程笔记</a>开始。Lovász教授成功地让这些内容浅显易懂且符合直觉，因此，比起正式的教材，这更适合初学者。</p><p>对于更加高阶的学习，我们推荐 _<a href="https://book.douban.com/subject/33396340/" target="_blank" rel="noopener">《计算机科学中的数学》</a>_，MIT同名课程的课程笔记，篇幅与书籍相当（事实上，现已出版）。这门课程的视频同样<a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/video-lectures/" target="_blank" rel="noopener">可免费获得</a>，是我们所推荐的学习视频。</p><p>对于线性代数，我们建议从<a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab" target="_blank" rel="noopener">Essence of linear algebra</a>系列视频开始，然后再去学习Gilbert Strang的<a href="https://book.douban.com/subject/34820335/" target="_blank" rel="noopener">《线性代数导论》</a>和<a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/" target="_blank" rel="noopener">视频课程</a>。</p><p><a href="https://book.douban.com/subject/33396340/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66759673-4387e380-eed3-11e9-8469-3e677d108e91.jpg" alt="计算机科学中的数学"></a> </p><blockquote><p>如果人们不相信数学是简单的，那么只能是因为他们没有意识到生活有多么复杂。</p><p>— John von Neumann</p></blockquote><h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><p>_<a href="https://book.douban.com/subject/30297919/" target="_blank" rel="noopener">《操作系统概念》</a>_ （“恐龙书”）和 _<a href="https://book.douban.com/subject/27096665/" target="_blank" rel="noopener">《现代操作系统》</a>_ 是操作系统领域的经典书籍。二者都因为写作风格和对学生不友好而招致了一些批评。</p><p>_<a href="https://book.douban.com/subject/33463930/" target="_blank" rel="noopener">《操作系统导论》（Operating Systems: Three Easy Pieces）</a>_ 是一个不错的替代品，并且<a href="http://pages.cs.wisc.edu/~remzi/OSTEP/" target="_blank" rel="noopener">可在网上免费获得（英文版）</a>。我们格外喜欢这本书的结构，并且认为这本书的习题很值得一做。</p><p>在读完《操作系统导论》后，我们鼓励你探索特定操作系统的设计。可以借助“{OS name} Internals”风格的书籍，比如 _<a href="https://www.amazon.com/Lions-Commentary-Unix-John/dp/1573980137/" target="_blank" rel="noopener">Lion’s commentary on Unix</a>_， _<a href="https://www.amazon.com/Design-Implementation-FreeBSD-Operating-System/dp/0321968972/" target="_blank" rel="noopener">The Design and Implementation of the FreeBSD Operating System</a>_，以及 _<a href="https://www.amazon.com/Mac-OS-Internals-Systems-Approach/dp/0321278542/" target="_blank" rel="noopener">Mac OS X Internals</a>_。对于 Linux ，我们推荐 Robert Love 的 _<a href="https://book.douban.com/subject/6097773/" target="_blank" rel="noopener">《Linux内核设计与实现》</a>_。</p><p>为了巩固对操作系统的理解，阅读小型系统内核的代码并且为其增加特性是一个很不错的方法。比如，<a href="https://pdos.csail.mit.edu/6.828/2016/xv6.html" target="_blank" rel="noopener">xv6</a>，由MIT的一门课程所维护的从Unix V6到ANSI C和x86的移植，就是一个很棒的选择。《操作系统导论》有一个附录，记载了一些可能的<a href="http://pages.cs.wisc.edu/~remzi/OSTEP/lab-projects-xv6.pdf" target="_blank" rel="noopener">xv6实验项目</a>，其中充满了关于潜在项目的很棒想法。</p><p><a href="https://book.douban.com/subject/33463930/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66759780-78943600-eed3-11e9-8eb5-6472c318c265.jpg" alt="操作系统导论"></a> </p><h3 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h3><p>鉴于有那么多关于网络服务端和客户端的软件工程，计算机网络是计算机科学中价值最为“立竿见影”的领域之一。我们的学生，系统性地学习了计算机网络，最终能够理解那些曾困扰他们多年的术语、概念和协议。</p><p>在这一主题上，我们最爱的书籍是 _<a href="https://book.douban.com/subject/30280001/" target="_blank" rel="noopener">《计算机网络：自顶向下方法》</a>_。书中的小项目和习题相当值得练习，尤其是其中的“Wireshark labs”（<a href="http://www-net.cs.umass.edu/wireshark-labs/" target="_blank" rel="noopener">这部分在网上可以获得</a>）。</p><p>如果更喜欢视频课程，我们推荐Stanford的<a href="https://lagunita.stanford.edu/courses/Engineering/Networking-SP/SelfPaced/about" target="_blank" rel="noopener">_Introduction to Computer Networking_</a>，可在他们的MOOC平台Lagunita上免费观看。</p><p>对于计算机网络的学习，做项目比完成小的习题更有益。一些可能的项目有：HTTP服务器，基于UDP的聊天APP，<a href="http://jvns.ca/blog/2014/08/12/what-happens-if-you-write-a-tcp-stack-in-python/" target="_blank" rel="noopener">迷你TCP栈</a>，代理，负载均衡器，或者分布式哈希表。</p><p><a href="https://book.douban.com/subject/30280001/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66760004-d9bc0980-eed3-11e9-9b3f-74bf54b9571f.jpg" alt="《计算机网络：自顶向下方法》"></a> </p><blockquote><p>你无法盯着水晶球预见未来，未来的互联网何去何从取决于社会。</p><p>— Bob Kahn</p></blockquote><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>比起其他主题，自学数据库系统需要更多的付出。这是一个相对年轻的研究领域，并且出于很强的商业动机，研究者把想法藏在紧闭的门后。此外，许多原本有潜力写出优秀教材的作者反而选择了加入或创立公司。</p><p>鉴于如上情况，我们鼓励自学者大体上抛弃教材，而是从<a href="https://archive.org/details/UCBerkeley_Course_Computer_Science_186" target="_blank" rel="noopener">2015年春季学期的CS 186课程</a>（Joe Hellerstein在Berkeley的数据库课程）开始，然后前往阅读论文。</p><p>对于初学者，有一篇格外值得提及的论文：“<a href="http://db.cs.berkeley.edu/papers/fntdb07-architecture.pdf" target="_blank" rel="noopener">Architecture of a Database System</a>”。这篇论文提供了独特的对关系型数据库管理系统（RDBMS）如何工作的高层次观点，是后续学习的实用梗概。</p><p>_<a href="https://book.douban.com/subject/2256069/" target="_blank" rel="noopener">《Readings in Database Systems》</a>_，或者以<a href="http://www.redbook.io/" target="_blank" rel="noopener">数据库“红书”</a>更为人知，是由Peter Bailis，Joe Hellerstein和Michael Stonebraker编纂的论文合集。对于那些想要在CS 186课程的水平更进一步的学习者，“红书”应当是下一步。</p><p>如果你坚持一定要一本导论教材，那我们推荐Ramakrishnan和Gehrke所著的 _<a href="https://book.douban.com/subject/1155934/" target="_blank" rel="noopener">《数据库管理系统：原理与设计》</a>_。如需更深一步，Jim Gray的经典著作 _<a href="https://book.douban.com/subject/2586390/" target="_blank" rel="noopener">《Transaction Processing: Concepts and Techniques》</a>_ 值得一读，不过我们不建议把这本书当作首要资源。</p><p>如果没有编写足够数量的代码，很难巩固数据库理论。CS 186课程的学生给Spark添加特性，倒是不错的项目，不过我们仅仅建议从零实现一个简单的关系型数据库管理系统。自然，它将不会有太多的特性，但是即便只实现典型的关系型数据库管理系统每个方面最基础的功能，也是相当有启发的。</p><p>最后，数据模型往往是数据库中一个被忽视的、教学不充分的方面。关于这个主题，我们推荐的书籍是 _<a href="https://book.douban.com/subject/17915870/" target="_blank" rel="noopener">Data and Reality: A Timeless Perspective on Perceiving and Managing Information in Our Imprecise World</a>_。</p><p><a href="https://book.douban.com/subject/2256069/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66760126-08d27b00-eed4-11e9-82c6-46c571036aa1.jpg" alt="Readings in Database Systems"></a> <a href="https://book.douban.com/subject/1155934/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66760358-85655980-eed4-11e9-9130-66d2ecea5700.jpg" alt="数据库管理系统：原理与设计"></a> </p><h3 id="编程语言与编译器"><a href="#编程语言与编译器" class="headerlink" title="编程语言与编译器"></a>编程语言与编译器</h3><p>多数程序员学习编程语言的知识，而多数计算机科学家学习编程语言 _相关_ 的知识。这使得计算机科学家比起程序员拥有显著的优势，即便在编程领域！因为他们的知识可以推而广之：相较只学习过特定编程语言的人，他们可以更深入更快速地理解新的编程语言。</p><p>我们推荐的入门书是 Bob Nystrom 所著的优秀的 _<a href="https://craftinginterpreters.com/contents.html" target="_blank" rel="noopener">Crafting Interpreters</a>_，可在网上免费获取。这本书条理清晰，富有趣味性，非常适合那些想要更好地理解语言和语言工具的人。我们建议你花时间读完整本书，并尝试任何一个感兴趣的“挑战”。</p><p>另一本更为传统的推荐书籍是 _<a href="https://book.douban.com/subject/3296317/" target="_blank" rel="noopener">《编译原理》</a>_，通常称为“龙书”。不幸的是，这本书不是为自学者而设计的，而是供教师从中挑选一些主题用于1-2学期的教学。</p><p>如果你选择使用龙书进行自学，你需要从中甄选主题，而且最好是在导师的帮助下。我们建议依据某个视频课程来设定学习的结构，然后按需从龙书中获取深入的内容。我们推荐的在线课程是<a href="https://www.edx.org/course/compilers" target="_blank" rel="noopener">Alex Aiken在MOOC平台 edX 所开设的</a>。</p><p><a href="https://book.douban.com/subject/3296317/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20233656/66760486-ca898b80-eed4-11e9-80ba-df298ac8d5da.jpg" alt="编译原理"></a> </p><blockquote><p>不要做一个只写样板代码的程序员。相反，给用户和其他程序员创造工具。从纺织工业和钢铁工业中学习历史教训：你想制造机器和工具，还是操作这些机器？</p><p>— Ras Bodik 在他的编译器课程伊始</p></blockquote><h3 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h3><p>随着计算机在数量上的增加，计算机同样开始 _分散_。尽管商业公司过去愿意购买越来越大的大型机，现在的典型情况是，甚至很小的应用程序都同时在多台机器上运行。思考这样做的利弊权衡，即是分布式系统的研究所在，也是越来越重要的一项技能。</p><p>我们推荐的自学参考书是 Martin Kleppmann 的 _<a href="https://book.douban.com/subject/30329536/" target="_blank" rel="noopener">《数据密集型应用系统设计》</a>_。与传统的教科书相比，它是一本为实践者设计的具有很高的可读性的书，并且保持了深度和严谨性。</p><p>对于那些偏爱传统教材，或者希望可以从网上免费获取的人，我们推荐的教材是Maarten van Steen和Andrew Tanenbaum所著的 _《分布式系统原理与范型》（<a href="https://book.douban.com/subject/3108801/" target="_blank" rel="noopener">中文第二版</a>，<a href="https://book.douban.com/subject/26979326/" target="_blank" rel="noopener">英文第三版</a>）_。</p><p>对于喜欢视频课程的人，<a href="https://www.youtube.com/watch?v=cQP8WApzIQQ&amp;list=PLrw6a1wE39_tb2fErI4-WkMbsvGQk9_UB" target="_blank" rel="noopener">MIT的6.824</a> 是一门很好的在线视频课程，由 Robert Morris 教授的研究生课程，在<a href="https://pdos.csail.mit.edu/6.824/schedule.html" target="_blank" rel="noopener">这里</a>可以看到课程安排。</p><p>不管选择怎样的教材或者其他辅助资料，学习分布式系统必然要求阅读论文。<a href="http://dsrg.pdos.csail.mit.edu/papers/" target="_blank" rel="noopener">这里</a>有一个不错的论文清单，而且我们强烈建议你出席你当地的<a href="http://paperswelove.org/" target="_blank" rel="noopener">Papers We Love</a>（仅限美国）。</p><p><a href="https://book.douban.com/subject/30329536/" target="_blank" rel="noopener"><img src="https://user-images.githubusercontent.com/20510068/82111034-94ff9600-9774-11ea-9d49-90b00f746659.png" alt="数据密集型应用系统设计"></a> </p><h3 id="人工智能-计算机图形学"><a href="#人工智能-计算机图形学" class="headerlink" title="人工智能/计算机图形学"></a>人工智能/计算机图形学</h3><p>我们试图把计算机科学主题清单限制到那些我们认为 _每一个软件工程师_ 都应该了解的内容，不限于专业或行业。拥有了这些基础，你将能更加轻松地挑选教材或论文，然而无需指引地学习核心概念。在这里，我们给出一些其他常见主题的自学起点：</p><ul><li>人工智能：通过观看视频并完成Pacman项目来学习<a href="http://ai.berkeley.edu/" target="_blank" rel="noopener">Berkeley的AI课程</a>。至于教材，使用Russell和Norvig编写的 _<a href="https://book.douban.com/subject/25796281/" target="_blank" rel="noopener">《人工智能：一种现代方法》</a>_。</li><li>机器学习：学习吴恩达在Coursera上的课程。耐心学习，先确保理解了基础概念再奔向类如深度学习的诱人新主题。</li><li>计算机图形学：学习<a href="http://inst.eecs.berkeley.edu/~cs184/fa12/onlinelectures.html" target="_blank" rel="noopener">Berkeley CS 184课程</a>的材料，使用<a href="https://book.douban.com/subject/30402778/" target="_blank" rel="noopener">《计算机图形学：原理及实践》</a>作为教材。</li></ul><h3 id="一定要严格遵守推荐的学习次序吗？"><a href="#一定要严格遵守推荐的学习次序吗？" class="headerlink" title="一定要严格遵守推荐的学习次序吗？"></a>一定要严格遵守推荐的学习次序吗？</h3><p>不过在我们看来，最重要的“先决条件”是：先学计算机架构再学操作系统或数据库，先学计算机网络和操作系统再学分布式系统。</p><h3 id="和Open-Source-Society、freeCodeCamp-curricula等比起来，这份指引"><a href="#和Open-Source-Society、freeCodeCamp-curricula等比起来，这份指引" class="headerlink" title="和Open Source Society、freeCodeCamp curricula等比起来，这份指引?"></a>和Open Source Society、freeCodeCamp curricula等比起来，这份指引?</h3><p><a href="https://github.com/open-source-society/computer-science" target="_blank" rel="noopener">OSS指引</a>涵盖太多主题，在许多主题中推荐劣质资源，没有就特定课程哪些方面有价值提供原因或指引。我们努力对这份指引中的课程加以限制，仅仅包括那些你作为软件工程师 _确实需要了解的_，不论你的专业方向，并且对每门课程为何必要做出了解释以帮助你理解。</p><p>FreeCodeCamp主要关注编程，而不是计算机科学。至于你为什么要学习计算机科学，参见<a href="#为什么要学习计算机科学">上文</a>。如果你是个新手，我们建议先学 freeCodeCamp 的课程，一两年后再回归本指南。</p><h3 id="XX编程语言怎么样"><a href="#XX编程语言怎么样" class="headerlink" title="XX编程语言怎么样?"></a>XX编程语言怎么样?</h3><p>学习一门特定的编程语言和学习计算机科学的一个领域完全不在一个维度——相比之下，学习语言 _容易_ 且 _缺乏价值_。如果你已经了解了一些语言，我们强烈建议遵照我们的指引，然后在学习的空当中习得语言，或者暂且不管以后再说。如果你已经把编程学得不错了（比如学完了 _《计算机程序的构造和解释》_），尤其是如果你学习过<strong>编译器</strong>，那么面对一门新的语言，你只需要花一个周末稍多的时间即可基本掌握，之后你可以在工作中学习相关的类库/工具/生态。</p><h3 id="XX流行技术怎么样"><a href="#XX流行技术怎么样" class="headerlink" title="XX流行技术怎么样?"></a>XX流行技术怎么样?</h3><p>没有任何一种技术的重要程度可以达到学习其使用足以成为计算机科学教学的核心部分。不过，你对学习那门技术充满热情，这很不错。诀窍是先从特定的技术回退到基本的领域或概念，判断这门流行技术在技术的宏观大局中位于何处，然后才深入学习这门技术。</p><h3 id="为什么你们还在推荐SICP"><a href="#为什么你们还在推荐SICP" class="headerlink" title="为什么你们还在推荐SICP?"></a>为什么你们还在推荐SICP?</h3><p>先尝试读一下，有些人觉得 SICP 让人神魂颠倒，这在其他书很少见。如果你不喜欢，你可以尝试其他的东西，也许以后再回到 SICP。</p><h3 id="为什么你们还在推荐龙书"><a href="#为什么你们还在推荐龙书" class="headerlink" title="为什么你们还在推荐龙书?"></a>为什么你们还在推荐龙书?</h3><p>龙书依旧是内容最为完整的编译器单本书籍。由于过分强调一些如今不够时新的主题的细节，比如解析，这本书招致了恶评。然而事实上，这本书从未打算供人一页一页的学习，而仅仅是为了给教师准备一门课程提供足够的材料。类似地，自学者可以从书中量身按需挑选主题，或者最好依照公开课授课教师在课程大纲中的建议。</p><hr><h1 id="人工智能领域"><a href="#人工智能领域" class="headerlink" title="人工智能领域"></a>人工智能领域</h1><p>人工智能属于计算机科学的一个分支。传统的人工智能是研究人类如何产生智能，然后让机器学习人的思考方式去行为，现代人工智能概念提出者约翰·麦卡锡认为，机器不一定需要像人一样思考才能获得智能，而重点是让机器能够解决人脑所能解决的问题。</p><p>AI目前包含大量各种各样的子领域，范围从通用领域，如学习和感知，到专门领域，如下棋、证明数学定理、在复杂的街道上开车和诊断疾病。计算机尚需具有以下能力：</p><ul><li>自然语言处理(natural language processing)使之能成功地用语言交流；</li><li>知识表示(knowledge representation)以存储知道的或听到的信息；</li><li>自动推理(automated reasoning)以运用存储的信息来回答问题并推出新结论；</li><li>机器学习(machine learning)以适应新情况并检测和预测模式。</li><li>计算机视觉(computer vision)以感知物体；</li><li>机器人学(robotics)以操作和移动对象。</li></ul><p>人工智能核心技术发展的两条主线是脑科学和类脑科学的研究。[^2018中国人工智能发展报告]</p><p><img src="/blog//jiangxj.top/blog/2020/07/15/计算机科学/Users\JXJ\Documents\blog\hexo\source\_posts\计算机科学\人工智能发展历程.jpg" alt="人工智能发展历程"></p><h2 id="人工智能的基础"><a href="#人工智能的基础" class="headerlink" title="人工智能的基础"></a>人工智能的基础</h2><p>哲学：形式规则、思想如何从物理的大脑中产生、知识来自何方、知识如何导致行动</p><p>数学：逻辑、计算和概率。其中贝叶斯规则构成了人工智能系统中大多数用于不确定性推理的现代方法的基础。</p><p>经济：决策理论、博弈论、运筹学。决策理论把概率理论和效用理论结合起来，在概率描述能适当捕捉决策者制定者的环境的情况下，做出决策提供一个形式化且完整的框架。</p><p>神经科学：人脑和数字计算机。</p><p>心理学：认知理论。认知理论应该描述详细的信息处理机制，靠这个机制可以实现某种认知功能。</p><p>计算机工程：建造高效的计算机。</p><p>控制论：目标函数。</p><p>语言学：语言与思维的关联。知识表示，自然语言处理。[^人工智能·一种现代的方法(3rd)]</p><p>大数据：也是人工智能的基础，而使大数据转变为知识或生产力，离不开机器学习，机器学习可以说是人工智能的核心，是使得机器具有类似人的智能的根本途径。</p><p>机器学习和深度学习算法是人工智能中的两大热点，关系如下：</p><p><img src="/blog//jiangxj.top/blog/2020/07/15/计算机科学/Users\JXJ\Documents\blog\hexo\source\_posts\计算机科学\人工智能与相关研究领域的关系.png" alt="人工智能与相关研究领域的关系"></p><p>机器学习强调三个关键词：算法、模型、算力。其本质如下：</p><p><img src="/blog//jiangxj.top/blog/2020/07/15/计算机科学/Users\JXJ\Documents\blog\hexo\source\_posts\计算机科学\机器学习本质.png" alt="机器学习本质"></p><p>大数据时代，产生数据的能力空前高涨，如互联网、移动网、物联网、成千上万的传感器、穿戴设备、定位系统等，存储数据、处理数据等能力也得到了几何级数的提升。Hadoop、Spark技术为存储和处理大数据提供了有效的方法。</p><p>数据就是信息，其背后隐含着大量不易被我们感官识别的信息、知识、规律等，如何揭示这些信息、规则、趋势，需要用到数据挖掘。</p><p>机器学习的任务，就是在大数据量的基础上，发掘有用信息，其处理的数据越多，机器学习就越能体现出优势。如语言识别、图像识别、天气预测等等。</p><h2 id="机器学习经典书"><a href="#机器学习经典书" class="headerlink" title="机器学习经典书"></a>机器学习经典书</h2><h3 id="pattern-recognition-and-machine-learning"><a href="#pattern-recognition-and-machine-learning" class="headerlink" title="pattern recognition and machine learning"></a>pattern recognition and machine learning</h3><p>被认为是贝叶斯方法的扛鼎之作，系统地介绍了模式识别和机器学习领域内的概念和基础。整体目录如下：</p><ul><li>第一章 绪论 </li><li>第二章 概率分布</li><li>第三章 线性回归模型</li><li>第四章 线性分类模型</li><li>第五章 神经网络</li><li>第六章 核方法</li><li>第七章 稀疏核机器</li><li>第八章 图模型</li><li>第九章 混合模型和EM</li><li>第十章 近似判断</li><li>第十一章 采样方法</li><li>第十二章 连续潜在变量</li><li>第十三章 顺序数据</li><li>第十四章 组合模型</li></ul><p><a href="/download/PRML_英文版.pdf">pattern recognition and machine learning</a></p><p><a href="/download/PRML_中文版.pdf">模式识别与机器学习</a></p><p><a href="http://www.52nlp.cn/author/prml" target="_blank" rel="noopener">PRML读书会-我爱自然语言处理</a></p><h3 id="周志华-机器学习-西瓜书"><a href="#周志华-机器学习-西瓜书" class="headerlink" title="周志华-机器学习(西瓜书)"></a>周志华-机器学习(西瓜书)</h3><p>整体目录如下：</p><ul><li>第一章 绪论</li><li>第二章 模型评估与选择</li><li>第三章 线性模型</li><li>第四章 决策树</li><li>第五章 神经网络</li><li>第六章 支持向量机</li><li>第七章 贝叶斯分类</li><li>第八章 集成学习</li><li>第九章 聚类</li><li>第十章 降维与度量学习</li><li>第十一章 特征选择与稀疏学习</li><li>第十二章 计算学习理论</li><li>第十三章 半监督学习</li><li>第十四章 概率图模型</li><li>第十五章 规则学习</li><li>第十六章 强化学习</li></ul><p><a href="/download/周志华-机器学习.pdf">周志华-机器学习</a></p><p><a href="/download/周志华西瓜书公式推导.pdf">周志华-机器学习-公式推导</a></p><h3 id="李航-统计学习方法-一、二版"><a href="#李航-统计学习方法-一、二版" class="headerlink" title="李航-统计学习方法(一、二版)"></a>李航-统计学习方法(一、二版)</h3><p><a href="/download/统计学习方法李航.pdf">李航-统计学习方法</a></p><h2 id="深度学习经典书"><a href="#深度学习经典书" class="headerlink" title="深度学习经典书"></a>深度学习经典书</h2><h3 id="深度学习-花书"><a href="#深度学习-花书" class="headerlink" title="深度学习-花书"></a>深度学习-花书</h3><h3 id="stanford-CS231n课程"><a href="#stanford-CS231n课程" class="headerlink" title="stanford CS231n课程"></a>stanford CS231n课程</h3><p>stanford CS231n课程：CS231n的全称是<a href="http://vision.stanford.edu/teaching/cs231n/index.html" target="_blank" rel="noopener">CS231n: Convolutional Neural Networks for Visual Recognition</a>，即<strong>面向视觉识别的卷积神经网络</strong>。该课程是<a href="http://vision.stanford.edu/index.html" target="_blank" rel="noopener">斯坦福大学计算机视觉实验室</a>推出的课程。需要注意的是，目前大家说CS231n，大都指的是2016年冬季学期（一月到三月）的最新版本。本课程将深入讲解深度学习框架的细节问题，聚焦面向视觉识别任务（尤其是图像分类任务）的端到端学习模型。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2>]]></content>
    
    <summary type="html">
    
      计算机课程和人工智能领域所学课程及经典参考书籍整理
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="课程" scheme="https://jiangxj.top/blog/tags/%E8%AF%BE%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>工具资源整理</title>
    <link href="https://jiangxj.top/blog/2020/07/08/%E5%B7%A5%E5%85%B7%E8%B5%84%E6%BA%90%E6%95%B4%E7%90%86-%E5%B8%B8%E6%9B%B4/"/>
    <id>https://jiangxj.top/blog/2020/07/08/工具资源整理-常更/</id>
    <published>2020-07-07T16:00:00.000Z</published>
    <updated>2020-07-08T08:41:21.488Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="GitHub上各式各样的小徽章制作"><a href="#GitHub上各式各样的小徽章制作" class="headerlink" title="GitHub上各式各样的小徽章制作"></a>GitHub上各式各样的小徽章制作</h2><p>徽章是一种小巧精美的小图标，一般配有相关文字进行辅助说明，富有表现力。</p><p>其本质是一种<code>svg</code>格式的矢量图标，不仅出现在GitHub项目主页，能够表现图片的地方都可以出现徽章。</p><h3 id="徽章的使用"><a href="#徽章的使用" class="headerlink" title="徽章的使用"></a>徽章的使用</h3><p>大多是徽章是<code>svg</code>格式，也不排除某些是<code>png</code>格式，都可以当成图标使用。</p><p>如果希望在<code>markdown</code>文件中使用徽章，最好使用在线链接，或者引入到本地相关文件中。</p><blockquote><p>徽章格式：<code>[![图片说明](图片源地址)](超链接地址)</code>     即超链接内部嵌套图片</p></blockquote><p><a href="https://github.com/snowdreams1006" target="_blank" rel="noopener"><img src="https://img.shields.io/badge/github-snowdreams1006-brightgreen.svg" alt="github"></a></p><p>如果是在<code>HTML</code>文件中使用徽章，同样需要先取得在线徽章地址，然后按照<code>HTML</code>语法插入图片即可。</p><blockquote><p>徽章格式：<code>&lt;a href=&quot;超链接地址&quot;&gt;&lt;img src=&quot;图片源地址&quot; alt=&quot;图片文字说明&quot;&gt;&lt;/a&gt;</code>   即超链接内部嵌套图片</p></blockquote><p><a href="https://github.com/snowdreams1006" target="_blank" rel="noopener">     <img src="https://img.shields.io/badge/github-snowdreams1006-brightgreen.svg" alt="github"></a></p><p>不论什么语法，最核心的是获得<strong>徽章链接</strong>。至于不同语言有着各自的语法，按照语言规则手动拼接即可。</p><h3 id="徽章分类"><a href="#徽章分类" class="headerlink" title="徽章分类"></a>徽章分类</h3><p>以徽章<strong>格式</strong>为标准，分为<code>svg</code>和<code>png</code>两类</p><p>以徽章<strong>内容数据是否是动态</strong>为标准，可以分为静态数据和动态数据。</p><p>还有一些其他分类，不赘诉。</p><h3 id="徽章来源"><a href="#徽章来源" class="headerlink" title="徽章来源"></a>徽章来源</h3><p>徽章有不同的分类，不管是哪一张分类，在线徽章最为简单便捷，下面介绍几个提供在线生成徽章的网站。</p><ul><li><p><a href="https://shields.io/" target="_blank" rel="noopener">shields.io</a></p></li><li><p><a href="https://badgen.net/" target="_blank" rel="noopener">badgen.net</a></p></li><li><p><a href="https://forthebadge.com/" target="_blank" rel="noopener">forthebadge.com</a></p></li><li><p><a href="https://badge.fury.io/" target="_blank" rel="noopener">badge.fury.io</a></p></li><li><p><a href="https://github.com/boennemann/badges" target="_blank" rel="noopener">github.com/boennemann/badges</a></p></li></ul><p><a href="https://www.npmjs.com/package/vue-giant-tree/" target="_blank" rel="noopener"><img src="https://img.shields.io/npm/v/vue-giant-tree.svg" alt="npm"></a>  <a href><img src="https://img.shields.io/github/license/tower1229/vue-giant-tree.svg" alt="license"></a></p><p><a href="https://www.cnblogs.com/snowdreams1006/p/11068107.html" target="_blank" rel="noopener">本文来源</a></p>]]></content>
    
    <summary type="html">
    
      整理一些常用工具资源
    
    </summary>
    
      <category term="工具使用" scheme="https://jiangxj.top/blog/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="工具使用" scheme="https://jiangxj.top/blog/tags/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>LSTM网络理解</title>
    <link href="https://jiangxj.top/blog/2020/07/07/LSTM%E7%BD%91%E7%BB%9C%E7%90%86%E8%A7%A3/"/>
    <id>https://jiangxj.top/blog/2020/07/07/LSTM网络理解/</id>
    <published>2020-07-06T16:00:00.000Z</published>
    <updated>2021-06-28T14:11:21.332Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Recurrent-Neural-Network"><a href="#Recurrent-Neural-Network" class="headerlink" title="Recurrent Neural Network"></a>Recurrent Neural Network</h2><p>传统的神经网络很难处理一件事——使用先前事件推断后续的事件。RNN解决了这个问题，是包含循环的网络，允许信息的持久化。</p><img src="/blog/2020/07/07/LSTM网络理解/RNN-unrolled.png" title="RNN-unrolled"><p>$A$正在读取输入$x_t$，并输出$h_t$。循环可以使得信息可以从当前步传递到下一步。</p><p>RNN can be thought of as multiple copies of the same network, each passing a message to a successor(接替者). Consider what happens if we unroll the loop:</p><img src="/blog/2020/07/07/LSTM网络理解/RNN-unrolled.png" title="RNN-unrolled"><p>This chain-like nature reveals that RNN are intimately related to sequences and lists(和序列和列表相关). </p><p>There have been incredible success applying RNNs to a variety of problems: <strong>Speech recognition, Language modeling, Translation, Image captioning…</strong></p><p>Essential to these successes is the use of “LSTMs”, a very special kind of RNN which works, for many tasks, much much better than standard version.</p><h2 id="The-problem-of-Long-Term-Dependencies"><a href="#The-problem-of-Long-Term-Dependencies" class="headerlink" title="The problem of Long-Term Dependencies"></a>The problem of Long-Term Dependencies</h2><p>One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task.</p><p>In theory, RNNs are absolutely capable of handling  long-term dependencies. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large. While, as the gap grows, RNNs become unable to learn to connect the information.</p><p>例如：有一个语言模型用来基于先前的的词来预测下一个词，如果试着预测”the clouds are in the sky”最后的一个词，并不需要任何其他的上下文，显然最后的一个词就是sky。在这样的场景中，相关的信息和预测的词位置之间的间隔非常小，RNN可以学会使用先前的信息。</p><img src="/blog/2020/07/07/LSTM网络理解/RNN-shorttermdepdencies.png" title="RNN-shorttermdepdencies"><p>然而，对于一些更加复杂的场景，如预测”I grew up in France… I speak fluent French”最后的词，当前的信息建议下一个词可能是一种语言的名字，这需要先前提到的离当前位置很远的France的上下文。此时，相关信息和当前预测位置之间的间隔变得很大，在这个间隔不断变大时，RNN会丧失学习到连接如此远的信息的能力。虽然可以仔细挑选参数来解决这类toy problems。但在实践中，RNN肯定不能够成功学习到这些知识，Bengio,et al.(1994)等人对该问题进行了深入研究，发现一些使得RNN训练变得非常困难的根本原因。</p><img src="/blog/2020/07/07/LSTM网络理解/RNN-longtermdependencies.png" title="RNN-shorttermdepdencies"><p>LSTM don’t have this problem!</p><h2 id="LSTM-Networks"><a href="#LSTM-Networks" class="headerlink" title="LSTM Networks"></a>LSTM Networks</h2><p>Long Short Term Memory networks(LSTMs)是一种RNN特殊的类型，可以学习长期依赖信息。LSTM由<a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf" target="_blank" rel="noopener">Hochreiter &amp; Schmidhuber(1997)</a>提出，并被<a href="https://scholar.google.com/citations?user=DaFHynwAAAAJ&amp;hl=en" target="_blank" rel="noopener">Alex Graves</a>进行了改良和推广。</p><p>LSTMs are <strong>explicitly designed</strong> to avoid the long-term dependency problem. Remembering info for long periods of time is practically their <strong>default behavior</strong>, not something they struggle to learn.</p><p>All RNNs have the form of a chain of repeating modules of neural networks(重复神经网络模块的链式结构). </p><p><strong>标准的RNN</strong></p><p>标准的RNN中，重复的模块只有一个简单的结构，如一个tanh层：</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-SimpleRNN.png" title="LSTM3-SimpleRNN"></div><p><strong>LSTM</strong></p><p>LSTM重复模块不同于单一神经网络层，这里是有四个，以一种非常特殊的方式进行交互：</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-chain.png" title="LSTM3-chain"></div><p><strong>LSTM解析图元素</strong></p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM2-notation.png" title="LSTM2-notation"></div><p>Neural Network Layer: 学习到的网络层</p><p>Pointwise Operation: pointwise操作，如向量的和</p><p>Vector Transfer: 传输一整个向量，从一个节点输出到其他节点的输入</p><p>Concatenate: 向量的连接</p><p>Copy: 内容被复制，然后分发到不同的位置</p><h2 id="The-Core-Idea-Behinds-LSTMs"><a href="#The-Core-Idea-Behinds-LSTMs" class="headerlink" title="The Core Idea Behinds LSTMs"></a>The Core Idea Behinds LSTMs</h2><p>LSTM的关键是细胞状态，水平线在图上方贯穿运行。</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-C-line.png" title="LSTM3-C-line"></div><p>细胞状态类似于传送带，直接在整个链上运行，只有一些少量的线性交互，信息在上面流传保持不变会变得很容易。</p><p>LSTM通过精心设计的“<strong>门(gates)</strong>”结构来去除或者增加信息到细胞状态的能力。</p><p>门是一种让信息选择式的通过的方法，包含一个sigmoid神经网络层和一个pointwise乘法操作。</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-gate.png" title="LSTM3-gate"></div><p>Sigmoid层输出0-1之间的数值，描述每个部分有多少量可以通过。0表示“不允许任何量通过”，1表示“允许任意量通过”。</p><p>LSTM有三个门，来保护和控制细胞状态。</p><h2 id="Step-by-Step-LSTM-Walk-Through"><a href="#Step-by-Step-LSTM-Walk-Through" class="headerlink" title="Step-by-Step LSTM Walk Through"></a>Step-by-Step LSTM Walk Through</h2><p>第一步<strong>决定从细胞状态中丢弃什么信息</strong>。通过<strong>忘记门层(forget gate layer)</strong>完成。该门读取$h_{t-1}$和$x_t$，输出一个0-1之间的数值给每个在细胞状态$C_{t-1}$中的数字。1表示完全保留，0表示完全舍弃。</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-focus-f.png" title="LSTM3-focus-f"></div><p>第二步<strong>决定什么样的新信息被存放到细胞状态中</strong>。包含两个部分，一是sigmoid层（输入门层）决定什么值将要更新，还有一个是tanh层将创建一个新的候选值向量$\tilde{C}_t$，会被加入到状态中。</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-focus-i.png" title="LSTM3-focus-i"></div><p>第三步<strong>确定更新信息</strong>。$C_{t-1}$更新为$C_t$。把旧状态与$f_t$相乘，丢弃掉确定需要丢弃的信息。接着加上$i_t \times \tilde{C}_t$，即是新的候选值，根据我们决定更新每个状态的程度进行变化。</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-focus-C.png" title="LSTM3-focus-C"></div><p>第四步<strong>更新细胞状态</strong>。最终，确定输出什么值，这个输出将会基于我们的细胞状态，但也是一个过滤后的版本。</p><p>首先，运行一个sigmoid层来确定细胞状态的哪一部分将输出出去。接着，把细胞状态通过tanh进行处理，得到一个在-1到1之间的值，并将其与sigmoid门的输出相乘。最终，仅输出我们确定输出的那部分。</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-focus-o.png" title="LSTM3-focus-o"></div><h2 id="Variants-on-LSTMs"><a href="#Variants-on-LSTMs" class="headerlink" title="Variants on LSTMs"></a>Variants on LSTMs</h2><p>以上介绍的是正常的LSTM结构，实际使用上，都会采用微小的变体。</p><p>1、流形的LSTM变体。</p><p>是由<a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="noopener">Gers &amp; Schmidhuber(2000)</a>提出的，增加了”peephole connection”。让 门层 也会接受细胞状态的输入。</p><div style="width:70%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-var-peepholes.png" title="LSTM3-var-peepholes"></div><p>图例中是所有部分都加入了peephole到每个门上，也有加入部分的peephole。</p><p>2、使用coupled忘记和输入门。</p><p>不同于之前是分开确定什么忘记和需要添加什么新的信息，这里是一同做出决定。We only forget when we’re going to input something in its place. We only input new values to the state when we forget something older.</p><div style="width:50%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-var-tied.png" title="LSTM3-var-tied"></div><p>仅仅在输入的当前位置进行忘记，仅仅输入新的值到已经忘记的旧的信息状态里。</p><p>3、Gated Recurrent Unit (GRU)</p><p>是由<a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Cho,et al.(2014)</a>提出的。将忘记门和输入门合成一个单一的 <strong>更新门</strong>。同样还混合了细胞状态和隐藏状态以及其他一些改动。最终的模型比标准的LSTM模型更加简单。</p><div style="width:50%;margin:auto"><img src="/blog/2020/07/07/LSTM网络理解/LSTM3-var-GRU.png" title="LSTM3-var-GRU"></div><p>还有很多其他类型变体形式，如<a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="noopener">Yao,et al.(2015)</a>提出的Depth Gated RNN。<a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="noopener">Koutnik, et al.(2014)</a>提出的Clockwork RNN。<a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="noopener">Greff, et al.(2015)</a>给出了流行的LSTM变体的比较，结论是基本一样。<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">Jozefowicz,et al.(2015)</a>在超过10000种RNN架构上进行了测试，发现一些架构在某些任务上也取得了比LSTM更好的结果。</p><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">参考资料——colah’s blog</a></p>]]></content>
    
    <summary type="html">
    
      LSTM网络原理理解
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="LSTM网络" scheme="https://jiangxj.top/blog/tags/LSTM%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>数据科学中需要用到的数学</title>
    <link href="https://jiangxj.top/blog/2020/06/10/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E4%B8%AD%E9%9C%80%E8%A6%81%E7%94%A8%E5%88%B0%E7%9A%84%E6%95%B0%E5%AD%A6/"/>
    <id>https://jiangxj.top/blog/2020/06/10/数据科学中需要用到的数学/</id>
    <published>2020-06-10T02:22:20.000Z</published>
    <updated>2021-06-02T03:53:14.375Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote><p>摘自Benjamin Obi Tayo Ph.D.博文</p></blockquote><img src="/blog/2020/06/10/数据科学中需要用到的数学/1_P7GJzEC-0f_IqbQH677uVw.png" title="数据科学中用到的数学"><h1 id="I-Introduction"><a href="#I-Introduction" class="headerlink" title="I. Introduction"></a>I. Introduction</h1><p>If you are a data science aspirant, you no doubt have the following questions in mind:</p><p><strong><em>Can I become a data scientist with little or no math background?\</em></strong></p><p><strong><em>What essential math skills are important in data science?\</em></strong></p><p>There are so many good packages that can be used for building predictive models or for producing data visualizations. Some of the most common packages for descriptive and predictive analytics include:</p><ul><li>Ggplot2</li><li>Matplotlib</li><li>Seaborn</li><li>Scikit-learn</li><li>Caret</li><li>TensorFlow</li><li>PyTorch</li><li>Keras</li></ul><p>Thanks to these packages, anyone can build a model or produce a data visualization. However, very solid background knowledge in mathematics is essential for fine-tuning your models to produce reliable models with optimal performance. It is one thing to build a model, it is another thing to interpret the model and draw out meaningful conclusions that can be used for data-driven decision making. It’s important that before using these packages, you have an understanding of the mathematical basis of each, that way you are not using these packages simply as black-box tools.</p><h1 id="II-Case-Study-Building-A-Multiple-Regression-Model"><a href="#II-Case-Study-Building-A-Multiple-Regression-Model" class="headerlink" title="II. Case Study: Building A Multiple Regression Model"></a><strong>II. Case Study: Building A Multiple Regression Model</strong></h1><p>Let’s suppose we are going to be building a multi-regression model. Before doing that, we need to ask ourselves the following questions:</p><p><em>How big is my dataset?</em></p><p><em>What are my feature variables and target variable?</em></p><p><em>What predictor features correlate the most with the target variable?</em></p><p><em>What features are important?</em></p><p><em>Should I scale my features?</em></p><p><em>How should my dataset be partitioned into training and testing sets?</em></p><p><em>What is principal component analysis (PCA)?</em></p><p><em>Should I use PCA for removing redundant features?</em></p><p><em>How do I evaluate my model? Should I used R2 score, MSE, or MAE?</em></p><p><em>How can I improve the predictive power of the model?</em></p><p><em>Should I use regularized regression models?</em></p><p><em>What are the regression coefficients?</em></p><p><em>What is the intercept?</em></p><p><em>Should I use non-parametric regression models such as KNeighbors regression or support vector regression?</em></p><p><em>What are the hyperparameters in my model, and how can they be fine-tuned to obtain the model with optimal performance?</em></p><p>Without a sound math background, you wouldn’t be able to address the questions raised above. The bottom line is that in data science and machine learning, mathematical skills are as important as programming skills. As a data science aspirant, it is therefore essential that you invest time to study the theoretical and mathematical foundations of data science and machine learning. Your ability to build reliable and efficient models that can be applied to real-world problems depends on how good your mathematical skills are. To see how math skills are applied in building a machine learning regression model, please see this article: <a href="https://medium.com/swlh/machine-learning-process-tutorial-222327f53efb" target="_blank" rel="noopener">Machine Learning Process Tutorial.</a></p><p>Let’s now discuss some of the essential math skills needed in data science and machine learning.</p><h1 id="III-Essential-Math-Skills-for-Data-Science-and-Machine-Learning"><a href="#III-Essential-Math-Skills-for-Data-Science-and-Machine-Learning" class="headerlink" title="III. Essential Math Skills for Data Science and Machine Learning"></a>III. Essential Math Skills for Data Science and Machine Learning</h1><h2 id="1-Statistics-and-Probability"><a href="#1-Statistics-and-Probability" class="headerlink" title="1. Statistics and Probability"></a>1. Statistics and Probability</h2><p>Statistics and Probability is used for visualization of features, data preprocessing, feature transformation, data imputation, dimensionality reduction, feature engineering, model evaluation, etc.</p><p>Here are the topics you need to be familiar with: <strong>Mean, Median, Mode, Standard deviation/variance, Correlation coefficient and the covariance matrix, Probability distributions (Binomial, Poisson, Normal), p-value, Baye’s Theorem (Precision, Recall, Positive Predictive Value, Negative Predictive Value, Confusion Matrix, ROC Curve), Central Limit Theorem, R_2 score, Mean Square Error (MSE), A/B Testing, Monte Carlo Simulation*</strong></p><h2 id="2-Multivariable-Calculus"><a href="#2-Multivariable-Calculus" class="headerlink" title="2. Multivariable Calculus"></a>2. Multivariable Calculus</h2><p>Most machine learning models are built with a dataset having several features or predictors. Hence, familiarity with multivariable calculus is extremely important for building a machine learning model.</p><p>Here are the topics you need to be familiar with: <strong><em>Functions of several variables; Derivatives and gradients; Step function, Sigmoid function, Logit function, ReLU (Rectified Linear Unit) function; Cost function; Plotting of functions; Minimum and Maximum values of a function\</em></strong></p><h2 id="3-Linear-Algebra"><a href="#3-Linear-Algebra" class="headerlink" title="3. Linear Algebra"></a>3. Linear Algebra</h2><p>Linear algebra is the most important math skill in machine learning. A data set is represented as a matrix. Linear algebra is used in data preprocessing, data transformation, dimensionality reduction, and model evaluation.</p><p>Here are the topics you need to be familiar with: <strong><em>Vectors; Norm of a vector; Matrices; Transpose of a matrix; The inverse of a matrix; The determinant of a matrix; Trace of a Matrix; Dot product; Eigenvalues; Eigenvectors\</em></strong></p><h2 id="4-Optimization-Methods"><a href="#4-Optimization-Methods" class="headerlink" title="4. Optimization Methods"></a>4. Optimization Methods</h2><p>Most machine learning algorithms perform predictive modeling by minimizing an objective function, thereby learning the weights that must be applied to the testing data in order to obtain the predicted labels.</p><p>Here are the topics you need to be familiar with: <strong><em>Cost function/Objective function; Likelihood function; Error function; Gradient Descent Algorithm and its variants (e.g. Stochastic Gradient Descent Algorithm)\</em></strong></p><h1 id="IV-Summary-and-Conclusion"><a href="#IV-Summary-and-Conclusion" class="headerlink" title="IV. Summary and Conclusion"></a>IV. Summary and Conclusion</h1><p>In summary, we’ve discussed the essential math and theoretical skills that are needed in data science and machine learning. There are several free online courses that will teach you the necessary math skills that you need in data science and machine learning. As a data science aspirant, it’s important to keep in mind that the theoretical foundations of data science are very crucial for building efficient and reliable models. You should, therefore, invest enough time to study the mathematical theory behind each machine learning algorithm.</p><h1 id="V-References"><a href="#V-References" class="headerlink" title="V. References"></a>V. References</h1><p><a href="https://medium.com/towards-artificial-intelligence/linear-regression-basics-for-absolute-beginners-68ed9ff980ae" target="_blank" rel="noopener">Linear Regression Basics for Absolute Beginners.</a></p><p><a href="https://medium.com/towards-artificial-intelligence/mathematics-of-principal-component-analysis-with-r-code-implementation-595a340908fa" target="_blank" rel="noopener">Mathematics of Principal Component Analysis with R Code Implementation.</a></p><p><a href="https://medium.com/swlh/machine-learning-process-tutorial-222327f53efb" target="_blank" rel="noopener">Machine Learning Process Tutorial.</a></p>]]></content>
    
    <summary type="html">
    
      data science中用到的数学
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="data science" scheme="https://jiangxj.top/blog/tags/data-science/"/>
    
      <category term="math" scheme="https://jiangxj.top/blog/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu代理软件Qv2ray使用</title>
    <link href="https://jiangxj.top/blog/2020/05/27/ubuntu%E4%BB%A3%E7%90%86%E8%BD%AF%E4%BB%B6Qv2ray%E4%BD%BF%E7%94%A8/"/>
    <id>https://jiangxj.top/blog/2020/05/27/ubuntu代理软件Qv2ray使用/</id>
    <published>2020-05-27T09:20:03.000Z</published>
    <updated>2020-06-18T02:07:45.293Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Qv2ray是一款全平台的代理软件，简单配置就可以使用。</p><p><a href="https://github.com/Qv2ray/Qv2ray" target="_blank" rel="noopener">官方github地址</a></p><p><a href="https://qv2ray.github.io/" target="_blank" rel="noopener">官方手册</a></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>官方库下载release的版本（下的2.5.0的），下载的是Ubuntu的程序包：</p><p><code>Qv2ray.v2.5.0.linux-x64.AppImage</code></p><p>下载的是<code>.appimage</code>文件，右键属性，在权限一栏，勾选上<code>允许作为程序执行文件</code>，双击打开，进入软件。</p><h3 id="v2ray内核设置"><a href="#v2ray内核设置" class="headerlink" title="v2ray内核设置"></a>v2ray内核设置</h3><p>进入软件后，点击首选项，设置v2ray内核。</p><p>这里首先需要下载<a href="https://github.com/v2ray/v2ray-core/releases/" target="_blank" rel="noopener">v2ray-core</a></p><p>然后将其放到Qv2ray的资源目录中。配置如下：</p><img src="/blog/2020/05/27/ubuntu代理软件Qv2ray使用/qv2ray1.png" title="配置方法"><h3 id="加入订阅链接"><a href="#加入订阅链接" class="headerlink" title="加入订阅链接"></a>加入订阅链接</h3><p>直接订阅之后，连接服务器即可</p><p>Qv2ray的代理端口配置：</p><img src="/blog/2020/05/27/ubuntu代理软件Qv2ray使用/qv2ray2.png" title="代理端口配置"><h3 id="系统代理端口设置"><a href="#系统代理端口设置" class="headerlink" title="系统代理端口设置"></a>系统代理端口设置</h3><img src="/blog/2020/05/27/ubuntu代理软件Qv2ray使用/Qv2ray3.png" title="系统代理端口设置"><h3 id="浏览器的代理配置"><a href="#浏览器的代理配置" class="headerlink" title="浏览器的代理配置"></a>浏览器的代理配置</h3><p>使用的是chrome插件：switchOmega 。配置如下：</p><img src="/blog/2020/05/27/ubuntu代理软件Qv2ray使用/qv2ray4.png" title="浏览器代理配置"><h3 id="windows端配置"><a href="#windows端配置" class="headerlink" title="windows端配置"></a>windows端配置</h3><p>下载clash for windows安装后，配置一键导入即可。</p><p><a href="https://javid.cn/qv2ray/" target="_blank" rel="noopener">本文参考来源</a></p><p>附：</p><p>在Ubuntu18.04上用<a href="https://github.com/jiangxufeng/v2rayL" target="_blank" rel="noopener">v2rayL</a>代理软件<a href="https://javid.cn/ubuntuproxy/" target="_blank" rel="noopener">教程</a>。需要的环境较为苛刻（Ubuntu18.04+python3.6），一直没能在Ubuntu16.04上配置成功.</p>]]></content>
    
    <summary type="html">
    
      ubuntu16.04平台使用Qv2ray代理软件
    
    </summary>
    
      <category term="教程" scheme="https://jiangxj.top/blog/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="Qv2ray" scheme="https://jiangxj.top/blog/tags/Qv2ray/"/>
    
  </entry>
  
  <entry>
    <title>概率神经网络和粒子群算法</title>
    <link href="https://jiangxj.top/blog/2020/05/20/%E6%A6%82%E7%8E%87%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95/"/>
    <id>https://jiangxj.top/blog/2020/05/20/概率神经网络-粒子群算法/</id>
    <published>2020-05-19T16:00:00.000Z</published>
    <updated>2020-05-15T02:32:42.172Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="概率神经网络"><a href="#概率神经网络" class="headerlink" title="概率神经网络"></a>概率神经网络</h1><p>Specht.D.F根据已有的神经网络理论同时融入概率学的相关知识，提出了概率神经网络的理论。概率神经网络是一种前馈神经网络，充分利用贝叶斯准则理论，能够进行较为准确的数据分类。在贝叶斯决策中，引用了概率密度函数的知识，同时充分结合了贝叶斯最小风险准则，实现了对数据的分类研究。概率神经网络已广泛应用于数据分类、模式识别、图像或语音识别等领域。</p><p>概率神经网络参数较少且内部的隐藏层不需要人为的设定，便于构建网络模型。同时使用贝叶斯准则大大提高了模式分类的准确性。在训练数据充足的情况下，能够很好地表达输入数据与输出数据的内在联系，即使在网络工作的过程中需要加入新的训练样本，网络的整体结构亦不需改进。</p><p><strong>概率神经网络与BP网络比较</strong>：</p><p>概率神经网络采用了 贝叶斯最小风险准则，在模式分类上具有较高的正确率，在故障诊断上有明显优势。</p><p>概率神经网络结构简单，需要调节的参数较少，更容易收敛。</p><p>根据贝叶斯理论，在一般情况下，概率神经网络的收敛值较为固定，达到了对故障知识的充分利用，结果的可信程度较高，而BP网络的输入到输出的过程中，存在不可预知的规则，受主观影响较大，结果存在不稳定的情况。</p><p>概率神经网络在工作过程中，增加或删除某些样本，网络的整体结构不会发生过大的变化，仅仅就是对某一层节点数的增加或删除。对于BP网络，增加或减少训练数据后，网络层与层之间的权值很可能发生改变，如不及时进行更新，输出结果很可能会偏离期望值。BP网络的训练数据的改变意味着整个网络的改变。</p><h1 id="粒子群算法"><a href="#粒子群算法" class="headerlink" title="粒子群算法"></a>粒子群算法</h1><p>粒子群算法(Particle Swarm Optimization)属于仿生学的优化算法。核心思想是从人为设定的随机解出发，通过不断的迭代寻找最优的适应度值。PSO没有像遗传算法那样的变异、交叉等复杂过程。</p><p><strong>算法原理</strong>：</p><p>在一个$D$维空间内，种群由$n$个粒子组成$X=(X_1,X_2,\dots,X_n)$，第$i$个粒子表示为1个$D$维的向量$Xi = (X_{i1},X_{i2},\dots,X_{iD})^T$，表示第$i$个粒子在$D$维空间中的位置，即问题的一个潜在解，由目标函数可以求出每个粒子的适应度值。第$i$个粒子的速度为$Vi = (V_{i1},V_{i2},\dots,V_{iD})^T$,其个体极值为$Pi = (P_{i1},P_{i2},\dots,P_{iD})^T$，群体极值为$P_g = (P_{g1},P_{g2},\dots,P_{gD})^T$。</p><p>在每次迭代过程中，粒子通过个体极值与群体极值更新自身的速度和位置，即：<br>$$<br>V_{id}^{k+1} = wV_{id}^k +c_1r_1(P_{id}^k - X_{id}^k) +c_2r_2(P_{gd}^k -X_{id}^k)<br>$$</p><p>$$<br>X_{id}^{k+1} = X_{id}^k + V_{id}^{k+1}<br>$$</p><p>其中：$i =1,2,\dots,n$，$n$表示群体的粒子数目</p><p>​           $d=1,2,\dots,D$,$D$是解空间维数</p><p>​           $k$表示当前迭代次数</p><p>​           $w$表示惯性权重</p><p>​           $X_{id}^k$为当前粒子在迭代到第$k$次的位置分量</p><p>​           $V_{id}^k$为当前粒子在迭代到第$k$次的速度分量</p><p>​          $P_{id}^k$为当前粒子在迭代到第$k$次的个体历史最优分量</p><p>​          $P_{gd}^k$为当前粒子在迭代到第$k$次的群体历史最优分量</p><p>​          $r_1,r_2$为[0,1]之间的随机数</p><p>​          $c_1,c_2$为非负的常数，称为学习因子。分别调节自身的认知能力和对群体的认知能力，对粒子寻找到最优值有重要作用。</p><p>在粒子在寻优过程中可能出现盲目搜索的现象，需要将粒子搜索的速度和位置限定在一定的区间内保证粒子在可行解空间内有目的的搜索。</p><p><strong>算法流程</strong>：</p><p>主要包括：初始化粒子、更新粒子的位置和速度、最优值的确定以及结束情况的判断。</p><ol><li>种群初始化。主要是在可行的解空间内设置：种群规模、学习因子、粒子的位置和速度、最大迭代次数、粒子执行搜索的空间范围和速度范围等参数。</li><li>适应度函数的建立。结合优化类型确定适应度函数，然后计算每一个粒子当前的适应度值，通过适应度值，确定粒子的群体极值与个体极值</li><li>对粒子的位置和速度进行更新</li><li>个体极值的确定，对于群体的每一个粒子，将当前适应度值与粒子自身历史适应度值进行比较。若优于历史适应度值，将当前适应度值作为个体极值，反之历史极值仍为个体极值</li><li>群体极值的确定。对于群体中的每一个粒子，将当前的适应度值与整个种群的最优适应度值进行比较。若优于群体最优适应度值，则将当前适应度值作为群体极值，反之，原群体极值仍为群体最优适应度值</li><li>对迭代是否结束进行判定，若达到预先设定的误差或者达到了最大的迭代次数，循环结束，输出得到最优值，反之，返回2继续执行。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">st=&gt;start: 开始</span><br><span class="line">op0=&gt;operation: 粒子群的初始化</span><br><span class="line">op1=&gt;operation: 计算粒子的适应度值</span><br><span class="line">op2=&gt;operation: 根据适应度值更新个体的极值和群体极值</span><br><span class="line">op3=&gt;operation: 更新粒子的速度和位置</span><br><span class="line">cond=&gt;condition: 满足终止条件</span><br><span class="line"></span><br><span class="line">e=&gt;end: 结束</span><br><span class="line"></span><br><span class="line">st-&gt;op0-&gt;op1-&gt;op2-&gt;op3-&gt;cond</span><br><span class="line">cond(yes)-&gt;e</span><br><span class="line">cond(no) -&gt;op1</span><br></pre></td></tr></table></figure><p><strong>粒子群算法在解空间内存有如下特点</strong>：</p><ol><li>算法无论在初始化还是寻优等方面都有一定的随机性，这样可以使得找到的结果尽可能地接近最优值，利于解决复杂问题。</li><li>对初值地设定随机，其变化不影响最终地结果</li><li>目标函数是粒子群算法地寻优依据，函数包括多种类型，包括不可微地函数</li><li>粒子群算法作为一种群体智能优化算法，过程易理解，适应性强</li><li>与GA的“优胜劣汰”不同，粒子群算法不遵循此项规则，从算法开始到结束，种群中的每一个粒子都参与算法寻优的全过程，使粒子群算法能够很好的表达种群的信息，寻优结果要优于遗传算法。</li></ol>]]></content>
    
    <summary type="html">
    
      概率神经网络和粒子群算法原理简介
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>深入理解机器学习原理及方法</title>
    <link href="https://jiangxj.top/blog/2020/05/20/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E5%8F%8A%E6%96%B9%E6%B3%95/"/>
    <id>https://jiangxj.top/blog/2020/05/20/深入理解机器学习原理及方法/</id>
    <published>2020-05-19T16:00:00.000Z</published>
    <updated>2020-05-15T02:54:27.842Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="chapter-2-统计学习理论"><a href="#chapter-2-统计学习理论" class="headerlink" title="chapter 2 统计学习理论"></a>chapter 2 统计学习理论</h2><h3 id="统计学习理论的一般框架"><a href="#统计学习理论的一般框架" class="headerlink" title="统计学习理论的一般框架"></a>统计学习理论的一般框架</h3><p>1、学习器的输入</p><p>领域集：一个任意的集合$\mathcal{X}$，称为实例空间</p><p>标签集：$\mathcal{Y}$</p><p>训练集：带标签的样本</p><p>2、学习器的输出</p><p>输出是一个预测规则：$h : \mathcal{X} \to \mathcal{Y}$。该函数也称为预测器/分类器，用来预测一个新的领域元素的标签。</p><p>3、数据生成模型</p><p>训练数据的产生过程：首先根据概率分布$\mathcal{D}$采集样本点$x_i$，然后利用标记函数$f: \mathcal{X} \to \mathcal{Y}$打上合适的标签。</p><p>4、衡量成功</p><p>分类器的误差：未能成功预测随机数据点正确标签的概率（随机数据点是从潜在的分布中生成的）。</p><p>$h$的误差是$h(x) \ne f(x)$的概率，其中$x$是根据分布$\mathcal{D}$采集的随机样本。</p><h3 id="经验风险最小化-ERM"><a href="#经验风险最小化-ERM" class="headerlink" title="经验风险最小化(ERM)"></a>经验风险最小化(ERM)</h3><p>一个学习算法的输入是一个训练集$S$，训练集从一个未知分布$\mathcal{D}$中采样获得，通过目标函数$f$对训练样本进行标记。</p><p>预测器$h_S : \mathcal{X} \to \mathcal{Y}$，学习算法目标是求出一个最小的预测器$h$，使得关于未知分布$\mathcal{D}$和$f$的预测误差最小化。<br>$$<br>L_S(h) \overset{\rm{def}}{=}\frac{|h(x_i) \ne y_i,i\in \{1,\dots,m\}|}{m}<br>$$<br>从预测器$h$出发到最小化$L_S(h)$，称为经验风险最小化（ERM）。</p><p>显然，无论样本是什么，$L_S(h_S) =0$，分类器会选择一种ERM算法（经验最小损失假设，没有分类器会比这种假设具有更小的误差），在训练集上效果很好，在验证集上效果很差，会出现过拟合问题。</p><h3 id="考虑归纳偏置的ERM"><a href="#考虑归纳偏置的ERM" class="headerlink" title="考虑归纳偏置的ERM"></a>考虑归纳偏置的ERM</h3><p>ERM规则容易导致过拟合，需要进行修正，找到使其不会过拟合的条件。</p><p>通常解决方案：在一个受限的搜索空间使用ERM学习准则。</p><p>一个学习器在接触到数据之前选择一个分类器的集合$\mathcal{H}$，这个集合称为<strong>假设类</strong>。每一个$h \in \mathcal{H}$是从$\mathcal{X}\to \mathcal{Y}$的一个函数。对于给定的假设类$\mathcal{H}$和一个训练样本集$S$，ERM学习器根据在$S$上的最小化概率误差，利用ERM规则选择一个预测器$h \in \mathcal{H}$。<br>$$<br>\rm{ERM}_{\mathcal{H}}(S)  \in \arg \min_{h \in \mathcal{H}} L_S(h) ,argmin表示从\mathcal{H}选择使L_S(h)最小的假设h<br>$$<br>通过限制学习器从$\mathcal{H}$中选择预测器，选择偏向于一个特别的预测器集合，这种限制称为归纳偏置。这种选择决定在于学习器接触训练数据之前，因此需要先验知识。</p><p>如果$\mathcal{H}$是有限类，当拥有足够多的训练样本，$\rm{ERM}_{\mathcal{H}}$将不会过拟合。</p><p>由于$L_{\mathcal{D,f}}(h_s)$是依赖于训练集$S$，训练集通过一个随机过程采样，因此通过风险$L_{\mathcal{D,f}}(h_s)$来选择预测器$h_s$也存在随机性，总有一定概率使得采样获得训练数据中有一些训练数据对于分布$\mathcal{D}$来说完全不具有代表性。一般来说，将采样得到的非代表性样本的概率表示为$\delta$，同时$1-\delta$称为置信参数(confidence parameter)。</p><p>由于无法保证标签预测绝对准确，引入一个参数评价预测的质量，称为精度参数(accuracy parameter)，记作$\varepsilon$，当$L_{\mathcal{D,f}}(h_s) \le \varepsilon$，认为算法输出一个近似正确的预测。</p><h2 id="chapter-3-概率近似正确-PAC-模型"><a href="#chapter-3-概率近似正确-PAC-模型" class="headerlink" title="chapter 3  概率近似正确(PAC)模型"></a>chapter 3  概率近似正确(PAC)模型</h2><p>一般学习模型——概率近似正确(PAC)学习模型</p><p>在经验风险最小化的规则下，对于一个有限假设类，如果有足够夺得训练样本（训练样本的数量独立于潜在的分布，并且独立于标记函数），那么输出的假设类是概率近似正确的。</p><blockquote><p>(PAC可学习)：若存在一个函数$m_{\mathcal{H}}:(0,1)^2 \to \mathbb{N}$和一个学习算法，使得对于任意$\varepsilon，\delta(0,1)$和$\mathcal{X}$上的任一分布$\mathcal{D}$，任意的标记函数$f:\mathcal{X} \to \{0,1\}$，如果在$\mathcal{H,D,f}$下满足可实现假设，那么当样本数量$m \ge m_{\mathcal{H}}(\varepsilon,\delta)$时，其中样本由分布$\mathcal{D}$独立同分布采样得到并且由函数$f$标记，算法将以不小于$1-\delta$的概率返回一个假设类$h$，使得该假设类$h$满足$L_{\mathcal{D,f}}(h) \le \varepsilon$</p></blockquote><p>PAC包含两个近似参数：准确度参数$\varepsilon$表征输出的分类器和最优分类器之间的距离（PAC的近似正确部分）；置信度参数$\delta$表征分类器达到准确要求的可能性（PAC的概率部分）。</p><p>函数$m_{\mathcal{H}}:(0,1)^2\to \mathbb{N}$决定学习假设类$\mathcal{H}$的采样复杂度：保证一个概率近似正确解所需要的样本数量。</p><p>任一有限假设类是PAC可学习的，其采样复杂度满足：<br>$$<br>m_{\mathcal{H}}(\varepsilon,\delta) \le \lceil \frac{\log(|\mathcal{H}|) / \delta}{\varepsilon} \rceil<br>$$</p><blockquote><p>(不可知PAC可学习)：若存在一个函数$m_{\mathcal{H}}:(0,1)^2 \to \mathbb{N}$和一个学习算法，使得对于任意$\varepsilon，\delta(0,1)$和$\mathcal{X}$上的任一分布$\mathcal{D}$，当样本数量$m \ge m_{\mathcal{H}}(\varepsilon,\delta)$时，其中样本由分布$\mathcal{D}$独立同分布采样得到，算法将以不小于$1-\delta$的概率返回一个假设类$h$，使得该假设类$h$满足：</p><p>$L_{\mathcal{D}}(h) \le \min \limits_{h’ \in \mathcal{H}} L_{\mathcal{D}}(h’)+   \varepsilon$</p></blockquote><p>不可知PAC可学习是PAC可学习的泛化，当不满足可实现的假设时，学习是不能保证任意小的误差的，然而，在不可知PAC学习的定义下，即使和假设类中最好的分类器有差距，学习器依然可以认为是学习成功的。PAC学习要求学习器学到的分类器，其误差达到一个很小的绝对值，而且和假设类可达到的最小误差没有关系。</p><p>学习问题建模</p><p>多分类问题：不再是二分类问题，对于这类任务，学习器需要根据已有的正确分类，对新的输入给出相应的正确分类。</p><p>回归问题：希望找到数据的简单模型——数据$\mathcal{X,Y}$之间的关联函数。度量是否成功的标准不同，可以使用期望平方差来评估假设函数$h:\mathcal{X} \to \mathcal{Y}$给出的预测值与真实值之间的差异，即：<br>$$<br>L_{\mathcal{D}}(h) \overset{def}{=} \mathbb{E}_{(x,y) \sim \mathcal{D}} (h(x) - y)^2<br>$$<br>分类问题的损失函数：</p><p>0-1损失：随机变量$z$取值序列对集合$\mathcal{X} \times \mathcal{Y}$，损失函数为：<br>$$<br>\mathscr{L}_{0-1}(h,(x,y))\overset{def} = \cases{0 \qquad 若h(x) = y \ 1 \qquad 若h(x) \ne y}<br>$$<br>平方损失：随机变量$z$取值序列对集合$\mathcal{X} \times \mathcal{Y}$，损失函数为：<br>$$<br>\mathscr{L}_{sq} (h,(x,y)) \overset{def} = (h(x) - y)^2<br>$$</p><h2 id="chapter-4-一致收敛"><a href="#chapter-4-一致收敛" class="headerlink" title="chapter 4 一致收敛"></a>chapter 4 一致收敛</h2><p>在可实现的假设下，任何有限的假设类都是PAC可学习的。</p><p>一致收敛：用来表明在有一般损失函数的不可知PAC模型中，只要距离损失函数是有界的，任何有限类都是可学习的。</p><h2 id="chapter-5-没有免费午餐定理-amp-误差分解"><a href="#chapter-5-没有免费午餐定理-amp-误差分解" class="headerlink" title="chapter 5  没有免费午餐定理&amp;误差分解"></a>chapter 5  没有免费午餐定理&amp;误差分解</h2><p>没有学习器能在所有的任务上学习成功，具体阐述为：</p><blockquote><p>(没有免费午餐定理) 对实例空间$\mathcal{X}$上0-1损失的二分任务，令$A$表示任意的学习算法，样本大小$m$表示小于$\frac{|\mathcal{X}|}{2}$的任意数，则在$\mathcal{X} \times \{0,1\}$上存在一个分布$\mathcal{D}$，使得：</p><p>1、存在一个函数$f:\mathcal{X} \to \{0,1\}$，满足$L_{\mathcal{D}}(f) = 0$</p><p>2、在样本集$\mathcal{S} \sim \mathcal{D}^m$上，以至少$\frac{1}{7}$的概率满足$L_{\mathcal{D}}(A(S)) \ge \frac{1}{8}$</p></blockquote><p>对于每个学习器，都存在一个任务使其失败，即使这个任务能够被另一个学习器成功学习。即 不存在通用的学习器，每个学习器都有其特定的任务，为了学习成功要采用一些关于任务的先验知识。</p><p>误差分解</p><p>将一个$\rm{ERM}_{\mathcal{H}}$预测器的误差分解为两部分，$h_S$是预测器的一个假设，有：<br>$$<br>L_{\mathcal{D}}(h_S) = \varepsilon _{app} + \varepsilon_{est}<br>$$<br>其中：$\varepsilon_{app} = \min\limits_{h \in \mathcal{H}} L_{\mathcal{D}}(h)$</p><p>逼近误差：假设类里预测器所取得的最小风险。由于限制到一个具体假设类所引起的风险，即所产生的归纳偏置。逼近误差不依赖于样本大小，取决于所选择的假设类。扩大假设类可以减小逼近误差。</p><p>估计误差：逼近误差与ERM预测器误差之间的差异。产生原因是：经验风险（训练误差）是真实风险的一个估计，最小化经验风险预测器只是最小化真实风险预测器的一个估计。</p><h2 id="chapter-6-VC维"><a href="#chapter-6-VC维" class="headerlink" title="chapter 6  VC维"></a>chapter 6  VC维</h2><h3 id="VC维概述"><a href="#VC维概述" class="headerlink" title="VC维概述"></a>VC维概述</h3><p>如果不对假设类加以限制，任何学习算法总会遇到表现很差的情况，与此同时，总是有学习算法在此情况下表现很好。</p><p>使用一个有限集$C \subset \mathcal{X}$，并且考虑在$C$上元素的分布族，其中每个分布由从$C$到$\{0,1\}$目标函数产生，为了使得任何算法都失败，可以从由$C$到$\{0,1\}$所有可能的函数构成的集合中选择一个目标函数。</p><p>考虑到一个假设类$\mathcal{H}$的PAC可学习性，需要构建一些分布使得某些假设$h \in \mathcal{H}$达到零风险。</p><blockquote><p>（限制$\mathcal{H}$在$C$上）令$\mathcal{H}$是从$\mathcal{X}$到$\{0,1\}$的一个函数类，并且令$C = \{c_1,\dots,c_m\} \subset \mathcal{X}$。限制$\mathcal{X}$在$C$上就是由来自$\mathcal{H}$从$C$上到$\{0,1\}$的函数构成的集合。即：<br>$$<br>\mathcal{H}_C =\{[h(c_1),\dots,h(c_m)]:h\in \mathcal{H}\}<br>$$<br>将每个从$C$到$\{0,1\}$的函数表示为形如$\{0,1\}^{|C|}$的向量。</p></blockquote><blockquote><p>（打散）如果限制$\mathcal{H}$在$C$上是从$C$到$\{0,1\}$的所有函数的集合，则假设类$\mathcal{H}$打散了有限集$C \subset \mathcal{X}$，此时$|\mathcal{H}_C | = 2^{|C|}$。</p></blockquote><blockquote><p>（VC维）假设类$\mathcal{H}$的VC维，记作VCdim($\mathcal{H}$)，是$\mathcal{H}$可以打散的最大集合$C \subset \mathcal{X}$的大小，如果$\mathcal{H}$可以打散任意大的集合，称$\mathcal{H}$的VC维是无穷的。</p><p>令$\mathcal{H}$是无穷VC维的假设类，那么$\mathcal{H}$不是PAC可学习的。</p></blockquote><h3 id="PAC学习的基本定理"><a href="#PAC学习的基本定理" class="headerlink" title="PAC学习的基本定理"></a>PAC学习的基本定理</h3><p>VC维无限的类不是可学习的，因此可以得到统计学习的基本定理：</p><p>令$\mathcal{H}$是一个由从$\mathcal{X}$到$\{0,1\}$的映射函数构成的假设类，且令损失函数为0-1损失，下面说法等价：</p><p>1、$\mathcal{H}$有一致收敛性</p><p>2、任何ERM规则都是对于$\mathcal{H}$成功的不可知PAC学习器</p><p>3、$\mathcal{H}$是不可知PAC可学习的</p><p>4、$\mathcal{H}$是PAC可学习的</p><p>5、任何ERM规则都是对$\mathcal{H}$成功的PAC学习器</p><p>6、$\mathcal{H}$的VC维有限</p><h2 id="chapter-7-不一致可学习"><a href="#chapter-7-不一致可学习" class="headerlink" title="chapter 7 不一致可学习"></a>chapter 7 不一致可学习</h2><h3 id="不一致可学习概述"><a href="#不一致可学习概述" class="headerlink" title="不一致可学习概述"></a>不一致可学习概述</h3><p>不一致可学习 允许学习器针对所竞争的不同假设使用不同数量的样本，认为一个假设$h$以$(\varepsilon ,\delta)$可与另一个假设$h’$竞争，$L_{\mathcal{D}}(h) \le L_{\mathcal{D}}(h’) + \varepsilon$成立的概率不少于$(1-\delta)$。</p><p>在PAC可学习中，当我们寻找具有绝对的最小风险的假设（在可能的情况下）或者寻找一个与最小风险差不多风险（在绝对最小风险不可知情况下）的假设，样本数量仅仅依赖于精度和置信度。、</p><p>在不一致学习中，允许样本数量以$m_{\mathcal{H}}(\varepsilon ,\delta,h)$的形式表示，也即，不一致可学习在表现形式上也依赖<strong>竞争力变量</strong>$h$。</p><blockquote><p>（不一致可学习）若存在一个学习算法$A$和一个函数$m_{H}^{NUL}:(0,1)^2 \times \mathcal{H} \to \mathbb{N}$，使得对于任意的$\varepsilon,\delta \in (0,1)，h \in \mathcal{H}$，如果样本数量$m \ge m_{H}^{NUL}(\varepsilon ,\delta,h)$，那么对每个分布$\mathcal{D}$和所有的样本$\mathcal{S} \sim \mathcal{D}^m$，下式成立的概率不少于$1-\delta$，<br>$$<br>L_{\mathcal{D}}(A(S)) \le L_{\mathcal{D}}(h) + \varepsilon<br>$$<br>则假设类$\mathcal{H}$是不一致可学习的。</p></blockquote><h3 id="结构风险最小化-SRM"><a href="#结构风险最小化-SRM" class="headerlink" title="结构风险最小化(SRM)"></a>结构风险最小化(SRM)</h3><p>通过具体化一个假设类$\mathcal{H}$来利用先验知识，并且相信这样一个假设类中包含完成当前任务的有效预测器。</p><p>另一种表达先验知识的方式是将假设类$\mathcal{H}$上的偏好具体化，在结构风险最小化范例中，首先假定$\mathcal{H}$能够写成$\mathcal{H} = \mathop{\cup}\limits_{n \in N}\mathcal{H}_n$，然后具体化一个权重函数：$\omega:\mathbb{N} \to [0,1]$，这个权重函数给每个假设类赋予一个权重，高的权值表示对该假设类的强烈偏好。</p><blockquote><p>先验：$\mathcal{H} = \mathop{\cup}\limits_{n \in N}\mathcal{H}_n$，$\mathcal{H}_n$满足一致收敛，复杂度函数为$m_{\mathcal{H}_n}^{UC}$</p><p>​            $\omega: \mathbb{N} \to [0,1]$，其中$\sum\limits_{n}\omega(n) \le 1$</p><p>定义：$\varepsilon_n(m,\delta) = \min \{\varepsilon \in (0,1):m_{\mathcal{H}_n}^{UC}(\varepsilon,\delta) \le m\}$，$n_h = \min\{n: h \in \mathcal{H}_n\}$</p><p>输入：训练集$S \sim \mathcal{D}^m$，置信度$\delta$</p><p>输出：$h \in \arg \min\limits_{h \in \mathcal{H}}[L_S(h) + \varepsilon_{n(h)} (m,\omega(n(h))·\delta)]$</p></blockquote><p>与经验风险最小化不同，SRM不仅关心经验风险$L_S(h)$，而且为了最小化估计误差，更加关心在最小经验风险的偏置和$\varepsilon_{n(h)} (m,\omega(n(h))·\delta)]$最小化之间取得一个平衡。</p><h2 id="chapter-9-线性预测"><a href="#chapter-9-线性预测" class="headerlink" title="chapter 9 线性预测"></a>chapter 9 线性预测</h2><p>定义仿射函数类：<br>$$<br>L_d = \{h_{\omega,b}: \pmb \omega \in \mathbb{R}^d，b \in \mathbb{R}\}<br>$$</p><p>$$<br>h_{\omega,b} (\pmb x) = &lt;\pmb{\omega ,x}&gt; + b = \left( \sum\limits_{i=1}^{d} \omega_i x_i\right) +b<br>$$</p><p>记作：$L_d = \{ \pmb{x\mapsto&lt;\omega,x&gt;} +b:\omega \in \mathbb{R}^d , b \in \mathbb{R}\}$</p><p>$L_d$是函数集合，其中每个函数被$\pmb \omega \in \mathbb{R}^d$和$b \in \mathbb{R}$参数化，并以向量$\pmb x$作为输入，以标量$&lt;\pmb {\omega,x}&gt;+b$作为输出。</p><p>将偏移量$b$包含在$\pmb \omega$中，可以写成$\pmb \omega’ = (b,\omega_1,\dots,\omega_d) \in \mathbb{R}^{d+1}$且$\pmb x ‘ =(1,x_1,\dots,x_d) \in \mathbb{R}^{d+1}$，从而有：<br>$$<br>h_{\omega,b} (\pmb x) = &lt;\pmb{\omega ,x}&gt; + b = &lt;\pmb {\omega’,x’}&gt;<br>$$</p><h3 id="线性规划"><a href="#线性规划" class="headerlink" title="线性规划"></a>线性规划</h3><p>在线性不等式约束下最大化线性函数，即：<br>$$<br>\max\limits_{\omega \in \mathbb{R}^d} &lt;\pmb {u,\omega}&gt; \ s.t. A\pmb \omega \ge \pmb v<br>$$<br>其中，$\pmb \omega \in \mathbb{R}^d$是希望求解的参数向量，$A$是$m \times d$维矩阵，$\pmb v \in \mathbb{R}^m,\pmb u \in \mathbb{R}^d$为向量。</p><h3 id="感知器算法"><a href="#感知器算法" class="headerlink" title="感知器算法"></a>感知器算法</h3><p>构建一系列的向量$\pmb{\omega^{(1)},\omega^{(2)},\dots}$，初始的$\pmb {\omega^{(1)}} = 0$，在第$t$次迭代时，感知器找到被$\pmb {\omega^{(t)}}$错分的样本$i$，该样本使得${sign}(&lt;\pmb{\omega^{(t)},x_i}&gt;) \ne y_i$，通过将样本$\pmb x_i$乘比例系数$y_i$加入向量，感知器的更新$\pmb \omega^{(t)}$使得$\pmb \omega^{(t+1)} = \pmb \omega ^{(t)} + y_i \pmb x_i$。</p><p>目标是对所有的$i$有$y_i \langle\pmb \omega ,\pmb x_i\rangle &gt; 0$且：<br>$$<br>y_i \langle \pmb\omega^{(t+1)},\pmb x_i\rangle = y_i \langle \pmb\omega^{(t)}+y_i \pmb x_i,\pmb x_i\rangle = y_i \langle \pmb\omega^{(t)},\pmb x_i\rangle + ||\pmb x_i||^2<br>$$</p><blockquote><p>感知器批处理算法</p><p>输入：训练集$(\pmb x_1 , y_1),\dots,(\pmb x_m , y_m )$</p><p>初始化：$\pmb \omega^{(1)} = (0,\dots,0)$</p><p>循环： $t= 1,2,\dots $</p><p>​             如果$(\exists i\quad s.t.  \quad  y_i \langle \pmb\omega^{(t)},\pmb x_i\rangle\le 0 $，那么</p><p>​             $\pmb \omega^{(t+1)} = \pmb \omega ^{(t)} + y_i \pmb x_i$</p><p>​             否则</p><p>​                   输出$\pmb \omega^{(t)} $</p></blockquote><h2 id="chapter-10-boosting"><a href="#chapter-10-boosting" class="headerlink" title="chapter 10 boosting"></a>chapter 10 boosting</h2>]]></content>
    
    <summary type="html">
    
      《深入理解机器学习原理及方法》研读
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>编译器原理简介</title>
    <link href="https://jiangxj.top/blog/2020/05/20/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    <id>https://jiangxj.top/blog/2020/05/20/编译器/</id>
    <published>2020-05-19T16:00:00.000Z</published>
    <updated>2020-05-15T02:31:48.776Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>1、概念</p><p>广义上说，能把高级语言转化为低级语言的都算编译器，编译的存在就是为高级语言服务。</p><p>计算机语言分为三层，最底层，机器语言，即0和1；往上是汇编语言，指明操作什么部件干什么活，是对机器干活的描述，再往上是高级语言，人不用理机器干什么活，只需要明确地表达自己要达到什么目的。</p><p>对于CPU而言，只认识二进制的机器码，指挥CPU运行程序，需要一个“翻译”，将代码翻译成机器码给CPU，让它知道如何执行你的程序。常见的“翻译”工具有：汇编器、编译器、解释器。</p><p>汇编器：将汇编代码直接翻译成机器码，速度快，但可读性差，写大型程序很难实现。</p><p>编译器：将常用的高级语言，如Java/c++等，翻译成机器码，编译很慢，但是执行起来很快。</p><p>解释器：程序不需要编译，程序在运行时才翻译成机器码，每执行一次都要翻译一次。效率低，运行慢，典型的解释行语言如PHP/JS/Python。</p><p>2、Java代码的执行</p><p>依赖于Java虚拟机(JVM)，JVM能直接识别字节码。Java代码经过编译会产生class文件，即字节码文件，再交由JVM处理。当字节码被放到某种指令集的机器上，由运行环境中的虚拟机将字节码直接编译成该指令集的机器码然后执行，所以不管指令集是什么，只要更换运行环境中的虚拟机就能执行，从而实现跨平台性。</p><p><img src="https://pic1.zhimg.com/80/v2-3eed6368f57d6791327eed3536a58ab4_hd.jpg" alt="img"></p><p>以hotspot为例，有几种翻译形式：</p><p>（1）解释执行</p><p>逐条将字节码翻译成机器码并执行；无需等待编译</p><p>（2）即时编译（just-in-time,JIT）</p><p>将一个方法中包含的所有字节码编译成机器码后再执行；运行速度更快</p><p>在ART中，不要求跨平台性，直接在一个平台上运行，可以不用实时编译浪费时间。在ART中，直接将字节码在安装时编译为机器码，在安卓开发中，ART实际上是在机器上实现的，和编译器没有关系，编译器编译的还是字节码。</p><p>3、Android代码执行</p><p>开发Android目前最多的还是Java，Android工程中的Java源文件经过编译也是生成class文件，最后打包为DEX字节码文件，负责将DEX字节码翻译成字节码的是Dalvik或者ART。</p><p>在Android5.0之前，是Dalvik的天下，Dalvik是解释执行加上JIT，每次app运行时，动态的将一部分Dalvik字节码解释为机器码，随着app的运行，更多的字节码被编译和缓存。因为JIT只编译了一部分代码，具有更小的内存占用和更少的设备物理空间占用。但是边解释边执行，效率低下。</p><p>Android4.4开始，引入ART，到5.0，正式代替Dalvik，ART使用的是AOT(Ahead of time)的编译方式，即在应用安装过程中，就将所有的Dex字节码编译成机器码存储在设备空间中，完全抛弃JIT。带来的好处：</p><ul><li>app运行更快，直接运行机器码</li><li>减少应用的启动时间，本地代码可以直接执行</li><li>节省电量消耗，不需要再去一行一行解释字节码</li><li>增强了垃圾回收</li><li>增强了开发者工具</li></ul><p>但是，在安装期间翻译字节码，安装过程会很长，尤其是对一些大型应用来说，另外，安装过程中翻译出来的机器码占用了更大的机身存储空间。</p><p>Android7.0，又加入了JIT，一个具备代码分析功能的即时编译器，根据二八定律，经常运行的热点代码可能只占20%，甚至更少，没有必要通过AOT提前将所有的字节码翻译成机器码。安装过程中，放弃AOT，加快安装速度，初次使用时需要解释执行。使用app时，JIT开始分析代码，在合适的时候将字节码翻译成机器码，在Android应用运行时持续提高其性能，设备空闲时，AOT发挥作用，将热点代码翻译成机器码并保存下来，进一步提高运行效率。</p><p>现在的Android是 解释执行、JIT、AOT共存的。所做的无非是 安装速度、空间占用和运行速度的平衡。</p><p>4、现代编译器结构</p><p>现代编译器通常分为前端和后端，前端将高级语言转化为中间的统一代码，然后由后端将中间代码编译为机器代码，处理硬件架构相关的优化。</p><p><img src="https://pic4.zhimg.com/80/v2-12a256d50907445c4f9ef18f6def57b3_hd.jpg" alt="img"></p><p>当前最主要的编译器有两个：GCC和llvm。早在iOS4时xcode的前端有两种，gcc和clang，后端是llvm和GCC，后来统一为clang+llvm，而目前NDK前端也有GCC和clang，后端为llvm。但安卓已经全面放弃GCC全面转向clang。也就是说，当我们考虑一个现代编译器时，必须前后端同时考虑。</p><p>5、方舟编译器</p><p>IOS的快、流畅是建立在苹果强大的A系列处理器，精心设计的swift语言，继承swiftc编译命令的xcode工具，高效的IOS系统，严格的权限管理等基础上，称之为软硬件集合一体化的典范。</p><p>方舟编译器舍弃了现在Android中的ART虚拟机，不需要编译为字节码文件（DEX），在生成apk的安装包时直接编译生成的适合的机器码，在终端设备上安装后直接就可以执行，省去虚拟机，省去JIT和AOT。</p><p>PPT 中最后一句话是 “希望 APP 厂商尽快使用” ，并不是手机厂商，所以不排除方舟编译器可以直接将 Apk ，或者说 Apk 中的 DEX 打包成机器码格式。但由于机器码并不是平台兼容的，所以并不能确定方舟编译器是否必须要绑定 EMUI。</p><p>方舟编译器是为了改变现有的代码和编程习惯的基础上进行编译的优化，使得APP运行更为流畅，最终的目的是成为一个跨硬件平台、跨系统、跨语言的软件编译平台。编译器是一个桥梁，连接着上层的开发语言与底层的硬件，又与操作系统紧密结合，掌握了编译器，更换开发语言，更换硬件架构甚至更换操作系统都会有很大的帮助。</p><p><a href="https://zhuanlan.zhihu.com/p/62152260" target="_blank" rel="noopener">参考资料1</a></p><p><a href="https://blog.csdn.net/weixin_44946052/article/details/89441380" target="_blank" rel="noopener">参考资料2</a></p><p><a href="https://zhuanlan.zhihu.com/p/65307730" target="_blank" rel="noopener">参考资料3</a></p>]]></content>
    
    <summary type="html">
    
      编译器原理简介&amp;方舟编译器
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Anaconda教程</title>
    <link href="https://jiangxj.top/blog/2020/05/20/Anaconda%E6%95%99%E7%A8%8B/"/>
    <id>https://jiangxj.top/blog/2020/05/20/Anaconda教程/</id>
    <published>2020-05-19T16:00:00.000Z</published>
    <updated>2020-05-15T02:23:46.715Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="修改conda-的镜像源"><a href="#修改conda-的镜像源" class="headerlink" title="修改conda 的镜像源"></a>修改conda 的镜像源</h2><p>（现在不可用）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line"></span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure><p>此时，在目录 C:\Users&lt;你的用户名&gt; 下就会生成配置文件.condarc，内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: true</span><br></pre></td></tr></table></figure><h2 id="jupyter-notebook使用"><a href="#jupyter-notebook使用" class="headerlink" title="jupyter notebook使用"></a>jupyter notebook使用</h2><p>创建带jupyter notebook内核的虚拟环境：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name py37_Pytorch python=<span class="number">3.7</span> ipykernel</span><br></pre></td></tr></table></figure><p>关联和conda的环境和包：</p><p><code>conda install nb_conda</code></p><p>Markdown生成目录：</p><p><code>conda install -c conda-forge jupyter_contrib_nbextensions</code></p><p><a href="https://www.jianshu.com/p/91365f343585" target="_blank" rel="noopener">jupyter notebook使用教程</a></p><p>在虚拟环境下创建kernel文件：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="keyword">install</span> -n 环境名称 ipykernel</span><br></pre></td></tr></table></figure><p>将环境写入jupyter notebook的kernel中</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m ipykernel install --<span class="keyword">user</span> <span class="title">--name</span> 环境名称 --display-name <span class="string">"Python (环境名称)"</span></span><br></pre></td></tr></table></figure><h2 id="pip-安装-PyTorch步骤"><a href="#pip-安装-PyTorch步骤" class="headerlink" title="pip 安装 PyTorch步骤"></a>pip 安装 PyTorch步骤</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install https://download.pytorch.org/whl/cpu/torch<span class="number">-1.0</span><span class="number">.0</span>-cp37-cp37m-win_amd64.whl</span><br></pre></td></tr></table></figure><p>安装版本为<code>torch-1.0.0</code>，CPU版本，没有CUDA，python3.x版本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --no-deps torchvision</span><br></pre></td></tr></table></figure><p>不使用：<code>pip3 install torchvision</code>，会报错。</p><p><a href="https://redstonewill.com/1948/" target="_blank" rel="noopener">PyTorch安装</a></p><h2 id="pip和conda区别"><a href="#pip和conda区别" class="headerlink" title="pip和conda区别"></a>pip和conda区别</h2><p>conda是一种通用包管理系统，是一个与语言无关的跨平台的环境管理器，可以构建和管理任何语言的任何类型的软件。因此适用于python包。</p><p>pip代表pip install packages，是python官方认可的包管理器，最常用于安装python包索引（PyPI）上的发布的包。</p><p>conda install包，默认是安装在base（anaconda）环境下，conda在指定的环境下安装包：</p><p><code>conda install -n env_name pandas</code>。</p><p>anaconda是一个python的发行版，conda是一个包管理器。</p><h2 id="pip和pip3区别"><a href="#pip和pip3区别" class="headerlink" title="pip和pip3区别"></a>pip和pip3区别</h2><p>在安装库numpy，pip3 install numpy和pip install numpy命令效果一致的，但当有多个版本的python虚拟环境时，用pip3可以自动区别用python3来安装库文件，避免发生和python2的冲突。</p><p>若只安装了python3，pip和pip3是一样的效果，安装python3后，会自动安装pip3，添加scripts到环境变量(避免出现不是内部或外部命令问题)。</p><p>若多版本python存在，使用pip install ，新安装的库文件会放在目录：<code>python2.x/site_packages</code>中；使用 pip3 install ，新安装的库文件会放在目录：<code>python3.x/site-packages</code>中。</p><h2 id="一些常用命令"><a href="#一些常用命令" class="headerlink" title="一些常用命令"></a>一些常用命令</h2><p><code>conda activate env_name</code>激活环境，当前被激活环境前有*号</p><p><code>conda deactivate env_name</code>关闭环境</p><p>（Linux下）：</p><p><code>source activate/deactivate env_name</code></p><p><code>conda remove -n env_name --all</code>删除环境</p><p><code>conda create --name env_name python=3.x</code>创建一个基于python3.x的名为env_name的虚拟环境，同样正对于python2.x版本。</p><p><code>conda env list</code>查看所有安装的环境</p><p><code>conda install requests</code>安装包</p><p><code>conda install -n env_name numpy</code>安装在指定的环境下的包，若不指定，则是安装在当前活跃环境，也可通过-c指定某个channel来安装。</p><p><code>conda list</code>查看所安装的包</p><p><code>conda update requests</code>包更新</p><p><code>conda update -n env_name packages</code>指定环境下的包更新</p><p><code>conda remove requests</code>删除包</p><p><code>conda list -n env_name</code>查看指定环境下的已安装包</p><p><code>conda search numpy</code>查找package信息</p><hr><p>conda将conda、python等都看成packages，都可以通过conda来管理conda和python版本，如：</p><p><code>conda update conda</code>更新conda</p><p><code>conda update anaconda</code>更新当前环境下的anaconda。</p><p><code>conda update python</code>假设当前环境下的python为3.7版本，会升级为3.7.x系列的最新版本、</p><p>Anaconda的bin目录加入PATH，可能有不同的~/anaconadx/bin，：</p><p><code>echo &#39;export PATH = &quot;~/anaconda3/bin:$PATH&quot;&#39; &gt;&gt; ~/.bashrc</code>      Linux下的添加命令。</p><p>运行<code>conda --version</code>检查是否正确。</p><p><a href="https://www.jianshu.com/p/2f3be7781451#" target="_blank" rel="noopener">Anaconda基本使用总结</a></p>]]></content>
    
    <summary type="html">
    
      Anaconda使用简单教程
    
    </summary>
    
      <category term="教程" scheme="https://jiangxj.top/blog/categories/%E6%95%99%E7%A8%8B/"/>
    
    
  </entry>
  
  <entry>
    <title>hexo多终端同步</title>
    <link href="https://jiangxj.top/blog/2020/05/18/hexo%E5%A4%9A%E7%BB%88%E7%AB%AF%E5%90%8C%E6%AD%A5/"/>
    <id>https://jiangxj.top/blog/2020/05/18/hexo多终端同步/</id>
    <published>2020-05-18T07:27:23.000Z</published>
    <updated>2021-01-13T10:21:36.408Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="准备条件"><a href="#准备条件" class="headerlink" title="准备条件"></a>准备条件</h2><p>两台终端，其中一台已经被配置hexo+github博客平台（win平台）。</p><p>安装好node和hexo，git环境</p><p>其中node使用<code>nvm</code>进行安装：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvm <span class="built_in">list</span>  <span class="comment">#查找所有的node版本</span></span><br><span class="line">nvm use &lt;版本号&gt;  <span class="comment">#切换使用指定的版本</span></span><br></pre></td></tr></table></figure><h2 id="备份本地博客的文件"><a href="#备份本地博客的文件" class="headerlink" title="备份本地博客的文件"></a>备份本地博客的文件</h2><p>由于 Github 上保存的只是生成的网页静态文件，因此需要新建一个分支保存本地原始文件，方便在不同的电脑上写博客。需要解决备份问题。</p><p>机制是这样的，<code>hexo d</code>上传部署到GitHub的是hexo编译后的文件，用来生成网页的，不包含源文件。即上传的是在本地目录里自动生成的<code>.deploy_git</code>里面。其它文件，包括写在<code>source</code>里面的，和配置文件，主题文件，都没有上传到GitHub上。</p><p>所以可以利用git的分支管理，将源文件上传到GitHub的同一仓库的另一个分支即可。</p><p>创建两个分支：master 与 source，<br>在博客目录下：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>cd blog       <span class="comment">#注意要删除已经存在.git隐藏文件夹</span></span><br><span class="line"><span class="variable">$ </span>git init        <span class="comment">#在当前目录新建一个git代码库</span></span><br><span class="line"><span class="variable">$ </span>git add .     <span class="comment">#添加blog目录所有文件</span></span><br><span class="line"><span class="variable">$ </span>git branch hexo <span class="comment">#新建一个hexo分支</span></span><br><span class="line"><span class="variable">$ </span>git checkout hexo <span class="comment">#切换到hexo分支</span></span><br><span class="line"><span class="variable">$ </span>git remote add origin git<span class="variable">@github</span>.com：yourname/yourname.github.io.git <span class="comment">#本地与github项目对接</span></span><br><span class="line"><span class="variable">$ </span>git push origin hexo       /<span class="regexp">/将新的分支发布到GitHub上</span></span><br></pre></td></tr></table></figure><p>这样GitHub项目的库里会多出一个hexo分支，是用于多终端同步的关键部分。</p><p>出现以下错误：<code>error：failed to push some refs to</code></p><p>解决方法：<code>git pull --rebase origin master</code>。把远程库中的更新合并到本地库中。 </p><p>在另一个终端中更新博客，只需要将GitHub上source分支clone下来，进行初次相关配置。</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将Github中hexo分支clone到本地</span></span><br><span class="line"><span class="variable">$ </span>git clone -b hexo git<span class="variable">@github</span>.<span class="symbol">com:</span>yourname/yourname.github.io.git</span><br><span class="line"></span><br><span class="line">/jiangxjun.github.io  <span class="variable">$ </span>git checkout -b hexo     <span class="comment">#cheackout 远程代码到本地hexo分支</span></span><br><span class="line"><span class="comment"># 注意，这里一定要切换到刚刚clone的文件夹内执行</span></span><br><span class="line"><span class="variable">$ </span>git init</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个.md文件，并编辑完成自己的博客内容</span></span><br><span class="line"><span class="variable">$ </span>hexo new post <span class="string">"new blog name"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 经测试每次只要更新sorcerer中的文件到Github中即可，因为只是新建了一篇新博客</span></span><br><span class="line">/jiangxjun.github.io/hexo  <span class="variable">$ </span>git add source</span><br><span class="line"><span class="variable">$ </span>touch README</span><br><span class="line"><span class="variable">$ </span>git add README</span><br><span class="line"><span class="variable">$ </span>git commit -m <span class="string">"update blog"</span></span><br><span class="line"><span class="variable">$ </span>git remote add origin git<span class="variable">@github</span>.com：yourname/yourname.github.io.git</span><br><span class="line"><span class="comment"># 更新分支</span></span><br><span class="line"><span class="variable">$ </span>git push -u origin +hexo<span class="comment"># push更新完分支之后将自己写的博客对接到自己搭的博客网站上，同时同步了Github中的master</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#出现更新被拒绝，当前分支的最新提交落后于其对应的远程分支</span></span><br><span class="line"><span class="variable">$ </span>git fetch origin <span class="comment">#获取远程更新</span></span><br><span class="line"><span class="variable">$ </span>git merge origin/master <span class="comment"># 把更新内容合并到本地分支</span></span><br><span class="line"><span class="variable">$ </span>git push -u origin +hexo</span><br></pre></td></tr></table></figure><h2 id="遇到的坑"><a href="#遇到的坑" class="headerlink" title="遇到的坑"></a>遇到的坑</h2><p>在github上下载源代码时候，遇到<code>git clone</code>命令出现错误：</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Permissiondenied (publickey).</span><br><span class="line"></span><br><span class="line">fatal:Could <span class="keyword">not</span> <span class="built_in">read</span> <span class="built_in">from</span> remote repository.</span><br><span class="line"></span><br><span class="line">Please make sure you have <span class="keyword">the</span> correct access rights</span><br><span class="line"></span><br><span class="line"><span class="keyword">and</span> <span class="keyword">the</span> repository exists.</span><br></pre></td></tr></table></figure><p>原因是：本地（或服务器上）没有生成<code>ssh key</code>。解决办法如下：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">(base)</span> jiang@jiang-X299:~$ <span class="keyword">cd</span> ~<span class="string">/.ssh</span> <span class="keyword">ls</span></span><br><span class="line"><span class="keyword">ls</span> <span class="comment">#查看是否有文件id_rsa以及文件id_rsa.pub</span></span><br></pre></td></tr></table></figure><p>没有，则终端命令如下：</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> ssh-keygen -t rsa -C <span class="string">"your_email@example.com"</span>   <span class="comment">#修改为自己的邮箱，途中需要输入密码，不管，一路回车即可，即生成你的ssh key</span></span><br><span class="line"> ssh -v git@github.com  <span class="comment">#最后会出现No more authentication methods to try. </span></span><br><span class="line">                          Permission denied (publickey)</span><br><span class="line"> </span><br><span class="line">ssh-agent -<span class="keyword">s</span>      <span class="comment">#输入该命令，会出现SSH_AUTH_SOCK=/tmp/ssh-a94vS6DUEnSA/agent.14751; </span></span><br><span class="line">               export SSH_AUTH_SOCK;</span><br><span class="line">               SSH_AGENT_PID=<span class="number">14752</span>; export SSH_AGENT_PID;</span><br><span class="line">               echo Agent pid <span class="number">14752</span>;</span><br><span class="line"></span><br><span class="line">ssh-add ~<span class="regexp">/.ssh/id</span>_rsa    <span class="comment">#输入该命令，会出现identity added:(一些ssh key文件路径的信息)</span></span><br><span class="line">                      （注意）如果出现错误提示：Could <span class="keyword">not</span> <span class="keyword">open</span> a connection to your authentication agent.请执行命令：<span class="keyword">eval</span> <span class="string">`ssh-agent -s`</span>后继续执行命令 ssh-add ~<span class="regexp">/.ssh/id</span>_rsa</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">然后打开你刚刚生成的id_rsa.pub，将里面的内容复制，进入你的github账号，在settings下，SSH <span class="keyword">and</span> GPG <span class="keyword">keys</span>下new SSH key，title随便取一个名字，然后将id_rsa.pub里的内容复制到Key中，完成后Add SSH Key。</span><br><span class="line"></span><br><span class="line">最后一步，验证Key</span><br><span class="line"></span><br><span class="line">　　在ternimal下输入命令：</span><br><span class="line"></span><br><span class="line">　　ssh -T git@github.com</span><br><span class="line"></span><br><span class="line">　　提示：Hi xxx! You<span class="string">'ve successfully authenticated, but GitHub does not provide shell  access.</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      解决github+hexo的博客多终端同步问题
    
    </summary>
    
      <category term="教程" scheme="https://jiangxj.top/blog/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="hexo" scheme="https://jiangxj.top/blog/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu使用教程</title>
    <link href="https://jiangxj.top/blog/2020/05/18/ubuntu%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <id>https://jiangxj.top/blog/2020/05/18/ubuntu使用教程/</id>
    <published>2020-05-18T06:06:10.000Z</published>
    <updated>2021-01-13T10:21:36.409Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Ubuntu磁盘操作"><a href="#Ubuntu磁盘操作" class="headerlink" title="Ubuntu磁盘操作"></a>Ubuntu磁盘操作</h2><p>需要root权限</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="keyword">su</span></span><br><span class="line"><span class="keyword">su</span> ***</span><br></pre></td></tr></table></figure><p>用命令<code>fdisk -l</code>查看系统识别磁盘情况</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Device     Boot     <span class="keyword">Start</span>       <span class="keyword">End</span>   Sectors   <span class="keyword">Size</span> <span class="keyword">Id</span> <span class="keyword">Type</span></span><br><span class="line">/dev/sda1  *         <span class="number">2048</span> <span class="number">960335871</span> <span class="number">960333824</span> <span class="number">457.9</span>G <span class="number">83</span> Linux</span><br><span class="line">/dev/sda2       <span class="number">960337918</span> <span class="number">976771071</span>  <span class="number">16433154</span>   <span class="number">7.9</span>G  <span class="number">5</span> <span class="keyword">Extended</span></span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: <span class="number">2.7</span> TiB, <span class="number">3000592982016</span> <span class="keyword">bytes</span>, <span class="number">5860533168</span> sectors</span><br><span class="line">Units: sectors <span class="keyword">of</span> <span class="number">1</span> * <span class="number">512</span> = <span class="number">512</span> <span class="keyword">bytes</span></span><br><span class="line">Sector <span class="keyword">size</span> (<span class="keyword">logical</span>/<span class="keyword">physical</span>): <span class="number">512</span> <span class="keyword">bytes</span> / <span class="number">4096</span> <span class="keyword">bytes</span></span><br><span class="line">I/O <span class="keyword">size</span> (<span class="keyword">minimum</span>/<span class="keyword">optimal</span>): <span class="number">4096</span> <span class="keyword">bytes</span> / <span class="number">4096</span> <span class="keyword">bytes</span></span><br><span class="line">Disklabel <span class="keyword">type</span>: gpt</span><br><span class="line">Disk identifier: <span class="number">1</span>AB82561-C5FD<span class="number">-47</span>A9<span class="number">-9</span>A29<span class="number">-31835617</span>EBD3</span><br><span class="line"></span><br><span class="line">Device     <span class="keyword">Start</span>        <span class="keyword">End</span>    Sectors  <span class="keyword">Size</span> <span class="keyword">Type</span></span><br><span class="line">/dev/sdb1   <span class="number">2048</span> <span class="number">5860532223</span> <span class="number">5860530176</span>  <span class="number">2.7</span>T Microsoft basic <span class="keyword">data</span></span><br></pre></td></tr></table></figure><p>可以看到磁盘的挂载点，然后<code>cd</code>切换到对应的磁盘，访问。</p><p>跟磁盘相关的几个常用命令：</p><p><code>df -h</code>：查看磁盘占用情况</p><p><code>df -T</code>：查看磁盘的文件系统类型(type)</p><p><code>fdisk -l</code>：查看所有被系统识别的磁盘</p><h2 id="ubuntu-hexo-github搭建博客"><a href="#ubuntu-hexo-github搭建博客" class="headerlink" title="ubuntu +hexo +github搭建博客"></a>ubuntu +hexo +github搭建博客</h2><p><strong>1、安装git</strong></p><p><strong>2、安装node.js</strong></p><p>为了避免安装的 Node.js 版本过旧导致后续的 Hexo 安装过程出错，应该使用 NVM（Node Version Manager）安装 Node.js。官方给出了两个安装脚本，直接复制到命令行即可：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -o- https:<span class="regexp">//</span>raw.githubusercontent.com<span class="regexp">/creationix/</span>nvm<span class="regexp">/v0.33.2/i</span>nstall.sh | bash</span><br></pre></td></tr></table></figure><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wget -qO- https:<span class="regexp">//</span>raw.githubusercontent.com<span class="regexp">/creationix/</span>nvm<span class="regexp">/v0.33.2/i</span>nstall.sh | bash</span><br></pre></td></tr></table></figure><p>安装完成后，<strong>重启终端</strong>使用。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ nvm <span class="keyword">install</span> stable <span class="comment">#安装 nvm</span></span><br><span class="line">完成安装。安装完成后可使用</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure><p>环境配置：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="comment"># 在底部添加 PATH 变量</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:/usr/local/node/bin</span><br><span class="line"><span class="comment"># 保存生效</span></span><br><span class="line">source etc/profile</span><br></pre></td></tr></table></figure><p>具体教程参考<a href="https://www.fengkx.top/post/building-a-blog-based-on-hexo-and-github-in-ubuntu/index.html" target="_blank" rel="noopener">此文</a>。</p><p>注意node版本和hexo版本匹配问题，如果node版本过高，执行<code>hexo g -d</code>部署会出现问题。</p><p><strong>3、安装多版本node/npm</strong></p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">nvm</span> <span class="selector-tag">install</span> 10<span class="selector-class">.15</span><span class="selector-class">.3</span>  #安装10<span class="selector-class">.15</span><span class="selector-class">.3</span>版本</span><br></pre></td></tr></table></figure><p>具体参考<a href="https://www.runoob.com/w3cnote/nvm-manager-node-versions.html" target="_blank" rel="noopener">此文</a></p><p><strong>4、修改hexo版本</strong></p><p>update hexo in <code>package.json</code></p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//package.json</span></span><br><span class="line"><span class="string">"dependencies"</span>:&#123;</span><br><span class="line">    <span class="string">"hexo"</span>: <span class="string">"^4.2.0"</span>  <span class="meta">#删除原版本</span></span><br><span class="line">    <span class="string">"hexo"</span>: <span class="string">"^4.2.1"</span>  <span class="meta">#输入新版本</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">npm</span> update</span><br><span class="line">hexo -v</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Ubuntu的基本使用教程
    
    </summary>
    
      <category term="教程" scheme="https://jiangxj.top/blog/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="ubuntu" scheme="https://jiangxj.top/blog/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>迁移学习和深度迁移学习原理</title>
    <link href="https://jiangxj.top/blog/2020/05/18/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"/>
    <id>https://jiangxj.top/blog/2020/05/18/迁移学习/</id>
    <published>2020-05-17T16:00:00.000Z</published>
    <updated>2020-06-18T02:39:58.317Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><blockquote><p>S. J. Pan and Q. Yang, “<strong>A Survey on Transfer Learning</strong>“ in <em>IEEE Transactions on Knowledge and Data Engineering</em>, vol. 22, no. 10, pp. 1345-1359</p></blockquote><h2 id="迁移学习概念"><a href="#迁移学习概念" class="headerlink" title="迁移学习概念"></a>迁移学习概念</h2><p>传统机器学习的领域假设训练数据和测试数据属于相同的特征空间并在同一分布，然而现实中这种假设往往得不到满足。例如，我们对目标领域的分类问题，却只有源领域的训练数据，但源领域数据与目标领域数据要么不在同一个特征空间，要么不满足相同的数据分布，例如需要进行的文本分类语言是西班牙语。但只提供了了葡萄牙语的文本。</p><p>在某些情况下成功地进行知识迁移能够很大程度上提高学习的性能，但也同时降低了标记目标领域数据带来的大量时间和人力成本。</p><p>近年来，迁移学习已经成为一种解决<strong>知识迁移问题</strong>的新型学习框架，<a href="https://ieeexplore.ieee.org/document/5288526" target="_blank" rel="noopener">这篇论文【S. J. Pan and Q. Yang, “A Survey on Transfer Learning,” in <em>IEEE Transactions on Knowledge and Data Engineering</em>, vol. 22, no. 10, pp. 1345-1359】</a>讨论了使用迁移学习进行分类、回归和聚类的一般过程，也讨论了迁移学习和其他相关的机器学习技术之间的关系，如领域适应性、多任务学习、样本选择和变量变换。</p><p>传统的机器学习/数据挖掘只有在训练集和测试集数据都来自同一个feature space和the same distribution的时候才有较好的表现，也就意味着如果每一次更换了数据集重新训练模型，会变得很麻烦。比如：</p><p>（1）从数据类型/内容上看，获取新的数据集很贵很麻烦</p><p>（2）从时间维度上看，有些数据很容易过期，不同时期的数据分布会不同。对于每个时间段都要进行一次训练很麻烦（如进行室内wifi定位）</p><p>2005年DARPA的信息处理办公室(IPTO)给迁移学习有了一个新的定义：一个系统具有把从先前的任务学习到的识别和应用知识的能力运用到新的任务上的能力。</p><p>区别于多任务学习(multi-task learning)中将source和target tasks同等对待，迁移学习更多的关注target tasks，在迁移学习中，两者不再对等。</p><h2 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h2><p>几个关键词：<strong>domain（域）</strong>和<strong>task（任务）</strong>，<strong>source（源）</strong>和<strong>target（目标）</strong></p><p>domain包括两部分：feature space和probability（概率）。domain不同可能分为两种情况，特征空间不同或者概率不同。</p><p>task包括两部分：label space和objective predictive function（目标预测函数）。同样如上所述。</p><p>source：用于训练模型的域/任务。</p><p>target：使用基于source训练出来的模型对自己的数据进行预测/分类/聚类等机器学习任务的域/任务。</p><p>领域（domain）$\mathcal{D}$包括特征空间$\mathcal{X}$和边缘分布（marginal probability distribution）$P(X)$，$X = \{x_1,x_2,\dots,x_n\} \in \mathcal{X}$。即：$\mathcal{D}= \{\mathcal{X},P(X)\}$</p><p>任务（task）$\mathcal{T}$包括标签空间$\mathcal{Y}$和目标预测函数$f(·)$，也就是条件概率分布，记作$P(y|x)$。即：$\mathcal{T} = \{\mathcal{Y},f(·)\}$</p><p><strong>迁移学习定义</strong>：给出一个源领域$\mathcal{T}_S$和学习任务$\mathcal{T}_S$，一个目标领域$\mathcal{D}_T$和学习任务$\mathcal{T}_T$，迁移学习指的是通过从$\mathcal{D}_S$和$\mathcal{T}_S$学到的知识了来帮助在$\mathcal{D}_T$中目标函数$f_T(·)$的学习。$\mathcal{D}_T \neq \mathcal{D}_S$或者$\mathcal{T}_T \neq \mathcal{T}_S$</p><p>源领域和目标领域不同指的是$\mathcal{X}_S \neq \mathcal{X}_T$【即特征空间不同】或者$P_S(X) \neq P_T(X)$【即源和目标任务的边缘分布不同】</p><p>源任务和目标任务不同指的是$\mathcal{Y}_S \neq \mathcal{Y}_T $【即任务标签集不同】或者$P(Y_S |X_S) \neq P(Y_T | X_T)$【即源和目标任务的条件概率不同】</p><h2 id="迁移学习的划分"><a href="#迁移学习的划分" class="headerlink" title="迁移学习的划分"></a>迁移学习的划分</h2><p><strong>①从问题角度来看</strong><br>（1）迁移什么？</p><p>哪一部分知识可以被迁移？</p><p>（2）怎么迁移？</p><p>那当然就是训练出适合的模型啦。</p><p>（3）什么时候需要用到迁移学习？</p><p>当source domain和target domain没什么关系或者太不相同的时候，迁移效果可能就不那么好了，甚至可能会比不迁移的时候表现要更差，这个就叫做<strong>negative transfer</strong>了。</p><p>可以看到，迁移学习的能力也是有限的，所以我们需要关注迁移学习的边界在哪里，比如用conditional Kolmogorov complexity去衡量tasks之间的相关性。</p><p>作者指出，现在很多工作都关注前两个问题，但实际上第三个问题是很重要的，因为你在那捣腾半天最后发现其实迁移了还不如不迁移，那不是白费心思嘛。所以作者认为这个问题应当被重视，比如说可以在迁移之前先看看source和domain之间的transferability（可迁移性）。</p><p> <strong>②从迁移场景来看</strong><br>（1）Homogeneous TL（同构学习）：source domain和target domain的feature space相同。</p><p>（2）Heterogeneous TL（异构学习）：source domain和target domain的feature space不同。</p><p><strong>③从迁移算法来看</strong><br>（1）Inductive TL（归纳式迁移学习）</p><p>source和target的domain可能一样或不一样，task不一样；target domain的labeled数据可得，source domain不一定可得。</p><p>所以呢，根据source domain的labeled数据可以再细分为两类：</p><p>multi_task learning（多任务学习）：source domain的labeled数据可得。<br>self-taught learning（自学习）：source domain的labeled数据不可得。</p><img src="/blog/2020/05/18/迁移学习/20170308151057479.png" title="归纳式迁移学习"><blockquote><p>代表性论文引用：Dai W, Yang Q,Xue G R, et al. Boosting for transfer learning[C]//Machine Learning, Proceedings of the Twenty-Fourth International   Conference. DBLP, 2007:193-200.</p></blockquote><p>（2）Transductive TL（直推式迁移学习）</p><p>source和target的task一样，domain不一样；source domain的labeled数据可得，target domain的不可得。注意我们提过，domain不一样意味着两种可能：feature space不一样，或者feature space一样而probability不一样。而后一种情况和domain adaptation（域适配）息息相关。这里也可以根据domain和task的个数分为两个情况：</p><p>Domain Adaptation（域适配）：不同的domains+single task<br>Sample Selection Bias（样本选择偏差）/Covariance Shift（协方差转变）：single domain+single task</p><img src="/blog/2020/05/18/迁移学习/20170308151131042.png" title="直推式迁移学习"><blockquote><p>代表性论文引用：Arnold A, Nallapati R, Cohen W W. A comparativestudy of methods for transductive transfer    learning[C]//Data Mining Workshops,2007. ICDM Workshops 2007. Seventh IEEE International Conference on. IEEE,2007: 77-82.</p></blockquote><p>（3）Unsupervised TL（无监督迁移学习）</p><p>source和target的domain和task都不一样；source domain和target domain的labeled数据都不可得。</p><img src="/blog/2020/05/18/迁移学习/20170308151150215.png" title="无监督迁移学习"><blockquote><p>代表性论文引用：Dai W, Yang Q, Xue G R, et al. Self-taughtclustering[C]//Proceedings of the 25th international conference on Machinelearning. ACM, 2008: 200-207.</p></blockquote><p>将迁移学习根据领域和任务的不同进行了划分：</p><img src="/blog/2020/05/18/迁移学习/分类.png" title="迁移学习根据领域和任务不同分类"><p>综上，这几个方法差别主要是：<strong>（1）source和domain之间，domain是否相同，task是否相同；（2）source domain和target domain的labeled数据是否可以得到。</strong></p><img src="/blog/2020/05/18/迁移学习/tabel1.png" title="Relation Between Traditional ML & Various Transfer Learning Setting"><img src="/blog/2020/05/18/迁移学习/table2.png" title="Different Settings of Transfer Learning"><p><strong>④从“迁移什么”来看</strong></p><p>（1）Instance-based TL（样本迁移）</p><p>尽管source domain数据不可以整个直接被用到target domain里，但是在source domain中还是找到一些可以重新被用到target domain中的数据。对它们调整权重，使它能与target domain中的数据匹配之后可以进行迁移。盗一张图，比如在这个例子中就是找到例子3，然后加重它的权值，这样在预测的时候它所占权重较大，预测也可以更准确。</p><p>instance reweighting（样本重新调整权重）和importance sampling（重要性采样）是instance-based TL里主要用到的两项技术。</p><img src="/blog/2020/05/18/迁移学习/2018041120463545.png" title="样本迁移"><p>（2）Feature-representation-transfer（特征迁移）</p><p>找到一些好的有代表性的特征，通过特征变换把source domain和target domain的特征变换到同样的空间，使得这个空间中source domain和target domain的数据具有相同的分布，然后进行传统的机器学习就可以了。</p><p>特征变换这一块可以举个栗子，比如评论男生的时候，你会说”好帅！好有男人味！好有担当！“；评论女生的时候，你会说”好漂亮！好有女人味！好温柔！“可以看出共同的特征就是“好看”。把“好帅”映射到“好看”，把“好漂亮”映射到“好看”，“好看”便是它们的共同特征。</p><p>（3）Parameter-transfer（参数/模型迁移）</p><p>假设source tasks和target tasks之间共享一些参数，或者共享模型hyperparameters（超参数）的先验分布。这样把原来的模型迁移到新的domain时，也可以达到不错的精度。</p><p>下面这个项目感觉用到就是这个parameter-transfer：<a href="https://cosx.org/2017/10/transfer-learning/" target="_blank" rel="noopener">基于深度学习和迁移学习的识花实践</a>。</p><p>（4）Relational-knowledge-transfer（关系迁移）</p><p>把相似的关系进行迁移，比如生物病毒传播到计算机病毒传播的迁移，比如师生关系到上司下属关系的迁移。</p><img src="/blog/2020/05/18/迁移学习/table3.png" title="Different Approaches Used in Different Settings"><h2 id="具体方法概述"><a href="#具体方法概述" class="headerlink" title="具体方法概述"></a>具体方法概述</h2><p>即上表的扩展分析：</p><p><strong>①Inductive TL</strong></p><p>（1）Instances TL</p><p>主要方法：TrAdaBoost（AdaBoost的拓展）</p><p>假设：source domain和target domain数据的feature和labels是一样的，但是分布不一样；部分source domain的数据会对target domain的学习有帮助，但有部分可能会不利于target domain的学习。</p><p>过程：大致就是不断地给好的source data赋予更高的权重，给不好的赋予更多的权重。</p><p>（2）Features TL</p><p>需要根据source domain的labeled data是否可得分为两类（回顾：Inductive TL是target domain的labeled data可得，但是source domain的未必可得）：</p><p>Supervised Feature Construction（监督的特征构建）</p><p>Unsupervised Feature Construction（非监督的特征构建）</p><p>大致过程：通过减少model error，找出低维的有代表性的特征</p><p>（3）Parameters TL</p><p>主要方法：MT-IVM（基于Gaussian Processes）</p><p>大致过程（注意这里讲述的不是上面提到的那个主要方法的过程，而是另一个方法的过程）：假设source和target的参数都可以分为两部分，一部分是source/target特有的参数，一部分是它们共同有的参数。把这两个参数丢到改进了的SVM问题中，把参数训练出来就好了。</p><p>（4）Relational TL</p><p>注意和上面三种方法不同的是，这个方法是在relational domains里进行的，这个domain里的数据不是iid（独立同分布）的，所以它不需要假设每个domain里的数据都必须iid。</p><p>主要方法：statistical relational learning（SRL，统计关系学习）</p><p><strong>②Transductive TL</strong></p><p>Transductive TL是source domain的label可得，target domain的label不可得。但是要注意！为了得到target data的边际分布，在training的时候是需要一些unlabeled的target data的。</p><p>（1）Instances TL</p><p>主要方法：Importance sampling。</p><p>大致过程：我们的目标是最小化target domain里的expected risk（期望风险），但是target domain里没有labeled数据可用，所以我们必须替换成source domain里的数据，通过一些方法可以把它替换成source domain里的数据再乘以一个权重，只要把这个权重算出来就好。</p><p>（2）Feature Representations TL</p><p>主要方法：Structural Correspondence Learning（SCL）</p><p>大致过程：定义一些pivot features（就是共同特征），然后把每一个pivot feature都当成是一个新的label vector，通过公式把权重学习出来，然后对权重进行SVD分解，最后在argumented feature vector上使用传统的判别式算法即可。这里argumented feature vector包括这些新的features和所有原来的feature。（我还没有详细看这一块儿，所以先直译了）</p><p>难点：如何寻找好的pivot feature、domain之间的依赖性。</p><p><strong>③ Unsupervised TL</strong></p><p>（1）Feature Representations TL</p><p>主要方法：涉及两个</p><p>Self-taught clustering（STC），主要用于transfer clustering（迁移聚类）。目标就是希望通过source domain里大量的unlabeled data对少量的target domain里的unlabeled data进行聚类。<br>TDA方法，这个主要用于解决transfer dimensionality reduction（迁移降维）问题</p><h2 id="目前存在的问题"><a href="#目前存在的问题" class="headerlink" title="目前存在的问题"></a>目前存在的问题</h2><p>（1）negative transfer的问题，比如怎么定义transferability，怎么衡量domain之间或task之间的相关性。</p><p>（2）目前的TL算法主要都是想要提高feature space相同probability不同时的表现的，domain不同或者task不同都有两种情况，一种是space不同，一种是space相同probability不同 ，但是这里说的就是<strong>目前TL算法主要致力于提高的都是概率不同的</strong>。但是很多时候我们其实也想要对feature space不同的domain和task进行迁移。即提到的heterogeneous TL（异构学习）问题。</p><p>（3）现在的TL主要都是应用到小且波动不大的数据集中（例如传感器数据、文本分类、图片分类等），以后要考虑如何用到更广泛的数据场景中。</p><h2 id="迁移学习的基本过程"><a href="#迁移学习的基本过程" class="headerlink" title="迁移学习的基本过程"></a>迁移学习的基本过程</h2><p>当可用的数据集特别少时，从头开始训练一个神经网络往往不能得到很好的结果，于是就从一个预训练模型开始训练，让网络本身已经具备一定的训练基础，然后用小数据集进行微调，便可以得到一个不错的结果。</p><p>通常加载预训练后，冻结模型的部分参数，一般只训练模型的最后几层，这样可以保留整个模型前面对物体特征提取的能力。预训练模型一定要与新的数据集有共同点，这样才能有效地预训练模型里的特征提取能力迁移到新的模型上。</p><p>一般过程：</p><p>1、加载预训练模型</p><p>2、冻结模型前面部分的参数</p><p>3、添加可训练的自定义的分类层，或使用原模型的分类层（如果可重用的话）</p><p>4、在新数据集上训练</p><h2 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h2><p>按照50%，25%，25%的比例划分training，valid，和testing。</p><p>目录整理如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/datadir</span><br><span class="line">     /train</span><br><span class="line">         /class1</span><br><span class="line">         /class2</span><br><span class="line">     </span><br><span class="line">    /valid    验证集</span><br><span class="line">         /class1</span><br><span class="line">         /class2</span><br><span class="line">    /test</span><br><span class="line">         /class1</span><br><span class="line">         /class2</span><br></pre></td></tr></table></figure><p>预训练模型是基于ImageNet的，训练图像大小224×224，需要对数据集的图像进行大小缩放。</p><h2 id="图像增广-data-augmentation"><a href="#图像增广-data-augmentation" class="headerlink" title="图像增广(data augmentation)"></a>图像增广(data augmentation)</h2><p>图像增广一般用来人工产生不同的图像，比如对图像进行旋转、翻转、随机裁剪、缩放等等。选择训练阶段对输入进行增广。</p><h2 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h2><p>定义training和validation的预处理方式。</p><p>定义dataset和dataloader。用datasets.imagesfolder来定义dataset时，pytorch可以自动将图片与对应的文件夹分类对应起来，应用上面定义好的transformers，然后dataset传入到dataloader里，dataloader在每一个循环会自动生成batchsize大小的图像和label。</p><h2 id="ImageNet的预训练模型"><a href="#ImageNet的预训练模型" class="headerlink" title="ImageNet的预训练模型"></a>ImageNet的预训练模型</h2><p>PyTorch自带了很多ImageNet上的预训练模型</p><p><a href="https://www.pytorchtutorial.com/pytorch-transfer-learning/" target="_blank" rel="noopener">PyTorch迁移学习实现图像分类</a></p><p><a href="https://www.pytorchtutorial.com/" target="_blank" rel="noopener">PyTorch 中文网</a></p><h1 id="深度迁移学习"><a href="#深度迁移学习" class="headerlink" title="深度迁移学习"></a>深度迁移学习</h1><blockquote><p>论文：A Survey on Deep Transfer Learning</p><p>清华大学智能技术与系统国家重点实验室近期发表的深度迁移学习综述，首次定义了深度迁移学习的四个分类，包括基于实例、映射、网络和对抗的迁移学习方法，并在每个方向上都给出了丰富的参考文献。</p><p><a href="https://zhuanlan.zhihu.com/p/44654536" target="_blank" rel="noopener">参考</a></p></blockquote><img src="/blog/2020/05/18/迁移学习/深度迁移学习论文.png" title="深度迁移学习综述论文"><h2 id="回顾迁移学习"><a href="#回顾迁移学习" class="headerlink" title="回顾迁移学习"></a>回顾迁移学习</h2><p><strong>迁移学习</strong>：解决训练数据不足这一基本问题，试图放松训练数据和测试数据必须是独立同分布(i.i.d)的假设，将知识从源域迁移到目标域。</p><img src="/blog/2020/05/18/迁移学习/迁移学习形式化定义.PNG" title="迁移学习形式化定义"><p>给出一个源领域$\mathcal{T}_S$和学习任务$\mathcal{T}_S$，一个目标领域$\mathcal{D}_T$和学习任务$\mathcal{T}_T$，迁移学习指的是通过从$\mathcal{D}_S$和$\mathcal{T}_S$学到的知识了来帮助在$\mathcal{D}_T$中目标函数$f_T(·)$的学习。$\mathcal{D}_T \neq \mathcal{D}_S$或者$\mathcal{T}_T \neq \mathcal{T}_S$</p><h2 id="深度迁移学习-1"><a href="#深度迁移学习-1" class="headerlink" title="深度迁移学习"></a>深度迁移学习</h2><p>如何利用深度神经网络进行有效的知识传递很重要，即深度迁移学习。定义如下：</p><p><strong>深度迁移学习定义</strong>：给定一个迁移学习任务，定义为$\left(\mathcal{D}_S,\mathcal{T}_S,\mathcal{D}_T,\mathcal{T}_T,f_{\mathcal{T}}(·)\right)$。其中$f_{\mathcal{T}}(·)$是一个反映深度神经网络的非线性函数。</p><p><strong>深度迁移学习分类</strong>：基于实例的深度迁移学习、基于映射的深度迁移学习、基于网络的深度迁移学习和基于对抗的深度迁移学习。</p><h3 id="基于实例的深度迁移学习"><a href="#基于实例的深度迁移学习" class="headerlink" title="基于实例的深度迁移学习"></a>基于实例的深度迁移学习</h3><p>使用特定的权重调整策略，从源域中选择部分实例作为目标域训练集的补充，并为这些选择的实例分配合适的权值。</p><p>是基于这样的假设：“虽然两个域之间存在差异，但是源域中的部分实例可以被具有适当权重的目标域使用”。</p><h3 id="基于映射的深度迁移学习"><a href="#基于映射的深度迁移学习" class="headerlink" title="基于映射的深度迁移学习"></a>基于映射的深度迁移学习</h3><p>将实例从源域和目标域映射到新的数据空间，在这个新的数据空间中，来自两个域的实例是相似的，适合于联合深度神经网络。</p><p>是基于这样的假设：“尽管两个源域之间存在差异，但它们在一个复杂的新数据空间中可能更加相似”。</p><h3 id="基于网络的深度迁移学习"><a href="#基于网络的深度迁移学习" class="headerlink" title="基于网络的深度迁移学习"></a>基于网络的深度迁移学习</h3><p>将源领域中预先训练好的部分网络，包括其网络结构和连接参数，重新利用，将其转化为用于目标领域的深度神经网络的一部分。</p><p>是基于这样的假设：“神经网络类似于人脑的处理机制，是一个迭代的、连续的抽象过程”。该网络的前端层可以看作是一个特征提取器，所提取的特征是通用的。</p><h3 id="基于对抗的深度迁移学习"><a href="#基于对抗的深度迁移学习" class="headerlink" title="基于对抗的深度迁移学习"></a>基于对抗的深度迁移学习</h3><p>在生成对抗网络(GAN)的启发下，引入对抗技术，寻找既适合于源域又适用于目标域的可迁移表达。</p><p>是基于这样的假设：“为了有效的迁移，良好的表征应该是对主要学习任务的区别性，以及对源域和目标域的不加区分”。</p><p><a href="https://zhuanlan.zhihu.com/p/89951541" target="_blank" rel="noopener">更详细的中文描述</a></p>]]></content>
    
    <summary type="html">
    
      主要分析迁移学习和深度迁移学习两篇综述文章
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="迁移学习" scheme="https://jiangxj.top/blog/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度迁移学习" scheme="https://jiangxj.top/blog/tags/%E6%B7%B1%E5%BA%A6%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>马尔科夫链-蒙特卡罗方法</title>
    <link href="https://jiangxj.top/blog/2020/05/16/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE-%E8%92%99%E7%89%B9%E5%8D%A1%E7%BD%97%E6%96%B9%E6%B3%95/"/>
    <id>https://jiangxj.top/blog/2020/05/16/马尔科夫链-蒙特卡罗方法/</id>
    <published>2020-05-15T16:00:00.000Z</published>
    <updated>2020-06-18T01:17:12.457Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>MCMC(markov chain monte carlo)马尔科夫链蒙特卡洛随机采样方法，是很多复杂算法求解的基础，用作一些复杂运算的近似求解。</p><h2 id="蒙特卡洛方法部分"><a href="#蒙特卡洛方法部分" class="headerlink" title="蒙特卡洛方法部分"></a>蒙特卡洛方法部分</h2><p><strong>概述</strong></p><p>通过大量的随机样本，去了解一个系统，进而得到所要计算的值。是以概率为基础的方法，与之对应的是确定性算法。</p><p><strong>基本思想</strong></p><p>​          所求解的问题是某随机事件A出现的概率（或者是某随机变量B的期望值）。通过某种“实验方法”，得出A事件出现的概率，以此估计出A事件出现的概率（或者得到随机变量B的某些数字特征，得出B的期望值）。</p><p><strong>工作过程</strong></p><p>​          Monte Carlo方法模拟某一个过程时，需要产生各种概率分布的随机变量，用统计方法把模拟的数字特征估计出来，从而得到实际问题的数值解。</p><p><strong>分类</strong></p><p>一类是所求解的问题具有内在的随机性，借助计算机的运算能力可以直接模拟这种随机过程。如分析中子在反应堆中的传输过程，依据其概率随机抽样得到裂变位置、速度和方向，模拟大量中子的行为后，经过统计得到中子传输的范围，作为堆设计的依据。</p><p>一类是所求解问题可以转化为某种随机分布的特征数，如随机事件发生的概率，或者随机变量的期望值，通过随机抽样，以随机事件出现的频率估计其概率，或者以抽样的数字特征估算随机变量的数字特征，作为问题的解。多用于求解复杂的多维积分问题。</p><p><strong>举例</strong></p><p>求解积分：$ \theta = \int_a^b f(x)dx $</p><p>一个简单近似求解方法是在$[a,b]$之间随机采样一个点，如$x_0$，然后用$f(x_0)$代表在这个区间上所有的$f(x)$的值，近似求解为：<br>$$<br>(b-a)f(x_0)<br>$$<br>在区间$[a,b]$上采样n个值：$x_0,x_1,\dots,x_{n-1}$，用其均值来代表区间上所有的$f(x)$的值，近似求解为：<br>$$<br>\frac{b-a}{n}\sum\limits_{i=0}^{n-1}f(x_i)<br>$$<br>上述是在假设$x$是在$[a,b]$上均匀分布的情况下，若不是均匀分布，则可以采用：如果得到$x$在$[a,b]$上的概率分布函数$p(x)$，有<br>$$<br>\theta = \int_{a}^b f(x)dx = \int_a^b \frac{f(x)}{p(x)} p(x)dx \approx \frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(x_i)}{p(x_i)}<br>$$<br>上式最右边为蒙特卡洛方法的一般形式，此处是连续函数形式的。</p><p>可见，当假设$x$在区间内均匀分布时候，即：$p(x_i) = 1/(b-a)$，带入上式可以得到：<br>$$<br>\frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(x_i)}{1/(b-a)} =\frac{b-a}{n}\sum\limits_{i=0}^{n-1}f(x_i)<br>$$<br><strong>概率分布采样</strong></p><p>如何基于概率分布去采样基于该概率分布的$n$个$x$样本集问题：</p><p>对于常见的均匀分布uniform（0，1）是非常容易采样的，一般是通过线性同余发生器可以生成(0,1)之间的伪随机数样本。</p><p>其他常见的概率分布，可以通过uniform(0,1)的样本转换得到，如二维的正太分布样本$(Z_1,Z_2)$可以通过独立采样得到uniform(0,1)样本对$(X_1,X_2)$。</p><p>其他的常见的连续分布，如$t$分布，$F$分布等，都可以通过类似得方式转换为uniform(0,1)得到的采样样本转化得到，在python中的numpy，scikit-learn等类库中，有生成这些常用分布样本的函数可以使用。</p><p><strong>接受-拒绝采样</strong></p><p>对于不常见的概率分布，一个可行的解决办法是：接受——拒绝采样。</p><p>设定一个程序可采样的分布$q(x)$，如高斯分布，然后按照一定的方法拒绝某些样本，以达到接近$p(x)$分布的目的，其中$q(x)$成为proposal distribution。</p><img src="/blog/2020/05/16/马尔科夫链-蒙特卡罗方法/1.png" title="高斯分布"><p>具体采用过程为：</p><p>设定一个方便采样的常用概率分布函数$q(x)$,以及一个常量$k$，使得$p(x)$总在$kq(x)$的下方。</p><p>采样得到的$q(x)$的一个样本$z_0$，然后，从均匀分布$(0,kq(z_0))$中采样得到一个值$u$，若$u$落在上图中的灰色区域，则拒绝抽样，否则接受这个样本$z_0$，重复以上过程得到$n$个接受的样本$z_0,z_1,\dots,z_{n-1}$，最后的蒙特卡罗方法求解结果为：<br>$$<br>\frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(x_i)}{p(x_i)}<br>$$<br>通过一系列的接受拒绝决策来达到用$q(x)$模拟$p(x)$概率分布。</p><h2 id="马尔科夫链部分"><a href="#马尔科夫链部分" class="headerlink" title="马尔科夫链部分"></a>马尔科夫链部分</h2><p><strong>概述</strong></p><p>假设某一个时刻状态转移的概率只依赖于它的前一个状态，这样做可以大大简化模型的复杂度，因此马尔科夫链在很多时间序列模型中得到广泛的应用，如循环神经网络RNN，隐式马尔科夫链HMM等。</p><p>数学定义描述为：</p><p>假设序列状态是$\dots X_{t-2},    X_{t-1},X_{t},X_{t+1},\dots$，那么在时刻$X_{t+1}$的状态的条件概率仅仅依赖于时刻$X_t$，即：<br>$$<br>P(X_{t+1} | \dots X_{t-2},    X_{t-1},X_{t})= P(X_{t+1}|X_t)<br>$$<br>因为某一时刻状态转移的概率只依赖于它的前一个状态，因而只能求出系统中任意两个状态之间的转换概率。</p><p><strong>举例</strong></p><img src="/blog/2020/05/16/马尔科夫链-蒙特卡罗方法/2.png" title="股市模型"><p>表示股市模型，共三种状态：牛市、熊市和横盘(stagnant market)。每一个状态都以一定的概率转化到下一个状态。如，牛市以0.025概率转化为横盘的状态。</p><p>上图可以表示为矩阵的形式，如果定义矩阵$P$某一个位置$P(i,j)$的值为$P(j|i)$，即从状态$i$转化为状态$j$的概率，定义牛市状态为0，熊市状态为1，横盘为2，得到马尔科夫链模型的状态转移矩阵为：<br>$$<br>P = \pmatrix{0.9 &amp; 0.075&amp;0.025 \ 0.15 &amp; 0.8 &amp; 0.05 \ 0.25 &amp; 0.25 &amp; 0.5}<br>$$<br><strong>状态转移矩阵的性质</strong></p><p>马尔科夫链模型的状态转移矩阵收敛到稳定概率分布与初始状态概率分布无关，即</p><p>得到稳定分布对应的马尔科夫链模型的状态转移矩阵，可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，经过一系列的转换，最终可以得到符合对应稳定概率分布的样本。</p><p>对于一个确定的状态转移矩阵$P$，$P^n$在$n$大于一定的值的时候也可以发现是确定的。</p><p>马尔科夫链性质数学描述：</p><p>如果一个非周期的马尔科夫链有状态转移矩阵$P$，并且它的任意两个状态是连通的，$\lim \limits_{n \rightarrow \infty} P_{ij}^n$与$i$无关，有：</p><ul><li>$\lim \limits_{n \rightarrow \infty} P_{ij}^n =\pi(j)$</li><li>$\lim\limits_{n \rightarrow \infty} P^n = \pmatrix{\pi(1) &amp; \pi(2) &amp; \dots &amp; \pi(j) &amp; \dots \ \pi(1) &amp; \pi(2) &amp; \dots &amp; \pi(j) &amp; \dots \ \dots \ \pi(1) &amp; \pi(2) &amp; \dots &amp; \pi(j) &amp; \dots \ \dots}$</li><li>$\pi(j) = \sum\limits_{i=0}^{\infty}\pi(i) P_{ij}$</li><li>$\pi$是方程$\pi P = \pi$的唯一非负解，其中：$\pi = [\pi(1),\pi(2),\dots,\pi(j), \dots]\sum\limits_{i=0}^{\infty}\pi(i) =1$</li></ul><p>（1）非周期性的马尔科夫链：这个主要是指马尔科夫链的状态转化不是循环的，如果是循环的则永远不会收敛。对于任意某一个状态$i,d$为集合$\{n|n \ge 1, P_{ii}^n &gt; 0\}$的最大公约数，如果$d=1$，则状态为非周期的。</p><p>（2）任何两个状态是连通的：从任意一个状态可以通过有限步到达其他的任意一个状态，不会出现条件概率一直为0导致不可达的情况。</p><p>（3）马尔科夫链的状态数是有限的，也可以是无限的，可以用于连续概率分布和离散概率分布</p><p>（4）$\pi$通常是马尔科夫链的平稳分布</p><p><strong>基于马尔科夫链采样</strong></p><p>得到了某个平稳分布所对应的马尔科夫链状态转移矩阵，很容易采样出这个平稳分布的样本集。</p><p>假设任意初始的概率分布为$\pi_0(x)$，经过第一轮马尔科夫链状态转移后的概率分布是$\pi_1(x)$，第$i$轮的概率分布是$\pi_i(x)$。经过$n$轮后的马尔科夫链收敛到平稳分布$\pi(x)$，即：<br>$$<br>\pi_n(x) = \pi_{n+1}(x)= \dots = \pi(x)<br>$$<br>对于每个分布$\pi_i(x)$，有：<br>$$<br>\pi_i(x) = \pi_{i-1}(x)P = \pi_{i-2}(x)P^2 = \pi_0(x)P^{i}<br>$$<br>采样过程：</p><p>首先，基于初始简单概率分布（如高斯分布）$\pi_0(x)$采样得到状态值$\pi_0$，基于条件概率分布$P(x|x_0)$采样状态值$x_1$，一直进行下去，当状态转移进行到一定的次数时，如$n$次，认为此时的样本集$(x_n,x_{n+1},x_{n+2},\dots)$即是符合平稳分布的对应的样本集，可以用来做蒙特卡洛模拟求和。</p><ol><li>输入马尔科夫链状态转移矩阵P，设定状态转移次数阈值$n_1$，需要样本个数$n_2$</li><li>从任意简答概率分布采样得到初始状态值$x_0$</li><li>for $t=0$ to $n_1+n_2 -1$：从条件概率分布$P(x|x_t)$中采样得到样本$x_{t+1}$样本集$(x_{n_1},x_{n_1+1},\dots,x_{n_1+n_2-1})$即为需要的平稳分布对应的样本集。</li></ol><p><strong>问题</strong>：随意给定一个平稳分布$\pi$，如何得到它所对应的马尔科夫链状态转移矩阵$P$。</p><p><strong>解决办法</strong>：MCMC采样和其易用版M-H采样。</p><h2 id="MCMC采样和M-H采样"><a href="#MCMC采样和M-H采样" class="headerlink" title="MCMC采样和M-H采样"></a>MCMC采样和M-H采样</h2><p><strong>马尔科夫链的细致平稳条件</strong></p><p>定义：</p><p>如果非周期的马尔科夫链的状态转移矩阵P和概率分布$\pi(x)$对于所有的$i,j$满足：<br>$$<br>\pi(i)P(i,j) = \pi(j)P(i,j)<br>$$<br>称概率分布$\pi(x)$是状态转移矩阵$P$的平稳分布。其中，$P(i,j)$表示从状态$i$到状态$j$的转化概率。</p><p>证明：<br>$$<br>\sum\limits_{i=1}^{\infty}\pi(i)P(i,j) = \sum\limits_{i=1}^{\infty}\pi(j)P(i,j) =\pi(j)\sum\limits_{i=1}^{\infty}P(j,i)=\pi(j)<br>$$<br>写成矩阵形式为：<br>$$<br>\pi P = \pi<br>$$<br>满足马尔科夫链的收敛性质，即只要找打可以使得概率分布$\pi(x)$满足细致平稳分布的矩阵P即可。</p><p><strong>MCMC采样</strong></p><p>一般情况下，目标平稳分布$\pi(x)$和某一个马尔科夫链状态转移矩阵Q不满足细致平稳条件，即：<br>$$<br>\pi(i)Q(i,j) \ne \pi(j)Q(j,i)<br>$$<br>引入$\alpha(i,j)$，使得上式成立，即：<br>$$<br>\pi(i)Q(i,j)\alpha(i,j) = \pi(j)Q(j,i)\alpha(j,i)<br>$$<br>其中：<br>$$<br>\alpha(i,j) = \pi(j)Q(j,i)<br>$$</p><p>$$<br>\alpha(j,i) = \pi(i)Q(i,j)<br>$$</p><p>得到分布$\pi(x)$对应的马尔科夫链状态转移矩阵P，满足：<br>$$<br>P(i,j) = Q(i,j)\alpha(i,j)<br>$$<br>即：目标矩阵P可以通过任意一个马尔科夫链状态转移矩阵Q乘以$\alpha(i,j)$得到，$\alpha(i,j)$称为<strong>接受率</strong>。取值$[0,1]$之间，相当于一个概率值。</p><p>MCMC采样过程：</p><ol><li><p>输入任意选定的马尔科夫链状态转移矩阵Q，平稳分布$\pi(x)$，设定状态转移次数阈值$n_1$，需要样本个数$n_2$</p></li><li><p>从任意简单概率分布采样得到初始状态值$x_0$</p></li><li><p>for $t=0$ to $n_1+n_2-1$:</p><p>(a)从条件概率分布$Q(x|x_t)$中采样得到样本$x_*$</p><p>(b)从均匀分布采样u~uniform[0,1]</p><p>(c)如果$u &lt; \alpha(x_t,x_<em>) = \pi(x_</em>)Q(x_<em>,x_t)$，则接受转移$x_t \rightarrow x_</em>$，即$x_{t+1} = x_*$</p><p>(d)否则不接受转移，即$x_{t+1} = x_t$</p></li></ol><p>样本集$(x_{n_1}，x_{n_1+1},\dots,x_{n_1+n_2-1})$即为所需要的平稳分布对应的样本集。</p><p><strong>问题</strong>：(c)步骤中，采样接受率$\alpha(x_t,x_*)$可能非常小，如0.1，导致大部分的采样值都被拒绝转移，采样效率很低，有可能采样百万次马尔科夫链还没有收敛，即$n_1$阈值次数需要设置的非常大。此时需要M-H采样。</p><p><strong>解决办法</strong>： M-H采样，解决MCMC采样接受率过低问题</p><p><strong>M-H采样</strong></p><p>Metropolis-Hastings采样的简称。</p><p>对接受率改造如下：<br>$$<br>\alpha(i,j) = \min \left\{ \frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)},1   \right\}<br>$$<br>M-H采样过程：</p><ol><li><p>输入任意选定的马尔科夫链状态转移矩阵Q，平稳分布$\pi(x)$，设定状态转移次数阈值$n_1$，需要样本个数$n_2$</p></li><li><p>从任意简单概率分布采样得到初始状态值$x_0$</p></li><li><p>for $t=0$ to $n_1+n_2-1$:</p><p>(a)从条件概率分布$Q(x|x_t)$中采样得到样本$x_*$</p><p>(b)从均匀分布采样u~uniform[0,1]</p><p>(c)如果$u &lt; \alpha(x_t,x_<em>) =\min \left\{ \frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)},1   \right\} $，则接受转移$x_t \rightarrow x_</em>$，即$x_{t+1} = x_*$</p><p>(d)否则不接受转移，即$x_{t+1} = x_t$</p></li></ol><p>样本集$(x_{n_1}，x_{n_1+1},\dots,x_{n_1+n_2-1})$即为所需要的平稳分布对应的样本集。</p><p>如果选择的马尔科夫链状态转移矩阵$Q$是对称的，即满足$Q(i,j) = Q(j,i)$，此时，接受率可以进一步简化为：<br>$$<br>\alpha(i,j) = \min \left\{ \frac{\pi(j)}{\pi(i)},1   \right\}<br>$$<br><strong>问题</strong>：</p><p>（1）大数据时代，数据特征非常多，M-H采样由于接受率计算式$\frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)}$的存在，在高维需要的计算时间非常可观，算法效率低，同时，由于接受率小于1，计算得到的结果会被拒绝。</p><p>（2）特征维度大，很多时候很难求出目标的各特征维度联合分布，但是可以方便的求出各个特征之间的条件概率分布，需要考虑的是  能否只有各维度之间条件概率分布的情况下方便的采样。</p><p><strong>解决办法</strong>： Gibbs采样。</p><h2 id="Gibbs采样"><a href="#Gibbs采样" class="headerlink" title="Gibbs采样"></a>Gibbs采样</h2><p><strong>重新寻找合适的细致平稳条件</strong></p><p>假设$\pi(x_1,x_2)$是一个二维联合分布，观察第一个特征维度相同的两个点$A(x_1^{(1)},x_2^{(2)}),B(x_1^{(1)},x_2^{(2)})$，有：<br>$$<br>\pi(x_1^{(1)},x_2^{(1)})\pi(x_2^{(2)}|x_1^{(1)}) = \pi(x_1^{(1)})\pi(x_2^{(1)}|x_1^{(1)})\pi(x_2^{(2)}|x_1^{(1)})<br>$$</p><p>$$<br>\pi(x_1^{(1)},x_2^{(2)})\pi(x_2^{(1)}|x_1^{(1)}) = \pi(x_1^{(1)})\pi(x_2^{(2)}|x_1^{(1)})\pi(x_2^{(1)}|x_1^{(1)})<br>$$</p><p>根据条件概率公式可得。</p><p>右侧相等，可得：<br>$$<br>\pi(x_1^{(1)},x_2^{(1)})\pi(x_2^{(2)}|x_1^{(1)}) =\pi(x_1^{(1)},x_2^{(2)})\pi(x_2^{(1)}|x_1^{(1)})<br>$$</p><p>$$<br>\pi(A)\pi(x_2^{(2)}|x_1^{(1)}) =\pi(B)\pi(x_2^{(1)}|x_1^{(1)})<br>$$</p><blockquote><p>如果非周期的马尔科夫链的状态转移矩阵P和概率分布$\pi(x)$对于所有的$i,j$满足：<br>$$<br>\pi(i)P(i,j) = \pi(j)P(i,j)<br>$$<br>称概率分布$\pi(x)$是状态转移矩阵$P$的平稳分布。其中，$P(i,j)$表示从状态$i$到状态$j$的转化概率。</p></blockquote><p>对比可见，在$x_1 = x_1^{(1)}$这条直线上，如果用条件概率分布$\pi(x_2|x_1^{(1)})$作为马尔科夫链的状态转移概率，则任意两点之间的转移满足细致平稳条件。同理，在直线$x_2 = x_2^{(1)}$上。</p><p>构造新的满足细致平稳条件：<br>$$<br>\pi(E)  P(E \rightarrow F) = \pi(F)  P(F \rightarrow E)<br>$$<br><strong>二维Gibbs采样</strong></p><p>需要两个维度之间的条件概率，具体过程如下：</p><p>(1)输入平稳分布$\pi(x_1,x_2)$，设定状态转移次数阈值$n_1$，需要样本个数$n_2$</p><p>(2)随机初始化初始状态值$x_1^{(0)},x_2^{(0)}$</p><p>(3)for $t=0$ to $n_1+n_2-1$：</p><p>​     (a)从条件概率分布$P(x_2|x_1^{(t)})$中采样得到样本$x_2^{t+1}$</p><p>​     (a)从条件概率分布$P(x_1|x_2^{(t+1)})$中采样得到样本$x_1^{t+1}$</p><p>样本集$\{(x_1^{(n_1)},x_2^{(n_1)}), (x_1^{(n_1+1)},x_2^{(n_1+1)}),\dots,(x_1^{(n_1+n_2-1)},x_2^{(n_1+n_2-1)})  \}$即为需要的平稳分布对应的样本集。</p><p>整个采样过程中，通过轮换坐标轴，采样的过程为：<br>$$<br>\left(x_1^{(1)},x_2^{(1)}\right) \rightarrow \left(x_1^{(1)},x_2^{(2)}\right) \rightarrow \left(x_1^{(2)},x_2^{(2)}\right) \rightarrow \dots \rightarrow \left(x_1^{(n_1+n_2-1)},x_2^{(n_1+n_2-1)}\right)<br>$$<br><img src="/blog/2020/05/16/马尔科夫链-蒙特卡罗方法/3.png" title="Gibbs采样"></p><p>采样是在两个坐标轴上不停的轮换，也可以每次随机选择一个坐标轴进行采样。常用的Gibbs采样实现都是基于坐标轴轮换的。</p><p><strong>多维Gibbs采样</strong></p><p>一个n维概率分布$\pi(x_1,x_2,\dots,x_n)$，可以通过在n个坐标轴上轮换采样，来得到新的样本，对于轮换到的任意一个坐标轴$x_i$上的转移，马尔科夫链的状态转移概率为$P(x_i | x_1,x_2,\dots,x_{i-1},x_{i+1},\dots,x_n)$，即固定$n-1$个坐标轴，在某一个坐标轴上移动。</p><p>整个采样过程和<strong>Lasso回归的坐标轴下降法算法</strong>  非常类似，只不过Lasso回归是固定n−1个特征，对某一个特征求极值。而Gibbs采样是固定n−1个特征在某一个特征采样。</p><p>Gibbs采样在高维特征的优势，采样要求数据至少两个维度，一维概率分布的采样无法用Gibbs采样的，此时M-H采样仍然成立。</p><p>Gibbs采样获取概率分布的样本集，蒙特卡罗方法用样本集模拟求和，奠定MCMC算法在大数据时代高维数据模拟求和时的作用。</p><p><a href="https://www.cnblogs.com/pinard/p/6625739.html" target="_blank" rel="noopener">MCMC方法参考资料</a></p><p><a href="https://blog.csdn.net/xiaozhu_1024/article/details/80585151" target="_blank" rel="noopener">Lasso回归</a></p>]]></content>
    
    <summary type="html">
    
      马尔科夫链-蒙特卡罗方法原理简介
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>计算机控制系统</title>
    <link href="https://jiangxj.top/blog/2020/05/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F/"/>
    <id>https://jiangxj.top/blog/2020/05/15/计算机控制系统/</id>
    <published>2020-05-14T16:00:00.000Z</published>
    <updated>2020-06-18T01:42:12.971Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>参考书籍 《计算机控制系统》刘建昌等著</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="一个典型的计算机控制系统的架构"><a href="#一个典型的计算机控制系统的架构" class="headerlink" title="一个典型的计算机控制系统的架构"></a>一个典型的计算机控制系统的架构</h2><img src="/blog/2020/05/15/计算机控制系统/1563412053509.png" title="典型的计算机控制系统架构"><p>数字信号：</p><p>$r(kT)$——给定输入，$y(kT)$——经A/D转换后的系统输出，$u(kT)$——由数字控制器计算的控制的控制信号，$e(kT)=r(kT)-y(kT)$——偏差信号。</p><p>离散模拟信号：</p><p>$y^*(t)$——经过采样开关的被控量信号【时间上离散，幅值上连续】</p><p>模拟信号：</p><p>$y(t)$——系统输出（被控量）</p><p>量化模拟信号：</p><p>$u^*(t)$——经D/A转换后的模拟控制信号【时间上连续，幅值上量化】</p><p>典型的计算机控制系统是：连续-离散混合系统。</p><p><strong>特点</strong>是：模拟、数字和离散模拟信号同在，输入输出均为模拟量的连续环节（被控对象、传感器）、输入和输出均为数字量环节（数字控制器、偏差计算）、输入输出为两类不同量的离散模拟环节（A/D，D/A）共存。</p><h2 id="计算机控制系统的应用要求"><a href="#计算机控制系统的应用要求" class="headerlink" title="计算机控制系统的应用要求"></a>计算机控制系统的应用要求</h2><ul><li>可靠性高</li><li>实时性好。对过程进行实时控制和监测</li><li>环境适应性强</li><li>过程输入和输出配套较好</li><li>系统扩展性好</li><li>系统开放性。在主系统接口、网络通信、软件兼容及升级等方面遵守开放性原则，便于系统扩展，异机种链接、软件的可移植和互换。</li><li>控制软件包功能强。具备丰富的控制算法，同时具备方便的人机交互，实时性好等性能</li></ul><h2 id="计算机控制系统的性能指标"><a href="#计算机控制系统的性能指标" class="headerlink" title="计算机控制系统的性能指标"></a>计算机控制系统的性能指标</h2><p>1、稳定性</p><p>2、稳态指标。</p><p>​       衡量控制系统精度的指标，用稳态误差来表征。稳态误差是输出量$y(t)$的稳态值$y(\infty)$与给定值$y_0$的差值，定义为：<br>$$<br>e(\infty) = y_0-y(\infty)<br>$$<br>其中$e(\infty)$表示控制精度，越小越好。稳态误差$e(\infty)$与控制系统本身的特性（如系统的开环传递函数）、系统的输入信号（如阶跃、速度或加速度输入信号）、反馈通道的干扰（测量干扰或监测回路的干扰）有关。</p><p>3、动态指标</p><p>​       能较为直观的反映控制系统的过渡过程特性。包括<strong>超调量$\sigma \%$、调节时间$t$、</strong>峰值时间$t_p$、<strong>衰减比</strong>$\eta$和振荡次数$N$。</p><p>4、综合指标</p><p>​      设计最优控制系统，常用的综合性能指标是<strong>积分型指标</strong>。如：<br>$$<br>J=\int_0^t e^2(t)dt<br>$$<br>这种“先误差平方后积分”形式的性能指标用于权衡系统总体误差的大小。数学上容易处理，可以得到解析解。</p><h2 id="一个计算机控制系统的典型硬件组成"><a href="#一个计算机控制系统的典型硬件组成" class="headerlink" title="一个计算机控制系统的典型硬件组成"></a>一个计算机控制系统的典型硬件组成</h2><img src="/blog/2020/05/15/计算机控制系统/1563413431889.png" title="计算机系统典型的硬件组成"><p>包括三部分：</p><ol><li>过程装置。包括被控对象、执行机构和测量变送装置</li><li>输入输出通道。包括过程通道和总线接口</li><li>计算机系统。计算机【计算机软件系统=系统软件+应用软件+数据库】和外部设备</li></ol><h3 id="模拟量输入通道"><a href="#模拟量输入通道" class="headerlink" title="模拟量输入通道"></a>模拟量输入通道</h3><p>通常由信号变换器、滤波器、多路模拟开关、前置放大器、采样保持器、A/D转换器、接口和控制电路等部分组成。</p><img src="/blog/2020/05/15/计算机控制系统/1563413702713.png" title="模拟量输入通道"><h3 id="模拟量输出通道"><a href="#模拟量输出通道" class="headerlink" title="模拟量输出通道"></a>模拟量输出通道</h3><p>通常由接口控制电路、D/A转换器（零阶保持期）、滤波器等部分组成。模拟量输出通道有两种结构形式：一是每个通道配置一个D/A转换器，二是通过多路模拟开关共用一个D/A转换器。</p><img src="/blog/2020/05/15/计算机控制系统/1563417797391.png" title="模拟量输出通道"><h3 id="数字量输入通道"><a href="#数字量输入通道" class="headerlink" title="数字量输入通道"></a>数字量输入通道</h3><p>基本功能就是把来自现场的数字信号或开关信号、脉冲信号，按照一定的时序要求送入数字控制器。</p><h3 id="数字量输出通道"><a href="#数字量输出通道" class="headerlink" title="数字量输出通道"></a>数字量输出通道</h3><p>基本功能是把控制器输出的数字控制信号，按照一定的时序要求，送入输出通道中部的<strong>数字执行机构</strong>，如继电器、可编程器件、步进电机等，通过数字执行机的动作实现被控对象的控制作用。</p><h3 id="总线接口"><a href="#总线接口" class="headerlink" title="总线接口"></a>总线接口</h3><h4 id="内部总线"><a href="#内部总线" class="headerlink" title="内部总线"></a>内部总线</h4><p>即计算机内部各外围芯片与处理器之间的总线，用于芯片一级的互连，是<strong>微处理器与外部硬件接口的通路</strong>。</p><p>内部并行总线包括：地址、数据和控制总线</p><img src="/blog/2020/05/15/计算机控制系统/1563418364558.png" title="内部并行总线"><p>内部串行总线SPI的典型结构图如下：</p><img src="/blog/2020/05/15/计算机控制系统/1563418454418.png" title="内部串行总线典型结构"><p>SPI系统使用4条线：串行时钟线（SCK）、主机输入/从机输出数据线MISO、主机输出、从机输入数据线MOSI和低电平有效的从机选择线SS。SCK、MOSI、MISO为共享数据线。</p><h4 id="系统总线"><a href="#系统总线" class="headerlink" title="系统总线"></a>系统总线</h4><p>计算机和各个插件板与系统板之间的总线（多总线multibus，STD bus，PC bus等）。</p><img src="/blog/2020/05/15/计算机控制系统/1563418835443.png" title="计算机各插件板与系统板之间总线"><p>CPU的总线驱动能力有限，大量的接口芯片不能直接挂在微处理器芯片上；存储器、I/O接口芯片太多，电路板安排不下，采用模块化设计会增加总线负载。此时需要在微处理器芯片和总线之间必须加上<strong>驱动器</strong>。</p><p>系统总线可分为5个主要类型：</p><ul><li>数据线。决定数据宽度</li><li>地址线。决定直接选址范围</li><li>控制线。具有控制、时序和中断功能，决定总线功能和适应性的好坏</li><li>电源线和地线</li><li>备用线</li></ul><h4 id="外部总线"><a href="#外部总线" class="headerlink" title="外部总线"></a>外部总线</h4><p>计算机和计算机之间、计算机和外部其它仪表或设备之间连接通信的总线。</p><h2 id="模数之间转换"><a href="#模数之间转换" class="headerlink" title="模数之间转换"></a>模数之间转换</h2><h3 id="D-A转换"><a href="#D-A转换" class="headerlink" title="D/A转换"></a>D/A转换</h3><p>按照规定的时间间隔T对控制器输出的数字量进行D/A转换。基本原则“按权展开求和”，对数字量中的每一位，按权值分别转换为模拟量，然后通过运放求和，得到相应的模拟量的输出。</p><p>$n$位D/A转换器件（DAC）的输出电压$V_{out}$为：<br>$$<br>V_{out} = V_{FSR}\left(\frac{B_1}{2}+\dots+\frac{B_n}{2^n}\right)<br>$$<br>其中，$V_{FSR}$为输出的满幅值电压；$B_1$是二进制最高有效位，$B_n$为最低有效位。</p><p>D/A转换器包括解码和信号恢复两个变换。<strong>解码</strong>用于把数字量转换为幅值等于该数字量的模拟脉冲信号（离散模拟信号，时间离散，幅值是模拟脉冲信号（电压、电流））。</p><p><strong>信号恢复器（保持器）</strong>将离散的模拟脉冲信号按一定的规则保持规定的时间间隔T，把时间离散变成时间上连续。</p><p><strong>D/A转换的误差</strong>：主要由D/A转换器转换精度（转换器字长）和保持器（采样点之间的插值）的形式以及时间间隔T来决定。</p><h3 id="A-D转换"><a href="#A-D转换" class="headerlink" title="A/D转换"></a>A/D转换</h3><p>四种类型：</p><ol><li>计数器式。速度慢，便宜</li><li>并行比较式。用在高速采样 ，当位数多成本高</li><li>双积分式。精度高，有较强抗干扰能力，速度慢，用在高精度低速度场合</li><li>逐次逼近式。兼顾精度和速度，在16位以下广泛使用</li></ol><p>A/D转换要完成采样、量化和编码3个变换。</p><p><strong>采用保持器</strong>对连续的模拟输入信号按一定时间间隔T进行采样，变成时间离散、幅值等于采样时刻输入信号值的序列信号。</p><p><strong>量化</strong>是将采样时刻的信号幅值按最小量化单位取整过程。量化单位越小，采样时刻信号的幅值与变换成的有限维数的二进制数码的差异越小。精度越高。</p><p><strong>编码</strong>将量化的分层信号变换成二进制数码（只是信号形式的改变），是一个无差的等效变换过程。</p><p><strong>A/D转换误差</strong>主要由A/D转换器转换速率（孔径时间）和转换精度（量化误差）来决定。</p><h2 id="计算机控制系统的理论问题"><a href="#计算机控制系统的理论问题" class="headerlink" title="计算机控制系统的理论问题"></a>计算机控制系统的理论问题</h2><p>1、信号转换问题</p><p>​       计算机控制系统在结构上 通常是模拟和数字部件组成的混合系统。</p><p>2、对象建模与性能分析</p><p>​       计算机控制系统是由纯离散系统的计算机和纯连续系统的被控对象构成的混合系统。为了便于分析和设计，都等效地看成<strong>离散系统</strong>处理。对离散系统通常采用<strong>时域的差分方程、复数域的z变换和脉冲传递函数、频域的频率特性以及离散状态空间方程</strong>作为系统数学描述的基本工具。</p><p>3、控制算法设计</p><p>​       研究对象的日趋复杂化，常规控制理论常常难以解决复杂控制系统的控制问题。</p><p>4、控制系统实现技术</p><p>​       采用数字控制器因而会产生数值误差。</p><h2 id="计算机控制系统的基本类型"><a href="#计算机控制系统的基本类型" class="headerlink" title="计算机控制系统的基本类型"></a>计算机控制系统的基本类型</h2><p>按照功能和结构划分，有：</p><p>1、操作指导控制系统。</p><p>​       提供现场情况和进行异常报警，还按照预先建立的数学模型和控制算法进行运算和处理，得出最优设定值打印显示，操作人员根据计算机给出的操作指导，并根据实际经验，经过分析判断，由人直接改变调节器的给定值或操作执行机构。</p><p>2、直接数字控制系统。</p><p>​       DDC系统是计算机把运算结果直接输出去控制生产过程。属于闭环系统，计算机系统对生产过程各参量进行检测，根据规定的数学模型，如PID算法进行运算，发出控制信号，直接控制生产过程。</p><p>​       不仅能完全取代模拟调节器，而且只要改变程序就可以实现其他的复杂控制规律，如前馈控制、非线性控制等。</p><img src="/blog/2020/05/15/计算机控制系统/1563427170177.png" title="直接数字控制系统"><p>3、计算机监督控制系统。</p><p>​       SCC（supervisory computer control）也称为计算机设定值控制系统。计算机的输出用来直接改变模拟调节器或DDC的设定值。</p><p>​       由两种形式：</p><p>​       <strong>SCC+模拟调节器的系统</strong></p><img src="/blog/2020/05/15/计算机控制系统/1563427343113.png" title="SCC+模拟调节器系统"><p>​      优点：能始终使得生产过程处于最优运行状态，与操作指导控制系统相比，不会因手调设定值的方式不同而引起控制质量的差异。灵活安全，出现故障仍可由模拟调节器单独完成操作。</p><p>​       缺点：需要采用模拟调节器。</p><p>​       <strong>SCC+DCC系统</strong></p><img src="/blog/2020/05/15/计算机控制系统/1563427517053.png" title="SCC+DCC系统"><p>​       SCC的输出直接改变DDC的设定值，两者之间通过数据传输直接实现。通常一台SCC可以控制数个DDC计算机，一旦DDC发生故障，可用SCC计算机代替DDC，确保生产的正常进行。</p><p>4、分级控制系统。</p><p>​       由管理信息系统（MIS）、计算机监督控制（SCC）和直接数字控制（DDC）三级控制组成。</p><img src="/blog/2020/05/15/计算机控制系统/1563427717723.png" title="分级控制系统"><p>SCC级为分级控制的中间级，功能是集中生产过程信息，对生产过程进行优化、实现自适应或最控制等，指挥DCC，接收MIS级命令并向MIS级汇报。</p><p>DDC用于直接控制生产过程，多采用微型机。</p><p>5、集散控制系统</p><p>​       DCS（distributed control system）是由微型机为核心的过程控制单元（PCU）、高速数据通道（DHW）、操作人员接口单元（OIU）和监控计算机等部分组成。</p><img src="/blog/2020/05/15/计算机控制系统/1563427946159.png" title="集散控制系统"><p>由于生产过程的大型化、复杂化和分散化，若采用一台计算机控制和管理，一旦计算机发生故障，整个系统停顿，“危险集中”。</p><p>集散控制的<strong>设计思想</strong>：“危险分散”，将控制功能分散，将监控和操作功能高度集中。</p><ul><li>PCU：由很多模板组成，每个控制模板是以微处理器为核心组成的功能板，可以对几个回路进行PID、前馈等多种控制。一个控件发生故障，只影响与之相关的几个回路，达到“危险分散”目的。PCU可以安装在离变送器和执行机构近的地方，缩短控制回路长度，减少噪声，提高可靠性，达到“地理上”分散。</li><li>DHW：将各个PCU、OIU、监控计算机等有机连接【相互协调不可分】起来以实现高级控制和集中控制。挂在DHW上任一单元发生故障，都不会影响其他单元之间的通信联系和正常工作。</li><li>OIU：实现集中监视和集中操作</li><li>监控计算机：实现最优控制和管理。监控机的功能是存取工厂所有的信息和控制参数，打印综合报告，能进行长期趋势分析以及进行最优化计算机控制，控制各个现场过程控制单元（PCU）工作。</li></ul><p>6、总线控制系统。</p><p>​       现场总线控制系统（field  control system，FCS）的体系结构主要表现在：现场通信网络、现场设备互连、控制功能分散、通信线供电、开放式互联网络等方面。</p><p>​        FCS底层产品都带有<strong>CPU的智能单元</strong>【包括智能传感器、智能执行器等】，突破传统DCS的底层产品4-20mA模拟信号的传输。智能单元靠近现场设备，可以独立地完成测量、校正、调整、诊断和控制功能。现场总线协议将它们连接在仪器，任何一个单元出现故障都不会影响到其他单元，更不会影响全局，实现彻底的分散控制，更安全、可靠。</p><p>7、以太控制网络。</p><p>​       以太控制网络<strong>最典型的应用形式</strong>为：顶层采用Ethernet（以太网，局域网技术，包括<a href="https://baike.baidu.com/item/物理层" target="_blank" rel="noopener">物理层</a>的连线、电子信号和介质访问层<a href="https://baike.baidu.com/item/协议" target="_blank" rel="noopener">协议</a>的内容），网络层和传输层采用TCP/IP协议。嵌入式控制器、智能现场测控仪表和传感器可以很方便的接入以太控制网。</p><p>​       以太控制网容易与信息网络集成，组建统一的企业风格。以太控制避免了现场总线技术游离于计算机网络技术之外，使得现场总线技术和网络技术融合，实现网络控制系统的彻底开放。</p><h1 id="信号转换"><a href="#信号转换" class="headerlink" title="信号转换"></a>信号转换</h1><h2 id="信号变换原理"><a href="#信号变换原理" class="headerlink" title="信号变换原理"></a>信号变换原理</h2><h3 id="计算机控制系统信号转换分析"><a href="#计算机控制系统信号转换分析" class="headerlink" title="计算机控制系统信号转换分析"></a>计算机控制系统信号转换分析</h3><img src="/blog/2020/05/15/计算机控制系统/1563430889330.png" title="计算机控制系统信号"><p>（1）模拟信号。时间上连续，幅值上连续。即连续信号。</p><p>（2）离散模拟信号。时间上离散，幅值上连续的信号。即采样信号</p><p>（3）数字信号。时间上离散，幅值上离散（已经量化）的信号，可用一个序列数字表示</p><p>（4）量化。采用一组数码（多用二进制数码）来逼近 离散模拟信号的幅值，将其转换为数字信号</p><p>（5）采样。将模拟信号按一定的时间间隔抽样成离散模拟信号的过程。</p><img src="/blog/2020/05/15/计算机控制系统/1563431168766.png" title="采样过程"><p>采样函数可以用$x^<em>(t)$、$y^</em>(t)$及$e^<em>(t)$表示，`</em>`表示离散化。</p><p>采样分为：</p><ul><li>均匀采样：采样周期不变</li><li>非均匀采样：采样周期变化</li><li>随机采样：采样间隔大小随机变化</li></ul><h3 id="采样过程及采样函数的数学表示"><a href="#采样过程及采样函数的数学表示" class="headerlink" title="采样过程及采样函数的数学表示"></a>采样过程及采样函数的数学表示</h3><img src="/blog/2020/05/15/计算机控制系统/1563431405728.png" title="采样函数"><p>得到时间上离散的数值序列：<br>$$<br>f^*(t) = \{f(0T),f(1T),f(2T),\dots,f(kT),\dots\}<br>$$<br>其中$T$为采样周期。</p><p>==脉冲采样==：</p><img src="/blog/2020/05/15/计算机控制系统/1563431537001.png" title="脉冲采样"><p>采样周期$T$比采样开关闭合时间$\tau$大很多，即$\tau \ll T$，$\tau$比起被控对象的时间常数也非常小，认为$\tau \rightarrow 0$。</p><p>连续函数$f(t)$，经脉冲采样器调制后输出的一个采样函数$f^*(t)$。其中$\delta_T(t)=\sum\limits_{k=0}^{\infty} \delta(t-kT)$为单位理想脉冲序列。</p><p>采样函数：<br>$$<br>f^<em>(t) = f(t)\delta_T(t)=f(t)\sum\limits_{k=0}^{\infty} \delta(t-kT)<br>$$<br>其中$ \delta(t-kT)$为$t=kT$时刻的理想单位脉冲，定义为：<br>$$<br>\delta(t-kT) =\begin{equation}<br>\left\{<br>\begin{array}{lr}<br> \infty , t=kT\\<br> 0, t \ne kT<br> \end{array}<br> \right.<br>\end{equation}<br>$$<br>且冲量为1，即：<br>$$<br>\int_{0}^{\infty} \delta(t-kT)dt = 1<br>$$<br>得到理想脉冲采样函数数学表达式：<br>$$<br>f^</em>(t) =\sum\limits_{k=0}^{\infty} f(kT)\delta(t-kT)<br>$$<br>其中，$\delta(t-kT)$仅表示脉冲存在的时刻，冲量为1；脉冲的大小由采样时刻的函数值$f(kT)$决定，称为<strong>脉冲强度</strong>。</p><h3 id="采样函数的频谱分析及采样定理"><a href="#采样函数的频谱分析及采样定理" class="headerlink" title="采样函数的频谱分析及采样定理"></a>采样函数的频谱分析及采样定理</h3><p>$$<br>f^*(t) =f(t)\sum\limits_{k=0}^{\infty} \delta(t-kT)<br>$$</p><p>$$<br>\delta_T(t) =  \sum\limits_{k=-\infty}^{\infty}\delta(t-kT)= \sum\limits_{k=-\infty}^{\infty}C_ke^{jkw_st}<br>$$</p><p>其中，$w_s = \frac{2\pi}{T}$为采样角频率；$C_k$为傅里叶系数，表示为：<br>$$<br>C_k = \frac{1}{T}\int_{-\frac{T}{2}}^{\frac{T}{2}} \delta_T(t)e^{-jkw_st}dt<br>$$<br>$\delta_T(t)$在$\left[-\frac{T}{2},\frac{T}{2}\right]$时间内，仅在$t=0$时有脉冲，脉冲函数的筛选性，即：<br>$$<br>\int_{-\infty}^{\infty}\delta(t)f(t)dt = f(t) |_{t=0}<br>$$</p><p>$$<br>C_k = \frac{1}{T}e^{-jkw_s t}|_{t=0} = \frac{1}{T}<br>$$</p><p>$$<br>\delta_T(t) = \frac{1}{T}\sum\limits_{k=-\infty}^{\infty}e^{jkw_st}<br>$$</p><p>所以，采样函数可以写成：<br>$$<br>f^<em>(t) = \frac{1}{T}\sum\limits_{k=-\infty}^{\infty}f(t)e^{jkw_st}<br>$$<br>由拉氏变换$F(s) = \int_{0}^{\infty} f(t)e^{-st}dt$可得：<br>$$<br>F^</em>(s) = \int_{0}^{\infty}f^<em>(t)e^{-st}dt=\int_{0}^{\infty}\frac{1}{T}\sum\limits_{k=-\infty}^{\infty}f(t)e^{jkw_et}e^{-st}dt<br>$$<br>根据拉氏变换复位移定理得：<br>$$<br>F^</em>(s) = \frac{1}{T} \sum\limits_{k=-\infty}^{\infty}F(s-jkw_s)<br>$$<br>令$s=jw，n=-k$，直接求得采样函数得傅里叶变换式：<br>$$<br>F^<em>(jw) = \frac{1}{T}\sum\limits_{n=-\infty}^{\infty}F(jw+jnw_s)<br>$$<br>$F^</em>(jw)$为采样函数$f^*(t)$得频谱函数。</p><img src="/blog/2020/05/15/计算机控制系统/1563433414794.png"><p>采样周期$T$的选择会影响$f^<em>(t)$的频谱，<em>*采样定理要解决的问题是</em></em>：采样周期选多大，才能将采样信号较少失真地恢复为原连续信号。</p><p>==shannon采样定理==：<br>$$<br>w_s \ge 2w_{max}<br>$$<br>$$<br>T \le \frac{\pi}{w_{max}}<br>$$</p><p>如果一个连续信号不包含高于频率$w_{max}$的频率分量，完全可以用周期$T&lt; \frac{\pi}{w_{max}}$的均匀采样值来描述，即当采样频率$w_s &gt; 2w_{max}$，可以从采样信号中不失真地恢复原连续信号。</p><h2 id="采样恢复与保持器"><a href="#采样恢复与保持器" class="headerlink" title="采样恢复与保持器"></a>采样恢复与保持器</h2><p>计算机作为信息处理装置，其输出一般有两种形式：一是直接数字量输出，如开关形式、步进电机控制等；一种是需要将数字信号$u(kT)$转换为连续信号$u(t)$。</p><p>数字信号无失真的恢复成连续信号，有Shannon采样定理，采样频率$w_s \ge 2w_{max}$，则在被控对象前加一个理想滤波器：</p><img src="/blog/2020/05/15/计算机控制系统/1563434410526.png" title="采样恢复与保持器"><p>实际所采用的是<strong>保持器</strong>，与理想滤波器特性相近的物理可实现。</p><p>从脉冲序列$u^<em>(t)$的全部信息种恢复原来的连续信号$u(t)$，通过保持器来完成这个恢复过程。实际是一个多项式外推装置。一<strong>个方法是利用$u(t)$的幂级数展开公式</strong>，即：<br>$$<br>u(t)=u(kT) +u’(kT)(t-kT)+\frac{u’’(kT)}{2}(t-kT)^2+\dots,kT\le t&lt;(k+1)T<br>$$<br>若按第一项组成外推器，所用$u(t)$的多项式是零阶的，称为<strong>零阶保持器</strong>，若按前两项组成外推装置，所用的多项式是一阶的，称为<em>*一阶保持器</em></em>。</p><p>导数值可以用各个采样时刻的各阶差商来表示，即：<br>$$<br>u’(kT) = \frac{1}{T}\{u(kT)-u[(k-1)T]\}<br>$$</p><p>$$<br>u’’(kT) = \frac{1}{T}\{u’(kT)-u’[(k-1)T]\}<br>$$</p><p>同理可得$u’[(k-1)T]$，以此类推得：<br>$$<br>u’’(kT) = \frac{1}{T^2}\{u(kT) - 2u[(k-1)T]+u[(k-2)T]\}<br>$$</p><h3 id="零阶保持器"><a href="#零阶保持器" class="headerlink" title="零阶保持器"></a>零阶保持器</h3><p>$$<br>u_h(t) =u(t)= u(kT),kT \le t\le(k+1)T<br>$$</p><p>特点是：零阶保持器把$kT$时刻的采样值，简单的、不增不减地保持到下一个采样时刻$(k+1)T$到来之前。</p><img src="/blog/2020/05/15/计算机控制系统/1563435974531.png" title="零阶保持器"><p>零阶保持器的传递函数：</p><img src="/blog/2020/05/15/计算机控制系统/1563436285801.png" title="零阶保持器传递函数"><p>脉冲响应函数$g_0(t)$分解后线性叠加：<br>$$<br>g_0(t) = l(t)-l(t-T)<br>$$<br>阶跃函数$l(t) = \cases{1,t\ge0 \ 0,t&lt;0}$</p><p>拉氏变换为：<br>$$<br>G_0(s) = L[g_0(t)] = \frac{1}{s}-\frac{1}{s}e^{-st} = \frac{1-e^{-st}}{s}<br>$$<br>输入单位脉冲$\delta(t)$的拉氏变换：<br>$$<br>X(s) = L[\delta(t)]=1<br>$$<br>零阶保持器的传递函数为：<br>$$<br>W_{h0}(s) = \frac{G_0(s)}{X(s)} = \frac{1-e^{-sT}}{s}<br>$$<br>零$s=jw$，得到零阶保持器的频率特性。</p><h3 id="一阶保持器"><a href="#一阶保持器" class="headerlink" title="一阶保持器"></a>一阶保持器</h3><p>$$<br>\begin{equation}<br>\begin{aligned}<br>u_h(t) &amp;= u(kT)+u’(kT)(t-kT),kT  \le t &lt;(k+1)T \ &amp;= u(kT) +\frac{u(kT)-u[(k-1)T]}{T}(t-kT)<br>\end{aligned}<br>\end{equation}<br>$$</p><h2 id="z变换及反变换"><a href="#z变换及反变换" class="headerlink" title="z变换及反变换"></a>z变换及反变换</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>是拉氏变换的特殊形式，在离散系统的分析及设计中发挥重要作用。<br>$$<br>F(s)= L[f(t)] = \int_{-\infty}^{\infty}f(t)e^{-st}dt<br>$$</p><p>$$<br>f^*(t) =\sum\limits_{k=0}^{\infty} f(kT)\delta(t-kT)<br>$$</p><p>其拉氏变换为：<br>$$<br>F^<em>(s) = L[f^</em>(T)] =\sum\limits_{k=0}^{\infty}f(kT)\left[\int_{-\infty}^{\infty}\delta(t-kT)e^{-st}dt\right]<br>$$<br>根据广义脉冲函数$\delta(t)$的性质：<br>$$<br>\int_{-\infty}^{\infty}\delta(t-kT)e^{-st}dt = e^{-skT}=L[\delta(t-kT)]<br>$$<br>令$z= e^{sT}$，得采样函数$f^<em>(t)$的$z$变换为：<br>$$<br>F^</em>(s) = \sum\limits_{k=0}^{\infty}f(kT)e^{-skT}<br>$$<br>$$<br>F(z) = \sum\limits_{k=0}^{\infty}f(kT)z^{-k}<br>$$</p><p>其中$f(kT)$表示时间序列的强度，$z^{-k}$表示时间序列出现的时刻，相对时间的起点，延迟了$k$个采样周期。$F(z)$既包含了信号幅值的信息，又包含了时间信息。</p><p><strong>注意到</strong>：在z变换中，仅仅考虑到采样时刻的采样值，所以$F(z)$只能表征采样函数$f^*(t)$的z变换，只能表征连续时间函数$f(t)$在采样时刻上的特性，不能表征采样点之间的特性。</p><h3 id="z变换方法"><a href="#z变换方法" class="headerlink" title="z变换方法"></a>z变换方法</h3><h3 id="z变换的基本定理"><a href="#z变换的基本定理" class="headerlink" title="z变换的基本定理"></a>z变换的基本定理</h3><h3 id="z反变换"><a href="#z反变换" class="headerlink" title="z反变换"></a>z反变换</h3><p>从$z$变换$F(z)$求出采样函数$f^<em>(t)$，称为$z$反变换，表示为：<br>$$<br>Z^{-1}[F(z)] = f^</em>(t)<br>$$<br>$z$变换得到的是各采样时刻上连续函数$f(t)$的数值序列值$f(kT)$，得不到两个采样时刻之间的连续函数的信息，因此无法用$z$反变换方法求出原连续函数$f(t)$，即$Z^{-1}[F(z)] \ne  f(t)$。</p><h3 id="扩展z变换"><a href="#扩展z变换" class="headerlink" title="扩展z变换"></a>扩展z变换</h3><p>因为$F(z)$只能反映连续信号$f(t)$在各个采样时刻的变换情况 ，而不能反映$f(t)$在采样时刻之间的任何变换信息。$z$变换的分析方法及所得结论只针对一些离散时刻有效，而在这些离散时刻之间的时刻是无效的。</p><p>在计算机控制系统的分析和设计时，不仅需要知道在采样点上的输入、输出关系，还要知道采样点之间的输入、输出关系，需要扩展$z$变换。</p><h1 id="计算机控制系统数学描述与性能分析"><a href="#计算机控制系统数学描述与性能分析" class="headerlink" title="计算机控制系统数学描述与性能分析"></a>计算机控制系统数学描述与性能分析</h1><h2 id="离散系统"><a href="#离散系统" class="headerlink" title="离散系统"></a>离散系统</h2><p>离散时间系统的输入和输出均为离散信号，离散系统可以抽象为一种系统的离散输入信号和系统的离散输出信号之间的数学变换和映射。</p><p>设单输入单输出的离散系统$D$的输入为$e(k)$，输出为$u(k)=u(kT)$。两者都是离散的数值序列。</p><img src="/blog/2020/05/15/计算机控制系统/1563498246228.png" title="离散系统"><p>有：<br>$$<br>u(k) = D[e(k)]<br>$$<br>$$<br>e(k)=ae_1(k) +be_2(k)<br>$$</p><p>$$<br>u(k) = aD[e_1(k)]+bD[e_2(k)]<br>$$</p><p>该系统的变换函数$D$是线性的，$u(k)$与$e(k)$之间是线性关系。</p><p>系统$D$的参数不随时间变化，即系统$D$的响应不取决于输入作用的时刻，系统是常系数的，即<strong>定常系统</strong>。</p><p>线性常系数离散系统一般采用<strong>差分方程</strong>来描述。系统在某一时刻$k$的输出$u(k)$，不仅取决于本时刻的输入$e(k)$，与过去的时刻的输入数值序列$e(k-1),e(k-2),\dots$有关，还与该时刻以前的输出值有关，即：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>&amp; u(k)+a_1u(k-1)+a_2u(k-2)+\dots+a_nu(k-n) \ &amp;=b_0e(k) +b_1e(k-1)+b_2e(k-2)+\dots+b_me(k-m)<br>\end{aligned}<br>\end{equation}<br>$$<br>即：<br>$$<br>u(k) = -\sum\limits_{i=1}^na_iu(k-i) +\sum\limits_{j=0}^mb_je(k-j)<br>$$<br>当系数均为常数时，是一个$n$阶线性常系数差分方程。上式是后向非齐次差分方程。</p><p><strong>前向差分方程和后向差分方程区别</strong>：前向多用于描述非零初始值的离散系统，后向多用于描述全零初始值的离散系统。</p><h2 id="差分方程"><a href="#差分方程" class="headerlink" title="差分方程"></a>差分方程</h2><p>描述离散控制系统，通过差分方程的求解，来分析和设计离散控制系统。</p><p>差分方程的解法有迭代法、经典解法和$z$变换解法。</p><h4 id="差分方程解法"><a href="#差分方程解法" class="headerlink" title="差分方程解法"></a>差分方程解法</h4><h2 id="脉冲传递函数"><a href="#脉冲传递函数" class="headerlink" title="脉冲传递函数"></a>脉冲传递函数</h2><p>线性连续系统的动态特性主要用传递函数来描述 ，线性离散控制系统则主要用<strong>脉冲传递函数</strong>来描述，脉冲传递函数也简称为$z$传递函数。</p><p><strong>脉冲传递函数定义：</strong></p><p>在线性离散控制系统中，在零初始条件下，一个 系统（或环节）输出脉冲序列的$z$变换与输入脉冲序列的$z$变换之比，即：<br>$$<br>W(z)= \frac{Y(z)}{X(z)}=\frac{输出脉冲序列的z变换 }{输入脉冲序列的z变换}<br>$$<br>脉冲传递函数<strong>仅取决于系统本身的特性</strong>，与输入量无关。</p><p>脉冲传递函数的推导：</p><h3 id="计算机控制系统的脉冲传递函数"><a href="#计算机控制系统的脉冲传递函数" class="headerlink" title="计算机控制系统的脉冲传递函数"></a>计算机控制系统的脉冲传递函数</h3><img src="/blog/2020/05/15/计算机控制系统/1563499824430.png" title="计算机控制系统的脉冲传递函数"><p>计算机控制系统由数字部分和连续对象部分构成的闭环控制系统，数字部分表示控制算法，它的输入和输出皆为离散信号序列。</p><p>可用脉冲传递函数$D(z)$来表示输出输入关系。再求出连续系统的等效脉冲传递函数$W_d(z)$，得到控制系统的各种脉冲传递函数。</p><h2 id="计算机控制系统的稳定性分析"><a href="#计算机控制系统的稳定性分析" class="headerlink" title="计算机控制系统的稳定性分析"></a>计算机控制系统的稳定性分析</h2><p>稳定性分析的基础是$z$变换，$z$变换与连续系统$s$变换在数学上的内在联系，可经过一定的变换把分析连续系统稳定性的方法引入到离散控制系统中。</p><p>由$s$平面上稳定性条件来分析$z$平面的稳定条件，然后由$s$平面到$z$平面的映射，分析采样周期对系统稳定性的影响。</p><h3 id="离散系统的稳定性条件"><a href="#离散系统的稳定性条件" class="headerlink" title="离散系统的稳定性条件"></a>离散系统的稳定性条件</h3><p>在连续系统中，闭环传递函数可以写成两个多项式之比：<br>$$<br>\frac{Y(s)}{R(s)} = \frac{b_0s^m +\dots+b_{m-1}s+b_m}{s^n +a_1s^{n-1}+\dots +a_{n-1}s +a_n}<br>$$<br><strong>连续系统稳定条件</strong>：闭环传递函数的全部极点位于$s$平面的做半平面内，或传递函数的极点具有负实部。</p><p>在离散系统中，若输入序列有限，其输出序列也是有限的。</p><p><strong>离散系统稳定性条件</strong>：闭环脉冲传递函数的全部极点位于$z$平面上以原点为圆心的单位圆内。</p><h3 id="采样周期与系统稳定性关系"><a href="#采样周期与系统稳定性关系" class="headerlink" title="采样周期与系统稳定性关系"></a>采样周期与系统稳定性关系</h3><p>计算机控制系统的控制对象是连续系统，等效离散化后的闭环系统的$z$传递函数模型与采样周期选取有关，极点分布也与采样周期的选取有关。</p><p><strong>一般来说，采样周期越小，系统稳定性越高</strong>，采样周期对系统稳定性的影响主要是由计算机控制系统中采样保持器引起的。</p><h2 id="离散系统稳定性的代数判据"><a href="#离散系统稳定性的代数判据" class="headerlink" title="离散系统稳定性的代数判据"></a>离散系统稳定性的代数判据</h2><h3 id="劳斯稳定性判据"><a href="#劳斯稳定性判据" class="headerlink" title="劳斯稳定性判据"></a>劳斯稳定性判据</h3><p>连续系统通过判断系统特征方程的根是否都在$s$平面虚轴左边来确定系统是否稳定。离散系统的稳定边界是$z$平面的单位圆，而不是虚轴，连续系统的Routh判据不能直接应用于离散系统的稳定性判别，需要引入$\omega$<strong>变换（双线性变换）</strong>。</p><p>通过$\omega$变换，把离散系统在$z$平面的稳定边界单位圆映射为新的$\omega$平面的虚轴；把离散系统$z$平面的稳定域——单位圆内部区域映射为新的$\omega$平面的左半平面，并且将离散系统原来以$z$为变量的特征多项式化为以$\omega$为变量的特征多项式。</p><p>$\omega$变换的定义为：<br>$$<br>z= \frac{1+(T/2)\omega}{1-(T/2)\omega}<br>$$<br>其中$T$为采样周期，得到$\omega$的解为：<br>$$<br>\omega = \frac{2}{T}·\frac{z-1}{z+1}<br>$$</p><h3 id="朱利稳定性判据"><a href="#朱利稳定性判据" class="headerlink" title="朱利稳定性判据"></a>朱利稳定性判据</h3><p>Jury稳定性判据是根据系统特征方程的系数判断系统的稳定性，不用求特征方程的根。</p><p>Jury一个重要优点是可以在$z$域直接进行，不需要进行$z-\omega$变换。</p><p>Routh判据不仅可以判断系统的稳定性，还可以判断出不稳定极点的个数，Jury判据只能判断出系统是否稳定。</p><h2 id="计算机控制系统稳态过程分析"><a href="#计算机控制系统稳态过程分析" class="headerlink" title="计算机控制系统稳态过程分析"></a>计算机控制系统稳态过程分析</h2><p>稳态指标是用<strong>稳态误差</strong>来表示，稳态误差是系统过渡过程结束到达到稳态以后，系统参数输入与系统输出之间的偏差。</p><p>稳态误差越小，系统控制稳态精度越高。</p><h2 id="计算机控制系统暂态分析"><a href="#计算机控制系统暂态分析" class="headerlink" title="计算机控制系统暂态分析"></a>计算机控制系统暂态分析</h2><p>暂态分析主要用系统在单位阶跃输入信号作用下的相应特性来描述，反映控制系统的动态过程。</p><p>主要性能指标用超调量$\sigma \%$、上升时间$t_r$、峰值时间$t_p$和调节时间$t_s$表示。</p><h2 id="计算机控制系统的频域特性分析"><a href="#计算机控制系统的频域特性分析" class="headerlink" title="计算机控制系统的频域特性分析"></a>计算机控制系统的频域特性分析</h2><h3 id="离散系统的频域描述"><a href="#离散系统的频域描述" class="headerlink" title="离散系统的频域描述"></a>离散系统的频域描述</h3><p>在连续系统中，一个系统（或环节）的频域特性是指，在正弦信号作用下，系统（或环节）的稳态输出与输入的复数比随输入信号频率变换的特性。</p><p>连续系统的频率特性公式：<br>$$<br>W(jw)= W(s)|_{s=jw}<br>$$<br>可得到离散系统的频率特性公式：<br>$$<br>W(e^{jwT})=W(z)|_{z=e^{jwT}}<br>$$<br>连续系统的频率特性$W(jw)$随着$w$变化，相当于$W(s)$当$s$沿虚轴变化时$s=jw$的特性；</p><p>离散系统的频率特性$W(e^{jwT})$相当于考察传递函数$W(z)$当$z$沿单位圆变化时$z=e^{jwT}$的特性。</p><h3 id="离散系统频域稳定性分析"><a href="#离散系统频域稳定性分析" class="headerlink" title="离散系统频域稳定性分析"></a>离散系统频域稳定性分析</h3><p>在离散系统中，奈奎斯特稳定判据（<strong>奈氏判据</strong>）根据<strong>复变函数的幅角原理，利用开环频率特性来判别闭环系统的稳定性。</strong></p><p>设离散系统的开环脉冲传递函数为$W_K(z) = \frac{M(z)}{N(z)}$，阶次低于$N(z)$的阶次，相应的单位反馈系统的闭环脉冲传递函数为：<br>$$<br>W_B(z) = \frac{W_K(z)}{1+W_K(z)} = \frac{M(z)}{M(z)+N(z)} = \frac{M(z)}{F(z)}<br>$$<br>系统闭环特征方程为：<br>$$<br>P(z) = 1+W_K(z) =\frac{M(z)+N(z)}{N(z)}=\frac{F(z)}{N(z)} =0<br>$$<br>其中$N(z)$是系统开环特征多项式，零点为开环系统极点；$F(z)$为系统闭环特征多项式，零点为闭环系统极点。</p><p>闭环系统稳定的充要条件：$F(z)$(或P(z))在单位圆外无零点。</p><h3 id="离散系统伯德图分析"><a href="#离散系统伯德图分析" class="headerlink" title="离散系统伯德图分析"></a>离散系统伯德图分析</h3><p>伯德图广泛应用于单输入单输出连续系统的设计，原理是利用开环系统的对数频率特性，对系统稳定性、稳态性能和暂态性能及逆行分析，是常用的系统频率特性的性能分析和校正环节的设计方法。</p><h1 id="数字控制器模拟化设计方法"><a href="#数字控制器模拟化设计方法" class="headerlink" title="数字控制器模拟化设计方法"></a>数字控制器模拟化设计方法</h1><img src="/blog/2020/05/15/计算机控制系统/1563504258372.png" title="数字控制器模拟化设计"><p>对于混合计算机控制系统，包括数字信号、模拟信号、离散模拟信号和量化模拟信号。</p><p><strong>模拟化设计方法有两种</strong>：一是利用熟悉的各种模拟系统设计方法（连续域设计方法）设计满意的模拟控制器，然后将其离散化为数字控制器。【<strong>数字控制器的模拟化设计方法</strong>】；二是首先把模拟被控对象连续部分离散化，然后直接在离散域设计数字控制器。【<strong>离散化设计（直接设计）方法</strong>】</p><p>对于数字化控制器模拟化设计方法：关心点在于把混合系统当作模拟系统来设计需要什么约束条件以及模拟控制器的离散化会给系统的性能带来什么影响。</p><h2 id="连续控制器的离散化方法"><a href="#连续控制器的离散化方法" class="headerlink" title="连续控制器的离散化方法"></a>连续控制器的离散化方法</h2><p>连续控制器的离散化是求连续控制器的传递函数$D(s)$的等效离散传递函数$D(z)$。</p><p>离散化的方法包括：$z$变换、差分变换、双线性变换、零极点匹配法等</p><h2 id="数字PID控制器"><a href="#数字PID控制器" class="headerlink" title="数字PID控制器"></a>数字PID控制器</h2><p>PID控制器表示比例（proportional）-积分（integral）-微分（differential）控制规律。控制器的输出和输入是比例-积分-微分关系。</p><p>基本的数字PID控制算法包括<strong>位置式PID控制算法</strong>和<strong>增量式PID控制算法</strong>。</p><p><strong>模拟PID控制器算法</strong>为：<br>$$<br>u(t) = K_p\left[e(t)+\frac{1}{T_i}\int_{0}^{t}e(t)dt+T_d\frac{de(t)}{dt}\right]<br>$$<br>其中，$u(t)$为输出；$e(t)$为输入；$K_p$为比例系数；$T_i$为积分时间常数；$T_d$为微分时间常数。</p><p><strong>模拟PID的传递函数形式</strong>：<br>$$<br>D(s)= \frac{U(s)}{E(s)} = K_p\left(1+\frac{1}{T_is} +T_d s\right)<br>$$<br><strong>模拟PID控制器离散化处理</strong>：用后向差分近似代替微分<br>$$<br>\begin{equation}<br>\left\{</p><p>\begin{array}{lr}<br>u(t)\approx u(kT)\\e(t) \approx e(kT) \ \int_{0}^{t}e(t)dt \approx T\sum\limits_{i=1}^{k}e(iT) \ \frac{de(t)}{dt}\approx \frac{e(kT)-e(kT-T)}{T}<br>\end{array}<br>\right.<br>\end{equation}<br>$$<br>省略采样周期$T$，即$kT=T$，有：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>u(k)&amp;= K_p \left\{ e(k) +\frac{T}{T_i}\sum\limits_{j=1}^{k}e(j) + \frac{T_d}{T}[e(k)-e(k-1)]          \right\} \ &amp;= K_pe(k) +K_i\sum\limits_{j=1}^{k}e(j) +K_d[e(k)-e(k-1)]<br>\end{aligned}<br>\end{equation}<br>$$<br>其中$K_i = K_p\frac{T}{T_i}$为积分系数；$K_d$为微分系数，上式为<strong>位置式数字PID控制算法</strong>。</p><p><strong>增量式数字PID算法</strong>：</p><p>由位置式PID控制算法得：<br>$$<br>u(k-1) = K_pe(k-1) +K_i\sum\limits_{j=1}^{k-1}e(j) +K_d[e(k-1)-e(k-2)]<br>$$</p><p>$$<br>\begin{equation}<br>\begin{aligned}<br>\Delta u(k) &amp;= u(k) - u(k-1)\ &amp; = K_p[e(k)-e(k-1)]+K_ie(k) +K_d[e(k) -2e(k-1)+e(k-2)]<br>\end{aligned}<br>\end{equation}<br>$$</p><p>增量式PID算法表示执行机构（如阀门、步进电机等）得调节增量，即$k$时刻相对于$k-1$时刻的调节增量。</p><p><strong>位置式数字PID控制算法一般形式</strong>：</p><p>由增量式PID算法得：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>u(k) &amp;= u(k-1) +\Delta u(k) \ &amp;= u(k-1) +K_p[e(k)-e(k-1)]+K_ie(k) +K_d[e(k)-2e(k-1)+e(k-2)]</p><p>\end{aligned}<br>\end{equation}<br>$$</p><h2 id="数字PID控制器算法工程化改进"><a href="#数字PID控制器算法工程化改进" class="headerlink" title="数字PID控制器算法工程化改进"></a>数字PID控制器算法工程化改进</h2><h3 id="积分分离数字PID算法（PD算法）"><a href="#积分分离数字PID算法（PD算法）" class="headerlink" title="积分分离数字PID算法（PD算法）"></a>积分分离数字PID算法（PD算法）</h3><p>很多控制系统在开始启动、停止或较大幅度改变给定信号时，控制器输入端都会产生较大的偏差（系统给定和输出信号之间的偏差），PID算法中的积分项经过短时间积累就会使得控制量$u(k)$变得很大甚至达到饱和（执行机构的机械极限），此时控制系统会处于一种非线性状态，不能根据控制器输入偏差的变化按预期控制规律来正确地改变控制量。</p><p>积分项很大，需要经过很长时间误差才能被减下来，系统会产生严重超调。</p><p><strong>直接改进方法</strong>是把积分项分离出来，当偏差绝对值超出分离阈值A时，积分不起作用，构成PD控制器。当偏差绝对值在阈值范围内，积分起作用。<br>$$<br>u(k) = K_pe(k)+K_1K_i\sum\limits_{j=1}^{k} e(j) K_d[e(k) - e(k-1)]<br>$$</p><p>$$<br>K_1 = \cases{1, |e(j| \le A \ 0,|e(j)| &gt; A}<br>$$</p><p>其中，$K_1$为逻辑系数；$A$为积分分离阈值。</p><img src="/blog/2020/05/15/计算机控制系统/1563507093264.png" title="PD算法"><p>算法流程：</p><img src="/blog/2020/05/15/计算机控制系统/1563507337946.png" title="算法流程"><h3 id="带死区的数字PID控制算法"><a href="#带死区的数字PID控制算法" class="headerlink" title="带死区的数字PID控制算法"></a>带死区的数字PID控制算法</h3><p>被控变量达到工艺要求的精度，即系统的输出与输入之间的偏差达到要求的控制进度，偏差无限小，代价大；复杂的控制过程中有多个控制系统并存，各个被控变量之间可能存在一定的关联，过分追求一个指标，可能会影响其他指标，只需要达到设定指标即可。</p><img src="/blog/2020/05/15/计算机控制系统/1563507373962.png" title="带死区的数字PID控制算法"><p>死区算法为：<br>$$<br>e’(k) = \cases{e(k), |e(k| &gt;B \ 0,|e(k| \le B}<br>$$<br>有：<br>$$<br>\Delta u(k) =K_p[e’(k) - e’(k-1)] +K_ie’(k) +K_d[e’(k)-2e’(k-1)+e’(k-2)]<br>$$<br>带死区的位置式PID算法为：<br>$$<br>u(k) =u(k-1) +\Delta u(k)<br>$$<br>注意：由于PID控制器积分的<strong>保持作用</strong>，当$e’(k) = 0$时，PID控制器的输出保持$k-1$时刻的值的输出，而非零。</p><h3 id="不完全微分PID算法"><a href="#不完全微分PID算法" class="headerlink" title="不完全微分PID算法"></a>不完全微分PID算法</h3><p>PID控制算法中<strong>微分环节对改善系统超调量等动态性能具有重要作用，但是它对高频干扰信号比较敏感</strong>。</p><p>当控制器输入偏差信号突然变化时，PID控制器中的微分项将很大，持续时间又很短，产生<strong>微分失控</strong>现象。</p><img src="/blog/2020/05/15/计算机控制系统/1563508036395.png" title="不完全微分PID算法"><p>不完全微分PID控制算法中的微分作用持续很长时间，具有更好的抗干扰作用。</p><p>不完全微分PID控制算法增量形式为：<br>$$<br>\Delta u(k) = \alpha \Delta u(k-1) +(1-\alpha)\Delta u’(k)<br>$$<br>其中：<br>$$<br>\Delta u’(k) = K_p[e(k)-e(k-1)] +K_i e(k) +K_d [e(k) -2e(k-1)+e(k-2)]<br>$$</p><h3 id="微分先行PID控制算法"><a href="#微分先行PID控制算法" class="headerlink" title="微分先行PID控制算法"></a>微分先行PID控制算法</h3><p>在给定值频繁升降变换的场合，为了避免系统超调量过大甚至发生振荡，导致执行机构剧烈动作，需要对模拟PID控制器进行改进。</p><img src="/blog/2020/05/15/计算机控制系统/1563513446098.png" title="微分先行PID控制算法"><p>输出微分先行：只对输出微分，不对输入微分。适合给定值频繁升降的场合，可以避免给定值引起的超调量过大。</p><p>偏差微分先行：对给定值和输出量都有微分作用。适合串级控制的副控制回路。</p><h1 id="数字控制器离散化（直接）设计方法"><a href="#数字控制器离散化（直接）设计方法" class="headerlink" title="数字控制器离散化（直接）设计方法"></a>数字控制器离散化（直接）设计方法</h1><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p><strong>设计思路</strong>：将连续的控制对象及其零阶保持器用适当的方法离散化后，系统完全变成离散系统，因而可以用离散系统的设计方法直接在$z$域进行控制器的设计。</p><p>这种离散化的设计方法，稳定性好、精度高，一般用于可以精确建立对象的数学模型的情况。是在给定的采样周期下进行设计的，因此采样周期的选择取决于被控对象的特性，不受分析设计方法的限制。</p><img src="/blog/2020/05/15/计算机控制系统/1563514491951.png" title="数字控制器离散化设计方法"><p>闭环系统的脉冲传递函数为：<br>$$<br>W_B(z) = \frac{Y(z)}{R(z)} = \frac{D(z)W_d(z)}{1+D(z)W_d(z)} = \frac{W_K(z)}{1+W_K(z)}<br>$$<br>系统闭环的误差的脉冲传递函数为：<br>$$<br>W_e(z)=\frac{E(z)}{R(z)} = \frac{1}{1+D(z)W_d(z)}<br>$$</p><p>$$<br>W_B(z) = 1-W_e(z)<br>$$</p><p>得到控制器的脉冲传递函数为：<br>$$<br>D(z) = \frac{W_B(z)}{W_d(z)[1-W_B(z)]} = \frac{1-W_e(z)}{W_d(z)W_e(z)} = \frac{W_B(z)}{W_d(z)W_e(z)}<br>$$<br>若已知被控对象的脉冲传递函数$W_d(z)$，并根据性能指标要求确定出整个系统的闭环脉冲传递函数$W_B(z)$或闭环误差脉冲传递函数$W_e(z)$，则数字控制器$D(z)$可以唯一确定。</p><p><strong>数字控制器直接设计法的解析设计过程如下：</strong></p><ol><li>确定被控对象的传递函数模型，是算法设计的基础。直接设计法假定得到了被控对象的精确模型$W(s)$，将其连同前面的零阶保持器一起离散化后，得到被控对象的广义被控模型$W_d(z)$。</li><li>根据控制系统的性能指标要求及其它约束条件，确定出闭环系统的传递函数$W_B(z)$或$W_e(z)$，或者两者同时确定，满足约束条件$W_B(z) = 1-W_e(z)$。</li><li>根据上述$D(z)$计算公式确定控制器传递函数模型$D(z)$。</li><li>根据$D(z)$编制控制算法。</li></ol><p>直接设计方法的<strong>关键</strong>在于：闭环系统的脉冲传递函数$W_B(z)$（或者$W_e(z)$ ）的选择。要满足数字控制器物理可实现性、稳定性、准确性和快速性等方面的要求。</p><h2 id="最小拍控制器的设计方法"><a href="#最小拍控制器的设计方法" class="headerlink" title="最小拍控制器的设计方法"></a>最小拍控制器的设计方法</h2><p><strong>最小拍系统</strong>：最少调整时间系统或最快响应系统，是指系统对单位阶跃输入、单位速度输入或单位加速度输入等典型输入信号，具有最快的响应速度，经过最少个采样周期，使得输出的稳态误差为零，达到输出完全跟踪输入的目的。</p><p>根据以上原则来确定控制器$D(z)$的脉冲传递函数，即计算机控制算法 。</p><h2 id="最小拍控制器工程化改进"><a href="#最小拍控制器工程化改进" class="headerlink" title="最小拍控制器工程化改进"></a>最小拍控制器工程化改进</h2><p>最小拍控制系统存在不足之处：</p><ul><li>输出在采样点之间可能存在波纹</li><li>对各种典型输入函数的适应性差</li><li>对被控对象的模型参数变化敏感</li></ul><h2 id="大林算法"><a href="#大林算法" class="headerlink" title="大林算法"></a>大林算法</h2><p>最小拍控制设计方法，只适合一些计算机控制系统，对于<strong>系统输出的超调量有严格限制</strong>的系统并不理想。</p><p>对于一些纯滞后调节系统，滞后时间比较长，要求没有超调量或很少超调量，而调节时间允许在较多的采样周期内结束，<strong>超调</strong>是主要的设计指标。此时PID算法效果也欠佳。</p><p>大林（Dahlin）算法针对纯滞后的一阶和二阶惯性环节所提出的一种直接综合设计方法，具有良好的控制效果。</p><h3 id="算法设计原理"><a href="#算法设计原理" class="headerlink" title="算法设计原理"></a>算法设计原理</h3><p>设被控对象为带有纯滞后的一阶或二阶环节，即：<br>$$<br>W(s) = \frac{K}{T_1s+1}e^{-\tau s}, \tau = NT<br>$$</p><p>$$<br>W(s) = \frac{K}{(T_1s +1)(T_2s +1)}e^{-\tau s}，\tau = NT<br>$$</p><p>其中，$T_1,T_2$为对象时间常数；$\tau$为对象纯滞后时间，一般是采样周期的整数倍$NT$；$T$为采样周期。</p><p>大林算法的控制目标是：设计合适的数字控制器，使得整个闭环系统的传递函数为带有纯滞后的一阶惯性环节，且要求闭环系统的纯滞后时间等于对象的纯滞后时间，即：<br>$$<br>W_B(s) = \frac{e^{-\tau s}}{T_0s +1},\tau = NT<br>$$<br>其中，$T_0$为等效的闭环系统的时间常数。</p><h2 id="数字控制器程序实现"><a href="#数字控制器程序实现" class="headerlink" title="数字控制器程序实现"></a>数字控制器程序实现</h2><p>从$D(z)$算式的复杂性和控制系统的灵活性出发，采用计算机软件的方法实现更适宜。</p><p>包括直接程序设计、串联程序设计和并行程序设计。</p><h1 id="状态空间模型"><a href="#状态空间模型" class="headerlink" title="状态空间模型"></a>状态空间模型</h1><p>古典控制理论中，常采用线性微分方程和传递函数这两种输入输出的数学模型来描述线性定常动态系统。把系统看成一个“黑箱”来处理，不表征系统内部结构和内部变量，只反映外部变量即输入输出变量间的因果关系，称为<strong>外部描述</strong>。外部描述不能反映系统内部的某些特性。</p><p>现代控制理论中，采用<strong>状态空间</strong>描述，是一种<strong>内部描述</strong>的数学模型。用到外部变量和内部变量，由两个数学表达式组成，一个是反映系统内部状态的变量组$x_1,x_2,\dots,x_n$和输入变量组$u_1,u_2,\dots,u_p$之间因果关系的数学表达式。称为<strong>状态方程</strong>（微分方程或差分方程形式）。</p><p>另一个是表征系统内部状态的变量组$x_1,x_2,\dots,x_n$与输入变量组$u_1,u_2,\dots,u_p$和输出变量组$y_1,y_2,\dots,y_q$之间关系的数学表达式，称为<strong>输出方程</strong>。</p><h2 id="状态空间描述的基本定义"><a href="#状态空间描述的基本定义" class="headerlink" title="状态空间描述的基本定义"></a>状态空间描述的基本定义</h2><p><strong>状态</strong>：</p><p>控制系统的状态是指系统过去、现在和将来的状况。</p><p><strong>状态变量</strong>：</p><p>指能完全表征系统运动状态的最小一组变量。完全表征是指：</p><ol><li>任何时刻$t=t_0$，这组状态变量的值$x_1(t_0),\dots,x_n(t_0)$就表示系统在该时刻的状态。</li><li>当$t \ge t_0$时的输入$u(t)$给定，且上述初始状态确定时，状态变量能完全确定系统在$t \ge t_0$的行为。</li></ol><p>状态变量的最小性体现在：状态变量$x_1(t),\dots,x_n(t)$是为完全表征系统行为所必需最少个数的系统状态变量，减少状态变量个数会破坏表征的完整性，增加变量的个数是不需要的。</p><p><strong>状态向量</strong>：</p><p>若一个系统有$n$个彼此独立的状态变量$x_1(t),\dots,x_n(t)$，构成状态向量$\pmb X(t)$：<br>$$<br>\pmb X(t)=\begin{bmatrix}<br>x_1(t) \ x_2(t)\ \vdots \ x_n(t)<br>\end{bmatrix}<br>$$<br><strong>状态空间</strong>：</p><p>以状态变量$x_1(t),\dots,x_n(t)$为坐标轴构成的$n$维空间为状态空间。系统在任意时刻的状态，都可以用状态空间中的一个点来表示。</p><p>给定初始时刻$t_0$的状态$\pmb X(t_0)$，得到状态空间中的一个初始点，随着时间的推移，$\pmb X(t)$在状态空间中描绘出一条轨迹，称为<strong>状态轨迹</strong>。</p><p><strong>状态方程</strong>：</p><p>系统的状态变量与输入变量之间的关系用一组<strong>一阶微分方程来描述</strong>的数学模型称为状态方程。</p><p><strong>输出方程</strong>：</p><p>输出变量与状态变量、输入变量之间的关系的数学表达式</p><p><strong>状态空间表达式</strong>：</p><p>状态方程和输出方程组合，构成对一个系统动态行为的完整描述，称为状态空间表达式（或状态空间模型）。</p><h2 id="离散系统的状态空间模型"><a href="#离散系统的状态空间模型" class="headerlink" title="离散系统的状态空间模型"></a>离散系统的状态空间模型</h2><p>可以表示成：<br>$$<br>\cases{\pmb X(k+1) = F \pmb X(k) + G\pmb u(k) \ \pmb y(k) = C\pmb X(k) +D\pmb u(k)}<br>$$<br>其中，$\pmb X$为$n$维状态向量；$\pmb u$为$m$维控制向量；$\pmb y$为$p$维输出向量；$F(n\times n)$为离散系统状态转移矩阵；$G(n \times m)$为离散系统的输入矩阵或控制转移矩阵；$C(p \times n)$为状态输出矩阵；$D(p\times m)$为直接传输矩阵。</p><h2 id="系统的能控性和能观性"><a href="#系统的能控性和能观性" class="headerlink" title="系统的能控性和能观性"></a>系统的能控性和能观性</h2><p>对于一个控制系统，特别是多变量控制系统，有如下两个问题：</p><ol><li>在有限时间内，控制作用能否使系统从初始状态转移到要求的状态 【能控性问题】</li><li>在有限时间内，能否通过对系统输出的测定来估计系统的初始状态 【能观性问题】</li></ol><p>对于一个线性离散系统状态空间表示：<br>$$<br>\begin{equation}<br>\left\{<br>\begin{array}{lr}<br>       \pmb X(k+1) = F \pmb X(k) + G\pmb u(k) \ \pmb y(k) = C\pmb X(k)<br>\end{array}<br>\right.<br>\end{equation}<br>$$<br><strong>能控性定义</strong>：如果存在控制向量序列$\pmb u(k),\pmb u(k+1),\dots,\pmb u(N-1)$,使得系统从第$k$步的状态向量$\pmb X(k)$开始，在第$N$步达到零状态，即$\pmb X(N) =0$，其中$N$是大于$k$的有限数，称此系统在第$k$步上是能空的。</p><p>如果对于每个$k$值，系统的所有状态都是能控的，称系统状态是完全能控的，简称<strong>能控</strong>。</p><p><strong>能控性判据</strong>：完全能控的充要条件是矩阵$\pmatrix{G &amp; FG &amp; F^2G &amp; \dots &amp; F^{n-1}G}$的秩为$n$，该矩阵也称为系统的能控性矩阵，以$Q_c$表示，能控性判据为：<br>$$<br>rank Q_c = rank \begin{bmatrix}G &amp;FG &amp;F^2G &amp;\dots &amp; F^{n-1}G\end{bmatrix} = n<br>$$<br><strong>能观性定义</strong>：在已知输入变量$\pmb u(k)$的情况下，若能根据第$i$步及$n-1$步的输出观察值$\pmb y(i),\pmb y(i+1),\dots,\pmb y(i+n-1)$唯一能确定出第$i$步上的状态$\pmb X(i)$，称系统在第$i$步上是能观测的。</p><p>如果系统在任何$i$步上都是能观测的，称系统状态是完全能观测的，简称<strong>能观测</strong>。</p><p><strong>能观性判据</strong>：完全能观性的充要条件是矩阵$\pmatrix{G &amp; FG &amp; F^2G &amp; \dots &amp; F^{n-1}G}^T$的秩为$n$，该矩阵称为系统的能观性矩阵，以$Q_o$表示，能观性判据为：<br>$$<br>rankQ_o = rank<br>\left[<br>\begin{matrix}<br>C \ CF \ \vdots \ CF^{n-1}<br>\end{matrix}<br>\right]<br>=n<br>$$</p><h2 id="状态可测时按极点配置设计控制规律"><a href="#状态可测时按极点配置设计控制规律" class="headerlink" title="状态可测时按极点配置设计控制规律"></a>状态可测时按极点配置设计控制规律</h2><img src="/blog/2020/05/15/计算机控制系统/1563867748410.png" title="极点配置法"><p>系统的动态性能：完全取决于系统闭环传递函数的极点。</p><p><strong>极点配置法的基本思想</strong>：由系统性能要求确定闭环系统期望的极点位置，然后依据期望极点位置确定反馈增益矩阵。</p><p>极点配置设计的控制器包括两部分：一部分是<strong>状态观测器</strong>，根据所测量到的输出量$y(k)$重构出全部状态$\hat{x}(k)$；另一部分是<strong>控制规律</strong>，直接反馈重构的全部状态。</p><p>设控制对象的状态方程为：<br>$$<br>\mathbf x(k+1) = F\mathbf x(k) +G \mathbf u(k)<br>$$</p><p>其中$\pmb x \in R^n,\pmb u\in R^m$，控制规律为线性状态反馈，即：<br>$$<br>\pmb u(k) =-L \pmb x(k)<br>$$<br><strong>如何设计反馈控制规律$L$，使得闭环系统具有所需要的极点配置</strong>。</p><p>闭环系统的状态方程为：<br>$$<br>\pmb x(k+1) = (F-GL)\pmb x(k)<br>$$<br>闭环系统的特征方程为：<br>$$<br>|z I-F+GL|=0<br>$$<br>设所需要的闭环系统的极点为$\beta_i(i=1,2,\dots,n)$，得到闭环系统的特征方程为：<br>$$<br>\alpha_c(z) = (z-\beta_1)(z-\beta_2)\dots(z-\beta_n)= z^n +\alpha_1z^{n-1}+\dots + \alpha_n =0<br>$$<br>结合上面两个式子，可得到反馈控制$L$应满足的方程：<br>$$<br>|zI - F+GL| = \alpha_c(z)<br>$$<br>对于任意的极点配置，$L$具有唯一解的充要条件是控制对象完全能控，即：<br>$$<br>rank\begin{bmatrix}G &amp;FG&amp; \dots &amp; F^{n-1}G\end{bmatrix}=n<br>$$<br><strong>物理意义</strong>：只有当系统的所有状态都是能控的，才能通过适当的状态反馈控制使得闭环系统的极点配置到任意指定的位置上。</p><p><strong>关于解反馈控制$L$的方程方法有：</strong></p><p>1、首先根据相应连续的系统性能指标的要求来给定$s$平面中的极点，然后再根据$z_i = e^{s_i T}(i=1,2,\dots,n)$的关系来求得$z$平面的极点分布，其中$T$为采样周期。</p><p>2、如果将闭环系统的极点均配置在原点，即$\alpha_c(z) = z^n$，最后会得到最小拍控制。所有的状态在经过最多的$n$拍后变能回到零（平衡状态）。采用最小拍控制避免了给定闭环系统极点的困难。有一个缺点：当选取较小的采样周期时，要求很大的控制量。</p><p>3、直接方法，展开反馈控制$L$的方程的左边行列式，通过与已知的$\alpha_c(z)$比较系数得到$L$各个元素，此法对于低阶系统合适，对于高阶系统十分困难。</p><p>4、对控制对象的离散状态方程$\pmb x(k+1) = F\pmb x(k) + G \pmb u(k)$实行非奇异变换$\bar{\pmb x}(k) = P \pmb x(k)$，使得控制对象的状态方程变为能控标准型。具体如下：<br>$$<br>\bar{\pmb x}(k+1) = \bar{F}\bar{\pmb x}(k) + \bar{G}\pmb u(k)<br>$$<br>其中：<br>$$<br>\bar{F} = PFP^{-1} = \pmatrix{0 &amp; \dots &amp; \ \vdots &amp; I_{n-1}&amp; \ 0 &amp; &amp; \-a_n &amp;\dots &amp; -a_1},\bar{G} = PG = \pmatrix{0 \ \vdots \\0\\1}<br>$$<br>对于新的状态$\bar{\pmb x}(k)$，控制规律变为：<br>$$<br>\pmb u(k) = - \bar{L}\bar{\pmb x}(k)<br>$$<br>其中：<br>$$<br>\bar{L} = L P^{-1}<br>$$<br>这样有：<br>$$<br>\bar{\pmb x}(k+1) =(\bar{F} - \bar{G}\bar{L})\bar{\pmb x}(k) = H\bar{\pmb x}(k)<br>$$</p><p>$$<br>H= \pmatrix{0 &amp; \dots &amp; \ \vdots &amp; I_{n-1}&amp; \ 0 &amp; &amp; \-a_n &amp;\dots &amp; -a_1}-\pmatrix{0 \ \vdots \\0\\1}\pmatrix{\bar{L}_1 &amp; \dots &amp; \bar{L}_n } = \pmatrix{0 &amp; \dots &amp; \ \vdots &amp; I_{n-1}&amp; \ 0 &amp; &amp; \-(a_n+\bar{L}_1) &amp;\dots &amp; -(a_1+\bar{L}_n)}<br>$$</p><p>$H$为特征多项式的伴随矩阵形式，得到闭环系统的特征方程为：<br>$$<br>z^n + (a_1 + \bar{L}_n) z^{n-1} + \dots + (a_n+ \bar{L}_1)=0<br>$$<br>又因为：$\alpha_c(z) =  z^n +\alpha_1z^{n-1}+\dots + \alpha_n =0$，可得到：<br>$$<br>\bar{L}_1 = a_n-a_n,\dots,\bar{L}_n = a_1-a_1<br>$$<br>向量形式：<br>$$<br>\bar{L} = \pmatrix{a_n &amp;a_{n-1} &amp; \dots &amp; a_1} - \pmatrix{a_n &amp;a_{n-1} &amp; \dots &amp; a_1}<br>$$<br>可得到所需要的反馈系数矩阵为：<br>$$<br>L = \bar{L} P<br>$$<br>关键在于非奇异矩阵$P$的计算。</p><p>最后可得到：<br>$$<br>L = \pmatrix{0&amp; \dots 0 &amp;1} \pmatrix{G&amp;FG &amp; \dots &amp; F^{n-1}G}^{-1}\alpha_c(F)<br>$$<br>上式是利用极点胚子设计控制规律的实用算法，称为<strong>Ackermann公式</strong>。</p><h2 id="按极点配置设计观测器"><a href="#按极点配置设计观测器" class="headerlink" title="按极点配置设计观测器"></a>按极点配置设计观测器</h2><p>实际上，按极点配置设计控制规律时，所有的状态不能直接用于反馈。</p><p>常用的方法是：找到一个算法，能够根据所测量到的输出量重构出全部状态，记$\hat{\pmb x}(k)$为实际状态$\pmb x(k)$的重构或称为$\pmb x(k)$的估计。用$\pmb u(k) = -L\hat{\pmb x}(k)$代替实际状态的反馈。</p><p>这种能够根据输出量来重构系统状态的算法称为<strong>观测器</strong>。</p><h2 id="状态不可测时控制器的设计"><a href="#状态不可测时控制器的设计" class="headerlink" title="状态不可测时控制器的设计"></a>状态不可测时控制器的设计</h2><h3 id="分离性原理"><a href="#分离性原理" class="headerlink" title="分离性原理"></a>分离性原理</h3><p>闭环系统的$2n$个极点由两部分组成：一部分是按极点配置设计控制规律所给定的$n$个极点即<strong>控制极点</strong>。另一部分是按极点配置设计观测器给定的$n$个极点即<strong>观测极点</strong>。</p><p>根据分离性原理可以使得控制规律和观测器的设计分开设计，简化。</p><p>控制极点是根据系统的性能要求设计的，因此，闭环系统的性能应主要取决于控制极点，即<strong>控制极点应是整个闭环系统的主导极点</strong>。</p><p>观测器的引入，通常会使得系统的性能变差，为减少观测器极点的影响，观测器的极点所决定的状态重构的跟随速度应远远大于控制极点所决定的系统响应速度，极限状态下，观测器极点放置在原点，此时，状态重构具有最快的跟随速度。</p><h3 id="按极点配置控制器设计步骤"><a href="#按极点配置控制器设计步骤" class="headerlink" title="按极点配置控制器设计步骤"></a>按极点配置控制器设计步骤</h3><p>1、按对系统的性能要求给定$n$个控制极点</p><p>2、按极点配置设计出控制规律$L$</p><p>3、合适给定观测器的极点，对全阶观测器给定$n$个极点，对于降阶观测器给定$n-1$个极点。若测量不存在较大的误差或噪声，可考虑将所有的观测器极点放置在原点；反之，考虑按状态重构的跟随速度比控制极点所对应的系统响应速度快4-5倍的要求给定观测器的极点。</p><p>4、选择所采用的观测器类型。</p><p>​      若测量较准确，而且测量量便是其中一个状态，考虑选用降阶观测器，否则选用全阶观测器。若控制器的计算延时和采样周期的大小处于同一量级，可考虑采用预报观测器，否则考虑采用现时观测器。</p><p>5、根据给定的观测器极点及所选定的观测器类型计算增益矩阵$K$</p><p>6、根据所设计的控制规律及观测器由计算机加以实现。</p><h1 id="先进控制规律的设计方法"><a href="#先进控制规律的设计方法" class="headerlink" title="先进控制规律的设计方法"></a>先进控制规律的设计方法</h1><p>先进控制的任务是用来处理常规控制效果不好，甚至无法控制的复杂工业过程控制的问题。</p><p><strong>先进控制的主要特点</strong>是：</p><p>1、是一种基于模型的控制策略，可以是一种精确的数学模型，如最优控制。可以是一种不精确的模型，如自校正控制、模型预测控制，或者是基于知识的控制，如模糊控制。</p><p>2、通常用于处理复杂的多变量过程控制问题，如大时滞、多变量耦合、被控变量与控制变量存在各种约束等。</p><p>3、实现需要足够的计算能力作为支撑平台。</p><h2 id="线性二次型最优控制器设计"><a href="#线性二次型最优控制器设计" class="headerlink" title="线性二次型最优控制器设计"></a>线性二次型最优控制器设计</h2><p>极点配置法主要设计参数是闭环极点得位置，仅限于说明单输入单输出系统。</p><p>最优控制寻求一种最优控制策略，使某一性能指标最佳，这一性能指标常以对状态及控制作用得二次型积分<strong>（称为代价函数）</strong>表示。称为<strong>线性二次型LQ（linear quadratic）控制问题</strong>。</p><p>LQ控制是状态反馈，不仅能用于单输入单输出系统，同时也能用于多输入多输出及时变系统。</p><p>设线性时不变系统得离散状态方程为：<br>$$<br>\pmb x(k+1) = F\pmb x(k) + G\pmb u(k)<br>$$<br>初始条件是：$\pmb x(0) = \pmb x_0$；$\pmb x(k)$是$n$维状态向量；$\pmb u(k)$是$m$维控制向量；$F,G$分别是$n \times n,n\times m$系数矩阵。</p><p>给定二次型性能指标函数：<br>$$<br>J= \pmb x^T(N) Q_0 \pmb x(N)+ \sum\limits_{k=0}^{N-1}[\pmb x^T(k)Q_1\pmb x(k) + \pmb u^T(k) Q_2\pmb u(k)]<br>$$<br>其中，$Q_0,Q_1$是非负定对称阵，$Q_2$是正定对称阵。</p><p>要求确定控制序列$\pmb u(k)(k=0,1,\dots,N)$，使得$J$所示的性能指标函数极小，这样的控制序列$\pmb u(k)$为线性二次型控制问题的<strong>最优控制</strong>。$\pmb x(k)$为相应的<strong>最优轨迹</strong>，$J$为<strong>最优性能值</strong>。</p><p><strong>线性最优控制问题</strong>有：</p><p>1、有限时间最优问题，此时末时刻$N$固定且有限</p><p>2、无线时间最优问题，$N=\infty$</p><p><strong>线性二次型最优控制问题</strong>可分为：</p><p>1、调解问题。综合$\pmb u(k)$，使得系统由初始状态$\pmb x(0)$转移到平衡状态$\pmb x_e =0$，同时使得性能指标$J$极小，称为<strong>LQR(linear quadratic regular)问题</strong>。</p><p>2、跟踪问题。综合$\pmb u(k)$，使得系统输出$\pmb y(k)$跟踪某参考信号$\pmb y_r(k)$，同时使相应的二次型性能指标$J$极小。</p><h2 id="自校正控制器设计"><a href="#自校正控制器设计" class="headerlink" title="自校正控制器设计"></a>自校正控制器设计</h2><p>自适应控制器本身具有逐步减小系统不确定的能力，本身能不断地检测系统参数或运行指标，根据参数的变化或运行指标的变化，改变控制参数或改变控制作用，使得系统运行于最优或接近最优工作状态。</p><img src="/blog/2020/05/15/计算机控制系统/1563938622094.png" title="自校正控制器设计"><p>自校正<strong>基本思想</strong>：</p><p>将参数递推估计算法与对系统运行指标的要求结合起来，形成一个能自动校正控制器参数的实时计算机控制系统。</p><p>自校正<strong>组成部分</strong>：</p><p>1、参数估计器。根据对象的输入$u$和输出$y$的实测数据，用在线递推辨识方法，辨识被控对象的参数向量$\theta$和随机干扰的数学模型</p><p>2、控制器参数计算。按照辨识求得的参数向量估计值$\hat{\theta}$，计算控制器的参数</p><p>3、控制器。按照辨识求得的参数向量估计值$\hat{\theta}$和对系统运行指标的要求，随时调整调节器或控制器参数，给出最优控制$u$，使得系统适应于本身参数的变化和环境干扰的变化，处于最优工作状态。</p><p>设计自校正控制器<strong>主要问题</strong>：</p><p>用递推辨识算法辨识系统的参数，然后根据系统运行指标来确定控制器的参数。</p><p>在实际应用中，常以递推<strong>最小二乘法为参数估计方法</strong>，以<strong>最小方差为控制目标函数</strong>。</p><h3 id="最小二乘法参数辨识算法"><a href="#最小二乘法参数辨识算法" class="headerlink" title="最小二乘法参数辨识算法"></a>最小二乘法参数辨识算法</h3><p>==一次完成最小二乘法==</p><p>设被辨识的系统模型为：<br>$$<br>A(z^{-1})y(k) = B(z^{-1})u(k) + \xi(k)<br>$$<br>其中：<br>$$<br>A(z^{-1}) = 1+a_1 z^{-1} + \dots + a_n z^{-n}<br>$$</p><p>$$<br>B(z^{-1}) = b_0 + b_1 z^{-1} + \dots + b_m z^{-m}<br>$$</p><p>$z^{-1}$为时间向后平移算子，$y(k),u(k)$为系统的输出和输入，$\xi(k)$为不可测随机干扰，$n,m$为模型阶次。</p><p>上述模型是<strong>受控自回归积分滑动平均(CARIMA)模型中$C(z^{-1}) = 1$形式</strong>。</p><p>把待估计的模型参数和$k$时刻以前的观测数据记为向量形式，有：<br>$$<br>\pmb \theta = \begin{bmatrix} a_1,a_2, \dots ,a_n,b_0,b_1,\dots,b_m \end{bmatrix}^T<br>$$</p><p>$$<br>\varphi^T(k) = \begin{bmatrix} -y(k-1),\dots,-y(k-n),u(k),\dots,u(k-m)\end{bmatrix}<br>$$</p><p>辨识系统模型可写为：<br>$$<br>y(k) = \varphi^T(k) \pmb \theta + \xi(k)<br>$$<br>把$k=1,2,\dots,n,\dots,n+N$的全部数据代入可得到$N$个方程，矩阵形式表示为：<br>$$<br>\pmb Y_N = \pmb \Phi_N \pmb \theta +\pmb \xi_N<br>$$<br>其中：<br>$$<br>\pmb Y_N = \begin{bmatrix}y(n+1) \ y(n+2) \ \vdots \ y(n+N)\end{bmatrix}_{N\times 1} , \pmb \xi_N = \begin{bmatrix} \xi(n+1) \\\xi(n+2) \ \vdots \ \xi(n+N)\end{bmatrix}_{N\times 1}<br>$$<br>最小二乘法估计<strong>原理</strong>：从模型参数向量$\pmb \theta$中找到估计量$\hat{\pmb {\theta}}$，使得模型的输出与实际输出之间的<strong>误差的平方和最小</strong>。估计准则为：<br>$$<br>J= \sum\limits_{k=n+1}^{n+N}[y(k)- \varphi^T(k) \hat{\pmb{\theta}}]^2 =\pmb (Y_N - \pmb \Phi_N \pmb{\hat{ \theta}})^T (Y_N - \pmb \Phi_N \pmb{\hat{ \theta}})<br>$$<br>两边对$\pmb {\hat{\theta}}$求导，得到使得$J$最小的$\pmb {\hat{\theta}}$。可得：<br>$$<br>\pmb {\hat{\theta}} = (\pmb{\Phi_N^T} \pmb{\Phi_N})^{-1}\pmb{\Phi_N^T}\pmb Y_N<br>$$<br>若获得$k=1,2,\dots,n,\dots,n+N$的全部观测数据后，估计量$\pmb {\hat{\theta}}$一次计算出来，称为<strong>一次完成最小二乘算法</strong>。</p><p>==递推最小二乘算法==</p><p>一次完成最小二乘法需要存储全部观测数据，随着$N$增大，相应的计算量和存储空间将迅速增加。解决最小二乘法的在线辨识问题。</p><p>在进行$n+N$次观测后，又获得了一组新的观测数据$\{u(m+N+1),y(n+N+1)\}$,可构成$\pmb Y_{N+1},\pmb \Phi_{N+1}$，并计算出$\pmb {\hat{\theta}}_{N+1}$。</p><p>递推最小二乘法公式为：<br>$$<br>\cases{\pmb {\hat{\theta}}(k) = \pmb {\hat{\theta}}(k-1)+\pmb K(k)[y(k)- \varphi^T(k) \hat{\pmb{\theta}}(k-1)]\ \ \pmb K(k) = \pmb P(k-1)\varphi(k)[1+\varphi^T(k)\pmb P(k-1)\varphi(k)]^{-1}\ \ \pmb P(k) = [I-\pmb K(k)\varphi^T(k)]\pmb P(k-1)      }<br>$$<br>公式<strong>物理意义</strong>：</p><p>新的参数估计值$\pmb {\hat{\theta}}(k)$是由前一步的估计值$\pmb {\hat{\theta}}(k-1)$和修正项组成，修正项正比于新的观测数据$y(k)$与前一步模型预测量$\varphi^T(k)\pmb {\hat{\theta}}(k-1)$的偏差，$\pmb K(k)$为修正系数矩阵，$\pmb P(k)$正比于参数估计误差的方差，$\pmb P(k)$越大表示参数估计值越不准确，越小表示参数估计值越接近真值。</p><p>==带遗忘因子的递推最小二乘法==</p><p>当系统参数随时间变化时，新数据比老数据更能反映参数变化的状况，因此要使<strong>参数估计能够适应系统参数的时变特性</strong>，需要用指数加权的方法来逐渐削弱或“遗忘”老数据的影响。</p><p>带遗忘因子的最小二乘法公式为：<br>$$<br>\cases{\pmb {\hat{\theta}}(k) = \pmb {\hat{\theta}}(k-1)+\pmb K(k)[y(k)- \varphi^T(k) \hat{\pmb{\theta}}(k-1)]\ \ \pmb K(k) = \pmb P(k-1)\varphi(k)[\lambda+\varphi^T(k)\pmb P(k-1)\varphi(k)]^{-1}\ \ \pmb P(k) = \frac{1}{\lambda}[I-\pmb K(k)\varphi^T(k)]\pmb P(k-1)      }<br>$$<br>遗忘因子$\lambda$越小，表示遗忘越快，越重视当前数据，越能反映当前系统的变化，适用于参数变化速度相对于辨识速度较快的时变系统。</p><p>$\lambda$越大，重视更多的历史数据，得到更多的系统信息，辨识精度越高，适用于参数变化速度远低于辨识速度的慢时变系统。</p><p>==增广最小二乘递推算法==</p><p>被辨识的系统的模型为CARMA形式，且其$C(z^{-1} ) \ne 1$，即：<br>$$<br>A(z^{-1})y(k) = B(z^{-1})u(k) +C(z^{-1})\xi(k)<br>$$<br>其中：$C(z^{-1}) = 1+ c_1 z^{-1} + \dots + c_n z^{-n}$</p><p>$\xi{(k)}$是零均值白噪声序列，多项式$C(z^{-1})$各项系数未知，需要辨识。这类模型参数的辨识可采用增广最小二乘法来获得模型未知参数的估计。</p><p>增广最小二乘法递推算法公式为：<br>$$<br>\cases{\pmb {\hat{\theta}}(k) = \pmb {\hat{\theta}}(k-1)+\pmb K(k)[y(k)- \hat{\varphi}^T(k) \hat{\pmb{\theta}}(k-1)]\ \ \pmb K(k) = \pmb P(k-1)\hat{\varphi}(k)[1+\hat{\varphi}^T(k)\pmb P(k-1)\hat{\varphi}(k)]^{-1}\ \ \pmb P(k) = [I-\pmb K(k)\hat{\varphi}^T(k)]\pmb P(k-1)      }<br>$$<br>增广最小二乘法不仅能获得系统控制通道模型参数估计，还能获得噪声通道模型的参数估计，算法与最小二乘法基本相同，不同的只是参数向量$\pmb {\theta}$和数据向量$\varphi^T(k)$的维数扩充了，每次估计都需要计算一次噪声估计值$\hat{\xi}(k)$。</p><h3 id="自校正控制器设计-1"><a href="#自校正控制器设计-1" class="headerlink" title="自校正控制器设计"></a>自校正控制器设计</h3><p><strong>基本思想</strong>：</p><p>将参数估计递推算法与各种不同类型的控制算法相结合，以形成能自动校正控制器参数的实时计算机控制系统。</p><h2 id="模型预测控制器设计"><a href="#模型预测控制器设计" class="headerlink" title="模型预测控制器设计"></a>模型预测控制器设计</h2><p>模型预测控制（MPC）<strong>主要特征</strong>：</p><p>以预测模型为基础，采用二次在线滚动优化性能指标和反馈校正的策略，克服受控对象建模误差和结构、参数与环境等不确定因素的影响。</p><p><strong>研究现状</strong>：</p><p>预测控制开始与极点配置、自适应控制、鲁棒控制、精确线性化、解耦控制和非线性控制结合；</p><p>并且随着智能控制技术的发展，预测控制向着智能预测控制方向发展，如：模糊预测控制、神经网络预测控制、遗传算法预测控制以及自学习预测控制等；</p><p>将人工智能、大系统递阶原理等引入预测控制，构成多层智能预测控制的模式。</p><p><strong>核心</strong>：</p><p><strong>基于滚动时域原理，算法中包含了预测模型、滚动优化和反馈校正</strong>三个基本原理，即</p><p>1、在当前时刻，基于过程的动态模型，对未来某段时域内的过程输出序列做出预测，预测值是当前和未来控制作用的函数。</p><p>2、按照某个目标函数确定当前和未来控制作用大小，控制作用将使未来输出预测序列沿着某个参考轨迹“最优地”达到期望的输出设定值，但只实施当前控制量。</p><p>3、在下一时刻，根据最新实测数据对前一时刻的过程输出预测序列做出校正，并重复1，2。</p><img src="/blog/2020/05/15/计算机控制系统/1563951796173.png" title="模型预测控制器"><h3 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h3><p>是以对象的内部模型，即对象在脉冲或阶跃信号作用下的时间响应为基础，用以估计系统在输入序列作用下的输出。</p><h3 id="预测控制算法"><a href="#预测控制算法" class="headerlink" title="预测控制算法"></a>预测控制算法</h3><p>常用的主要是<strong>模型算法控制</strong>和<strong>动态矩阵控制</strong>两种。</p><p>==模型算法控制==（MAC）基本上包括四个部分：预测模型、反馈校正、参考轨迹和滚动优化。</p><p>==动态矩阵控制==（DMC）是一种基于对象阶跃响应的预测控制算法，适用于有时滞、开环渐近稳定的非最小相位系统。算法包括：预测模型、反馈校正和滚动优化。</p><h2 id="模糊控制器设计"><a href="#模糊控制器设计" class="headerlink" title="模糊控制器设计"></a>模糊控制器设计</h2><p>模糊控制器不要求掌握被控对象的精确数学模型，根据人的经验规则组织控制决策表，由该决策表决定控制量的大小。</p><h3 id="模糊数学"><a href="#模糊数学" class="headerlink" title="模糊数学"></a>模糊数学</h3><h3 id="模糊控制原理"><a href="#模糊控制原理" class="headerlink" title="模糊控制原理"></a>模糊控制原理</h3><p>核心部分是采用模糊控制器。</p><p>模糊控制器主要包括：输入量的模糊化接口、知识库、推理机和输出清晰化接口四个部分。</p><img src="/blog/2020/05/15/计算机控制系统/1563952613926.png" title="模糊控制器"><p>==模糊化==</p><p>仿照人的思维进行模糊控制，必须把输入通道采样得到的精确量变成模糊推理需要的模糊量，通过模糊化接口完成。</p><p>==知识库==</p><p>由数据库和规则库两部分组成。</p><p>数据库：模糊控制器而得输入变量、输出变量经模糊化处理后，其全部模糊子集的隶属度或隶属函数存放在模糊控制器的数据库中。</p><p>规则库：用来存放全部模糊控制规则，在推理时为“推理机”提供控制规则。</p><p>==推理机==</p><p>模糊控制器中，根据输入模糊量和知识库（数据库、规则库）完成模糊推理并求解模糊关系方程，从而获得模糊控制量的功能部分。</p><p>模糊控制规则是模糊决策，是人们在控制生产过程中的经验总结。</p><p>==清晰化接口==</p><p>被控对象每次只能接收一个精确的控制量，需要将模糊控制量转换成精确量，称为去模糊。方法有：最大隶属度方法、加权平均法和中位数判决法等。</p><h3 id="模糊PID控制器设计"><a href="#模糊PID控制器设计" class="headerlink" title="模糊PID控制器设计"></a>模糊PID控制器设计</h3><img src="/blog/2020/05/15/计算机控制系统/1563953080889.png" title="模糊PID控制器设计"><p>采用的是双模糊控制器（FC1、FC2）结构，$r,y$分别为系统的设定值和输出，$d$为外部扰动输入，$e$为设定值和输出的偏差，$\Delta e$为系统输出$y$的增量。</p><h1 id="网络控制系统-NCS"><a href="#网络控制系统-NCS" class="headerlink" title="网络控制系统(NCS)"></a>网络控制系统(NCS)</h1><p>网络控制在计算机控制系统的基础上，在控制器和被控对象之间加入通信网络（有线或无线网络），使得传感器到控制器的反馈通道信息传输和控制器到执行器的前向通道信息传输通过通信网络进行，实现对被控对象的计算机远程控制。</p><img src="/blog/2020/05/15/计算机控制系统/1563953558247.png" title="网络控制系统"><p>通信网络的不确定性和复杂性，相当于在控制器和控制对象之间增加了一个<strong>不确定的动态环节</strong>，$p_k^{sc}(·)$表示反馈通道的动态特性，$p_k^{ca}(·)$表示前向通道的动态特性。</p><p>反馈通道的信息$y(k)$经过网络传输到控制器变成$\bar{y}(k) = p_k^{sc}[y(k)]$；</p><p>前向通道的信息$u(k)$经过网络传输到执行器变成$\bar{u}(k) = p_k^{ca}[u(k)]$</p><p>网络的加入使得控制对象结构发生了变化，增加了通信接收器和通信发送器。</p><p><strong>通信接收器</strong>：包括通信网络接口和D/A转换器，作用于执行器</p><p><strong>通信发送器</strong>：包括A/D转换器和通信网络接口，变成数字信号，通过网络接口将数字信号打包发送到网络上。</p><p><strong>通信网络引入控制系统优劣</strong>：</p><p>连接智能现场设备和自动化系统，实现现场设备控制的分布化和网络化，具有信息资源共享、连接线数大大较少、易于扩展、易于维护、高效、可靠和灵活；</p><p>增加控制系统的复杂性，由于网络通信带宽、承载能力和服务能力的限制，使数据的传输不可避免存在时延、丢包、多包传输及抖动等诸多问题，导致系统性能下降甚至不稳定，给系统分析、设计带来很大的困难。</p><h2 id="网络控制系统概述"><a href="#网络控制系统概述" class="headerlink" title="网络控制系统概述"></a>网络控制系统概述</h2><p>传感器、控制器和执行器机构通过通信网络形成闭环控制系统。NCS中控制部件间通过共享通信网络进行信息（对象输出、参考输入和控制器输出等）交换。</p><img src="/blog/2020/05/15/计算机控制系统/1563954451180.png" title="网络控制系统结构 网络控制系统存在两种结构：直接结构和分层结构。 {% asset_img 1563954505257.png 网络控制系统结构分类"><p><strong>直接结构</strong>：控制信号封装在帧或报文中，通过网络发送到被控对象，被控对象传感器的测量数据同样以帧或数据包的形式通过网络发送到控制器。</p><p>典型应用包括远程学习实验室和直接电动机的速度控制等。</p><p><strong>分层结构</strong>：主控制器通过网络将计算好的参考信号发送到远程系统，远程系统根据参考信号来执行本地的闭环控制，并将传感器测量数据返回主控制器。</p><p>网络控制回路具有比本地控制回路更长的采样周期，典型应用包括移动机器人、遥控操作系统、汽车控制以及航天器等。</p><p><strong>对NCS评价的标准</strong>：网络服务质量（QoS）和系统控制性能（QoP）.</p><p>QoS：包括网络吞吐量、传输效率、误码率、时延可预测性和任务的可调度性</p><p>QoP：与常规控制系统一样，包括稳定性、快速性、准确性、超调和振荡等。</p><h2 id="网络控制系统的研究内容"><a href="#网络控制系统的研究内容" class="headerlink" title="网络控制系统的研究内容"></a>网络控制系统的研究内容</h2><p>包括对网络的控制(control of network)、通过网络的控制(control through network)和着眼于网络控制系统总体性能指标的综合控制(integrated control and network)。</p><p><strong>1、对网络的控制</strong></p><p>围绕网络的服务质量、从拓扑结构、任务调度算法和介质访问控制层协议等不同角度提出解决方案，满足系统对实时性的要求，减小网络时延、时序错乱、数据包丢失等一系列问题。</p><p>可以通过<strong>运筹学</strong>和<strong>控制理论</strong>的方法来实现。</p><p>包括：NCS体系结构和通信协议的研究、NCS时延分析和网络调度、NCS数据包的传送问题、NCS中带通信约束的控制问题、NCS的系统与信息的集成。</p><p><strong>2、通过网络的控制</strong></p><p>在现有的网络条件下，设计相适应的NCS控制器，保证NCS良好的控制性能和稳定性。</p><p>可以通过建立NCS数学模型并运用控制理论方法进行研究。</p><p><strong>NCS数学模型</strong>：</p><p>NCS中被控对象的连续工作状态方程为：<br>$$<br>\cases{\dot{\pmb x}(t) = A\pmb x(t) +B\pmb u(t-\tau) \ \ \pmb y(t) = C\pmb x(t)  }<br>$$<br>其中$\tau$为网络时延。</p><p>节点工作方式分为时间驱动和事件驱动两种，根据节点不同的工作方式，可以得到不同的系统离散事件模型。</p><p><strong>NCS的常规控制规律设计方法</strong>：</p><p>将NCS看成一个参数或时延时变系统，将常规的PID控制、Smith预估控制等，进行相应的改进，使之适应NCS控制性能的要求。</p><p><strong>NCS先进控制规律设计方法</strong>：</p><p>包括极点配置设计方法、最优化控制设计方法、鲁棒控制设计方法、智能控制设计方法等。<strong>基本思想</strong>：利用先进的控制律设计方法，设计网络控制系统的控制器，适应网络控制系统复杂特性的情况，进一步提高网络的控制性能。</p><p><strong>3、综合控制</strong></p><p><strong>协同考虑控制与调度</strong>：NCS闭环性能不仅依赖于控制算法的设计，还依赖于网络资源的调度，需要同时考虑网络协议和控制器的设计。</p><p><strong>NCS并行计算</strong>：存在大量费时的计算密集问题，并行计算需要多处理器协同工作和相互通信，NCS为并行计算提供必要的硬件环境。<strong>需要设计适合控制系统的并行算法</strong>。</p><h2 id="实时控制网络"><a href="#实时控制网络" class="headerlink" title="实时控制网络"></a>实时控制网络</h2><p>控制网络的实时性一般采用两种技术来实现：</p><p>1、<strong>简化技术</strong>。将网络形式简化成线型，将通信模型简化为只有物理层、数据链路层和应用层，将节点信息简化到只有几比特。</p><p>2、<strong>采用网络管理和数据链路调度技术</strong>。分时式实时系统的响应具有可预知性，但资源利用率低；抢先式实时系统资源利用率高，但响应具有不可预知性。很多控制网络将两者结合，达到某种平衡。</p><h3 id="控制网络的拓扑结构"><a href="#控制网络的拓扑结构" class="headerlink" title="控制网络的拓扑结构"></a>控制网络的拓扑结构</h3><p>网络拓扑指网络形状，物理上的连通性。以星型拓扑、总线拓扑、环型拓扑三种结构为基础。</p><blockquote><p><strong>拓扑</strong>：</p><p>把实体抽象为与其大小、形状无关的“点”，把连接实体的线路抽象为“线”，进而以图的形式来表示点与线之间的关系的方法。目的是在于研究这些点、线之间相连的关系。</p><p>表示点和线之间的关系的图称为<strong>拓扑结构</strong>图。</p><p><strong>几何结构</strong>：考察的是点、线之间的位置关系，强调的是点和线所构成的形状及大小。不同的几何结构可能具有相同的拓扑结构。</p><p><strong>网络拓扑结构</strong>：在计算机网络中，把计算机、终端、通信处理机等设备抽象成点，把连接这些设备的通信线路抽象成线，并将由这些点和线所构成的拓扑称为网络拓扑结构。</p><p>网络拓扑反映网络的结构关系。常见有总线型、星型、环型、树型和网状型等。</p><p><a href="https://blog.csdn.net/starshinning975/article/details/53511343" target="_blank" rel="noopener">参考博客</a></p></blockquote><img src="/blog/2020/05/15/计算机控制系统/1564017899902.png" title="控制网络的拓扑结构"> <p><strong>星型网络</strong>：各站点通过点到点的链路与中心站相连，数据的安全性和优先级容易控制，易实现网络监控，但中心节点的故障会引起整个网络瘫痪。</p><p><strong>总线型网络</strong>：所有站点共享一条数据通道，安装方便，成本低，但介质的故障会导致网络瘫痪，安全性低，监控困难。</p><p><strong>环型网络</strong>：各站点通过通信介质连成一个封闭的环型，容易安装和监控，但容量有限，网络建成以后，难以增加新的站点。</p><p><strong>树型拓扑</strong>：从总线拓扑演化而来，树根接收各站点发送的数据，然后广播发送到全网。</p><p><strong>网型拓扑</strong>：通信站点的互连结构</p><p><strong>混合拓扑</strong>：将两种或两种以上的单一拓扑结构混合起来，取两者的优点构成的拓扑。</p><h3 id="控制网络的协议模型"><a href="#控制网络的协议模型" class="headerlink" title="控制网络的协议模型"></a>控制网络的协议模型</h3><p>开放系统互连(OSI)参考模型共分为七层：物理层、数据链路层、网络层、传送层、会话层、表示层和应用层。</p><p>控制网络一般由OSI参考模型的物理层、数据链路层、应用层三层体系结构和通信媒质构成。</p><img src="/blog/2020/05/15/计算机控制系统/1564018591539.png" title="控制网络协议模型"><p>1、物理层。采用EIA-RS-232、EIA-RS-422/RS-485等协议。</p><p>2、数据链路层。考虑现场设备故障较多，更换频繁，数据链路层媒体访问控制多采用<strong>受控访问协议</strong>（包括轮询和令牌）协议，通常各PC、PLC作为主站，传感器、变送器等作为从站。需要支持点对点、点对多和广播通信方式。</p><p>3、应用层。解决应用怎样的高级语言（或过程控制语言）来作为面向用户的编程（或组态）语言，包括设备名称、网络变量与配置（捆绑）关系，参数与功能调用及相关说明，一般应具有符合IEC1131-3标准的图形用户界面（GUI）。</p><h3 id="控制网络的媒体访问技术"><a href="#控制网络的媒体访问技术" class="headerlink" title="控制网络的媒体访问技术"></a>控制网络的媒体访问技术</h3><p>媒体访问技术是挂在通信子网上的站点向通信介质存信息或者从通信介质上取信息的控制规则。</p><p>是对媒体的使用进行管理，将传输介质的频带有效地分配到网络上各个站点的方法，位于数据链路层中。</p><p>媒体访问控制是通信子网的核心内容，各个网络的性能在很大程度上取决于所采用的媒体访问控制方式，受其直接影响的性能有：网络的实时性、网络的吞吐量和有效利用等。</p><p><strong>媒体访问控制技术</strong>：</p><p>有冲突的媒体访问控制：在站点访问媒体时，可能会由于多个站点同时访问媒体而产生冲突，应用较多的协议：带有冲突检测的载波监听多路访问的CSMA/CD控制。   </p><p>无冲突的媒体访问控制：在网络上的站点访问传输媒体时，不会发生多个站点同时访问媒体的情况。应用较多的控制协议：<strong>令牌控制和主从控制</strong>。</p><h3 id="控制网络的类型"><a href="#控制网络的类型" class="headerlink" title="控制网络的类型"></a>控制网络的类型</h3><p>按<strong>通信方式</strong>分为：主从型、客户与服务器型、环型和通信型四种类型。</p><p><strong>主从型</strong>：通信由一个主站控制，主站轮询方式对子站“逐个”通信，简单，但危险集中，主站出问题，整个系统瘫痪。</p><p><strong>客户与服务器型</strong>：面向“事件”方式构建，无主站，有需要通信的“事件”发生，优先通信，即时响应好，是发展的主流方向。</p><p><strong>环型</strong>：所有的通信子站连成“一个环”，以数据移位的方式通信，简单有效，传输效率是目前控制网络最高的，但一个站出问题，通信中断。</p><p><strong>通信型</strong>：带有完整的OSI网络通信模型，是通信功能最强的控制网络。</p><p>按<strong>通信协议</strong>的特点分为：CSMA方式、TokenBus方式和主从Polling方式。</p><p><strong>CSMA方式</strong>：Ethernet、CAN、DeviceNet和LONWorks等</p><p><strong>TokenBus方式</strong>：Profibus、P-Net及ControlNet等</p><p><strong>主从Polling方式</strong>：FIP、CC-link以及某些专用的主从RS-422/RS-485网络</p><h3 id="EtherNet网络"><a href="#EtherNet网络" class="headerlink" title="EtherNet网络"></a>EtherNet网络</h3><p>采用的是有冲突的媒体访问控制方式的协议，工作过程是完全随机的，既不预先规定时间，也不预先建立每个节点传送信息的先后顺序，而是根据各个节点和传输线路的具体情况来确定。</p><p><strong>网络监听算法（CSMA）</strong>是CSMA/CD的核心，是一种“先听后讲”的算法，一个准备发送报文的站首先监听网络，以确定网络上是否有其他的站点在发送信号，即确定网络是否空闲。</p><p>1、非坚持的CSMA：网络空闲，则可以发送数据。如果网络忙，则等待由概率分布决定的、一定量的随机延迟时间，再监听网络的情况，即在这段随机延迟的时间内不监听网络。网络利用率低。</p><p>2、1-坚持CSMA：网络忙就一直监听，直到网络空闲，便立即发送数据。若有冲突，则等待一个随机时间间隔，重新监听。不可避免地有冲突发生，不利于网络吞吐量的提高。</p><p>3、P-坚持CSMA：网络忙，站点继续监听直到网络空闲，但发现网络空闲时，不立即发送数据，为减少冲突，以概率P发送数据，以概率（1-P）延迟一个时间单位，再监听网络。这个时间单位通常为网络上最大传播延迟的两倍，P值选择过大，增加冲突，P值过小，媒体利用率大大降低。</p><p>EtherNet网络作为最为广泛应用的网络协议，将成为过程级和控制级的主要传输技术。EtherNet能够与工厂信息管理系统进行直接地、无缝地连接，而不需要任何专用设备。</p><h3 id="CAN网络"><a href="#CAN网络" class="headerlink" title="CAN网络"></a>CAN网络</h3><p>CAN(controller area network)是串行总线控制器局域网络，与一般的通信网络相比，CAN的数据通信具有突出的可靠性、实时性和灵活性的特点。</p><img src="/blog/2020/05/15/计算机控制系统/1564022478527.png" title="CAN网络"><p>通过相应的CAN接口连接工业设备，构成低成本的网络。直接连接不仅<strong>提供了设备级故障诊断通通道</strong>，而且提高了通信效率和设备互换性。</p><p>CAN应用一种面向无损伤仲裁方法来解决媒体多路访问带来的冲突问题。<strong>仲裁过程</strong>是：</p><p>当网络空闲时，线路表现为“隐性”电平（recessive level），此时任何节点均可发送报文。发送节点发出的帧起始字段产生一个“显性”电平（dominant level），标志着发送开始。所有节点以首先开始发送节点的帧起始前沿来同步，若多个节点同时发送，在发送的仲裁场进行逐位比较。</p><blockquote><p><strong>网络仲裁</strong>：当网络多个节点同时发送 网络请求时，网络应如何做出选择，以保证网络最多只能被一个节点传送数据占据。</p></blockquote><p><strong>CAN仲裁原则</strong>：</p><p>（1）每个节点只能使用唯一的标识符发送数据</p><p>（2）对于任一标识符，只有具有相应标识符的节点发送带有此标识符的数据帧，而其他节点只能发送带有此标识符的远程帧</p><p>（3）不同的节点发送相同的标识符的远程帧时，必须由唯一确定的请求节点发送，或者不同的节点配以不同的<strong>DLC（数据帧长度）</strong>。</p><h3 id="ControlNet网络"><a href="#ControlNet网络" class="headerlink" title="ControlNet网络"></a>ControlNet网络</h3><p>是基于改型的CAN技术的一种高速确定性网络。作为一种高速串行通信系统和一种确定加预测的模式进行运作，适用于<strong>需要实时应用信息交换的设备之间的通信</strong>。</p><p>ControlNet网络是一种用于对信息传送有时间苛刻要求的、高速确定性网络，同时，它允许传送无时间苛求的报文数据。</p><p>ControlNet采用的令牌总线（TokenBus）控制方式。是最为普遍的无冲突介质访问控制协议。是将CSMA/CD和令牌环两种协议相结合，取其优点。</p><p>TokenBus只有取得<strong>令牌</strong>（一组具有特定格式的位）的站点才能发送数据帧，其他节点只能接收信息，或者被动地传送信息（在拥有令牌的节点的要求下发送信息）。发送完后，站点将令牌传递给下一个站点。</p><img src="/blog/2020/05/15/计算机控制系统/1564023588944.png" title="ControlNet网络"><p>在分布式主站系统中，ControlNet应用时间触发方式采取一个特殊的<strong>令牌传递机制</strong>：</p><p>网络上每个节点分配一个唯一的物理地址，持有令牌的节点可以发送数据，但是，网络上并没有真正的令牌在传输，而是每个节点监视收到的其数据帧的源节点地址，在该数据帧结束之后，每个节点设置一个隐性的令牌寄存器，其值为收到的物理地址+1，如果隐性令牌寄存器的值等于某个节点的物理地址，该节点发送数据。</p><p>网络中存在唯一的隐性令牌，在由主站构成的逻辑环中循环传递，主站之间通过一定的逻辑调度算法获得令牌的调度权，然后由它发起对其他主站或所属的从站的通信。</p><p><strong>令牌轮询技术</strong>：<br>通过任务调度来满足周期数据的不同实时性要求，既有静态的事先约定，也可以动态调整。优点是周期任务的实时性好且具有确定的或可预测的最大网络时延。<strong>主要缺点</strong>：无法处理突发事件。</p><p>ControlNet应用了<strong>数据分类</strong>技术解决这个问题：</p><p>（1）周期性数据：对应周期数据，按时传输，如数据采样</p><p>（2）事件性通信：对应突发数据，在事件发生时传输，如报警</p><p>（3）报文通信：对应非实时数据，被请求时传输，如程序下载</p><p>网络的媒体存储通过限制时间存储算法来控制，即：采用<strong>并行时间域多路存取（CTDMA）</strong>，控制各个节点在<strong>网络刷新时间（NUT）</strong>内传送信息的机会。</p><p>NUT包括三个部分：预先信息传送时间、非预定信息传送时间和网络维护时间。</p><p><strong>通信技术</strong>：<br>ControlNet采用的是多信道广播技术，如生产者/客户模式。这种通信模式是基于多信道广播的，允许网络上的所有节点，同时从单个数据源存储相同的数据。</p><p>在控制网链路上，由生产者发送的每个报文都包含一个连接标识符，已经组态的节点在收听广播时，可以识别其应收报文的连接标识符，变成一个客户以接收数据。</p><p>若该节点要发送信息，变成生产者，提高了网络的效率，特别是对组态信息等公共数据，多信道广播技术是一种有效的通信方式。</p><h3 id="CC-Link网络"><a href="#CC-Link网络" class="headerlink" title="CC-Link网络"></a>CC-Link网络</h3><p>是高速现场总线，不但处理信息数据，也处理控制数据。通过简单的总线，可以将工业设备连接成为分布式控制系统或设备层的网络，同时这个总线可以方便地连接到其他网络。</p><p>CC-Link采用<strong>单主从轮询工作模式</strong>，控制方式：网络的各节点间明显具有上下级特征，上级为主导节点，并由主导节点分配通信媒体的使用权，适用于自动化中的分布式系统，是一种集中控制，主要用于星型网络。</p><p>CC-Link<strong>数据链路层通信协议</strong>：EIA485协议</p><img src="/blog/2020/05/15/计算机控制系统/1564025332252.png" title="CC-Link网络"><h2 id="网络控制系统控制器的设计"><a href="#网络控制系统控制器的设计" class="headerlink" title="网络控制系统控制器的设计"></a>网络控制系统控制器的设计</h2><h3 id="PID网络控制器设计"><a href="#PID网络控制器设计" class="headerlink" title="PID网络控制器设计"></a>PID网络控制器设计</h3><p>理想的模拟PID控制器的传递函数为：<br>$$<br>D(s) = \frac{U(s)}{E(s)} = K_P +\frac{K_I}{s} + K_ds<br>$$<br>其中，$K_P$为比例系数，通过加大$K_P$的值来增加系统动态响应速度；$K_I$为积分系数，消除 系统稳态误差；$K_D$为微分系数，改变系统的动态性能。</p><p>采用双线性变换法，将上式离散化，得到：<br>$$<br>D(z) = D(s)|_{s=\frac{2}{h} ·\frac{1-z^{-1}}{1+z^{-1}}} = \frac{U(z)}{E(z)} = K_P +\frac{K_Ih}{2}·\frac{1-z^{-1}}{1+z^{-1}} +\frac{2K_D}{h}·\frac{1-z^{-1}}{1+z^{-1}}<br>$$<br>其中，$h$为采样周期。</p><p>常规PID控制器应用于网络控制系统的环境，由于网络特性的影响，PID控制器所控制的广义对象（包括网络和控制对象）实际上是一个<strong>时变系统</strong>，因此需要对PID参数$K_P,K_I,K_D$进行<strong>在线修正</strong>，以适应于网络控制系统的要求。</p><h3 id="极点配置网络控制器设计"><a href="#极点配置网络控制器设计" class="headerlink" title="极点配置网络控制器设计"></a>极点配置网络控制器设计</h3><p>在NCS中，首先建立系统的随机时变模型，然后对模型进行一系列的处理后设计控制器。控制器设计分为 <strong>控制规律的设计和状态观测器的设计</strong>。</p><p>根据给定的<strong>闭环系统的极点</strong>和<strong>观测器极点</strong>分别设计控制规律和观测器。</p><p>控制规律作用：根据系统的状态产生控制量。</p><p>观测器作用：利用带延迟的部分状态信息估计系统的全部状态。</p><p><strong>1、网络控制系统的模型分析</strong></p><p>通信网络的存在使得数据传输变得不确定，相当于在闭环中增加了时变的不确定的控制对象。闭环引入网络后，被控对象有了扩展，是包含<strong>直接控制对象和通信网络</strong>的广义被控对象。</p><p><strong>2、控制规律的设计</strong></p><p>假设控制器反馈的是系统的全部增广状态，控制规律为线性状态反馈，即：<br>$$<br>\pmb u(k) = -L^k \pmb z(k)<br>$$<br>目的是设计$L^k$使得闭环系统具有所需要的极点配置。</p><p><strong>3、状态观测器的设计</strong></p><p>实际控制中，控制器不能得到所有对象的状态，只能得到被控对象的输出，因此，在控制器中，要用被控对象的输出来重构出系统的所有的状态，这需要设计状态观测器。</p><p><strong>4、控制器的设计</strong></p><p>控制器包含观测器和控制规律，目的是设计$L^k$使得闭环系统取得好的性能指标。基于广义的被控对象的控制器的设计依然遵循<strong>分离性原理</strong>。</p><p>即闭环系统的极点由两部分组成，一部分是按照真实状态反馈设计控制规律的控制极点；另一部分是状态观测器的极点。</p><h1 id="计算机控制系统设计实现"><a href="#计算机控制系统设计实现" class="headerlink" title="计算机控制系统设计实现"></a>计算机控制系统设计实现</h1><h2 id="设计原则与设计方法"><a href="#设计原则与设计方法" class="headerlink" title="设计原则与设计方法"></a>设计原则与设计方法</h2><h2 id="硬件设计"><a href="#硬件设计" class="headerlink" title="硬件设计"></a>硬件设计</h2><p>总体上包括三个方面内容：计算机部分、执行机构与驱动技术、检测机构与传感器技术。</p><p><strong>常见的驱动技术</strong>：</p><p>采用电动机及其驱动器构成的电气传动系统直接驱动机械设备，在精度不高的情况下，一般采用通用型的传动系统，主要有：直流电气传动系统、交流电气传动系统、同步电动机传动系统等。</p><p>在高精度要求下，通常采用伺服驱动系统、直线电动机驱动系统等高精度传动系统。</p><p><strong>检测机构与传感器技术</strong>：</p><p>传感器：能够感受规定的被测量并按照一定规律转换成可用输出信号的器件和装置，通常由<strong>敏感元件和转换元件</strong>组成。</p><p>在计算机控制系统中，对检测机构与传感器基本要求：检测精度，检测机构的量程以及适用的环境等。</p><h2 id="软件设计"><a href="#软件设计" class="headerlink" title="软件设计"></a>软件设计</h2><p>包括监控软件、控制软件和信息管理软件三部分组成。</p><h3 id="数字控制器的实现问题"><a href="#数字控制器的实现问题" class="headerlink" title="数字控制器的实现问题"></a>数字控制器的实现问题</h3><p>数字控制器的设计是计算机控制系统设计的关键所在，包括数字控制器的理论设计与程序实现两部分。</p><p>数字控制器的理论设计：是根据被控对象和所确定的计算机控制系统的指标，设计出数字控制器的输入和输出函数的差分方程数学表达式。</p><h3 id="信号的数字滤波技术"><a href="#信号的数字滤波技术" class="headerlink" title="信号的数字滤波技术"></a>信号的数字滤波技术</h3><p>在模拟系统中，信号的处理是采用不同形式的有源或无源滤波器，如低通、高通、带通和带阻滤波器等。</p><p>在计算机控制系统中，采用数字滤波器，由软件编程实现。</p><p><strong>1、均值滤波</strong></p><p>在一个采样周期内，连续采样几个值，取其平均值为实际测量值。数学表达式为：<br>$$<br>Y = \frac{1}{N} \sum\limits_{i=1}^N X_i<br>$$<br>其中，$Y$是数字滤波器输出；$X_i$为第$i$次采样值；$N$为采样次数。</p><p>均值滤波实质是对信号的平滑处理，其平滑程度取决于采样次数$N$。$N$越大，计算结果越准确，但灵敏度降低，应折中处理。</p><p><strong>2、中值滤波</strong></p><p>连续采样三次$X_1,X_2,X_3$，去掉最大值和最小值，取中间值为本次采样值。数学表达式为：<br>如果$X_1 \le X_2 \le X_3$，则中值滤波器的输出为$Y = X_2$。</p><p>中值滤波对去掉脉动性的干扰比较有效，但不宜用于快速变化的变量的处理。</p><p><strong>3、抗干扰中值滤波</strong></p><p>消除脉冲型干扰信号。</p><p>连续采样$N$次，得到$X_1,X_2,\dots,X_N$，按数值由小到大额排列$X_1 \le X_2 \le \dots \le X_N$，去掉最小值$X_1$和最大值$X_N$，然后对剩余的采样值进行均值运算，结果作为滤波器的输出$Y$，计算公式为：<br>$$<br>Y = \frac{1}{N-2}\sum\limits_{i=2}^{N-1}X_i<br>$$<br><strong>4、限幅滤波</strong></p><p>大的随机干扰或者采样电路的不稳定，使得采样数据明显偏离实际值，或者两次采样之间的变化很大。</p><p>基本思路：根据被滤波信号的实际变化范围及变化的频率，确定滤波器的参数，即上下极限幅度$Y_h ,Y_l$及变化极限$\Delta Y_0$，对于一个采样值$x(k)$，滤波器的输出$y(k)$输出为：<br>$$<br>y(k) = \cases{x(k), \qquad Y_1 \le x(k) \le Y_h,|x(k)-y(k-1)|\le \Delta Y_0 \ \ y(k-1) + \Delta Y_0 ,\qquad  x(k) - y(k-1) &gt; \Delta Y_0 \ \ y(k-1) - \Delta Y_0 , \qquad x(k)-y(k-1) &lt; -\Delta Y_0 \ \ Y_h ,\qquad x(k) &gt; Y_h \ \ Y_1 , \qquad x(k) &lt; Y_1      }<br>$$<br>其中，滤波器参数$Y_h$和$Y_l$为被滤波信号的最大允许值和最小允许值，与被测信号的变换范围有关；$\Delta Y_0$与采样周期及被测信号的正常变化率有关。</p><p>限幅滤波器是针对特定的被测信号而设计的，加入了较多的人工干预成分，对参数选择有一定要求。</p><p><strong>5、惯性滤波</strong></p><p>是由连续域中的一阶惯性滤波器，经离散化处理后得到的。数学表达式为：<br>$$<br>y(k) = \alpha y(k-1) +(1-\alpha)y(k), \qquad 0&lt; \alpha &lt; 1<br>$$<br>滤波器当前时刻的输出值$y(k)$，是上次采样时刻的输出值$y(k-1)$与本次输入采样值$x(k)$的加权平均值，参数$\alpha$是$y(k-1)$的权，成为<strong>滤波系数</strong>。</p><p>$\alpha$越大，则表示上次滤波器的输出值在本次滤波器输出值中所占比重越大，即惯性越大。</p><h2 id="数字控制器程序实现性能分析"><a href="#数字控制器程序实现性能分析" class="headerlink" title="数字控制器程序实现性能分析"></a>数字控制器程序实现性能分析</h2><p>计算机控制系统数值误差的来源：</p><p>1、建立控制器离散数学模型时，需对其参数进行量化，因而会产生参数量化误差。</p><p>2、在信号转换过程中，由于A/D转换器的数字量字长有限，同时，受A/D转换时间和采样周期的影响，因此会在检测的反馈信号中产生采样量化误差。</p><p>3、因计算机控制系统的实时性要求，在计算机编程中所采用的数字量的字长也是有限的，会产生计算误差。</p><h2 id="量化效应与采样周期误差分析"><a href="#量化效应与采样周期误差分析" class="headerlink" title="量化效应与采样周期误差分析"></a>量化效应与采样周期误差分析</h2><h3 id="A-D转换的量化误差"><a href="#A-D转换的量化误差" class="headerlink" title="A/D转换的量化误差"></a>A/D转换的量化误差</h3><p>是在一定范围内变化的随机变量，通常所称的量化误差是相应变化范围的最大值，假定A/D转换器对输入模拟信号的转换量程为$0-X_m$，转换字长为$n$，量化误差为：<br>$$<br>q = \frac{X_m}{2^n}<br>$$</p><h3 id="孔径误差"><a href="#孔径误差" class="headerlink" title="孔径误差"></a>孔径误差</h3><p>设$T$为采样周期，$T_c$为A/D转换器的转换时间，假定$T\ge T_c$。只在$T_c$时间内观察到输入信号$x(t)$的变化，相当于一个时间窗口，$T_c$称为$A/D$转换器的孔径时间。</p><img src="/blog/2020/05/15/计算机控制系统/1564040994361.png" title="孔径误差"><p>A/D转换器的孔径时间对于变化的信号在转换过程中会形成一定的误差，若被转换的模拟信号不是一个恒定常量，而是随时间变化形成了连续时间函数$y(t)$，则在有一定的孔径时间$T_c$的情况下，A/D转换器将产生孔径误差。</p><p>最终的A/D转换的采样值为：<br>$$<br>y(t_2) = y(t_1) + \Delta y<br>$$<br>其中$\Delta y$为孔径误差，可以表示为：<br>$$<br>\Delta y = T_c \frac{dy}{dt}<br>$$<br>其中$T_c = t_2-t_1$。</p><p>若孔径误差过大，可通过选用转换速度更高的A/D转换器或者A/D之前加<strong>采样保持器</strong>来解决。</p><h3 id="采样周期造成的误差"><a href="#采样周期造成的误差" class="headerlink" title="采样周期造成的误差"></a>采样周期造成的误差</h3><p>一般采样周期$T$远大于A/D转换器的孔径时间$T_c$，对变换的模拟信号的影响远超A/D转换器的孔径时间的影响。</p><p>设被转换的模拟信号为正弦函数$x(t) = X_{max} \sin(\omega t + \theta_0)$，信号周期为$T_0 = \frac{2\pi}{\omega}$，采样周期为$T$时，$x(t)$的实际采样函数为：<br>$$<br>x^<em>(t) = X_{max} \sin (\omega kT + \theta_0), \quad kT \le t &lt; kT +T<br>$$<br>设$\frac{T_0}{T} =m$，$m$为自然数，$x^</em>(t)$是周期为$T_0$的周期函数，可表示为如下三角函数形式的傅里叶级数表达式：<br>$$<br>\cases{x^<em>(t) = a_0 \sum\limits_{n=1}^{\infty} [a_n \cos(n\omega t) + b_n \sin(n\omega t)]\ \ a_0 = \frac{1}{T_0} \int_{t-T_0}^{t}x^</em>(t) dt \ \ a_n = \frac{2}{T_0}\int_{t-T_0}^t x^<em>(t) \cos (n\omega t) dt \ \ b_n = \frac{2}{T_0} \int_{t-T_0}^t x^</em>(t) \sin (n\omega t)dt    }<br>$$<br>采样前的模拟信号只有基波分量，分析采样前后的误差情况，实际上就是将实际采样函数$x^*(t)$的基波信号的幅值相位与模拟信号相比较，只需要求出基波的系数$a_1$和$b_1$。<br>$$<br>a_1 = \frac{2X_{max}}{T_0} \sum\limits_{i=k-m}^{k-1} \int_{iT}^{(i+1)T} \sin (\omega iT+ \theta_0) \cos(\omega t)dt \ = -\frac{mX_{max}}{\pi} \sin(\frac{\pi}{m}) \sin (\frac{\pi}{m} -\theta_0) +A<br>$$<br>其中，$A = \frac{X_{max}}{\pi} \sin (\frac{\pi}{m}) \sum\limits_{i=k-m}^{k-1} \sin \left(\frac{4\pi}{m} i + \theta_0 + \frac{\pi}{m}\right)$。<br>$$<br>b_1 = \frac{2X_{max}}{T_0} \sum\limits_{i=k-m}^{k-1} \int_{iT}^{(i+1)T} \sin (\omega iT+ \theta_0) \sin(\omega t)dt \ = \frac{mX_{max}}{\pi} \sin(\frac{\pi}{m}) \cos (\frac{\pi}{m} -\theta_0) +B<br>$$<br>其中，$B = -\frac{X_{max}}{\pi} \sin (\frac{\pi}{m}) \sum\limits_{i=k-m}^{k-1} \cos \left(\frac{4\pi}{m} i + \theta_0 + \frac{\pi}{m}\right)$。</p><p>可得到实际采样函数的基波$x^<em>_1(t)$的幅值和相位，表达式为：<br>$$<br>x^</em>_1(t) = \sqrt{a_1^2 + b_1^2} \sin (\omega t + \theta_1)<br>$$<br>其中，$\theta_1 = \arctan(a_1/b_1)$。</p><p>与原函数相比，幅值误差为：<br>$$<br>\Delta X = X_{max} - \sqrt{a^2 + b^2}<br>$$<br>相位误差为：<br>$$<br>\Delta \theta = \theta_0 - \theta_1<br>$$</p><h2 id="计算机控制系统可靠性"><a href="#计算机控制系统可靠性" class="headerlink" title="计算机控制系统可靠性"></a>计算机控制系统可靠性</h2><p>提高可靠性的<strong>设计原则</strong>：</p><p>1、保证系统的硬件和软件自身质量，降低自身损坏和冲突的概率</p><p>2、提高硬件和软件对外部信号的抗干扰、扛冲击能力</p><p>3、系统的硬件和软件要有<strong>冗余设计和备份</strong></p><p>4、硬件和软件设计要使系统有<strong>故障诊断能力</strong>，将事故危害范围降到最低限度。</p><p><strong>软件部分的措施</strong>：</p><p>1、采用模块化设计。对系统及软件功能的分析和研究，合理地进行软件的模块划分，并明确每个模块所要完成的功能及与其他模块的调用和被调用关系。</p><p>2、充分测试，避免软件的自身冲突。</p><p>3、对输入信号的抗干扰设计。软件中设计滤波器，抑制和消除干扰的影响</p><p>4、系统的软件应具有一定的<strong>故障诊断能力和自修复能力</strong>。</p><p>5、看门狗技术。是一种CPU监控定时器，看门狗的运行靠硬件和相应软件的配合实现。<strong>工作机理</strong>：</p><p>​       在一个预先设定的时间内，若没有得到来自CPU的清零脉冲信号，则看门狗定时器将向CPU的复位端输出一个复位脉冲信号，这样可以使得因故障而导致程序陷入死循环的计算机系统重新从头开始工作。</p><h2 id="消除或抑制干扰影响的方法"><a href="#消除或抑制干扰影响的方法" class="headerlink" title="消除或抑制干扰影响的方法"></a>消除或抑制干扰影响的方法</h2><h1 id="伺服运动控制系统"><a href="#伺服运动控制系统" class="headerlink" title="伺服运动控制系统"></a>伺服运动控制系统</h1><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>伺服系统是可以<strong>按照一定的指令控制电动机执行规定的运行动作</strong>，一般由伺服电动机、传感器和控制器三部分构成闭环，完成精密控制。</p><p>伺服系统的<strong>基本要求</strong>：稳定性好、精度高，一般在0.001-0.01mm之间、快速响应性好，一般在200ms以内，甚至小于几十毫秒。</p><p>伺服系统对控制系统要求可分为如下几种形式：</p><p>1、点位运动控制。仅对终点位置有要求，与运动的中间过程（运动轨迹无关）。</p><p>2、连续轨迹（轮廓控制）运动控制。主要应用在数控系统、切割系统的运动轮廓控制中。</p><p>3、同步运动控制。多个轴之间的运动协调控制，可以是多个轴在运动全程中进行同步，也可以是在运动过程中的局部速度同步。</p><p>伺服系统<strong>主要特点</strong>：精确的检测装置、多种反馈比较原理和方法、高性能伺服电机、宽调速范围的速度调节系统、靠偏差工作。</p><img src="/blog/2020/05/15/计算机控制系统/1564043367055.png"><img src="/blog/2020/05/15/计算机控制系统/1564043379505.png"><p>伺服系统一般由电流环、速度环和位置环组成，其中电流环采用矢量控制，速度环和位置环采用PID控制。</p><img src="/blog/2020/05/15/计算机控制系统/1564043445173.png" title="伺服控制系统">]]></content>
    
    <summary type="html">
    
      计算机控制系统原理简介，包括PID，DCS等
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>信号处理涉及的几种变换</title>
    <link href="https://jiangxj.top/blog/2020/05/14/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E6%B6%89%E5%8F%8A%E5%88%B0%E7%9A%84%E5%87%A0%E7%A7%8D%E5%8F%98%E6%8D%A2/"/>
    <id>https://jiangxj.top/blog/2020/05/14/信号处理涉及到的几种变换/</id>
    <published>2020-05-13T16:00:00.000Z</published>
    <updated>2020-06-18T02:42:24.492Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>小波可以进行伸缩平移，源自傅里叶变换，都是频率变换的方法。</p><blockquote><p>傅里叶变换、短时傅里叶变换、小波变换</p><p>内积，基，归一化正交，投影，Hilbert空间，多分辨率，父小波，母小波</p></blockquote><p>==1、基==</p><p>傅里叶变换的基是不同频率的正弦曲线，把信号波分解成不同频率的正弦波的叠加和。</p><p>小波变换把信号分解成一系列的小波，小波种类多，同一种小波可以进行尺度变换，<strong>小波的特性是在整个时间范围内幅度的平均值是0，具有有限的持续时间和突变的频率和振幅，可以是不规则，不对称的</strong>。正弦波不是小波。</p><p><strong>基的特性是</strong>：</p><ul><li><p>非冗余性</p></li><li><p>完备性：即使基不是正交的，有相关性，若去掉其中一个，不成为基，</p></li><li><p>唯一性：给定一族基对一个函数的表达是唯一的</p></li><li><p>非正交性：一般情况下是非正交的，称为exact frame（resize basis），此时要表示信号可以将基正交化成唯一的正交基（对偶为其自身）；也可以求其对偶框架（dual frame），其对应了小波变换的双正交情形，信号可以依框架进行分解，然后用对偶框架重构。</p></li></ul><p><strong>框架</strong>：</p><p>在基集中添加一些新的向量，并随意调整空间位置，可能成为框架。把函数与基或框架作内积（函数空间到系数空间的变换），若变换后的能量（内积的平方和度量）仍然有一个大于0的上下界，才可以成为框架。</p><p>框架具有冗余性，系数的表达不具有唯一性。</p><p>若上下界相等，则为紧框架，且界表示冗余度；</p><p>若上下界相等且为1，成为pasval identity frame，此时不一定为正交基（相当于把一组正交基中的某一个拆成两个同方向的基之和，pasval identity 仍然成立），此时若再加上基的长度均为1的条件，则框架退化为正交基。</p><p>很多信号表示方法不能构成基，但能构成框架，如短时傅里叶变换中如要求窗函数满足基条件，则可推出函数具有很差的时频局部化性质（退化为傅里叶变换）。</p><p>==2、内积==</p><p>在Hilbert空间中，用来刻画两个向量的夹角，当内积为0时，两个向量正交。</p><p>若$g$为Hilbert空间里的正交基，内积为$f$向基上的正交投影，有如下推导：<br>$$<br>f·g = f^Tg= = \int f(t) \bar{g(t)}dt = f_1g_1 +f_2g_2 = |f||g|cos \theta<br>$$<br>如果两个向量内积为0，即正交；如果一个向量序列相互对偶正交，并且长度为1，是正交归一化。</p><p>对于$f(t) \in L^2(R)$（平方可积），存在$L^2(R)$上的一组标准正交基$g_i(t),i=1,2,\dots,$，使得：<br>$$<br>f(t) = \sum\limits_{i=1}^{\infty}f_ig_i(t)<br>$$<br>$L^2(R)$上任意一个函数$f(t)$都可以由$L^2(R)$的一个规范正交基$g_i(t)$进行线性组合表示出来。</p><p>==3、傅里叶变换==</p><p><strong>Fourier分析不能刻画时间域上信号的局部特性</strong></p><p><strong>Fourier分析对突变和非平稳信号的效果不好，没有时频分析</strong></p><p>傅里叶变换将函数投影到三角波上，将函数分解为不同频率的三角波，对于平稳信号的表示，近似最优表示。但是日常信号不是一直光滑的，而且奇异是非凡的，傅里叶在奇异点的表现不是很好，用大量的不同频率的三角波去逼近其系数衰减程度相当缓慢，而且会产生<strong>Gibbs效应</strong>。（内在原因是其基为全局性基，没有局部化能力，以致于局部一个小小的摆动会影响全局的系数，实际应用中很需要时频局部化，傅里叶缺乏此能力）。</p><p>对于非平稳信号，只知道包含哪些频率成分不够，还需要知道各个成分出现的时间。知道信号频率随时间变化的情况，各个时刻的<strong>瞬时频率</strong>及其值——<strong>时频分析</strong>。</p><blockquote><p><strong>瞬时频率</strong>：绝对意义上的瞬时频率是不存在的，单看一个时刻点的一个信号值，得不到它的频率，可以用很短的一段信号的频率作为该时刻的频率，得到的是时间分辨率有限的近似分析结果（SIFT）。小波等时频分析方法，用如衰减的基函数去测定信号的瞬时频率，思想类似。</p></blockquote><p>==4、短时傅里叶变换(SIFT)==</p><p>SIFT针对于傅里叶变换的时域太长而改进，也称为加窗傅里叶变换，这样有了局部化能力。</p><p><strong>SIFT定义</strong>：把整个时域过程分解为无数个等长的小过程，每个小过程近似平稳，再傅里叶变换，这样可以知道在哪个时间点上出现了什么频率了。即在时域上分成一段一段做FFT。</p><p><strong>窗的大小的影响</strong>：窗太窄，窗内信号太短，会导致频率分析不够精准，频率分辨率差；窗太宽，时域上不够精细，时间分辨率低。</p><blockquote><p>用<strong>海森堡不确定性原理</strong>解释：类似不能同时获取一个粒子的动量和位置，依次，也不能同时获取信号绝对精准的时刻和频率，是一对不可兼得的矛盾体。不知道在某个瞬间哪个频率分量存在，只知道在一个时间段内某个频带的分量存在，所以绝对意义的瞬时频率是不存在的。</p><p>很多物理量有这样的特征，比如能量和时间、角动量和角度。信号领域就是时域和频域，更为准确的描述是：一个信号不能在时空域和频域上同时过于集中，一个函数时域越“窄”，经傅里叶变换后的频域就越“宽”。</p></blockquote><p>对于时变的非稳态信号，高频适合小窗口，低频适合大窗口，SIFT的窗是固定的，在一次的SIFT中宽度不会变化，所以<strong>SIFT无法满足非稳态信号变化的频率的需求</strong>。</p><p>==5、小波变换==</p><p>小波是基于加窗傅里叶变换的窗口大小改变的思想，但是，SIFT是给信号加窗，分段做FFT；小波变换并没有采用的窗的思想，也没有做傅里叶变换，小波直接将傅里叶变换的基更换——<strong>将无限长的三角函数基换成了有限长的会衰减的小波基，这样获得频率，也可以定位到时间</strong>。</p><blockquote><p><strong>基函数</strong>：会伸缩、会平移（是两个正交基的分解）。缩得窄，对应高频；伸得宽，对应低频。基函数不断和信号做相乘。某一个尺度（宽窄）下乘得结果，可以看成信号所包含得当前尺度对应频率成分有多少。</p><p>基函数会在某些尺度下，与信号相乘得到一个很大的值，这样就知道信号包含该频率的成分的多少。小波的改变将无限长的三角函数基换成了有限长的会衰减的小波基。</p></blockquote><p><strong>小波公式</strong>：<br>$$<br>WT(a,\tau)= \frac{1}{\sqrt{a}}\int_{-\infty}^{\infty}f(t)*\psi(\frac{t-\tau}{a})dt<br>$$</p><img src="/blog/2020/05/14/信号处理涉及到的几种变换/20160705113512598.png" title="小波变换"><p>变量只有频率$w$，小波变换只有两个变量：尺度$a$（scale）和平移量$\tau$（translation）。尺度$a$控制小波函数的伸缩，平移量$\tau$控制小波函数的平移。尺度对应于频率（反比），平移量$\tau$对应于时间。</p><img src="/blog/2020/05/14/信号处理涉及到的几种变换/20160705113633849.png" title="平移-伸缩"><p>当伸缩、平移到上面这一种重合情况时，也会相乘得到一个大的值，与傅里叶不同的是，这不仅知道信号有这样频率的成分，而且知道在时域上存在的具体的位置。【解决局部性问题】当在每个尺度下都平移着和信号都乘过一遍后，能够知道在每个位置都包含哪些频率成分，这样可以做时频分析。【解决时频分析问题】</p><p>具体的还有<strong>子空间、多分辨率、母小波的变换，如何构造想要的小波函数，离散小波变换、正交小波变换、二维小波变换、小波包的应用</strong>。</p><p>每一个小波有一个mother wavelet，同时还有一个father wavelet，即scaling function。而小波的basis函数是对这个母小波和父小波的缩放和平移形成的，缩放倍数都是2的级数，平移大小与当前缩放的程度有关。</p><p>不同的母小波，衍生的小波基完全不同，<strong>小波展开的近似形式</strong>为：<br>$$<br>f(t) = \sum\limits_k \sum\limits_{j}a_{j,k}\psi_{j,k}(t)<br>$$<br>即小波级数，这些级数组合形成了小波变换中的基basis。与傅里叶级数不同的是，小波级数通常是orthonormal basis（规范化正交基），即不仅两两正交，还归一化的。</p><p>小波变换的<strong>三个特点</strong>：小波级数是二维的，能定位时域和频域，计算很快。</p><p><strong>小波的完整形式</strong>：</p><p>小波basis的形成，是基于基本的小波函数，即母小波来做缩放和平移的，母小波并非唯一的原始基，在构建小波基函数的集合时，通常用到一个尺度函数scaling function 。即成为父小波，两者都是归一化的，并且满足一个性质，它和对自己本身周期平移函数两两正交：<br>$$<br>f(t) = \sum\limits_k \sum\limits_{j}a_{j,k}\psi_{j,k}(t)<br>$$</p><p>$$<br>&lt;\varphi(t),\varphi(t-kT)&gt; = 0 ,\forall k<br>$$</p><p>完整的小波展开由父小波和母小波共同定义的：<br>$$<br>f(t) = \sum\limits_{k=-\infty}^{\infty}c_k\varphi(t-k)+\sum\limits_{k=-\infty}^{\infty}\sum\limits_{j=0}^{\infty}d_{j,k}\psi(2^jt-k)<br>$$<br>其中$\psi(t)$是母小波，$\varphi(t)$是父小波。</p><p><strong>小波的一些优势：</strong></p><p>对于突变信号，傅里叶变换存在吉布斯效应，用无限长的三角函数拟合不好突变信号，使用衰减的小波，只有小波函数和信号突变处重叠时，系数不为0.</p><p>小波可以实现<strong>正交化</strong>，短时傅里叶变换不能。采用正交基，变换域的系数会没有冗余信息，等于是用最少的数据表达最大的信息量，有利于数值压缩等领域。但是比如在图像增强领域，有时候反而希望能有一些冗余信息，更有利于对噪声的抑制和对某些特征的增强。</p><p><strong>小波变换的缺点</strong>：</p><p>作为图像处理方法，【和多尺度几何分析方法（超小波）比较】：对于图像这种二维信号，二维小波只能沿着2个方向进行，对图像中点的信息表达还可以，但是对线的信息表达比较差。此时ridgelet(脊波)、curvelet(曲波)等多尺度几何分析方法更有优势。</p><p>作为时频分析方法，【和HHT比】：小波变换没能脱离海森堡测不准原理的束缚，某种尺度下，不能在时间和频率上同时具有很高的精度，此外小波是非适应性的，基函数选定后不再修改。</p><p>==5、S变换==</p><p>S-transform可以看成是小波变换和SIFT的继承和法阵，傅里叶变换只能作用于收敛信号，SIFT的窗函数不可变，小波变换虽然窗函数可变，能进行多分辨率分析，但是其基函数选取困难。ST介于两者之间，<strong>可以自适应调节分辨率且其逆变换无损可逆</strong>。</p><p>ST是由地球物理学家Stockwell在1996年提出的一种时频分析方法，定义为：<br>$$<br>S(\tau,f)= \int_{-\infty}^{\infty}h(t)\frac{|f|}{\sqrt{2\pi}}e^{-\frac{(\tau-t)^2f^2}{2}}e^{-i2\pi ft}dt<br>$$<br>其中：$\tau$为时间，控制窗口函数在时间轴上的位置；$h(t)$为分析信号；$f$为频率；$S(\tau,f)$为变换得到的时频谱矩阵。</p><p>ST可以写成傅里叶频谱$H(f)$的形式：<br>$$<br>S(\tau,f) = \int_{-\infty}^{\infty}H(\alpha+f)e^{-\frac{2\pi^2 \alpha^2}{f^2}}e^{i2\pi \alpha \tau}d\alpha,(f \ne 0)<br>$$</p><p>对于离散信号，有：<br>$$<br>H\left[\frac{n}{NT}\right] = \frac{1}{N}\sum\limits_{K=0}^{N-1}h[KT]e^{-\frac{i2\pi nk}{N}}<br>$$<br>其中：$K$为离散的时间点，$k=0,1,\dots,N-1;N$为离散时间信号长度；$T$为采样时间间隔。</p><p>对于离散信号，令$f = \frac{n}{NT}$,$\tau = jT$，最终的离散信号的S变换可以表示为：<br>$$<br>S\left(jT,\frac{n}{NT}\right)= \sum\limits_{m=0}^{N-1}H\left[\frac{m+n}{NT}\right]e^{-\frac{2\pi^2m^2}{n^2}}e^{\frac{i2\pi mj}{N}},(n\ne 0)<br>$$<br><strong>ST克服了SIFT窗口的时宽不变的缺陷，能根据频率的变化和自适应调整分析时宽和提供直观的时间频率特征，且无须选择窗口函数域分析尺度</strong>。</p><p><strong>广义S变换公式推导</strong>：</p><p>对于傅里叶变换，其正变换为：<br>$$<br>H(f) = \int_{-\infty}^{\infty}h(t)\exp(-i2\pi ft)dt<br>$$<br>其中：$h(t)$为待分析的时间信号序列；$f$为频率；$t$表示时间；$H(f)$时是信号$h(t)$的傅里叶变换。</p><p>加入对时间序列$h(t)$加上一个窗函数$g(t)$，则其谱变为：<br>$$<br>H(f) = \int_{-\infty}^{\infty}h(t)g(t)\exp(-i2\pi ft)dt<br>$$<br>对于ST，首先定义一个<strong>高斯窗函数</strong>：<br>$$<br>g(t) = \frac{1}{\sigma \sqrt{2\pi}}\exp\left(\frac{t^2}{2\sigma^2}\right)<br>$$<br>其中：$\sigma$为高斯函数的方差，对上述高斯窗函数进行伸缩与平移，得到$S$变换的公式为：<br>$$<br>S(\tau,f,\sigma) = \int_{-\infty}^{\infty} h(t) \frac{1}{\sigma \sqrt{2\pi}}\exp \left[-\frac{(t-\tau)^2}{2\sigma^2}\right]·\exp(-i2\pi ft)dt<br>$$<br>其中：$\tau$表示高斯窗函数在时间上的平移量。</p><p>实际上：S变换就是<strong>把小波基函数用高斯窗来代</strong>替，也被定义为“相位正交”的连续小波变换。</p><p>信号$x(t)$的ST定义如下：<br>$$<br>\cases{S(\tau,f) = \int_{-\infty}^{\infty}x(t)w(t-\tau,f)e^{-i2\pi ft}dt  \ w(t-\tau,f) = \frac{|f|}{\sqrt{2\pi}}e^{\frac{-f^2(t-\tau)^2}{2}}}<br>$$<br>其中：$w(t-\tau,f)$为高斯窗函数；$\tau$为时移因子，控制高斯窗在时间轴的位置；$f$为频率。</p><p>由上式可知：</p><p>高斯窗口克服了短时傅里叶变换窗口高度和宽度固定的缺陷，其随频率而变化。因此，ST既可以获得某一时刻的频率信息，也可获得在某一频率上信号的幅值信息。</p><p><strong>S变换的应用</strong>：</p><p>将ST应用在PQD检测和分类的研究成果最多。PQD（Power Quality Disturbances）<strong>电能质量扰动</strong>会导致设备过热、电机停转、保护失灵以及计量不准等严重后果。</p><p><strong>基于S变换的PQD检测：</strong>PQD 检测包括扰动起止时刻的定位、 扰动持续时间和扰动幅值的测量等方面的内容。文献首次提出采用 S 变换模矩阵的等值线检测扰动的发生，并发现时频曲线的标准差与扰动幅值存在一一对应关系，可以用来测量扰动幅值，但该文对 S 变换应用于 PQD 检测仅是探索性的，并未形成一套完整可行的方法。</p><p>目前 S 变换应用于 PQD 检测主要集中于扰动频率与幅值、扰动起止时刻与持续时间这些常规参数的检测，而且只是考虑了稳态或存在稳定段的扰动幅值检测，对不存在稳定段的暂态扰动如振荡暂态、脉冲暂态等幅值的检测并没有提出有效的方法，同时对于 S 变换应用于振荡暂态衰减因子、电压切口深度及宽度等参数的检测尚未见文献报道。</p><p><strong>基于S变换的PQD分类</strong>：PQD的识别实际是一个模式分类问题，关键思想是针对PQD特征选定一个较优的分类器进行模式识别。目前基于S变换的PQD识别方法一般是从待分析的PQD信号的S变换模矩阵中提取特征，然后借助人工智能分类器实现分类。</p><ol><li>基于S变换和ANN的PQD分类。</li><li>基于S变换和SVM的PQD分类。</li><li>基于S变换和规则判别的PQD分类。</li></ol><p>S变换在PQD应用方面有待进一步研究的方面有：</p><ul><li>S变换的结果是二维复矩阵，能够提供丰富的时频信息，其相位和原始信号保持直接的联系，目前对相位信息的利用很少，对于PQD的某些应用如扰动源的定位利用相位信息比幅值信息应该更有效。</li><li>由于 S 变换的运算量很大，在实际应用时对计算环境会有很高的要求，因此，对 S 变换算法或计算过程进行改进，在保证 PQD 分析精度的基础上提高其运算实时性，是其现实广泛应用的前提。</li><li>对 PQD 最精确和全面的检测应该是将描述其数学模型的所有参量进行准确的估计，而目前S 变换应用于 PQD 检测主要集中于稳态扰动的参数检测，对暂态扰动如振荡暂态的最大幅值和衰减因子等参量的检测并没有提出有效的方法。</li><li>S 变换作为 PQD 信号的特征提取工具，如何针对具体应用情况从 S 变换提取最有效的特征量尚缺乏全面和系统的研究。</li><li>除检测和分类之外， S 变换在 PQD 其他方面的应用如信号去噪、扰动源定位尚不多见，同时，开发新形式的 S 变换为PQD 分析提供更适宜的时频分辨率，研究确定最优时频分辨率的理论依据也值得进一步研究。</li><li>S 变换在 PQD 分析的应用尚处于算法仿真阶段，其在具体硬件环境中的实现及实际应用效果的评价鲜见报道。</li></ul><p><strong>参考文献：</strong></p><blockquote><p>易吉良； 彭建春； 谭会生．S变换在电能质量扰动分析中的应用综述：电力系统保护与控制，2011</p></blockquote>]]></content>
    
    <summary type="html">
    
      小波变换&amp;傅里叶变换&amp;S变换等
    
    </summary>
    
      <category term="笔记" scheme="https://jiangxj.top/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
</feed>
